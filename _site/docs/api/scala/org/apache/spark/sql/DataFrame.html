<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html>
        <head>
          <title>DataFrame - org.apache.spark.sql.DataFrame</title>
          <meta name="description" content="DataFrame - org.apache.spark.sql.DataFrame" />
          <meta name="keywords" content="DataFrame org.apache.spark.sql.DataFrame" />
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      <link href="../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css" />
      <script type="text/javascript">
         if(top === self) {
            var url = '../../../../index.html';
            var hash = 'org.apache.spark.sql.DataFrame';
            var anchor = window.location.hash;
            var anchor_opt = '';
            if (anchor.length >= 1)
              anchor_opt = '@' + anchor.substring(1);
            window.location.href = url + '#' + hash + anchor_opt;
         }
   	  </script>
    
        </head>
        <body class="type">
      <div id="definition">
        <img src="../../../../lib/class_big.png" />
        <p id="owner"><a href="../../../package.html" class="extype" name="org">org</a>.<a href="../../package.html" class="extype" name="org.apache">apache</a>.<a href="../package.html" class="extype" name="org.apache.spark">spark</a>.<a href="package.html" class="extype" name="org.apache.spark.sql">sql</a></p>
        <h1>DataFrame</h1>
      </div>

      <h4 id="signature" class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <span class="name">DataFrame</span><span class="result"> extends <span class="extype" name="org.apache.spark.sql.RDDApi">RDDApi</span>[<span class="extype" name="org.apache.spark.sql.Row">Row</span>] with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      </h4>
      
          <div id="comment" class="fullcommenttop"><div class="comment cmt"><p>:: Experimental ::
A distributed collection of data organized into named columns.</p><p>A <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> is equivalent to a relational table in Spark SQL. There are multiple ways
to create a <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>:</p><pre><span class="cmt">// Create a DataFrame from Parquet files</span>
<span class="kw">val</span> people = sqlContext.parquetFile(<span class="lit">"..."</span>)

<span class="cmt">// Create a DataFrame from data sources</span>
<span class="kw">val</span> df = sqlContext.load(<span class="lit">"..."</span>, <span class="lit">"json"</span>)</pre><p>Once created, it can be manipulated using the various domain-specific-language (DSL) functions
defined in: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> (this class), <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>, and <a href="functions$.html" class="extype" name="org.apache.spark.sql.functions">functions</a>.</p><p>To select a column from the data frame, use <code>apply</code> method in Scala and <code>col</code> in Java.</p><pre><span class="kw">val</span> ageCol = people(<span class="lit">"age"</span>)  <span class="cmt">// in Scala</span>
Column ageCol = people.col(<span class="lit">"age"</span>)  <span class="cmt">// in Java</span></pre><p>Note that the <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a> type can also be manipulated through its various functions.</p><pre><span class="cmt">// The following creates a new column that increases everybody's age by 10.</span>
people(<span class="lit">"age"</span>) + <span class="num">10</span>  <span class="cmt">// in Scala</span>
people.col(<span class="lit">"age"</span>).plus(<span class="num">10</span>);  <span class="cmt">// in Java</span></pre><p>A more concrete example in Scala:</p><pre><span class="cmt">// To create DataFrame using SQLContext</span>
<span class="kw">val</span> people = sqlContext.parquetFile(<span class="lit">"..."</span>)
<span class="kw">val</span> department = sqlContext.parquetFile(<span class="lit">"..."</span>)

people.filter(<span class="lit">"age > 30"</span>)
  .join(department, people(<span class="lit">"deptId"</span>) === department(<span class="lit">"id"</span>))
  .groupBy(department(<span class="lit">"name"</span>), <span class="lit">"gender"</span>)
  .agg(avg(people(<span class="lit">"salary"</span>)), max(people(<span class="lit">"age"</span>)))</pre><p>and in Java:</p><pre><span class="cmt">// To create DataFrame using SQLContext</span>
DataFrame people = sqlContext.parquetFile(<span class="lit">"..."</span>);
DataFrame department = sqlContext.parquetFile(<span class="lit">"..."</span>);

people.filter(<span class="lit">"age"</span>.gt(<span class="num">30</span>))
  .join(department, people.col(<span class="lit">"deptId"</span>).equalTo(department(<span class="lit">"id"</span>)))
  .groupBy(department.col(<span class="lit">"name"</span>), <span class="lit">"gender"</span>)
  .agg(avg(people.col(<span class="lit">"salary"</span>)), max(people.col(<span class="lit">"age"</span>)));</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl><div class="toggleContainer block">
          <span class="toggle">Linear Supertypes</span>
          <div class="superTypes hiddenContent"><span class="extype" name="scala.Serializable">Serializable</span>, <span class="extype" name="java.io.Serializable">Serializable</span>, <span class="extype" name="org.apache.spark.sql.RDDApi">RDDApi</span>[<span class="extype" name="org.apache.spark.sql.Row">Row</span>], <span class="extype" name="scala.AnyRef">AnyRef</span>, <span class="extype" name="scala.Any">Any</span></div>
        </div></div>
        

      <div id="mbrsel">
        <div id="textfilter"><span class="pre"></span><span class="input"><input id="mbrsel-input" type="text" accesskey="/" /></span><span class="post"></span></div>
        <div id="order">
              <span class="filtertype">Ordering</span>
              <ol>
                <li class="group out"><span>Grouped</span></li>
                <li class="alpha in"><span>Alphabetic</span></li>
                <li class="inherit out"><span>By inheritance</span></li>
              </ol>
            </div>
        <div id="ancestors">
                <span class="filtertype">Inherited<br />
                </span>
                <ol id="linearization">
                  <li class="in" name="org.apache.spark.sql.DataFrame"><span>DataFrame</span></li><li class="in" name="scala.Serializable"><span>Serializable</span></li><li class="in" name="java.io.Serializable"><span>Serializable</span></li><li class="in" name="org.apache.spark.sql.RDDApi"><span>RDDApi</span></li><li class="in" name="scala.AnyRef"><span>AnyRef</span></li><li class="in" name="scala.Any"><span>Any</span></li>
                </ol>
              </div><div id="ancestors">
            <span class="filtertype"></span>
            <ol>
              <li class="hideall out"><span>Hide All</span></li>
              <li class="showall in"><span>Show all</span></li>
            </ol>
            <a href="http://docs.scala-lang.org/overviews/scaladoc/usage.html#members" target="_blank">Learn more about member selection</a>
          </div>
        <div id="visbl">
            <span class="filtertype">Visibility</span>
            <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
          </div>
      </div>

      <div id="template">
        <div id="allMembers">
        <div id="constructors" class="members">
              <h3>Instance Constructors</h3>
              <ol><li name="org.apache.spark.sql.DataFrame#&lt;init&gt;" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="&lt;init&gt;(sqlContext:org.apache.spark.sql.SQLContext,logicalPlan:org.apache.spark.sql.catalyst.plans.logical.LogicalPlan):org.apache.spark.sql.DataFrame"></a>
      <a id="&lt;init&gt;:DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">DataFrame</span><span class="params">(<span name="sqlContext">sqlContext: <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></span>, <span name="logicalPlan">logicalPlan: <span class="extype" name="org.apache.spark.sql.catalyst.plans.logical.LogicalPlan">LogicalPlan</span></span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">A constructor that automatically analyzes the logical plan.</p><div class="fullcomment"><div class="comment cmt"><p>A constructor that automatically analyzes the logical plan.</p><p>This reports error eagerly as the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> is constructed, unless
<span class="extype" name="SQLConf.dataFrameEagerAnalysis">SQLConf.dataFrameEagerAnalysis</span> is turned off.
</p></div></div>
    </li></ol>
            </div>

        

        

        <div id="values" class="values members">
              <h3>Value Members</h3>
              <ol><li name="scala.AnyRef#!=" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="!=(x$1:AnyRef):Boolean"></a>
      <a id="!=(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $bang$eq" class="name">!=</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.Any#!=" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="!=(x$1:Any):Boolean"></a>
      <a id="!=(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $bang$eq" class="name">!=</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="scala.AnyRef###" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="##():Int"></a>
      <a id="##():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $hash$hash" class="name">##</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef#==" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="==(x$1:AnyRef):Boolean"></a>
      <a id="==(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $eq$eq" class="name">==</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.Any#==" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="==(x$1:Any):Boolean"></a>
      <a id="==(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $eq$eq" class="name">==</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#agg" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="agg(expr:org.apache.spark.sql.Column,exprs:org.apache.spark.sql.Column*):org.apache.spark.sql.DataFrame"></a>
      <a id="agg(Column,Column*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">agg</span><span class="params">(<span name="expr">expr: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>, <span name="exprs">exprs: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Aggregates on the entire <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> without groups.</p><div class="fullcomment"><div class="comment cmt"><p>Aggregates on the entire <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> without groups.
{{
  // df.agg(...) is a shorthand for df.groupBy().agg(...)
  df.agg(max($&quot;age&quot;), avg($&quot;salary&quot;))
  df.groupBy().agg(max($&quot;age&quot;), avg($&quot;salary&quot;))
}}</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#agg" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="agg(exprs:java.util.Map[String,String]):org.apache.spark.sql.DataFrame"></a>
      <a id="agg(Map[String,String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">agg</span><span class="params">(<span name="exprs">exprs: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Java-specific) Aggregates on the entire <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> without groups.</p><div class="fullcomment"><div class="comment cmt"><p>(Java-specific) Aggregates on the entire <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> without groups.
{{
  // df.agg(...) is a shorthand for df.groupBy().agg(...)
  df.agg(Map(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;))
  df.groupBy().agg(Map(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;))
}}</p></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#agg" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="agg(exprs:Map[String,String]):org.apache.spark.sql.DataFrame"></a>
      <a id="agg(Map[String,String]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">agg</span><span class="params">(<span name="exprs">exprs: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Scala-specific) Aggregates on the entire <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> without groups.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Aggregates on the entire <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> without groups.
{{
  // df.agg(...) is a shorthand for df.groupBy().agg(...)
  df.agg(Map(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;))
  df.groupBy().agg(Map(&quot;age&quot; -&gt; &quot;max&quot;, &quot;salary&quot; -&gt; &quot;avg&quot;))
}}</p></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#agg" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="agg(aggExpr:(String,String),aggExprs:(String,String)*):org.apache.spark.sql.DataFrame"></a>
      <a id="agg((String,String),(String,String)*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">agg</span><span class="params">(<span name="aggExpr">aggExpr: (<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>)</span>, <span name="aggExprs">aggExprs: (<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>)*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Scala-specific) Compute aggregates by specifying a map from column name to
aggregate methods.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Compute aggregates by specifying a map from column name to
aggregate methods. The resulting <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> will also contain the grouping columns.</p><p>The available aggregate methods are <code>avg</code>, <code>max</code>, <code>min</code>, <code>sum</code>, <code>count</code>.</p><pre><span class="cmt">// Selects the age of the oldest employee and the aggregate expense for each department</span>
df.groupBy(<span class="lit">"department"</span>).agg(
  <span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>,
  <span class="lit">"expense"</span> -&gt; <span class="lit">"sum"</span>
)</pre></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#apply" visbl="pub" data-isabs="false" fullComment="no" group="dfops">
      <a id="apply(colName:String):org.apache.spark.sql.Column"></a>
      <a id="apply(String):Column"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">apply</span><span class="params">(<span name="colName">colName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Selects column based on the column name and return it as a <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>.</p>
    </li><li name="org.apache.spark.sql.DataFrame#as" visbl="pub" data-isabs="false" fullComment="no" group="dfops">
      <a id="as(alias:Symbol):org.apache.spark.sql.DataFrame"></a>
      <a id="as(Symbol):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">as</span><span class="params">(<span name="alias">alias: <span class="extype" name="scala.Symbol">Symbol</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Scala-specific) Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with an alias set.</p>
    </li><li name="org.apache.spark.sql.DataFrame#as" visbl="pub" data-isabs="false" fullComment="no" group="dfops">
      <a id="as(alias:String):org.apache.spark.sql.DataFrame"></a>
      <a id="as(String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">as</span><span class="params">(<span name="alias">alias: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with an alias set.</p>
    </li><li name="scala.Any#asInstanceOf" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="asInstanceOf[T0]:T0"></a>
      <a id="asInstanceOf[T0]:T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span class="extype" name="scala.Any.asInstanceOf.T0">T0</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#cache" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="cache():DataFrame.this.type"></a>
      <a id="cache():DataFrame.this.type"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cache</span><span class="params">()</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.this.type</span>
      </span>
      </h4>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="scala.AnyRef#clone" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="clone():Object"></a>
      <a id="clone():AnyRef"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">clone</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.AnyRef">AnyRef</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../../../../java$lang.html" class="extype" name="java.lang">java.lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.CloneNotSupportedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#col" visbl="pub" data-isabs="false" fullComment="no" group="dfops">
      <a id="col(colName:String):org.apache.spark.sql.Column"></a>
      <a id="col(String):Column"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">col</span><span class="params">(<span name="colName">colName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Selects column based on the column name and return it as a <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>.</p>
    </li><li name="org.apache.spark.sql.DataFrame#collect" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="collect():Array[org.apache.spark.sql.Row]"></a>
      <a id="collect():Array[Row]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">collect</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[<span class="extype" name="org.apache.spark.sql.Row">Row</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns an array that contains all of <span class="extype" name="Row">Row</span>s in this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns an array that contains all of <span class="extype" name="Row">Row</span>s in this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#collectAsList" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="collectAsList():java.util.List[org.apache.spark.sql.Row]"></a>
      <a id="collectAsList():List[Row]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">collectAsList</span><span class="params">()</span><span class="result">: <span class="extype" name="java.util.List">List</span>[<span class="extype" name="org.apache.spark.sql.Row">Row</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a Java list that contains all of <span class="extype" name="Row">Row</span>s in this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a Java list that contains all of <span class="extype" name="Row">Row</span>s in this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#columns" visbl="pub" data-isabs="false" fullComment="no" group="basic">
      <a id="columns:Array[String]"></a>
      <a id="columns:Array[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">columns</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns all column names as an array.</p>
    </li><li name="org.apache.spark.sql.DataFrame#count" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="count():Long"></a>
      <a id="count():Long"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">count</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Long">Long</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the number of rows in the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the number of rows in the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#createJDBCTable" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="createJDBCTable(url:String,table:String,allowExisting:Boolean):Unit"></a>
      <a id="createJDBCTable(String,String,Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">createJDBCTable</span><span class="params">(<span name="url">url: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="table">table: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="allowExisting">allowExisting: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save this RDD to a JDBC database at <code>url</code> under the table name <code>table</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Save this RDD to a JDBC database at <code>url</code> under the table name <code>table</code>.
This will run a <code>CREATE TABLE</code> and a bunch of <code>INSERT INTO</code> statements.
If you pass <code>true</code> for <code>allowExisting</code>, it will drop any table with the
given name; if you pass <code>false</code>, it will throw if the table already
exists.</p></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#describe" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="describe(cols:String*):org.apache.spark.sql.DataFrame"></a>
      <a id="describe(String*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">describe</span><span class="params">(<span name="cols">cols: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Computes statistics for numeric columns, including count, mean, stddev, min, and max.</p><div class="fullcomment"><div class="comment cmt"><p>Computes statistics for numeric columns, including count, mean, stddev, min, and max.
If no columns are given, this function computes statistics for all numerical columns.</p><p>This function is meant for exploratory data analysis, as we make no guarantee about the
backward compatibility of the schema of the resulting <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>. If you want to
programmatically compute summary statistics, use the <code>agg</code> function instead.</p><pre>df.describe(<span class="lit">"age"</span>, <span class="lit">"height"</span>).show()

<span class="cmt">// output:</span>
<span class="cmt">// summary age   height</span>
<span class="cmt">// count   10.0  10.0</span>
<span class="cmt">// mean    53.3  178.05</span>
<span class="cmt">// stddev  11.6  15.7</span>
<span class="cmt">// min     18.0  163.0</span>
<span class="cmt">// max     92.0  192.0</span></pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#distinct" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="distinct:org.apache.spark.sql.DataFrame"></a>
      <a id="distinct:DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">distinct</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> that contains only the unique rows from this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> that contains only the unique rows from this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#dtypes" visbl="pub" data-isabs="false" fullComment="no" group="basic">
      <a id="dtypes:Array[(String,String)]"></a>
      <a id="dtypes:Array[(String,String)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">dtypes</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[(<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns all column names and their data types as an array.</p>
    </li><li name="scala.AnyRef#eq" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="eq(x$1:AnyRef):Boolean"></a>
      <a id="eq(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">eq</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#equals" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="equals(x$1:Any):Boolean"></a>
      <a id="equals(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#except" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="except(other:org.apache.spark.sql.DataFrame):org.apache.spark.sql.DataFrame"></a>
      <a id="except(DataFrame):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">except</span><span class="params">(<span name="other">other: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> containing rows in this frame but not in another frame.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> containing rows in this frame but not in another frame.
This is equivalent to <code>EXCEPT</code> in SQL.</p></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#explain" visbl="pub" data-isabs="false" fullComment="no" group="basic">
      <a id="explain():Unit"></a>
      <a id="explain():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">explain</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Only prints the physical plan to the console for debugging purpose.</p>
    </li><li name="org.apache.spark.sql.DataFrame#explain" visbl="pub" data-isabs="false" fullComment="no" group="basic">
      <a id="explain(extended:Boolean):Unit"></a>
      <a id="explain(Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">explain</span><span class="params">(<span name="extended">extended: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Prints the plans (logical and physical) to the console for debugging purpose.</p>
    </li><li name="org.apache.spark.sql.DataFrame#explode" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="explode[A,B](inputColumn:String,outputColumn:String)(f:A=&gt;TraversableOnce[B])(implicitevidence$2:reflect.runtime.universe.TypeTag[B]):org.apache.spark.sql.DataFrame"></a>
      <a id="explode[A,B](String,String)((A)⇒TraversableOnce[B])(scala.reflect.api.JavaUniverse.TypeTag[B]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">explode</span><span class="tparams">[<span name="A">A</span>, <span name="B">B</span>]</span><span class="params">(<span name="inputColumn">inputColumn: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="outputColumn">outputColumn: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="params">(<span name="f">f: (<span class="extype" name="org.apache.spark.sql.DataFrame.explode.A">A</span>) ⇒ <span class="extype" name="scala.TraversableOnce">TraversableOnce</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.explode.B">B</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.api.TypeTags.TypeTag">scala.reflect.api.JavaUniverse.TypeTag</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.explode.B">B</span>]</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Scala-specific) Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> where a single column has been expanded to zero
or more rows by the provided function.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> where a single column has been expanded to zero
or more rows by the provided function.  This is similar to a <code>LATERAL VIEW</code> in HiveQL. All
columns of the input row are implicitly joined with each value that is output by the function.</p><pre>df.explode(<span class="lit">"words"</span>, <span class="lit">"word"</span>)(words: <span class="std">String</span> <span class="kw">=&gt;</span> words.split(<span class="lit">" "</span>))</pre></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#explode" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="explode[A&lt;:Product](input:org.apache.spark.sql.Column*)(f:org.apache.spark.sql.Row=&gt;TraversableOnce[A])(implicitevidence$1:reflect.runtime.universe.TypeTag[A]):org.apache.spark.sql.DataFrame"></a>
      <a id="explode[A&lt;:Product](Column*)((Row)⇒TraversableOnce[A])(scala.reflect.api.JavaUniverse.TypeTag[A]):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">explode</span><span class="tparams">[<span name="A">A &lt;: <span class="extype" name="scala.Product">Product</span></span>]</span><span class="params">(<span name="input">input: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>*</span>)</span><span class="params">(<span name="f">f: (<span class="extype" name="org.apache.spark.sql.Row">Row</span>) ⇒ <span class="extype" name="scala.TraversableOnce">TraversableOnce</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.explode.A">A</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.api.TypeTags.TypeTag">scala.reflect.api.JavaUniverse.TypeTag</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.explode.A">A</span>]</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">(Scala-specific) Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> where each row has been expanded to zero or more
rows by the provided function.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> where each row has been expanded to zero or more
rows by the provided function.  This is similar to a <code>LATERAL VIEW</code> in HiveQL. The columns of
the input row are implicitly joined with each row that is output by the function.</p><p>The following example uses this function to count the number of books which contain
a given word:</p><pre><span class="kw">case</span> <span class="kw">class</span> Book(title: <span class="std">String</span>, words: <span class="std">String</span>)
<span class="kw">val</span> df: RDD[Book]

<span class="kw">case</span> <span class="kw">class</span> Word(word: <span class="std">String</span>)
<span class="kw">val</span> allWords = df.explode('words) {
  <span class="kw">case</span> Row(words: <span class="std">String</span>) <span class="kw">=&gt;</span> words.split(<span class="lit">" "</span>).map(Word(_))
}

<span class="kw">val</span> bookCountPerWord = allWords.groupBy(<span class="lit">"word"</span>).agg(countDistinct(<span class="lit">"title"</span>))</pre></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#filter" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="filter(conditionExpr:String):org.apache.spark.sql.DataFrame"></a>
      <a id="filter(String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">filter</span><span class="params">(<span name="conditionExpr">conditionExpr: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Filters rows using the given SQL expression.</p><div class="fullcomment"><div class="comment cmt"><p>Filters rows using the given SQL expression.</p><pre>peopleDf.filter(<span class="lit">"age > 15"</span>)</pre></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#filter" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="filter(condition:org.apache.spark.sql.Column):org.apache.spark.sql.DataFrame"></a>
      <a id="filter(Column):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">filter</span><span class="params">(<span name="condition">condition: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Filters rows using the given condition.</p><div class="fullcomment"><div class="comment cmt"><p>Filters rows using the given condition.</p><pre><span class="cmt">// The following are equivalent:</span>
peopleDf.filter($<span class="lit">"age"</span> &gt; <span class="num">15</span>)
peopleDf.where($<span class="lit">"age"</span> &gt; <span class="num">15</span>)
peopleDf($<span class="lit">"age"</span> &gt; <span class="num">15</span>)</pre></div></div>
    </li><li name="scala.AnyRef#finalize" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="finalize():Unit"></a>
      <a id="finalize():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">finalize</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../../../../java$lang.html" class="extype" name="java.lang">java.lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="symbol">classOf[java.lang.Throwable]</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#first" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="first():org.apache.spark.sql.Row"></a>
      <a id="first():Row"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">first</span><span class="params">()</span><span class="result">: <span class="extype" name="org.apache.spark.sql.Row">Row</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the first row.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the first row. Alias for head().</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#flatMap" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="flatMap[R](f:org.apache.spark.sql.Row=&gt;TraversableOnce[R])(implicitevidence$4:scala.reflect.ClassTag[R]):org.apache.spark.rdd.RDD[R]"></a>
      <a id="flatMap[R]((Row)⇒TraversableOnce[R])(ClassTag[R]):RDD[R]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">flatMap</span><span class="tparams">[<span name="R">R</span>]</span><span class="params">(<span name="f">f: (<span class="extype" name="org.apache.spark.sql.Row">Row</span>) ⇒ <span class="extype" name="scala.TraversableOnce">TraversableOnce</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.flatMap.R">R</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.flatMap.R">R</span>]</span>)</span><span class="result">: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="org.apache.spark.sql.DataFrame.flatMap.R">R</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new RDD by first applying a function to all rows of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>,
and then flattening the results.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new RDD by first applying a function to all rows of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>,
and then flattening the results.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#foreach" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="foreach(f:org.apache.spark.sql.Row=&gt;Unit):Unit"></a>
      <a id="foreach((Row)⇒Unit):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">foreach</span><span class="params">(<span name="f">f: (<span class="extype" name="org.apache.spark.sql.Row">Row</span>) ⇒ <span class="extype" name="scala.Unit">Unit</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Applies a function <code>f</code> to all rows.</p><div class="fullcomment"><div class="comment cmt"><p>Applies a function <code>f</code> to all rows.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#foreachPartition" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="foreachPartition(f:Iterator[org.apache.spark.sql.Row]=&gt;Unit):Unit"></a>
      <a id="foreachPartition((Iterator[Row])⇒Unit):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">foreachPartition</span><span class="params">(<span name="f">f: (<span class="extype" name="scala.Iterator">Iterator</span>[<span class="extype" name="org.apache.spark.sql.Row">Row</span>]) ⇒ <span class="extype" name="scala.Unit">Unit</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Applies a function f to each partition of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Applies a function f to each partition of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="scala.AnyRef#getClass" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getClass():Class[_]"></a>
      <a id="getClass():Class[_]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getClass</span><span class="params">()</span><span class="result">: <span class="extype" name="java.lang.Class">Class</span>[_]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#groupBy" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="groupBy(col1:String,cols:String*):org.apache.spark.sql.GroupedData"></a>
      <a id="groupBy(String,String*):GroupedData"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupBy</span><span class="params">(<span name="col1">col1: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="cols">cols: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Groups the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns, so we can run aggregation on them.</p><div class="fullcomment"><div class="comment cmt"><p>Groups the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns, so we can run aggregation on them.
See <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a> for all the available aggregate functions.</p><p>This is a variant of groupBy that can only group by existing columns using column names
(i.e. cannot construct expressions).</p><pre><span class="cmt">// Compute the average for all numeric columns grouped by department.</span>
df.groupBy(<span class="lit">"department"</span>).avg()

<span class="cmt">// Compute the max age and average salary, grouped by department and gender.</span>
df.groupBy($<span class="lit">"department"</span>, $<span class="lit">"gender"</span>).agg(<span class="std">Map</span>(
  <span class="lit">"salary"</span> -&gt; <span class="lit">"avg"</span>,
  <span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>
))</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#groupBy" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="groupBy(cols:org.apache.spark.sql.Column*):org.apache.spark.sql.GroupedData"></a>
      <a id="groupBy(Column*):GroupedData"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupBy</span><span class="params">(<span name="cols">cols: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>*</span>)</span><span class="result">: <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Groups the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns, so we can run aggregation on them.</p><div class="fullcomment"><div class="comment cmt"><p>Groups the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> using the specified columns, so we can run aggregation on them.
See <a href="GroupedData.html" class="extype" name="org.apache.spark.sql.GroupedData">GroupedData</a> for all the available aggregate functions.</p><pre><span class="cmt">// Compute the average for all numeric columns grouped by department.</span>
df.groupBy($<span class="lit">"department"</span>).avg()

<span class="cmt">// Compute the max age and average salary, grouped by department and gender.</span>
df.groupBy($<span class="lit">"department"</span>, $<span class="lit">"gender"</span>).agg(<span class="std">Map</span>(
  <span class="lit">"salary"</span> -&gt; <span class="lit">"avg"</span>,
  <span class="lit">"age"</span> -&gt; <span class="lit">"max"</span>
))</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#hashCode" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="hashCode():Int"></a>
      <a id="hashCode():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">hashCode</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#head" visbl="pub" data-isabs="false" fullComment="no" group="action">
      <a id="head():org.apache.spark.sql.Row"></a>
      <a id="head():Row"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">head</span><span class="params">()</span><span class="result">: <span class="extype" name="org.apache.spark.sql.Row">Row</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the first row.</p>
    </li><li name="org.apache.spark.sql.DataFrame#head" visbl="pub" data-isabs="false" fullComment="no" group="action">
      <a id="head(n:Int):Array[org.apache.spark.sql.Row]"></a>
      <a id="head(Int):Array[Row]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">head</span><span class="params">(<span name="n">n: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[<span class="extype" name="org.apache.spark.sql.Row">Row</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the first <code>n</code> rows.</p>
    </li><li name="org.apache.spark.sql.DataFrame#insertInto" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="insertInto(tableName:String):Unit"></a>
      <a id="insertInto(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">insertInto</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
Adds the rows from this RDD to the specified table.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Adds the rows from this RDD to the specified table.
Throws an exception if the table already exists.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#insertInto" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="insertInto(tableName:String,overwrite:Boolean):Unit"></a>
      <a id="insertInto(String,Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">insertInto</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="overwrite">overwrite: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
Adds the rows from this RDD to the specified table, optionally overwriting the existing data.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Adds the rows from this RDD to the specified table, optionally overwriting the existing data.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#insertIntoJDBC" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="insertIntoJDBC(url:String,table:String,overwrite:Boolean):Unit"></a>
      <a id="insertIntoJDBC(String,String,Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">insertIntoJDBC</span><span class="params">(<span name="url">url: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="table">table: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="overwrite">overwrite: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save this RDD to a JDBC database at <code>url</code> under the table name <code>table</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Save this RDD to a JDBC database at <code>url</code> under the table name <code>table</code>.
Assumes the table already exists and has a compatible schema.  If you
pass <code>true</code> for <code>overwrite</code>, it will <code>TRUNCATE</code> the table before
performing the <code>INSERT</code>s.</p><p>The table must already exist on the database.  It must have a schema
that is compatible with the schema of this RDD; inserting the rows of
the RDD in order via the simple statement
<code>INSERT INTO table VALUES (?, ?, ..., ?)</code> should not fail.</p></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#intersect" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="intersect(other:org.apache.spark.sql.DataFrame):org.apache.spark.sql.DataFrame"></a>
      <a id="intersect(DataFrame):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">intersect</span><span class="params">(<span name="other">other: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> containing rows only in both this frame and another frame.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> containing rows only in both this frame and another frame.
This is equivalent to <code>INTERSECT</code> in SQL.</p></div></div>
    </li><li name="scala.Any#isInstanceOf" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="isInstanceOf[T0]:Boolean"></a>
      <a id="isInstanceOf[T0]:Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#isLocal" visbl="pub" data-isabs="false" fullComment="no" group="basic">
      <a id="isLocal:Boolean"></a>
      <a id="isLocal:Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isLocal</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns true if the <code>collect</code> and <code>take</code> methods can be run locally
(without any Spark executors).</p>
    </li><li name="org.apache.spark.sql.DataFrame#javaRDD" visbl="pub" data-isabs="false" fullComment="no" group="rdd">
      <a id="javaRDD:org.apache.spark.api.java.JavaRDD[org.apache.spark.sql.Row]"></a>
      <a id="javaRDD:JavaRDD[Row]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">javaRDD</span><span class="result">: <a href="../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<span class="extype" name="org.apache.spark.sql.Row">Row</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the content of the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a <span class="extype" name="JavaRDD">JavaRDD</span> of <span class="extype" name="Row">Row</span>s.</p>
    </li><li name="org.apache.spark.sql.DataFrame#javaToPython" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="javaToPython:org.apache.spark.api.java.JavaRDD[Array[Byte]]"></a>
      <a id="javaToPython:JavaRDD[Array[Byte]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">javaToPython</span><span class="result">: <a href="../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<span class="extype" name="scala.Array">Array</span>[<span class="extype" name="scala.Byte">Byte</span>]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Converts a JavaRDD to a PythonRDD.</p><div class="fullcomment"><div class="comment cmt"><p>Converts a JavaRDD to a PythonRDD.
</p></div><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="package.html" class="extype" name="org.apache.spark.sql">org.apache.spark.sql</a>] </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#join" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="join(right:org.apache.spark.sql.DataFrame,joinExprs:org.apache.spark.sql.Column,joinType:String):org.apache.spark.sql.DataFrame"></a>
      <a id="join(DataFrame,Column,String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="params">(<span name="right">right: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>, <span name="joinExprs">joinExprs: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>, <span name="joinType">joinType: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>, using the given join expression.</p><div class="fullcomment"><div class="comment cmt"><p>Join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>, using the given join expression. The following performs
a full outer join between <code>df1</code> and <code>df2</code>.</p><pre><span class="cmt">// Scala:</span>
<span class="kw">import</span> org.apache.spark.sql.functions._
df1.join(df2, $<span class="lit">"df1Key"</span> === $<span class="lit">"df2Key"</span>, <span class="lit">"outer"</span>)

<span class="cmt">// Java:</span>
<span class="kw">import</span> static org.apache.spark.sql.functions.*;
df1.join(df2, col(<span class="lit">"df1Key"</span>).equalTo(col(<span class="lit">"df2Key"</span>)), <span class="lit">"outer"</span>);</pre></div><dl class="paramcmts block"><dt class="param">right</dt><dd class="cmt"><p>Right side of the join.</p></dd><dt class="param">joinExprs</dt><dd class="cmt"><p>Join expression.</p></dd><dt class="param">joinType</dt><dd class="cmt"><p>One of: <code>inner</code>, <code>outer</code>, <code>left_outer</code>, <code>right_outer</code>, <code>semijoin</code>.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#join" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="join(right:org.apache.spark.sql.DataFrame,joinExprs:org.apache.spark.sql.Column):org.apache.spark.sql.DataFrame"></a>
      <a id="join(DataFrame,Column):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="params">(<span name="right">right: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>, <span name="joinExprs">joinExprs: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Inner join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>, using the given join expression.</p><div class="fullcomment"><div class="comment cmt"><p>Inner join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>, using the given join expression.</p><pre><span class="cmt">// The following two are equivalent:</span>
df1.join(df2, $<span class="lit">"df1Key"</span> === $<span class="lit">"df2Key"</span>)
df1.join(df2).where($<span class="lit">"df1Key"</span> === $<span class="lit">"df2Key"</span>)</pre></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#join" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="join(right:org.apache.spark.sql.DataFrame):org.apache.spark.sql.DataFrame"></a>
      <a id="join(DataFrame):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="params">(<span name="right">right: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Cartesian join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Cartesian join with another <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><p>Note that cartesian joins are very expensive without an extra filter that can be pushed down.
</p></div><dl class="paramcmts block"><dt class="param">right</dt><dd class="cmt"><p>Right side of the join operation.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#limit" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="limit(n:Int):org.apache.spark.sql.DataFrame"></a>
      <a id="limit(Int):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">limit</span><span class="params">(<span name="n">n: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by taking the first <code>n</code> rows.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by taking the first <code>n</code> rows. The difference between this function
and <code>head</code> is that <code>head</code> returns an array while <code>limit</code> returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#logicalPlan" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="logicalPlan:org.apache.spark.sql.catalyst.plans.logical.LogicalPlan"></a>
      <a id="logicalPlan:LogicalPlan"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">logicalPlan</span><span class="result">: <span class="extype" name="org.apache.spark.sql.catalyst.plans.logical.LogicalPlan">LogicalPlan</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="package.html" class="extype" name="org.apache.spark.sql">org.apache.spark.sql</a>] </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#map" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="map[R](f:org.apache.spark.sql.Row=&gt;R)(implicitevidence$3:scala.reflect.ClassTag[R]):org.apache.spark.rdd.RDD[R]"></a>
      <a id="map[R]((Row)⇒R)(ClassTag[R]):RDD[R]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">map</span><span class="tparams">[<span name="R">R</span>]</span><span class="params">(<span name="f">f: (<span class="extype" name="org.apache.spark.sql.Row">Row</span>) ⇒ <span class="extype" name="org.apache.spark.sql.DataFrame.map.R">R</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.map.R">R</span>]</span>)</span><span class="result">: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="org.apache.spark.sql.DataFrame.map.R">R</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new RDD by applying a function to all rows of this DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new RDD by applying a function to all rows of this DataFrame.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#mapPartitions" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="mapPartitions[R](f:Iterator[org.apache.spark.sql.Row]=&gt;Iterator[R])(implicitevidence$5:scala.reflect.ClassTag[R]):org.apache.spark.rdd.RDD[R]"></a>
      <a id="mapPartitions[R]((Iterator[Row])⇒Iterator[R])(ClassTag[R]):RDD[R]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">mapPartitions</span><span class="tparams">[<span name="R">R</span>]</span><span class="params">(<span name="f">f: (<span class="extype" name="scala.Iterator">Iterator</span>[<span class="extype" name="org.apache.spark.sql.Row">Row</span>]) ⇒ <span class="extype" name="scala.Iterator">Iterator</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.mapPartitions.R">R</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.sql.DataFrame.mapPartitions.R">R</span>]</span>)</span><span class="result">: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="org.apache.spark.sql.DataFrame.mapPartitions.R">R</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new RDD by applying a function to each partition of this DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new RDD by applying a function to each partition of this DataFrame.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="scala.AnyRef#ne" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ne(x$1:AnyRef):Boolean"></a>
      <a id="ne(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">ne</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#notify" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="notify():Unit"></a>
      <a id="notify():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notify</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#notifyAll" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="notifyAll():Unit"></a>
      <a id="notifyAll():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#numericColumns" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="numericColumns:Seq[org.apache.spark.sql.catalyst.expressions.Expression]"></a>
      <a id="numericColumns:Seq[Expression]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">numericColumns</span><span class="result">: <span class="extype" name="scala.Seq">Seq</span>[<span class="extype" name="org.apache.spark.sql.catalyst.expressions.Expression">Expression</span>]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="package.html" class="extype" name="org.apache.spark.sql">org.apache.spark.sql</a>] </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#orderBy" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="orderBy(sortExprs:org.apache.spark.sql.Column*):org.apache.spark.sql.DataFrame"></a>
      <a id="orderBy(Column*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">orderBy</span><span class="params">(<span name="sortExprs">sortExprs: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the given expressions.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the given expressions.
This is an alias of the <code>sort</code> function.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#orderBy" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="orderBy(sortCol:String,sortCols:String*):org.apache.spark.sql.DataFrame"></a>
      <a id="orderBy(String,String*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">orderBy</span><span class="params">(<span name="sortCol">sortCol: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="sortCols">sortCols: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the given expressions.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the given expressions.
This is an alias of the <code>sort</code> function.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#persist" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="persist(newLevel:org.apache.spark.storage.StorageLevel):DataFrame.this.type"></a>
      <a id="persist(StorageLevel):DataFrame.this.type"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">persist</span><span class="params">(<span name="newLevel">newLevel: <a href="../storage/StorageLevel.html" class="extype" name="org.apache.spark.storage.StorageLevel">StorageLevel</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.this.type</span>
      </span>
      </h4>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#persist" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="persist():DataFrame.this.type"></a>
      <a id="persist():DataFrame.this.type"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">persist</span><span class="params">()</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.this.type</span>
      </span>
      </h4>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#printSchema" visbl="pub" data-isabs="false" fullComment="no" group="basic">
      <a id="printSchema():Unit"></a>
      <a id="printSchema():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">printSchema</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Prints the schema to the console in a nice tree format.</p>
    </li><li name="org.apache.spark.sql.DataFrame#queryExecution" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="queryExecution:org.apache.spark.sql.SQLContext#QueryExecution"></a>
      <a id="queryExecution:QueryExecution"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">queryExecution</span><span class="result">: <a href="SQLContext$QueryExecution.html" class="extype" name="org.apache.spark.sql.SQLContext.QueryExecution">QueryExecution</a></span>
      </span>
      </h4>
      
    </li><li name="org.apache.spark.sql.DataFrame#rdd" visbl="pub" data-isabs="false" fullComment="no" group="rdd">
      <a id="rdd:org.apache.spark.rdd.RDD[org.apache.spark.sql.Row]"></a>
      <a id="rdd:RDD[Row]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rdd</span><span class="result">: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="org.apache.spark.sql.Row">Row</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the content of the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as an <span class="extype" name="RDD">RDD</span> of <span class="extype" name="Row">Row</span>s.</p>
    </li><li name="org.apache.spark.sql.DataFrame#registerTempTable" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="registerTempTable(tableName:String):Unit"></a>
      <a id="registerTempTable(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">registerTempTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Registers this RDD as a temporary table using the given name.</p><div class="fullcomment"><div class="comment cmt"><p>Registers this RDD as a temporary table using the given name.  The lifetime of this temporary
table is tied to the <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a> that was used to create this DataFrame.
</p></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#repartition" visbl="pub" data-isabs="false" fullComment="yes" group="rdd">
      <a id="repartition(numPartitions:Int):org.apache.spark.sql.DataFrame"></a>
      <a id="repartition(Int):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">repartition</span><span class="params">(<span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> that has exactly <code>numPartitions</code> partitions.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> that has exactly <code>numPartitions</code> partitions.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#resolve" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="resolve(colName:String):org.apache.spark.sql.catalyst.expressions.NamedExpression"></a>
      <a id="resolve(String):NamedExpression"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">resolve</span><span class="params">(<span name="colName">colName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="org.apache.spark.sql.catalyst.expressions.NamedExpression">NamedExpression</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="package.html" class="extype" name="org.apache.spark.sql">org.apache.spark.sql</a>] </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#sample" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="sample(withReplacement:Boolean,fraction:Double):org.apache.spark.sql.DataFrame"></a>
      <a id="sample(Boolean,Double):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sample</span><span class="params">(<span name="withReplacement">withReplacement: <span class="extype" name="scala.Boolean">Boolean</span></span>, <span name="fraction">fraction: <span class="extype" name="scala.Double">Double</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by sampling a fraction of rows, using a random seed.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by sampling a fraction of rows, using a random seed.
</p></div><dl class="paramcmts block"><dt class="param">withReplacement</dt><dd class="cmt"><p>Sample with replacement or not.</p></dd><dt class="param">fraction</dt><dd class="cmt"><p>Fraction of rows to generate.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#sample" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="sample(withReplacement:Boolean,fraction:Double,seed:Long):org.apache.spark.sql.DataFrame"></a>
      <a id="sample(Boolean,Double,Long):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sample</span><span class="params">(<span name="withReplacement">withReplacement: <span class="extype" name="scala.Boolean">Boolean</span></span>, <span name="fraction">fraction: <span class="extype" name="scala.Double">Double</span></span>, <span name="seed">seed: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by sampling a fraction of rows.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by sampling a fraction of rows.
</p></div><dl class="paramcmts block"><dt class="param">withReplacement</dt><dd class="cmt"><p>Sample with replacement or not.</p></dd><dt class="param">fraction</dt><dd class="cmt"><p>Fraction of rows to generate.</p></dd><dt class="param">seed</dt><dd class="cmt"><p>Seed for sampling.</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#save" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="save(source:String,mode:org.apache.spark.sql.SaveMode,options:Map[String,String]):Unit"></a>
      <a id="save(String,SaveMode,Map[String,String]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">save</span><span class="params">(<span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>, <span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
(Scala-specific)
Saves the contents of this DataFrame based on the given data source,
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
(Scala-specific)
Saves the contents of this DataFrame based on the given data source,
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#save" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="save(source:String,mode:org.apache.spark.sql.SaveMode,options:java.util.Map[String,String]):Unit"></a>
      <a id="save(String,SaveMode,Map[String,String]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">save</span><span class="params">(<span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>, <span name="options">options: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
Saves the contents of this DataFrame based on the given data source,
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Saves the contents of this DataFrame based on the given data source,
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#save" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="save(path:String,source:String,mode:org.apache.spark.sql.SaveMode):Unit"></a>
      <a id="save(String,String,SaveMode):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">save</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
Saves the contents of this DataFrame to the given path based on the given data source and
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Saves the contents of this DataFrame to the given path based on the given data source and
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#save" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="save(path:String,source:String):Unit"></a>
      <a id="save(String,String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">save</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
Saves the contents of this DataFrame to the given path based on the given data source,
using <span class="extype" name="SaveMode.ErrorIfExists">SaveMode.ErrorIfExists</span> as the save mode.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Saves the contents of this DataFrame to the given path based on the given data source,
using <span class="extype" name="SaveMode.ErrorIfExists">SaveMode.ErrorIfExists</span> as the save mode.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#save" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="save(path:String,mode:org.apache.spark.sql.SaveMode):Unit"></a>
      <a id="save(String,SaveMode):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">save</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
Saves the contents of this DataFrame to the given path and <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode,
using the default data source configured by spark.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Saves the contents of this DataFrame to the given path and <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode,
using the default data source configured by spark.sql.sources.default.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#save" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="save(path:String):Unit"></a>
      <a id="save(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">save</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
Saves the contents of this DataFrame to the given path,
using the default data source configured by spark.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Saves the contents of this DataFrame to the given path,
using the default data source configured by spark.sql.sources.default and
<span class="extype" name="SaveMode.ErrorIfExists">SaveMode.ErrorIfExists</span> as the save mode.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#saveAsParquetFile" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="saveAsParquetFile(path:String):Unit"></a>
      <a id="saveAsParquetFile(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsParquetFile</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Saves the contents of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a parquet file, preserving the schema.</p><div class="fullcomment"><div class="comment cmt"><p>Saves the contents of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a parquet file, preserving the schema.
Files that are written out using this method can be read back in as a <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>
using the <code>parquetFile</code> function in <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a>.</p></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#saveAsTable" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="saveAsTable(tableName:String,source:String,mode:org.apache.spark.sql.SaveMode,options:Map[String,String]):Unit"></a>
      <a id="saveAsTable(String,String,SaveMode,Map[String,String]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>, <span name="options">options: <span class="extype" name="scala.Predef.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
(Scala-specific)
Creates a table from the the contents of this DataFrame based on a given data source,
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
(Scala-specific)
Creates a table from the the contents of this DataFrame based on a given data source,
<a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p><p>Note that this currently only works with DataFrames that are created from a HiveContext as
there is no notion of a persisted catalog in a standard SQL context.  Instead you can write
an RDD out to a parquet file, and then register that file as a table.  This &quot;table&quot; can then
be the target of an <code>insertInto</code>.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#saveAsTable" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="saveAsTable(tableName:String,source:String,mode:org.apache.spark.sql.SaveMode,options:java.util.Map[String,String]):Unit"></a>
      <a id="saveAsTable(String,String,SaveMode,Map[String,String]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>, <span name="options">options: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
Creates a table at the given path from the the contents of this DataFrame
based on a given data source, <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a table at the given path from the the contents of this DataFrame
based on a given data source, <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p><p>Note that this currently only works with DataFrames that are created from a HiveContext as
there is no notion of a persisted catalog in a standard SQL context.  Instead you can write
an RDD out to a parquet file, and then register that file as a table.  This &quot;table&quot; can then
be the target of an <code>insertInto</code>.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#saveAsTable" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="saveAsTable(tableName:String,source:String,mode:org.apache.spark.sql.SaveMode):Unit"></a>
      <a id="saveAsTable(String,String,SaveMode):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
Creates a table at the given path from the the contents of this DataFrame
based on a given data source, <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a table at the given path from the the contents of this DataFrame
based on a given data source, <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a> specified by mode, and a set of options.</p><p>Note that this currently only works with DataFrames that are created from a HiveContext as
there is no notion of a persisted catalog in a standard SQL context.  Instead you can write
an RDD out to a parquet file, and then register that file as a table.  This &quot;table&quot; can then
be the target of an <code>insertInto</code>.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#saveAsTable" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="saveAsTable(tableName:String,source:String):Unit"></a>
      <a id="saveAsTable(String,String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="source">source: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
Creates a table at the given path from the the contents of this DataFrame
based on a given data source and a set of options,
using <span class="extype" name="SaveMode.ErrorIfExists">SaveMode.ErrorIfExists</span> as the save mode.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a table at the given path from the the contents of this DataFrame
based on a given data source and a set of options,
using <span class="extype" name="SaveMode.ErrorIfExists">SaveMode.ErrorIfExists</span> as the save mode.</p><p>Note that this currently only works with DataFrames that are created from a HiveContext as
there is no notion of a persisted catalog in a standard SQL context.  Instead you can write
an RDD out to a parquet file, and then register that file as a table.  This &quot;table&quot; can then
be the target of an <code>insertInto</code>.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#saveAsTable" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="saveAsTable(tableName:String,mode:org.apache.spark.sql.SaveMode):Unit"></a>
      <a id="saveAsTable(String,SaveMode):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="mode">mode: <a href="SaveMode.html" class="extype" name="org.apache.spark.sql.SaveMode">SaveMode</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
Creates a table from the the contents of this DataFrame, using the default data source
configured by spark.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a table from the the contents of this DataFrame, using the default data source
configured by spark.sql.sources.default and <span class="extype" name="SaveMode.ErrorIfExists">SaveMode.ErrorIfExists</span> as the save mode.</p><p>Note that this currently only works with DataFrames that are created from a HiveContext as
there is no notion of a persisted catalog in a standard SQL context.  Instead you can write
an RDD out to a parquet file, and then register that file as a table.  This &quot;table&quot; can then
be the target of an <code>insertInto</code>.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#saveAsTable" visbl="pub" data-isabs="false" fullComment="yes" group="output">
      <a id="saveAsTable(tableName:String):Unit"></a>
      <a id="saveAsTable(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsTable</span><span class="params">(<span name="tableName">tableName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::
Creates a table from the the contents of this DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::
Creates a table from the the contents of this DataFrame.
It will use the default data source configured by spark.sql.sources.default.
This will fail if the table already exists.</p><p>Note that this currently only works with DataFrames that are created from a HiveContext as
there is no notion of a persisted catalog in a standard SQL context.  Instead you can write
an RDD out to a parquet file, and then register that file as a table.  This &quot;table&quot; can then
be the target of an <code>insertInto</code>.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#schema" visbl="pub" data-isabs="false" fullComment="no" group="basic">
      <a id="schema:org.apache.spark.sql.types.StructType"></a>
      <a id="schema:StructType"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">schema</span><span class="result">: <span class="extype" name="org.apache.spark.sql.types.StructType">StructType</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the schema of this <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p>
    </li><li name="org.apache.spark.sql.DataFrame#select" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="select(col:String,cols:String*):org.apache.spark.sql.DataFrame"></a>
      <a id="select(String,String*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">select</span><span class="params">(<span name="col">col: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="cols">cols: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Selects a set of columns.</p><div class="fullcomment"><div class="comment cmt"><p>Selects a set of columns. This is a variant of <code>select</code> that can only select
existing columns using column names (i.e. cannot construct expressions).</p><pre><span class="cmt">// The following two are equivalent:</span>
df.select(<span class="lit">"colA"</span>, <span class="lit">"colB"</span>)
df.select($<span class="lit">"colA"</span>, $<span class="lit">"colB"</span>)</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#select" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="select(cols:org.apache.spark.sql.Column*):org.apache.spark.sql.DataFrame"></a>
      <a id="select(Column*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">select</span><span class="params">(<span name="cols">cols: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Selects a set of expressions.</p><div class="fullcomment"><div class="comment cmt"><p>Selects a set of expressions.</p><pre>df.select($<span class="lit">"colA"</span>, $<span class="lit">"colB"</span> + <span class="num">1</span>)</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#selectExpr" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="selectExpr(exprs:String*):org.apache.spark.sql.DataFrame"></a>
      <a id="selectExpr(String*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">selectExpr</span><span class="params">(<span name="exprs">exprs: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Selects a set of SQL expressions.</p><div class="fullcomment"><div class="comment cmt"><p>Selects a set of SQL expressions. This is a variant of <code>select</code> that accepts
SQL expressions.</p><pre>df.selectExpr(<span class="lit">"colA"</span>, <span class="lit">"colB as newName"</span>, <span class="lit">"abs(colC)"</span>)</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#show" visbl="pub" data-isabs="false" fullComment="no" group="action">
      <a id="show():Unit"></a>
      <a id="show():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">show</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Displays the top 20 rows of <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> in a tabular form.</p>
    </li><li name="org.apache.spark.sql.DataFrame#show" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="show(numRows:Int):Unit"></a>
      <a id="show(Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">show</span><span class="params">(<span name="numRows">numRows: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Displays the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> in a tabular form.</p><div class="fullcomment"><div class="comment cmt"><p>Displays the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> in a tabular form. For example:</p><pre>year  month AVG('Adj Close) MAX('Adj Close)
<span class="num">1980</span>  <span class="num">12</span>    <span class="num">0.503218</span>        <span class="num">0.595103</span>
<span class="num">1981</span>  <span class="num">01</span>    <span class="num">0.523289</span>        <span class="num">0.570307</span>
<span class="num">1982</span>  <span class="num">02</span>    <span class="num">0.436504</span>        <span class="num">0.475256</span>
<span class="num">1983</span>  <span class="num">03</span>    <span class="num">0.410516</span>        <span class="num">0.442194</span>
<span class="num">1984</span>  <span class="num">04</span>    <span class="num">0.450090</span>        <span class="num">0.483521</span></pre></div><dl class="paramcmts block"><dt class="param">numRows</dt><dd class="cmt"><p>Number of rows to show
</p></dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#sort" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="sort(sortExprs:org.apache.spark.sql.Column*):org.apache.spark.sql.DataFrame"></a>
      <a id="sort(Column*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sort</span><span class="params">(<span name="sortExprs">sortExprs: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the given expressions.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the given expressions. For example:</p><pre>df.sort($<span class="lit">"col1"</span>, $<span class="lit">"col2"</span>.desc)</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#sort" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="sort(sortCol:String,sortCols:String*):org.apache.spark.sql.DataFrame"></a>
      <a id="sort(String,String*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">sort</span><span class="params">(<span name="sortCol">sortCol: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="sortCols">sortCols: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the specified column, all in ascending order.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> sorted by the specified column, all in ascending order.</p><pre><span class="cmt">// The following 3 are equivalent</span>
df.sort(<span class="lit">"sortcol"</span>)
df.sort($<span class="lit">"sortcol"</span>)
df.sort($<span class="lit">"sortcol"</span>.asc)</pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#sqlContext" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="sqlContext:org.apache.spark.sql.SQLContext"></a>
      <a id="sqlContext:SQLContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">sqlContext</span><span class="result">: <a href="SQLContext.html" class="extype" name="org.apache.spark.sql.SQLContext">SQLContext</a></span>
      </span>
      </h4>
      
    </li><li name="scala.AnyRef#synchronized" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="synchronized[T0](x$1:=&gt;T0):T0"></a>
      <a id="synchronized[T0](⇒T0):T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: ⇒ <span class="extype" name="java.lang.AnyRef.synchronized.T0">T0</span></span>)</span><span class="result">: <span class="extype" name="java.lang.AnyRef.synchronized.T0">T0</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#take" visbl="pub" data-isabs="false" fullComment="yes" group="action">
      <a id="take(n:Int):Array[org.apache.spark.sql.Row]"></a>
      <a id="take(Int):Array[Row]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">take</span><span class="params">(<span name="n">n: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Array">Array</span>[<span class="extype" name="org.apache.spark.sql.Row">Row</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the first <code>n</code> rows in the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the first <code>n</code> rows in the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.</p></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#toDF" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="toDF(colNames:String*):org.apache.spark.sql.DataFrame"></a>
      <a id="toDF(String*):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toDF</span><span class="params">(<span name="colNames">colNames: <span class="extype" name="scala.Predef.String">String</span>*</span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with columns renamed.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with columns renamed. This can be quite convenient in conversion
from a RDD of tuples into a <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with meaningful names. For example:</p><pre><span class="kw">val</span> rdd: RDD[(<span class="std">Int</span>, <span class="std">String</span>)] = ...
rdd.toDF()  <span class="cmt">// this implicit conversion creates a DataFrame with column name _1 and _2</span>
rdd.toDF(<span class="lit">"id"</span>, <span class="lit">"name"</span>)  <span class="cmt">// this creates a DataFrame with column name "id" and "name"</span></pre></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@varargs</span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#toDF" visbl="pub" data-isabs="false" fullComment="no" group="basic">
      <a id="toDF():org.apache.spark.sql.DataFrame"></a>
      <a id="toDF():DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toDF</span><span class="params">()</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the object itself.</p>
    </li><li name="org.apache.spark.sql.DataFrame#toJSON" visbl="pub" data-isabs="false" fullComment="no" group="rdd">
      <a id="toJSON:org.apache.spark.rdd.RDD[String]"></a>
      <a id="toJSON:RDD[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toJSON</span><span class="result">: <a href="../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the content of the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a RDD of JSON strings.</p>
    </li><li name="org.apache.spark.sql.DataFrame#toJavaRDD" visbl="pub" data-isabs="false" fullComment="no" group="rdd">
      <a id="toJavaRDD:org.apache.spark.api.java.JavaRDD[org.apache.spark.sql.Row]"></a>
      <a id="toJavaRDD:JavaRDD[Row]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toJavaRDD</span><span class="result">: <a href="../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<span class="extype" name="org.apache.spark.sql.Row">Row</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns the content of the <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> as a <span class="extype" name="JavaRDD">JavaRDD</span> of <span class="extype" name="Row">Row</span>s.</p>
    </li><li name="org.apache.spark.sql.DataFrame#toString" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="toString():String"></a>
      <a id="toString():String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toString</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Predef.String">String</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#unionAll" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="unionAll(other:org.apache.spark.sql.DataFrame):org.apache.spark.sql.DataFrame"></a>
      <a id="unionAll(DataFrame):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">unionAll</span><span class="params">(<span name="other">other: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> containing union of rows in this frame and another frame.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> containing union of rows in this frame and another frame.
This is equivalent to <code>UNION ALL</code> in SQL.</p></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#unpersist" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="unpersist():DataFrame.this.type"></a>
      <a id="unpersist():DataFrame.this.type"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">unpersist</span><span class="params">()</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.this.type</span>
      </span>
      </h4>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#unpersist" visbl="pub" data-isabs="false" fullComment="yes" group="basic">
      <a id="unpersist(blocking:Boolean):DataFrame.this.type"></a>
      <a id="unpersist(Boolean):DataFrame.this.type"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">unpersist</span><span class="params">(<span name="blocking">blocking: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a>.this.type</span>
      </span>
      </h4>
      <p class="shortcomment cmt"></p><div class="fullcomment"><div class="comment cmt"></div><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> → RDDApi</dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait():Unit"></a>
      <a id="wait():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait(x$1:Long,x$2:Int):Unit"></a>
      <a id="wait(Long,Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Long">Long</span></span>, <span name="arg1">arg1: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait(x$1:Long):Unit"></a>
      <a id="wait(Long):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.sql.DataFrame#where" visbl="pub" data-isabs="false" fullComment="yes" group="dfops">
      <a id="where(condition:org.apache.spark.sql.Column):org.apache.spark.sql.DataFrame"></a>
      <a id="where(Column):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">where</span><span class="params">(<span name="condition">condition: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Filters rows using the given condition.</p><div class="fullcomment"><div class="comment cmt"><p>Filters rows using the given condition. This is an alias for <code>filter</code>.</p><pre><span class="cmt">// The following are equivalent:</span>
peopleDf.filter($<span class="lit">"age"</span> &gt; <span class="num">15</span>)
peopleDf.where($<span class="lit">"age"</span> &gt; <span class="num">15</span>)
peopleDf($<span class="lit">"age"</span> &gt; <span class="num">15</span>)</pre></div></div>
    </li><li name="org.apache.spark.sql.DataFrame#withColumn" visbl="pub" data-isabs="false" fullComment="no" group="dfops">
      <a id="withColumn(colName:String,col:org.apache.spark.sql.Column):org.apache.spark.sql.DataFrame"></a>
      <a id="withColumn(String,Column):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">withColumn</span><span class="params">(<span name="colName">colName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="col">col: <a href="Column.html" class="extype" name="org.apache.spark.sql.Column">Column</a></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> by adding a column.</p>
    </li><li name="org.apache.spark.sql.DataFrame#withColumnRenamed" visbl="pub" data-isabs="false" fullComment="no" group="dfops">
      <a id="withColumnRenamed(existingName:String,newName:String):org.apache.spark.sql.DataFrame"></a>
      <a id="withColumnRenamed(String,String):DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">withColumnRenamed</span><span class="params">(<span name="existingName">existingName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="newName">newName: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Returns a new <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a> with a column renamed.</p>
    </li></ol>
            </div>

        

        <div id="values" class="values members">
              <h3>Deprecated Value Members</h3>
              <ol><li name="org.apache.spark.sql.DataFrame#toSchemaRDD" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="toSchemaRDD:org.apache.spark.sql.DataFrame"></a>
      <a id="toSchemaRDD:DataFrame"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version use toDF) 1.3.0">toSchemaRDD</span><span class="result">: <a href="" class="extype" name="org.apache.spark.sql.DataFrame">DataFrame</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Left here for backward compatibility.</p><div class="fullcomment"><div class="comment cmt"><p>Left here for backward compatibility.</p></div><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version use toDF)</i> 1.3.0</p></dd></dl></div>
    </li></ol>
            </div>
        </div>

        <div id="inheritedMembers">
        <div class="parent" name="scala.Serializable">
              <h3>Inherited from <span class="extype" name="scala.Serializable">Serializable</span></h3>
            </div><div class="parent" name="java.io.Serializable">
              <h3>Inherited from <span class="extype" name="java.io.Serializable">Serializable</span></h3>
            </div><div class="parent" name="org.apache.spark.sql.RDDApi">
              <h3>Inherited from <span class="extype" name="org.apache.spark.sql.RDDApi">RDDApi</span>[<span class="extype" name="org.apache.spark.sql.Row">Row</span>]</h3>
            </div><div class="parent" name="scala.AnyRef">
              <h3>Inherited from <span class="extype" name="scala.AnyRef">AnyRef</span></h3>
            </div><div class="parent" name="scala.Any">
              <h3>Inherited from <span class="extype" name="scala.Any">Any</span></h3>
            </div>
        
        </div>

        <div id="groupedMembers">
        <div class="group" name="action">
              <h3>Actions</h3>
              
            </div><div class="group" name="basic">
              <h3>Basic DataFrame functions</h3>
              
            </div><div class="group" name="dfops">
              <h3>Language Integrated Queries</h3>
              
            </div><div class="group" name="output">
              <h3>Output Operations</h3>
              
            </div><div class="group" name="rdd">
              <h3>RDD Operations</h3>
              
            </div><div class="group" name="Ungrouped">
              <h3>Ungrouped</h3>
              
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>
      <script defer="defer" type="text/javascript" id="jquery-js" src="../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" id="jquery-ui-js" src="../../../../lib/jquery-ui.js"></script><script defer="defer" type="text/javascript" id="tools-tooltip-js" src="../../../../lib/tools.tooltip.js"></script><script defer="defer" type="text/javascript" id="template-js" src="../../../../lib/template.js"></script>
    </body>
      </html>