<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html>
        <head>
          <title>JavaStreamingContext - org.apache.spark.streaming.api.java.JavaStreamingContext</title>
          <meta name="description" content="JavaStreamingContext - org.apache.spark.streaming.api.java.JavaStreamingContext" />
          <meta name="keywords" content="JavaStreamingContext org.apache.spark.streaming.api.java.JavaStreamingContext" />
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      <link href="../../../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css" />
      <script type="text/javascript">
         if(top === self) {
            var url = '../../../../../../index.html';
            var hash = 'org.apache.spark.streaming.api.java.JavaStreamingContext';
            var anchor = window.location.hash;
            var anchor_opt = '';
            if (anchor.length >= 1)
              anchor_opt = '@' + anchor.substring(1);
            window.location.href = url + '#' + hash + anchor_opt;
         }
   	  </script>
    
        </head>
        <body class="type">
      <div id="definition">
        <a href="JavaStreamingContext$.html" title="Go to companion"><img src="../../../../../../lib/class_to_object_big.png" /></a>
        <p id="owner"><a href="../../../../../package.html" class="extype" name="org">org</a>.<a href="../../../../package.html" class="extype" name="org.apache">apache</a>.<a href="../../../package.html" class="extype" name="org.apache.spark">spark</a>.<a href="../../package.html" class="extype" name="org.apache.spark.streaming">streaming</a>.<a href="../package.html" class="extype" name="org.apache.spark.streaming.api">api</a>.<a href="package.html" class="extype" name="org.apache.spark.streaming.api.java">java</a></p>
        <h1><a href="JavaStreamingContext$.html" title="Go to companion">JavaStreamingContext</a></h1>
      </div>

      <h4 id="signature" class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="result"> extends <span class="extype" name="java.io.Closeable">Closeable</span></span>
      </span>
      </h4>
      
          <div id="comment" class="fullcommenttop"><div class="comment cmt"><p>A Java-friendly version of <a href="../../StreamingContext.html" class="extype" name="org.apache.spark.streaming.StreamingContext">org.apache.spark.streaming.StreamingContext</a> which is the main
entry point for Spark Streaming functionality. It provides methods to create
<a href="JavaDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaDStream">org.apache.spark.streaming.api.java.JavaDStream</a> and
<a href="JavaPairDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaPairDStream">org.apache.spark.streaming.api.java.JavaPairDStream.</a> from input sources. The internal
org.apache.spark.api.java.JavaSparkContext (see core Spark documentation) can be accessed
using <code>context.sparkContext</code>. After creating and transforming DStreams, the streaming
computation can be started and stopped using <code>context.start()</code> and <code>context.stop()</code>,
respectively. <code>context.awaitTermination()</code> allows the current thread to wait for the
termination of a context by <code>stop()</code> or by an exception.
</p></div><div class="toggleContainer block">
          <span class="toggle">Linear Supertypes</span>
          <div class="superTypes hiddenContent"><span class="extype" name="java.io.Closeable">Closeable</span>, <span class="extype" name="java.lang.AutoCloseable">AutoCloseable</span>, <span class="extype" name="scala.AnyRef">AnyRef</span>, <span class="extype" name="scala.Any">Any</span></div>
        </div></div>
        

      <div id="mbrsel">
        <div id="textfilter"><span class="pre"></span><span class="input"><input id="mbrsel-input" type="text" accesskey="/" /></span><span class="post"></span></div>
        <div id="order">
              <span class="filtertype">Ordering</span>
              <ol>
                
                <li class="alpha in"><span>Alphabetic</span></li>
                <li class="inherit out"><span>By inheritance</span></li>
              </ol>
            </div>
        <div id="ancestors">
                <span class="filtertype">Inherited<br />
                </span>
                <ol id="linearization">
                  <li class="in" name="org.apache.spark.streaming.api.java.JavaStreamingContext"><span>JavaStreamingContext</span></li><li class="in" name="java.io.Closeable"><span>Closeable</span></li><li class="in" name="java.lang.AutoCloseable"><span>AutoCloseable</span></li><li class="in" name="scala.AnyRef"><span>AnyRef</span></li><li class="in" name="scala.Any"><span>Any</span></li>
                </ol>
              </div><div id="ancestors">
            <span class="filtertype"></span>
            <ol>
              <li class="hideall out"><span>Hide All</span></li>
              <li class="showall in"><span>Show all</span></li>
            </ol>
            <a href="http://docs.scala-lang.org/overviews/scaladoc/usage.html#members" target="_blank">Learn more about member selection</a>
          </div>
        <div id="visbl">
            <span class="filtertype">Visibility</span>
            <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
          </div>
      </div>

      <div id="template">
        <div id="allMembers">
        <div id="constructors" class="members">
              <h3>Instance Constructors</h3>
              <ol><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#&lt;init&gt;" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="&lt;init&gt;(path:String,hadoopConf:org.apache.hadoop.conf.Configuration):org.apache.spark.streaming.api.java.JavaStreamingContext"></a>
      <a id="&lt;init&gt;:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="hadoopConf">hadoopConf: <span class="extype" name="org.apache.hadoop.conf.Configuration">Configuration</span></span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Re-creates a JavaStreamingContext from a checkpoint file.</p><div class="fullcomment"><div class="comment cmt"><p>Re-creates a JavaStreamingContext from a checkpoint file.</p></div><dl class="paramcmts block"><dt class="param">path</dt><dd class="cmt"><p>Path to the directory that was specified as the checkpoint directory</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#&lt;init&gt;" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="&lt;init&gt;(path:String):org.apache.spark.streaming.api.java.JavaStreamingContext"></a>
      <a id="&lt;init&gt;:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="path">path: <span class="extype" name="scala.Predef.String">String</span></span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Recreate a JavaStreamingContext from a checkpoint file.</p><div class="fullcomment"><div class="comment cmt"><p>Recreate a JavaStreamingContext from a checkpoint file.</p></div><dl class="paramcmts block"><dt class="param">path</dt><dd class="cmt"><p>Path to the directory that was specified as the checkpoint directory
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#&lt;init&gt;" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="&lt;init&gt;(conf:org.apache.spark.SparkConf,batchDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.api.java.JavaStreamingContext"></a>
      <a id="&lt;init&gt;:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="conf">conf: <a href="../../../SparkConf.html" class="extype" name="org.apache.spark.SparkConf">SparkConf</a></span>, <span name="batchDuration">batchDuration: <a href="../../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a JavaStreamingContext using a SparkConf configuration.</p><div class="fullcomment"><div class="comment cmt"><p>Create a JavaStreamingContext using a SparkConf configuration.</p></div><dl class="paramcmts block"><dt class="param">conf</dt><dd class="cmt"><p>A Spark application configuration</p></dd><dt class="param">batchDuration</dt><dd class="cmt"><p>The time interval at which streaming data will be divided into batches
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#&lt;init&gt;" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="&lt;init&gt;(sparkContext:org.apache.spark.api.java.JavaSparkContext,batchDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.api.java.JavaStreamingContext"></a>
      <a id="&lt;init&gt;:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="sparkContext">sparkContext: <a href="../../../api/java/JavaSparkContext.html" class="extype" name="org.apache.spark.api.java.JavaSparkContext">JavaSparkContext</a></span>, <span name="batchDuration">batchDuration: <a href="../../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a JavaStreamingContext using an existing JavaSparkContext.</p><div class="fullcomment"><div class="comment cmt"><p>Create a JavaStreamingContext using an existing JavaSparkContext.</p></div><dl class="paramcmts block"><dt class="param">sparkContext</dt><dd class="cmt"><p>The underlying JavaSparkContext to use</p></dd><dt class="param">batchDuration</dt><dd class="cmt"><p>The time interval at which streaming data will be divided into batches
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#&lt;init&gt;" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="&lt;init&gt;(master:String,appName:String,batchDuration:org.apache.spark.streaming.Duration,sparkHome:String,jars:Array[String],environment:java.util.Map[String,String]):org.apache.spark.streaming.api.java.JavaStreamingContext"></a>
      <a id="&lt;init&gt;:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="master">master: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="appName">appName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="batchDuration">batchDuration: <a href="../../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="sparkHome">sparkHome: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="jars">jars: <span class="extype" name="scala.Array">Array</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="environment">environment: <span class="extype" name="java.util.Map">Map</span>[<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>]</span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a StreamingContext.</p><div class="fullcomment"><div class="comment cmt"><p>Create a StreamingContext.</p></div><dl class="paramcmts block"><dt class="param">master</dt><dd class="cmt"><p>Name of the Spark Master</p></dd><dt class="param">appName</dt><dd class="cmt"><p>Name to be used when registering with the scheduler</p></dd><dt class="param">batchDuration</dt><dd class="cmt"><p>The time interval at which streaming data will be divided into batches</p></dd><dt class="param">sparkHome</dt><dd class="cmt"><p>The SPARK_HOME directory on the slave nodes</p></dd><dt class="param">jars</dt><dd class="cmt"><p>Collection of JARs to send to the cluster. These can be paths on the local file
            system or HDFS, HTTP, HTTPS, or FTP URLs.</p></dd><dt class="param">environment</dt><dd class="cmt"><p>Environment variables to set on worker nodes
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#&lt;init&gt;" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="&lt;init&gt;(master:String,appName:String,batchDuration:org.apache.spark.streaming.Duration,sparkHome:String,jars:Array[String]):org.apache.spark.streaming.api.java.JavaStreamingContext"></a>
      <a id="&lt;init&gt;:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="master">master: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="appName">appName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="batchDuration">batchDuration: <a href="../../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="sparkHome">sparkHome: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="jars">jars: <span class="extype" name="scala.Array">Array</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a StreamingContext.</p><div class="fullcomment"><div class="comment cmt"><p>Create a StreamingContext.</p></div><dl class="paramcmts block"><dt class="param">master</dt><dd class="cmt"><p>Name of the Spark Master</p></dd><dt class="param">appName</dt><dd class="cmt"><p>Name to be used when registering with the scheduler</p></dd><dt class="param">batchDuration</dt><dd class="cmt"><p>The time interval at which streaming data will be divided into batches</p></dd><dt class="param">sparkHome</dt><dd class="cmt"><p>The SPARK_HOME directory on the slave nodes</p></dd><dt class="param">jars</dt><dd class="cmt"><p>Collection of JARs to send to the cluster. These can be paths on the local file
            system or HDFS, HTTP, HTTPS, or FTP URLs.
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#&lt;init&gt;" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="&lt;init&gt;(master:String,appName:String,batchDuration:org.apache.spark.streaming.Duration,sparkHome:String,jarFile:String):org.apache.spark.streaming.api.java.JavaStreamingContext"></a>
      <a id="&lt;init&gt;:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="master">master: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="appName">appName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="batchDuration">batchDuration: <a href="../../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="sparkHome">sparkHome: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="jarFile">jarFile: <span class="extype" name="scala.Predef.String">String</span></span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a StreamingContext.</p><div class="fullcomment"><div class="comment cmt"><p>Create a StreamingContext.</p></div><dl class="paramcmts block"><dt class="param">master</dt><dd class="cmt"><p>Name of the Spark Master</p></dd><dt class="param">appName</dt><dd class="cmt"><p>Name to be used when registering with the scheduler</p></dd><dt class="param">batchDuration</dt><dd class="cmt"><p>The time interval at which streaming data will be divided into batches</p></dd><dt class="param">sparkHome</dt><dd class="cmt"><p>The SPARK_HOME directory on the slave nodes</p></dd><dt class="param">jarFile</dt><dd class="cmt"><p>JAR file containing job code, to ship to cluster. This can be a path on the
               local file system or an HDFS, HTTP, HTTPS, or FTP URL.
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#&lt;init&gt;" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="&lt;init&gt;(master:String,appName:String,batchDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.api.java.JavaStreamingContext"></a>
      <a id="&lt;init&gt;:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="master">master: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="appName">appName: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="batchDuration">batchDuration: <a href="../../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>)</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a StreamingContext.</p><div class="fullcomment"><div class="comment cmt"><p>Create a StreamingContext.</p></div><dl class="paramcmts block"><dt class="param">master</dt><dd class="cmt"><p>Name of the Spark Master</p></dd><dt class="param">appName</dt><dd class="cmt"><p>Name to be used when registering with the scheduler</p></dd><dt class="param">batchDuration</dt><dd class="cmt"><p>The time interval at which streaming data will be divided into batches
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#&lt;init&gt;" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="&lt;init&gt;(ssc:org.apache.spark.streaming.StreamingContext):org.apache.spark.streaming.api.java.JavaStreamingContext"></a>
      <a id="&lt;init&gt;:JavaStreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">JavaStreamingContext</span><span class="params">(<span name="ssc">ssc: <a href="../../StreamingContext.html" class="extype" name="org.apache.spark.streaming.StreamingContext">StreamingContext</a></span>)</span>
      </span>
      </h4>
      
    </li></ol>
            </div>

        

        

        <div id="values" class="values members">
              <h3>Value Members</h3>
              <ol><li name="scala.AnyRef#!=" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="!=(x$1:AnyRef):Boolean"></a>
      <a id="!=(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $bang$eq" class="name">!=</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.Any#!=" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="!=(x$1:Any):Boolean"></a>
      <a id="!=(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $bang$eq" class="name">!=</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="scala.AnyRef###" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="##():Int"></a>
      <a id="##():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $hash$hash" class="name">##</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef#==" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="==(x$1:AnyRef):Boolean"></a>
      <a id="==(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $eq$eq" class="name">==</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.Any#==" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="==(x$1:Any):Boolean"></a>
      <a id="==(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $eq$eq" class="name">==</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#actorStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="actorStream[T](props:akka.actor.Props,name:String):org.apache.spark.streaming.api.java.JavaReceiverInputDStream[T]"></a>
      <a id="actorStream[T](Props,String):JavaReceiverInputDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">actorStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="props">props: <span class="extype" name="akka.actor.Props">Props</span></span>, <span name="name">name: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="JavaReceiverInputDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaReceiverInputDStream">JavaReceiverInputDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.actorStream.T">T</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream with any arbitrary user implemented actor receiver.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream with any arbitrary user implemented actor receiver.
Storage level of the data will be the default StorageLevel.MEMORY_AND_DISK_SER_2.</p></div><dl class="paramcmts block"><dt class="param">props</dt><dd class="cmt"><p>Props object defining creation of the actor</p></dd><dt class="param">name</dt><dd class="cmt"><p>Name of the actor
</p></dd></dl><dl class="attributes block"> <dt>Note</dt><dd><span class="cmt"><p>An important point to note:
      Since Actor may exist outside the spark framework, It is thus user's responsibility
      to ensure the type safety, i.e parametrized type of data received and actorStream
      should be same.
</p></span></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#actorStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="actorStream[T](props:akka.actor.Props,name:String,storageLevel:org.apache.spark.storage.StorageLevel):org.apache.spark.streaming.api.java.JavaReceiverInputDStream[T]"></a>
      <a id="actorStream[T](Props,String,StorageLevel):JavaReceiverInputDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">actorStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="props">props: <span class="extype" name="akka.actor.Props">Props</span></span>, <span name="name">name: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="storageLevel">storageLevel: <a href="../../../storage/StorageLevel.html" class="extype" name="org.apache.spark.storage.StorageLevel">StorageLevel</a></span>)</span><span class="result">: <a href="JavaReceiverInputDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaReceiverInputDStream">JavaReceiverInputDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.actorStream.T">T</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream with any arbitrary user implemented actor receiver.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream with any arbitrary user implemented actor receiver.</p></div><dl class="paramcmts block"><dt class="param">props</dt><dd class="cmt"><p>Props object defining creation of the actor</p></dd><dt class="param">name</dt><dd class="cmt"><p>Name of the actor</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects
</p></dd></dl><dl class="attributes block"> <dt>Note</dt><dd><span class="cmt"><p>An important point to note:
      Since Actor may exist outside the spark framework, It is thus user's responsibility
      to ensure the type safety, i.e parametrized type of data received and actorStream
      should be same.
</p></span></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#actorStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="actorStream[T](props:akka.actor.Props,name:String,storageLevel:org.apache.spark.storage.StorageLevel,supervisorStrategy:akka.actor.SupervisorStrategy):org.apache.spark.streaming.api.java.JavaReceiverInputDStream[T]"></a>
      <a id="actorStream[T](Props,String,StorageLevel,SupervisorStrategy):JavaReceiverInputDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">actorStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="props">props: <span class="extype" name="akka.actor.Props">Props</span></span>, <span name="name">name: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="storageLevel">storageLevel: <a href="../../../storage/StorageLevel.html" class="extype" name="org.apache.spark.storage.StorageLevel">StorageLevel</a></span>, <span name="supervisorStrategy">supervisorStrategy: <span class="extype" name="akka.actor.SupervisorStrategy">SupervisorStrategy</span></span>)</span><span class="result">: <a href="JavaReceiverInputDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaReceiverInputDStream">JavaReceiverInputDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.actorStream.T">T</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream with any arbitrary user implemented actor receiver.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream with any arbitrary user implemented actor receiver.</p></div><dl class="paramcmts block"><dt class="param">props</dt><dd class="cmt"><p>Props object defining creation of the actor</p></dd><dt class="param">name</dt><dd class="cmt"><p>Name of the actor</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects
</p></dd></dl><dl class="attributes block"> <dt>Note</dt><dd><span class="cmt"><p>An important point to note:
      Since Actor may exist outside the spark framework, It is thus user's responsibility
      to ensure the type safety, i.e parametrized type of data received and actorStream
      should be same.
</p></span></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#addStreamingListener" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="addStreamingListener(streamingListener:org.apache.spark.streaming.scheduler.StreamingListener):Unit"></a>
      <a id="addStreamingListener(StreamingListener):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">addStreamingListener</span><span class="params">(<span name="streamingListener">streamingListener: <a href="../../scheduler/StreamingListener.html" class="extype" name="org.apache.spark.streaming.scheduler.StreamingListener">StreamingListener</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Add a <a href="../../scheduler/StreamingListener.html" class="extype" name="org.apache.spark.streaming.scheduler.StreamingListener">org.apache.spark.streaming.scheduler.StreamingListener</a> object for
receiving system events related to streaming.</p>
    </li><li name="scala.Any#asInstanceOf" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="asInstanceOf[T0]:T0"></a>
      <a id="asInstanceOf[T0]:T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span class="extype" name="scala.Any.asInstanceOf.T0">T0</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#awaitTermination" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="awaitTermination():Unit"></a>
      <a id="awaitTermination():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">awaitTermination</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Wait for the execution to stop.</p><div class="fullcomment"><div class="comment cmt"><p>Wait for the execution to stop. Any exceptions that occurs during the execution
will be thrown in this thread.
</p></div></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#awaitTerminationOrTimeout" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="awaitTerminationOrTimeout(timeout:Long):Boolean"></a>
      <a id="awaitTerminationOrTimeout(Long):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">awaitTerminationOrTimeout</span><span class="params">(<span name="timeout">timeout: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Wait for the execution to stop.</p><div class="fullcomment"><div class="comment cmt"><p>Wait for the execution to stop. Any exceptions that occurs during the execution
will be thrown in this thread.
</p></div><dl class="paramcmts block"><dt class="param">timeout</dt><dd class="cmt"><p>time to wait in milliseconds</p></dd><dt>returns</dt><dd class="cmt"><p><code>true</code> if it's stopped; or throw the reported error during the execution; or <code>false</code>
        if the waiting time elapsed before returning from the method.
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#binaryRecordsStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="binaryRecordsStream(directory:String,recordLength:Int):org.apache.spark.streaming.api.java.JavaDStream[Array[Byte]]"></a>
      <a id="binaryRecordsStream(String,Int):JavaDStream[Array[Byte]]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">binaryRecordsStream</span><span class="params">(<span name="directory">directory: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="recordLength">recordLength: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="JavaDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaDStream">JavaDStream</a>[<span class="extype" name="scala.Array">Array</span>[<span class="extype" name="scala.Byte">Byte</span>]]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">:: Experimental ::</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::</p><p>Create an input stream that monitors a Hadoop-compatible filesystem
for new files and reads them as flat binary files with fixed record lengths,
yielding byte arrays</p><p><b>Note:</b> We ensure that the byte array for each record in the
resulting RDDs of the DStream has the provided record length.
</p></div><dl class="paramcmts block"><dt class="param">directory</dt><dd class="cmt"><p>HDFS directory to monitor for new files</p></dd><dt class="param">recordLength</dt><dd class="cmt"><p>The length at which to split the records
</p></dd></dl><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@<a href="../../../annotation/Experimental.html" class="extype" name="org.apache.spark.annotation.Experimental">Experimental</a></span><span class="args">()</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#checkpoint" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="checkpoint(directory:String):Unit"></a>
      <a id="checkpoint(String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">checkpoint</span><span class="params">(<span name="directory">directory: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Sets the context to periodically checkpoint the DStream operations for master
fault-tolerance.</p><div class="fullcomment"><div class="comment cmt"><p>Sets the context to periodically checkpoint the DStream operations for master
fault-tolerance. The graph will be checkpointed every batch interval.</p></div><dl class="paramcmts block"><dt class="param">directory</dt><dd class="cmt"><p>HDFS-compatible directory where the checkpoint data will be reliably stored
</p></dd></dl></div>
    </li><li name="scala.AnyRef#clone" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="clone():Object"></a>
      <a id="clone():AnyRef"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">clone</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.AnyRef">AnyRef</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../../../../../../java$lang.html" class="extype" name="java.lang">java.lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.CloneNotSupportedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#close" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="close():Unit"></a>
      <a id="close():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">close</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="" class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext">JavaStreamingContext</a> → Closeable → AutoCloseable</dd></dl></div>
    </li><li name="scala.AnyRef#eq" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="eq(x$1:AnyRef):Boolean"></a>
      <a id="eq(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">eq</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#equals" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="equals(x$1:Any):Boolean"></a>
      <a id="equals(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#fileStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="fileStream[K,V,F&lt;:org.apache.hadoop.mapreduce.InputFormat[K,V]](directory:String,kClass:Class[K],vClass:Class[V],fClass:Class[F],filter:org.apache.spark.api.java.function.Function[org.apache.hadoop.fs.Path,Boolean],newFilesOnly:Boolean,conf:org.apache.hadoop.conf.Configuration):org.apache.spark.streaming.api.java.JavaPairInputDStream[K,V]"></a>
      <a id="fileStream[K,V,F&lt;:InputFormat[K,V]](String,Class[K],Class[V],Class[F],Function[Path,Boolean],Boolean,Configuration):JavaPairInputDStream[K,V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">fileStream</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>, <span name="F">F &lt;: <span class="extype" name="org.apache.hadoop.mapreduce.InputFormat">InputFormat</span>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.K">K</span>, <span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.V">V</span>]</span>]</span><span class="params">(<span name="directory">directory: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="kClass">kClass: <span class="extype" name="scala.Predef.Class">Class</span>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.K">K</span>]</span>, <span name="vClass">vClass: <span class="extype" name="scala.Predef.Class">Class</span>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.V">V</span>]</span>, <span name="fClass">fClass: <span class="extype" name="scala.Predef.Class">Class</span>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.F">F</span>]</span>, <span name="filter">filter: <a href="../../../api/java/function/Function.html" class="extype" name="org.apache.spark.api.java.function.Function">Function</a>[<span class="extype" name="org.apache.hadoop.fs.Path">Path</span>, <span class="extype" name="java.lang.Boolean">Boolean</span>]</span>, <span name="newFilesOnly">newFilesOnly: <span class="extype" name="scala.Boolean">Boolean</span></span>, <span name="conf">conf: <span class="extype" name="org.apache.hadoop.conf.Configuration">Configuration</span></span>)</span><span class="result">: <a href="JavaPairInputDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaPairInputDStream">JavaPairInputDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.K">K</span>, <span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.V">V</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream that monitors a Hadoop-compatible filesystem
for new files and reads them using the given key-value types and input format.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream that monitors a Hadoop-compatible filesystem
for new files and reads them using the given key-value types and input format.
Files must be written to the monitored directory by &quot;moving&quot; them from another
location within the same file system. File names starting with . are ignored.</p></div><dl class="paramcmts block"><dt class="tparam">K</dt><dd class="cmt"><p>Key type for reading HDFS file</p></dd><dt class="tparam">V</dt><dd class="cmt"><p>Value type for reading HDFS file</p></dd><dt class="tparam">F</dt><dd class="cmt"><p>Input format for reading HDFS file
</p></dd><dt class="param">directory</dt><dd class="cmt"><p>HDFS directory to monitor for new file</p></dd><dt class="param">kClass</dt><dd class="cmt"><p>class of key for reading HDFS file</p></dd><dt class="param">vClass</dt><dd class="cmt"><p>class of value for reading HDFS file</p></dd><dt class="param">fClass</dt><dd class="cmt"><p>class of input format for reading HDFS file</p></dd><dt class="param">filter</dt><dd class="cmt"><p>Function to filter paths to process</p></dd><dt class="param">newFilesOnly</dt><dd class="cmt"><p>Should process only new files and ignore existing files in the directory</p></dd><dt class="param">conf</dt><dd class="cmt"><p>Hadoop configuration</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#fileStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="fileStream[K,V,F&lt;:org.apache.hadoop.mapreduce.InputFormat[K,V]](directory:String,kClass:Class[K],vClass:Class[V],fClass:Class[F],filter:org.apache.spark.api.java.function.Function[org.apache.hadoop.fs.Path,Boolean],newFilesOnly:Boolean):org.apache.spark.streaming.api.java.JavaPairInputDStream[K,V]"></a>
      <a id="fileStream[K,V,F&lt;:InputFormat[K,V]](String,Class[K],Class[V],Class[F],Function[Path,Boolean],Boolean):JavaPairInputDStream[K,V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">fileStream</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>, <span name="F">F &lt;: <span class="extype" name="org.apache.hadoop.mapreduce.InputFormat">InputFormat</span>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.K">K</span>, <span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.V">V</span>]</span>]</span><span class="params">(<span name="directory">directory: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="kClass">kClass: <span class="extype" name="scala.Predef.Class">Class</span>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.K">K</span>]</span>, <span name="vClass">vClass: <span class="extype" name="scala.Predef.Class">Class</span>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.V">V</span>]</span>, <span name="fClass">fClass: <span class="extype" name="scala.Predef.Class">Class</span>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.F">F</span>]</span>, <span name="filter">filter: <a href="../../../api/java/function/Function.html" class="extype" name="org.apache.spark.api.java.function.Function">Function</a>[<span class="extype" name="org.apache.hadoop.fs.Path">Path</span>, <span class="extype" name="java.lang.Boolean">Boolean</span>]</span>, <span name="newFilesOnly">newFilesOnly: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="JavaPairInputDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaPairInputDStream">JavaPairInputDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.K">K</span>, <span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.V">V</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream that monitors a Hadoop-compatible filesystem
for new files and reads them using the given key-value types and input format.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream that monitors a Hadoop-compatible filesystem
for new files and reads them using the given key-value types and input format.
Files must be written to the monitored directory by &quot;moving&quot; them from another
location within the same file system. File names starting with . are ignored.</p></div><dl class="paramcmts block"><dt class="tparam">K</dt><dd class="cmt"><p>Key type for reading HDFS file</p></dd><dt class="tparam">V</dt><dd class="cmt"><p>Value type for reading HDFS file</p></dd><dt class="tparam">F</dt><dd class="cmt"><p>Input format for reading HDFS file
</p></dd><dt class="param">directory</dt><dd class="cmt"><p>HDFS directory to monitor for new file</p></dd><dt class="param">kClass</dt><dd class="cmt"><p>class of key for reading HDFS file</p></dd><dt class="param">vClass</dt><dd class="cmt"><p>class of value for reading HDFS file</p></dd><dt class="param">fClass</dt><dd class="cmt"><p>class of input format for reading HDFS file</p></dd><dt class="param">filter</dt><dd class="cmt"><p>Function to filter paths to process</p></dd><dt class="param">newFilesOnly</dt><dd class="cmt"><p>Should process only new files and ignore existing files in the directory</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#fileStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="fileStream[K,V,F&lt;:org.apache.hadoop.mapreduce.InputFormat[K,V]](directory:String,kClass:Class[K],vClass:Class[V],fClass:Class[F]):org.apache.spark.streaming.api.java.JavaPairInputDStream[K,V]"></a>
      <a id="fileStream[K,V,F&lt;:InputFormat[K,V]](String,Class[K],Class[V],Class[F]):JavaPairInputDStream[K,V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">fileStream</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>, <span name="F">F &lt;: <span class="extype" name="org.apache.hadoop.mapreduce.InputFormat">InputFormat</span>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.K">K</span>, <span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.V">V</span>]</span>]</span><span class="params">(<span name="directory">directory: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="kClass">kClass: <span class="extype" name="scala.Predef.Class">Class</span>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.K">K</span>]</span>, <span name="vClass">vClass: <span class="extype" name="scala.Predef.Class">Class</span>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.V">V</span>]</span>, <span name="fClass">fClass: <span class="extype" name="scala.Predef.Class">Class</span>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.F">F</span>]</span>)</span><span class="result">: <a href="JavaPairInputDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaPairInputDStream">JavaPairInputDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.K">K</span>, <span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.fileStream.V">V</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream that monitors a Hadoop-compatible filesystem
for new files and reads them using the given key-value types and input format.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream that monitors a Hadoop-compatible filesystem
for new files and reads them using the given key-value types and input format.
Files must be written to the monitored directory by &quot;moving&quot; them from another
location within the same file system. File names starting with . are ignored.</p></div><dl class="paramcmts block"><dt class="tparam">K</dt><dd class="cmt"><p>Key type for reading HDFS file</p></dd><dt class="tparam">V</dt><dd class="cmt"><p>Value type for reading HDFS file</p></dd><dt class="tparam">F</dt><dd class="cmt"><p>Input format for reading HDFS file
</p></dd><dt class="param">directory</dt><dd class="cmt"><p>HDFS directory to monitor for new file</p></dd><dt class="param">kClass</dt><dd class="cmt"><p>class of key for reading HDFS file</p></dd><dt class="param">vClass</dt><dd class="cmt"><p>class of value for reading HDFS file</p></dd><dt class="param">fClass</dt><dd class="cmt"><p>class of input format for reading HDFS file</p></dd></dl></div>
    </li><li name="scala.AnyRef#finalize" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="finalize():Unit"></a>
      <a id="finalize():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">finalize</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../../../../../../java$lang.html" class="extype" name="java.lang">java.lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="symbol">classOf[java.lang.Throwable]</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#getClass" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getClass():Class[_]"></a>
      <a id="getClass():Class[_]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getClass</span><span class="params">()</span><span class="result">: <span class="extype" name="java.lang.Class">Class</span>[_]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef#hashCode" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="hashCode():Int"></a>
      <a id="hashCode():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">hashCode</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.Any#isInstanceOf" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="isInstanceOf[T0]:Boolean"></a>
      <a id="isInstanceOf[T0]:Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="scala.AnyRef#ne" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ne(x$1:AnyRef):Boolean"></a>
      <a id="ne(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">ne</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#notify" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="notify():Unit"></a>
      <a id="notify():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notify</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#notifyAll" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="notifyAll():Unit"></a>
      <a id="notifyAll():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#queueStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="queueStream[T](queue:java.util.Queue[org.apache.spark.api.java.JavaRDD[T]],oneAtATime:Boolean,defaultRDD:org.apache.spark.api.java.JavaRDD[T]):org.apache.spark.streaming.api.java.JavaInputDStream[T]"></a>
      <a id="queueStream[T](Queue[JavaRDD[T]],Boolean,JavaRDD[T]):JavaInputDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">queueStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="queue">queue: <span class="extype" name="java.util.Queue">Queue</span>[<a href="../../../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.queueStream.T">T</span>]]</span>, <span name="oneAtATime">oneAtATime: <span class="extype" name="scala.Boolean">Boolean</span></span>, <span name="defaultRDD">defaultRDD: <a href="../../../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.queueStream.T">T</span>]</span>)</span><span class="result">: <a href="JavaInputDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaInputDStream">JavaInputDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.queueStream.T">T</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream from an queue of RDDs.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream from an queue of RDDs. In each batch,
it will process either one or all of the RDDs returned by the queue.</p><p>NOTE: changes to the queue after the stream is created will not be recognized.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of objects in the RDD
</p></dd><dt class="param">queue</dt><dd class="cmt"><p>Queue of RDDs</p></dd><dt class="param">oneAtATime</dt><dd class="cmt"><p>Whether only one RDD should be consumed from the queue in every interval</p></dd><dt class="param">defaultRDD</dt><dd class="cmt"><p>Default RDD is returned by the DStream when the queue is empty</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#queueStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="queueStream[T](queue:java.util.Queue[org.apache.spark.api.java.JavaRDD[T]],oneAtATime:Boolean):org.apache.spark.streaming.api.java.JavaInputDStream[T]"></a>
      <a id="queueStream[T](Queue[JavaRDD[T]],Boolean):JavaInputDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">queueStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="queue">queue: <span class="extype" name="java.util.Queue">Queue</span>[<a href="../../../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.queueStream.T">T</span>]]</span>, <span name="oneAtATime">oneAtATime: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="JavaInputDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaInputDStream">JavaInputDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.queueStream.T">T</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream from an queue of RDDs.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream from an queue of RDDs. In each batch,
it will process either one or all of the RDDs returned by the queue.</p><p>NOTE: changes to the queue after the stream is created will not be recognized.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of objects in the RDD
</p></dd><dt class="param">queue</dt><dd class="cmt"><p>Queue of RDDs</p></dd><dt class="param">oneAtATime</dt><dd class="cmt"><p>Whether only one RDD should be consumed from the queue in every interval</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#queueStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="queueStream[T](queue:java.util.Queue[org.apache.spark.api.java.JavaRDD[T]]):org.apache.spark.streaming.api.java.JavaDStream[T]"></a>
      <a id="queueStream[T](Queue[JavaRDD[T]]):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">queueStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="queue">queue: <span class="extype" name="java.util.Queue">Queue</span>[<a href="../../../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.queueStream.T">T</span>]]</span>)</span><span class="result">: <a href="JavaDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaDStream">JavaDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.queueStream.T">T</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream from an queue of RDDs.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream from an queue of RDDs. In each batch,
it will process either one or all of the RDDs returned by the queue.</p><p>NOTE: changes to the queue after the stream is created will not be recognized.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of objects in the RDD
</p></dd><dt class="param">queue</dt><dd class="cmt"><p>Queue of RDDs</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#rawSocketStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="rawSocketStream[T](hostname:String,port:Int):org.apache.spark.streaming.api.java.JavaReceiverInputDStream[T]"></a>
      <a id="rawSocketStream[T](String,Int):JavaReceiverInputDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rawSocketStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="hostname">hostname: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="port">port: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="JavaReceiverInputDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaReceiverInputDStream">JavaReceiverInputDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.rawSocketStream.T">T</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream from network source hostname:port, where data is received
as serialized blocks (serialized using the Spark's serializer) that can be directly
pushed into the block manager without deserializing them.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream from network source hostname:port, where data is received
as serialized blocks (serialized using the Spark's serializer) that can be directly
pushed into the block manager without deserializing them. This is the most efficient
way to receive data.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of the objects in the received blocks
</p></dd><dt class="param">hostname</dt><dd class="cmt"><p>Hostname to connect to for receiving data</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port to connect to for receiving data</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#rawSocketStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="rawSocketStream[T](hostname:String,port:Int,storageLevel:org.apache.spark.storage.StorageLevel):org.apache.spark.streaming.api.java.JavaReceiverInputDStream[T]"></a>
      <a id="rawSocketStream[T](String,Int,StorageLevel):JavaReceiverInputDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rawSocketStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="hostname">hostname: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="port">port: <span class="extype" name="scala.Int">Int</span></span>, <span name="storageLevel">storageLevel: <a href="../../../storage/StorageLevel.html" class="extype" name="org.apache.spark.storage.StorageLevel">StorageLevel</a></span>)</span><span class="result">: <a href="JavaReceiverInputDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaReceiverInputDStream">JavaReceiverInputDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.rawSocketStream.T">T</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream from network source hostname:port, where data is received
as serialized blocks (serialized using the Spark's serializer) that can be directly
pushed into the block manager without deserializing them.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream from network source hostname:port, where data is received
as serialized blocks (serialized using the Spark's serializer) that can be directly
pushed into the block manager without deserializing them. This is the most efficient
way to receive data.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of the objects in the received blocks
</p></dd><dt class="param">hostname</dt><dd class="cmt"><p>Hostname to connect to for receiving data</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port to connect to for receiving data</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#receiverStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="receiverStream[T](receiver:org.apache.spark.streaming.receiver.Receiver[T]):org.apache.spark.streaming.api.java.JavaReceiverInputDStream[T]"></a>
      <a id="receiverStream[T](Receiver[T]):JavaReceiverInputDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">receiverStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="receiver">receiver: <a href="../../receiver/Receiver.html" class="extype" name="org.apache.spark.streaming.receiver.Receiver">Receiver</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.receiverStream.T">T</span>]</span>)</span><span class="result">: <a href="JavaReceiverInputDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaReceiverInputDStream">JavaReceiverInputDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.receiverStream.T">T</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream with any arbitrary user implemented receiver.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream with any arbitrary user implemented receiver.
Find more details at: http://spark.apache.org/docs/latest/streaming-custom-receivers.html</p></div><dl class="paramcmts block"><dt class="param">receiver</dt><dd class="cmt"><p>Custom implementation of Receiver
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#remember" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="remember(duration:org.apache.spark.streaming.Duration):Unit"></a>
      <a id="remember(Duration):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">remember</span><span class="params">(<span name="duration">duration: <a href="../../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Sets each DStreams in this context to remember RDDs it generated in the last given duration.</p><div class="fullcomment"><div class="comment cmt"><p>Sets each DStreams in this context to remember RDDs it generated in the last given duration.
DStreams remember RDDs only for a limited duration of duration and releases them for garbage
collection. This method allows the developer to specify how long to remember the RDDs (
if the developer wishes to query old data outside the DStream computation).</p></div><dl class="paramcmts block"><dt class="param">duration</dt><dd class="cmt"><p>Minimum duration that each DStream should remember its RDDs
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#socketStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="socketStream[T](hostname:String,port:Int,converter:org.apache.spark.api.java.function.Function[java.io.InputStream,Iterable[T]],storageLevel:org.apache.spark.storage.StorageLevel):org.apache.spark.streaming.api.java.JavaReceiverInputDStream[T]"></a>
      <a id="socketStream[T](String,Int,Function[InputStream,Iterable[T]],StorageLevel):JavaReceiverInputDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">socketStream</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="hostname">hostname: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="port">port: <span class="extype" name="scala.Int">Int</span></span>, <span name="converter">converter: <a href="../../../api/java/function/Function.html" class="extype" name="org.apache.spark.api.java.function.Function">Function</a>[<span class="extype" name="java.io.InputStream">InputStream</span>, <span class="extype" name="java.lang.Iterable">Iterable</span>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.socketStream.T">T</span>]]</span>, <span name="storageLevel">storageLevel: <a href="../../../storage/StorageLevel.html" class="extype" name="org.apache.spark.storage.StorageLevel">StorageLevel</a></span>)</span><span class="result">: <a href="JavaReceiverInputDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaReceiverInputDStream">JavaReceiverInputDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.socketStream.T">T</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream from network source hostname:port.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream from network source hostname:port. Data is received using
a TCP socket and the receive bytes it interpreted as object using the given
converter.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>Type of the objects received (after converting bytes to objects)
</p></dd><dt class="param">hostname</dt><dd class="cmt"><p>Hostname to connect to for receiving data</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port to connect to for receiving data</p></dd><dt class="param">converter</dt><dd class="cmt"><p>Function to convert the byte stream to objects</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#socketTextStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="socketTextStream(hostname:String,port:Int):org.apache.spark.streaming.api.java.JavaReceiverInputDStream[String]"></a>
      <a id="socketTextStream(String,Int):JavaReceiverInputDStream[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">socketTextStream</span><span class="params">(<span name="hostname">hostname: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="port">port: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="JavaReceiverInputDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaReceiverInputDStream">JavaReceiverInputDStream</a>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream from network source hostname:port.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream from network source hostname:port. Data is received using
a TCP socket and the receive bytes is interpreted as UTF8 encoded \n delimited
lines. Storage level of the data will be the default StorageLevel.MEMORY_AND_DISK_SER_2.</p></div><dl class="paramcmts block"><dt class="param">hostname</dt><dd class="cmt"><p>Hostname to connect to for receiving data</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port to connect to for receiving data
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#socketTextStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="socketTextStream(hostname:String,port:Int,storageLevel:org.apache.spark.storage.StorageLevel):org.apache.spark.streaming.api.java.JavaReceiverInputDStream[String]"></a>
      <a id="socketTextStream(String,Int,StorageLevel):JavaReceiverInputDStream[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">socketTextStream</span><span class="params">(<span name="hostname">hostname: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="port">port: <span class="extype" name="scala.Int">Int</span></span>, <span name="storageLevel">storageLevel: <a href="../../../storage/StorageLevel.html" class="extype" name="org.apache.spark.storage.StorageLevel">StorageLevel</a></span>)</span><span class="result">: <a href="JavaReceiverInputDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaReceiverInputDStream">JavaReceiverInputDStream</a>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream from network source hostname:port.</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream from network source hostname:port. Data is received using
a TCP socket and the receive bytes is interpreted as UTF8 encoded \n delimited
lines.</p></div><dl class="paramcmts block"><dt class="param">hostname</dt><dd class="cmt"><p>Hostname to connect to for receiving data</p></dd><dt class="param">port</dt><dd class="cmt"><p>Port to connect to for receiving data</p></dd><dt class="param">storageLevel</dt><dd class="cmt"><p>Storage level to use for storing the received objects
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#sparkContext" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="sparkContext:org.apache.spark.api.java.JavaSparkContext"></a>
      <a id="sparkContext:JavaSparkContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">sparkContext</span><span class="result">: <a href="../../../api/java/JavaSparkContext.html" class="extype" name="org.apache.spark.api.java.JavaSparkContext">JavaSparkContext</a></span>
      </span>
      </h4>
      <p class="shortcomment cmt">The underlying SparkContext</p>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#ssc" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="ssc:org.apache.spark.streaming.StreamingContext"></a>
      <a id="ssc:StreamingContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name">ssc</span><span class="result">: <a href="../../StreamingContext.html" class="extype" name="org.apache.spark.streaming.StreamingContext">StreamingContext</a></span>
      </span>
      </h4>
      
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#start" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="start():Unit"></a>
      <a id="start():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">start</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Start the execution of the streams.</p>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#stop" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="stop(stopSparkContext:Boolean,stopGracefully:Boolean):Unit"></a>
      <a id="stop(Boolean,Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">stop</span><span class="params">(<span name="stopSparkContext">stopSparkContext: <span class="extype" name="scala.Boolean">Boolean</span></span>, <span name="stopGracefully">stopGracefully: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Stop the execution of the streams.</p><div class="fullcomment"><div class="comment cmt"><p>Stop the execution of the streams.</p></div><dl class="paramcmts block"><dt class="param">stopSparkContext</dt><dd class="cmt"><p>Stop the associated SparkContext or not</p></dd><dt class="param">stopGracefully</dt><dd class="cmt"><p>Stop gracefully by waiting for the processing of all
                      received data to be completed
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#stop" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="stop(stopSparkContext:Boolean):Unit"></a>
      <a id="stop(Boolean):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">stop</span><span class="params">(<span name="stopSparkContext">stopSparkContext: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Stop the execution of the streams.</p><div class="fullcomment"><div class="comment cmt"><p>Stop the execution of the streams.</p></div><dl class="paramcmts block"><dt class="param">stopSparkContext</dt><dd class="cmt"><p>Stop the associated SparkContext or not
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#stop" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="stop():Unit"></a>
      <a id="stop():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">stop</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Stop the execution of the streams.</p><div class="fullcomment"><div class="comment cmt"><p>Stop the execution of the streams. Will stop the associated JavaSparkContext as well.
</p></div></div>
    </li><li name="scala.AnyRef#synchronized" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="synchronized[T0](x$1:=&gt;T0):T0"></a>
      <a id="synchronized[T0](⇒T0):T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: ⇒ <span class="extype" name="java.lang.AnyRef.synchronized.T0">T0</span></span>)</span><span class="result">: <span class="extype" name="java.lang.AnyRef.synchronized.T0">T0</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#textFileStream" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="textFileStream(directory:String):org.apache.spark.streaming.api.java.JavaDStream[String]"></a>
      <a id="textFileStream(String):JavaDStream[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">textFileStream</span><span class="params">(<span name="directory">directory: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <a href="JavaDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaDStream">JavaDStream</a>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create an input stream that monitors a Hadoop-compatible filesystem
for new files and reads them as text files (using key as LongWritable, value
as Text and input format as TextInputFormat).</p><div class="fullcomment"><div class="comment cmt"><p>Create an input stream that monitors a Hadoop-compatible filesystem
for new files and reads them as text files (using key as LongWritable, value
as Text and input format as TextInputFormat). Files must be written to the
monitored directory by &quot;moving&quot; them from another location within the same
file system. File names starting with . are ignored.</p></div><dl class="paramcmts block"><dt class="param">directory</dt><dd class="cmt"><p>HDFS directory to monitor for new file
</p></dd></dl></div>
    </li><li name="scala.AnyRef#toString" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="toString():String"></a>
      <a id="toString():String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toString</span><span class="params">()</span><span class="result">: <span class="extype" name="java.lang.String">String</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#transform" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="transform[T](dstreams:java.util.List[org.apache.spark.streaming.api.java.JavaDStream[_]],transformFunc:org.apache.spark.api.java.function.Function2[java.util.List[org.apache.spark.api.java.JavaRDD[_]],org.apache.spark.streaming.Time,org.apache.spark.api.java.JavaRDD[T]]):org.apache.spark.streaming.api.java.JavaDStream[T]"></a>
      <a id="transform[T](List[JavaDStream[_]],Function2[List[JavaRDD[_]],Time,JavaRDD[T]]):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">transform</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="dstreams">dstreams: <span class="extype" name="java.util.List">List</span>[<a href="JavaDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaDStream">JavaDStream</a>[_]]</span>, <span name="transformFunc">transformFunc: <a href="../../../api/java/function/Function2.html" class="extype" name="org.apache.spark.api.java.function.Function2">Function2</a>[<span class="extype" name="java.util.List">List</span>[<a href="../../../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[_]], <a href="../../Time.html" class="extype" name="org.apache.spark.streaming.Time">Time</a>, <a href="../../../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.transform.T">T</span>]]</span>)</span><span class="result">: <a href="JavaDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaDStream">JavaDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.transform.T">T</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a new DStream in which each RDD is generated by applying a function on RDDs of
the DStreams.</p><div class="fullcomment"><div class="comment cmt"><p>Create a new DStream in which each RDD is generated by applying a function on RDDs of
the DStreams. The order of the JavaRDDs in the transform function parameter will be the
same as the order of corresponding DStreams in the list. Note that for adding a
JavaPairDStream in the list of JavaDStreams, convert it to a JavaDStream using
<a href="JavaPairDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaPairDStream">org.apache.spark.streaming.api.java.JavaPairDStream</a>.toJavaDStream().
In the transform function, convert the JavaRDD corresponding to that JavaDStream to
a JavaPairRDD using org.apache.spark.api.java.JavaPairRDD.fromJavaRDD().
</p></div></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#transformToPair" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="transformToPair[K,V](dstreams:java.util.List[org.apache.spark.streaming.api.java.JavaDStream[_]],transformFunc:org.apache.spark.api.java.function.Function2[java.util.List[org.apache.spark.api.java.JavaRDD[_]],org.apache.spark.streaming.Time,org.apache.spark.api.java.JavaPairRDD[K,V]]):org.apache.spark.streaming.api.java.JavaPairDStream[K,V]"></a>
      <a id="transformToPair[K,V](List[JavaDStream[_]],Function2[List[JavaRDD[_]],Time,JavaPairRDD[K,V]]):JavaPairDStream[K,V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">transformToPair</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>]</span><span class="params">(<span name="dstreams">dstreams: <span class="extype" name="java.util.List">List</span>[<a href="JavaDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaDStream">JavaDStream</a>[_]]</span>, <span name="transformFunc">transformFunc: <a href="../../../api/java/function/Function2.html" class="extype" name="org.apache.spark.api.java.function.Function2">Function2</a>[<span class="extype" name="java.util.List">List</span>[<a href="../../../api/java/JavaRDD.html" class="extype" name="org.apache.spark.api.java.JavaRDD">JavaRDD</a>[_]], <a href="../../Time.html" class="extype" name="org.apache.spark.streaming.Time">Time</a>, <a href="../../../api/java/JavaPairRDD.html" class="extype" name="org.apache.spark.api.java.JavaPairRDD">JavaPairRDD</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.transformToPair.K">K</span>, <span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.transformToPair.V">V</span>]]</span>)</span><span class="result">: <a href="JavaPairDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaPairDStream">JavaPairDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.transformToPair.K">K</span>, <span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.transformToPair.V">V</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a new DStream in which each RDD is generated by applying a function on RDDs of
the DStreams.</p><div class="fullcomment"><div class="comment cmt"><p>Create a new DStream in which each RDD is generated by applying a function on RDDs of
the DStreams. The order of the JavaRDDs in the transform function parameter will be the
same as the order of corresponding DStreams in the list. Note that for adding a
JavaPairDStream in the list of JavaDStreams, convert it to a JavaDStream using
<a href="JavaPairDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaPairDStream">org.apache.spark.streaming.api.java.JavaPairDStream</a>.toJavaDStream().
In the transform function, convert the JavaRDD corresponding to that JavaDStream to
a JavaPairRDD using org.apache.spark.api.java.JavaPairRDD.fromJavaRDD().
</p></div></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#union" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="union[K,V](first:org.apache.spark.streaming.api.java.JavaPairDStream[K,V],rest:java.util.List[org.apache.spark.streaming.api.java.JavaPairDStream[K,V]]):org.apache.spark.streaming.api.java.JavaPairDStream[K,V]"></a>
      <a id="union[K,V](JavaPairDStream[K,V],List[JavaPairDStream[K,V]]):JavaPairDStream[K,V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">union</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>]</span><span class="params">(<span name="first">first: <a href="JavaPairDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaPairDStream">JavaPairDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.union.K">K</span>, <span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.union.V">V</span>]</span>, <span name="rest">rest: <span class="extype" name="java.util.List">List</span>[<a href="JavaPairDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaPairDStream">JavaPairDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.union.K">K</span>, <span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.union.V">V</span>]]</span>)</span><span class="result">: <a href="JavaPairDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaPairDStream">JavaPairDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.union.K">K</span>, <span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.union.V">V</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a unified DStream from multiple DStreams of the same type and same slide duration.</p>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#union" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="union[T](first:org.apache.spark.streaming.api.java.JavaDStream[T],rest:java.util.List[org.apache.spark.streaming.api.java.JavaDStream[T]]):org.apache.spark.streaming.api.java.JavaDStream[T]"></a>
      <a id="union[T](JavaDStream[T],List[JavaDStream[T]]):JavaDStream[T]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">union</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="first">first: <a href="JavaDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaDStream">JavaDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.union.T">T</span>]</span>, <span name="rest">rest: <span class="extype" name="java.util.List">List</span>[<a href="JavaDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaDStream">JavaDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.union.T">T</span>]]</span>)</span><span class="result">: <a href="JavaDStream.html" class="extype" name="org.apache.spark.streaming.api.java.JavaDStream">JavaDStream</a>[<span class="extype" name="org.apache.spark.streaming.api.java.JavaStreamingContext.union.T">T</span>]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a unified DStream from multiple DStreams of the same type and same slide duration.</p>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait():Unit"></a>
      <a id="wait():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait(x$1:Long,x$2:Int):Unit"></a>
      <a id="wait(Long,Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Long">Long</span></span>, <span name="arg1">arg1: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait(x$1:Long):Unit"></a>
      <a id="wait(Long):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li></ol>
            </div>

        

        <div id="values" class="values members">
              <h3>Deprecated Value Members</h3>
              <ol><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#awaitTermination" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="awaitTermination(timeout:Long):Unit"></a>
      <a id="awaitTermination(Long):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 1.3.0) Use awaitTerminationOrTimeout(Long) instead">awaitTermination</span><span class="params">(<span name="timeout">timeout: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Wait for the execution to stop.</p><div class="fullcomment"><div class="comment cmt"><p>Wait for the execution to stop. Any exceptions that occurs during the execution
will be thrown in this thread.</p></div><dl class="paramcmts block"><dt class="param">timeout</dt><dd class="cmt"><p>time to wait in milliseconds
</p></dd></dl><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 1.3.0)</i> Use awaitTerminationOrTimeout(Long) instead</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.api.java.JavaStreamingContext#sc" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="sc:org.apache.spark.api.java.JavaSparkContext"></a>
      <a id="sc:JavaSparkContext"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">val</span>
      </span>
      <span class="symbol">
        <span class="name deprecated" title="Deprecated: (Since version 0.9.0) use sparkContext">sc</span><span class="result">: <a href="../../../api/java/JavaSparkContext.html" class="extype" name="org.apache.spark.api.java.JavaSparkContext">JavaSparkContext</a></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Annotations</dt><dd>
                <span class="name">@deprecated</span>
              
        </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 0.9.0)</i> use sparkContext</p></dd></dl></div>
    </li></ol>
            </div>
        </div>

        <div id="inheritedMembers">
        <div class="parent" name="java.io.Closeable">
              <h3>Inherited from <span class="extype" name="java.io.Closeable">Closeable</span></h3>
            </div><div class="parent" name="java.lang.AutoCloseable">
              <h3>Inherited from <span class="extype" name="java.lang.AutoCloseable">AutoCloseable</span></h3>
            </div><div class="parent" name="scala.AnyRef">
              <h3>Inherited from <span class="extype" name="scala.AnyRef">AnyRef</span></h3>
            </div><div class="parent" name="scala.Any">
              <h3>Inherited from <span class="extype" name="scala.Any">Any</span></h3>
            </div>
        
        </div>

        <div id="groupedMembers">
        <div class="group" name="Ungrouped">
              <h3>Ungrouped</h3>
              
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>
      <script defer="defer" type="text/javascript" id="jquery-js" src="../../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" id="jquery-ui-js" src="../../../../../../lib/jquery-ui.js"></script><script defer="defer" type="text/javascript" id="tools-tooltip-js" src="../../../../../../lib/tools.tooltip.js"></script><script defer="defer" type="text/javascript" id="template-js" src="../../../../../../lib/template.js"></script>
    </body>
      </html>