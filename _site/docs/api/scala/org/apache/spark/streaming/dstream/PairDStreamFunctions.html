<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html>
        <head>
          <title>PairDStreamFunctions - org.apache.spark.streaming.dstream.PairDStreamFunctions</title>
          <meta name="description" content="PairDStreamFunctions - org.apache.spark.streaming.dstream.PairDStreamFunctions" />
          <meta name="keywords" content="PairDStreamFunctions org.apache.spark.streaming.dstream.PairDStreamFunctions" />
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      <link href="../../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css" />
      <script type="text/javascript">
         if(top === self) {
            var url = '../../../../../index.html';
            var hash = 'org.apache.spark.streaming.dstream.PairDStreamFunctions';
            var anchor = window.location.hash;
            var anchor_opt = '';
            if (anchor.length >= 1)
              anchor_opt = '@' + anchor.substring(1);
            window.location.href = url + '#' + hash + anchor_opt;
         }
   	  </script>
    
        </head>
        <body class="type">
      <div id="definition">
        <img src="../../../../../lib/class_big.png" />
        <p id="owner"><a href="../../../../package.html" class="extype" name="org">org</a>.<a href="../../../package.html" class="extype" name="org.apache">apache</a>.<a href="../../package.html" class="extype" name="org.apache.spark">spark</a>.<a href="../package.html" class="extype" name="org.apache.spark.streaming">streaming</a>.<a href="package.html" class="extype" name="org.apache.spark.streaming.dstream">dstream</a></p>
        <h1>PairDStreamFunctions</h1>
      </div>

      <h4 id="signature" class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <span class="name">PairDStreamFunctions</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>]</span><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      </h4>
      
          <div id="comment" class="fullcommenttop"><div class="comment cmt"><p>Extra functions available on DStream of (key, value) pairs through an implicit conversion.
</p></div><div class="toggleContainer block">
          <span class="toggle">Linear Supertypes</span>
          <div class="superTypes hiddenContent"><span class="extype" name="scala.Serializable">Serializable</span>, <span class="extype" name="java.io.Serializable">Serializable</span>, <span class="extype" name="scala.AnyRef">AnyRef</span>, <span class="extype" name="scala.Any">Any</span></div>
        </div></div>
        

      <div id="mbrsel">
        <div id="textfilter"><span class="pre"></span><span class="input"><input id="mbrsel-input" type="text" accesskey="/" /></span><span class="post"></span></div>
        <div id="order">
              <span class="filtertype">Ordering</span>
              <ol>
                
                <li class="alpha in"><span>Alphabetic</span></li>
                <li class="inherit out"><span>By inheritance</span></li>
              </ol>
            </div>
        <div id="ancestors">
                <span class="filtertype">Inherited<br />
                </span>
                <ol id="linearization">
                  <li class="in" name="org.apache.spark.streaming.dstream.PairDStreamFunctions"><span>PairDStreamFunctions</span></li><li class="in" name="scala.Serializable"><span>Serializable</span></li><li class="in" name="java.io.Serializable"><span>Serializable</span></li><li class="in" name="scala.AnyRef"><span>AnyRef</span></li><li class="in" name="scala.Any"><span>Any</span></li>
                </ol>
              </div><div id="ancestors">
            <span class="filtertype"></span>
            <ol>
              <li class="hideall out"><span>Hide All</span></li>
              <li class="showall in"><span>Show all</span></li>
            </ol>
            <a href="http://docs.scala-lang.org/overviews/scaladoc/usage.html#members" target="_blank">Learn more about member selection</a>
          </div>
        <div id="visbl">
            <span class="filtertype">Visibility</span>
            <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
          </div>
      </div>

      <div id="template">
        <div id="allMembers">
        <div id="constructors" class="members">
              <h3>Instance Constructors</h3>
              <ol><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#&lt;init&gt;" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="&lt;init&gt;(self:org.apache.spark.streaming.dstream.DStream[(K,V)])(implicitkt:scala.reflect.ClassTag[K],implicitvt:scala.reflect.ClassTag[V],implicitord:Ordering[K]):org.apache.spark.streaming.dstream.PairDStreamFunctions[K,V]"></a>
      <a id="&lt;init&gt;:PairDStreamFunctions[K,V]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">new</span>
      </span>
      <span class="symbol">
        <span class="name">PairDStreamFunctions</span><span class="params">(<span name="self">self: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="kt">kt: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>]</span>, <span name="vt">vt: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>]</span>, <span name="ord">ord: <span class="extype" name="scala.Ordering">Ordering</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>]</span>)</span>
      </span>
      </h4>
      
    </li></ol>
            </div>

        

        

        <div id="values" class="values members">
              <h3>Value Members</h3>
              <ol><li name="scala.AnyRef#!=" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="!=(x$1:AnyRef):Boolean"></a>
      <a id="!=(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $bang$eq" class="name">!=</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.Any#!=" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="!=(x$1:Any):Boolean"></a>
      <a id="!=(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $bang$eq" class="name">!=</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="scala.AnyRef###" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="##():Int"></a>
      <a id="##():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $hash$hash" class="name">##</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef#==" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="==(x$1:AnyRef):Boolean"></a>
      <a id="==(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $eq$eq" class="name">==</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.Any#==" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="==(x$1:Any):Boolean"></a>
      <a id="==(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $eq$eq" class="name">==</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="scala.Any#asInstanceOf" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="asInstanceOf[T0]:T0"></a>
      <a id="asInstanceOf[T0]:T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span class="extype" name="scala.Any.asInstanceOf.T0">T0</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="scala.AnyRef#clone" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="clone():Object"></a>
      <a id="clone():AnyRef"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">clone</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.AnyRef">AnyRef</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../../../../../java$lang.html" class="extype" name="java.lang">java.lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.CloneNotSupportedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#cogroup" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="cogroup[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$12:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Iterable[V],Iterable[W]))]"></a>
      <a id="cogroup[W](DStream[(K,W)],Partitioner)(ClassTag[W]):DStream[(K,(Iterable[V],Iterable[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cogroup</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W">W</span>)]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="scala.Iterable">Iterable</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="scala.Iterable">Iterable</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W">W</span>]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
The supplied org.apache.spark.Partitioner is used to partition the generated RDDs.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#cogroup" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="cogroup[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$11:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Iterable[V],Iterable[W]))]"></a>
      <a id="cogroup[W](DStream[(K,W)],Int)(ClassTag[W]):DStream[(K,(Iterable[V],Iterable[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cogroup</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W">W</span>)]</span>, <span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="scala.Iterable">Iterable</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="scala.Iterable">Iterable</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W">W</span>]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#cogroup" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="cogroup[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$10:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Iterable[V],Iterable[W]))]"></a>
      <a id="cogroup[W](DStream[(K,W)])(ClassTag[W]):DStream[(K,(Iterable[V],Iterable[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">cogroup</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W">W</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="scala.Iterable">Iterable</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="scala.Iterable">Iterable</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W">W</span>]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
Hash partitioning is used to generate the RDDs with Spark's default number
of partitions.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#combineByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="combineByKey[C](createCombiner:V=&gt;C,mergeValue:(C,V)=&gt;C,mergeCombiner:(C,C)=&gt;C,partitioner:org.apache.spark.Partitioner,mapSideCombine:Boolean)(implicitevidence$1:scala.reflect.ClassTag[C]):org.apache.spark.streaming.dstream.DStream[(K,C)]"></a>
      <a id="combineByKey[C]((V)⇒C,(C,V)⇒C,(C,C)⇒C,Partitioner,Boolean)(ClassTag[C]):DStream[(K,C)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">combineByKey</span><span class="tparams">[<span name="C">C</span>]</span><span class="params">(<span name="createCombiner">createCombiner: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C">C</span></span>, <span name="mergeValue">mergeValue: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C">C</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C">C</span></span>, <span name="mergeCombiner">mergeCombiner: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C">C</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C">C</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C">C</span></span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>, <span name="mapSideCombine">mapSideCombine: <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">true</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C">C</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C">C</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Combine elements of each key in DStream's RDDs using custom functions.</p><div class="fullcomment"><div class="comment cmt"><p>Combine elements of each key in DStream's RDDs using custom functions. This is similar to the
combineByKey for RDDs. Please refer to combineByKey in
org.apache.spark.rdd.PairRDDFunctions in the Spark core documentation for more information.
</p></div></div>
    </li><li name="scala.AnyRef#eq" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="eq(x$1:AnyRef):Boolean"></a>
      <a id="eq(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">eq</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#equals" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="equals(x$1:Any):Boolean"></a>
      <a id="equals(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef#finalize" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="finalize():Unit"></a>
      <a id="finalize():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">finalize</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../../../../../java$lang.html" class="extype" name="java.lang">java.lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="symbol">classOf[java.lang.Throwable]</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#flatMapValues" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="flatMapValues[U](flatMapValuesFunc:V=&gt;TraversableOnce[U])(implicitevidence$9:scala.reflect.ClassTag[U]):org.apache.spark.streaming.dstream.DStream[(K,U)]"></a>
      <a id="flatMapValues[U]((V)⇒TraversableOnce[U])(ClassTag[U]):DStream[(K,U)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">flatMapValues</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="flatMapValuesFunc">flatMapValuesFunc: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="scala.TraversableOnce">TraversableOnce</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.flatMapValues.U">U</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.flatMapValues.U">U</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.flatMapValues.U">U</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying a flatmap function to the value of each key-value pairs in
'this' DStream without changing the key.</p>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#fullOuterJoin" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="fullOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$24:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],Option[W]))]"></a>
      <a id="fullOuterJoin[W](DStream[(K,W)],Partitioner)(ClassTag[W]):DStream[(K,(Option[V],Option[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">fullOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W">W</span>)]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W">W</span>]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
the partitioning of each RDD.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#fullOuterJoin" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="fullOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$23:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],Option[W]))]"></a>
      <a id="fullOuterJoin[W](DStream[(K,W)],Int)(ClassTag[W]):DStream[(K,(Option[V],Option[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">fullOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W">W</span>)]</span>, <span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W">W</span>]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
partitions.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#fullOuterJoin" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="fullOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$22:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],Option[W]))]"></a>
      <a id="fullOuterJoin[W](DStream[(K,W)])(ClassTag[W]):DStream[(K,(Option[V],Option[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">fullOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W">W</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W">W</span>]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
number of partitions.
</p></div></div>
    </li><li name="scala.AnyRef#getClass" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getClass():Class[_]"></a>
      <a id="getClass():Class[_]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getClass</span><span class="params">()</span><span class="result">: <span class="extype" name="java.lang.Class">Class</span>[_]</span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#groupByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="groupByKey(partitioner:org.apache.spark.Partitioner):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]"></a>
      <a id="groupByKey(Partitioner):DStream[(K,Iterable[V])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKey</span><span class="params">(<span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="scala.Iterable">Iterable</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> on each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> on each RDD. The supplied
org.apache.spark.Partitioner is used to control the partitioning of each RDD.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#groupByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="groupByKey(numPartitions:Int):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]"></a>
      <a id="groupByKey(Int):DStream[(K,Iterable[V])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKey</span><span class="params">(<span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="scala.Iterable">Iterable</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> to each RDD. Hash partitioning is used to
generate the RDDs with <code>numPartitions</code> partitions.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#groupByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="groupByKey():org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]"></a>
      <a id="groupByKey():DStream[(K,Iterable[V])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKey</span><span class="params">()</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="scala.Iterable">Iterable</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> to each RDD. Hash partitioning is used to
generate the RDDs with Spark's default number of partitions.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#groupByKeyAndWindow" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="groupByKeyAndWindow(windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,partitioner:org.apache.spark.Partitioner):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]"></a>
      <a id="groupByKeyAndWindow(Duration,Duration,Partitioner):DStream[(K,Iterable[V])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="scala.Iterable">Iterable</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Create a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Create a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
Similar to <code>DStream.groupByKey()</code>, but applies it over a sliding window.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>partitioner for controlling the partitioning of each RDD in the new
                      DStream.
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#groupByKeyAndWindow" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="groupByKeyAndWindow(windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,numPartitions:Int):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]"></a>
      <a id="groupByKeyAndWindow(Duration,Duration,Int):DStream[(K,Iterable[V])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="scala.Iterable">Iterable</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
Similar to <code>DStream.groupByKey()</code>, but applies it over a sliding window.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>number of partitions of each RDD in the new DStream; if not specified
                      then Spark's default number of partitions will be used
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#groupByKeyAndWindow" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="groupByKeyAndWindow(windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]"></a>
      <a id="groupByKeyAndWindow(Duration,Duration):DStream[(K,Iterable[V])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="scala.Iterable">Iterable</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> over a sliding window. Similar to
<code>DStream.groupByKey()</code>, but applies it over a sliding window. Hash partitioning is used to
generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#groupByKeyAndWindow" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="groupByKeyAndWindow(windowDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]"></a>
      <a id="groupByKeyAndWindow(Duration):DStream[(K,Iterable[V])]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="scala.Iterable">Iterable</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>])]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> over a sliding window. This is similar to
<code>DStream.groupByKey()</code> but applies it over a sliding window. The new DStream generates RDDs
with the same interval as this DStream. Hash partitioning is used to generate the RDDs with
Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval
</p></dd></dl></div>
    </li><li name="scala.AnyRef#hashCode" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="hashCode():Int"></a>
      <a id="hashCode():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">hashCode</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.Any#isInstanceOf" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="isInstanceOf[T0]:Boolean"></a>
      <a id="isInstanceOf[T0]:Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#join" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="join[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$15:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,W))]"></a>
      <a id="join[W](DStream[(K,W)],Partitioner)(ClassTag[W]):DStream[(K,(V,W))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W">W</span>)]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W">W</span>))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
The supplied org.apache.spark.Partitioner is used to control the partitioning of each RDD.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#join" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="join[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$14:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,W))]"></a>
      <a id="join[W](DStream[(K,W)],Int)(ClassTag[W]):DStream[(K,(V,W))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W">W</span>)]</span>, <span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W">W</span>))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#join" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="join[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$13:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,W))]"></a>
      <a id="join[W](DStream[(K,W)])(ClassTag[W]):DStream[(K,(V,W))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">join</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W">W</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W">W</span>))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
Hash partitioning is used to generate the RDDs with Spark's default number of partitions.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#leftOuterJoin" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="leftOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$18:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,Option[W]))]"></a>
      <a id="leftOuterJoin[W](DStream[(K,W)],Partitioner)(ClassTag[W]):DStream[(K,(V,Option[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">leftOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W">W</span>)]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W">W</span>]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
the partitioning of each RDD.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#leftOuterJoin" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="leftOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$17:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,Option[W]))]"></a>
      <a id="leftOuterJoin[W](DStream[(K,W)],Int)(ClassTag[W]):DStream[(K,(V,Option[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">leftOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W">W</span>)]</span>, <span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W">W</span>]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
partitions.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#leftOuterJoin" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="leftOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$16:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,Option[W]))]"></a>
      <a id="leftOuterJoin[W](DStream[(K,W)])(ClassTag[W]):DStream[(K,(V,Option[W]))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">leftOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W">W</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W">W</span>]))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
number of partitions.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#mapValues" visbl="pub" data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="mapValues[U](mapValuesFunc:V=&gt;U)(implicitevidence$8:scala.reflect.ClassTag[U]):org.apache.spark.streaming.dstream.DStream[(K,U)]"></a>
      <a id="mapValues[U]((V)⇒U)(ClassTag[U]):DStream[(K,U)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">mapValues</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="mapValuesFunc">mapValuesFunc: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.mapValues.U">U</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.mapValues.U">U</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.mapValues.U">U</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying a map function to the value of each key-value pairs in
'this' DStream without changing the key.</p>
    </li><li name="scala.AnyRef#ne" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ne(x$1:AnyRef):Boolean"></a>
      <a id="ne(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">ne</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#notify" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="notify():Unit"></a>
      <a id="notify():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notify</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#notifyAll" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="notifyAll():Unit"></a>
      <a id="notifyAll():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="reduceByKey(reduceFunc:(V,V)=&gt;V,partitioner:org.apache.spark.Partitioner):org.apache.spark.streaming.dstream.DStream[(K,V)]"></a>
      <a id="reduceByKey((V,V)⇒V,Partitioner):DStream[(K,V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKey</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span></span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
merged using the supplied reduce function. org.apache.spark.Partitioner is used to control
the partitioning of each RDD.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="reduceByKey(reduceFunc:(V,V)=&gt;V,numPartitions:Int):org.apache.spark.streaming.dstream.DStream[(K,V)]"></a>
      <a id="reduceByKey((V,V)⇒V,Int):DStream[(K,V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKey</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span></span>, <span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
merged using the supplied reduce function. Hash partitioning is used to generate the RDDs
with <code>numPartitions</code> partitions.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="reduceByKey(reduceFunc:(V,V)=&gt;V):org.apache.spark.streaming.dstream.DStream[(K,V)]"></a>
      <a id="reduceByKey((V,V)⇒V):DStream[(K,V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKey</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
merged using the associative reduce function. Hash partitioning is used to generate the RDDs
with Spark's default number of partitions.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKeyAndWindow" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,invReduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,partitioner:org.apache.spark.Partitioner,filterFunc:((K,V))=&gt;Boolean):org.apache.spark.streaming.dstream.DStream[(K,V)]"></a>
      <a id="reduceByKeyAndWindow((V,V)⇒V,(V,V)⇒V,Duration,Duration,Partitioner,((K,V))⇒Boolean):DStream[(K,V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span></span>, <span name="invReduceFunc">invReduceFunc: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span></span>, <span name="windowDuration">windowDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>, <span name="filterFunc">filterFunc: ((<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>)) ⇒ <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
The reduced value of over a new window is calculated using the old window's reduced value :</p><ol class="decimal"><li>reduce the new values that entered the window (e.g., adding new counts)
 2. &quot;inverse reduce&quot; the old values that left the window (e.g., subtracting old counts)
This is more efficient than reduceByKeyAndWindow without &quot;inverse reduce&quot; function.
However, it is applicable to only &quot;invertible reduce functions&quot;.</li></ol></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">invReduceFunc</dt><dd class="cmt"><p>inverse reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>partitioner for controlling the partitioning of each RDD in the new
                      DStream.</p></dd><dt class="param">filterFunc</dt><dd class="cmt"><p>Optional function to filter expired key-value pairs;
                      only pairs that satisfy the function are retained
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKeyAndWindow" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,invReduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,numPartitions:Int,filterFunc:((K,V))=&gt;Boolean):org.apache.spark.streaming.dstream.DStream[(K,V)]"></a>
      <a id="reduceByKeyAndWindow((V,V)⇒V,(V,V)⇒V,Duration,Duration,Int,((K,V))⇒Boolean):DStream[(K,V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span></span>, <span name="invReduceFunc">invReduceFunc: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span></span>, <span name="windowDuration">windowDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a> = <span class="symbol"><span class="name"><a href="DStream.html#slideDuration:org.apache.spark.streaming.Duration">self.slideDuration</a></span></span></span>, <span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span> = <span class="symbol"><span class="name"><a href="../../SparkContext.html#defaultParallelism:Int">ssc.sc.defaultParallelism</a></span></span></span>, <span name="filterFunc">filterFunc: ((<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>)) ⇒ <span class="extype" name="scala.Boolean">Boolean</span> = <span class="symbol">null</span></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
The reduced value of over a new window is calculated using the old window's reduced value :</p><ol class="decimal"><li>reduce the new values that entered the window (e.g., adding new counts)</li></ol><p> 2. &quot;inverse reduce&quot; the old values that left the window (e.g., subtracting old counts)</p><p>This is more efficient than reduceByKeyAndWindow without &quot;inverse reduce&quot; function.
However, it is applicable to only &quot;invertible reduce functions&quot;.
Hash partitioning is used to generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">invReduceFunc</dt><dd class="cmt"><p>inverse reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">filterFunc</dt><dd class="cmt"><p>Optional function to filter expired key-value pairs;
                      only pairs that satisfy the function are retained
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKeyAndWindow" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,partitioner:org.apache.spark.Partitioner):org.apache.spark.streaming.dstream.DStream[(K,V)]"></a>
      <a id="reduceByKeyAndWindow((V,V)⇒V,Duration,Duration,Partitioner):DStream[(K,V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span></span>, <span name="windowDuration">windowDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. Similar to
<code>DStream.reduceByKey()</code>, but applies it over a sliding window.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>partitioner for controlling the partitioning of each RDD
                      in the new DStream.
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKeyAndWindow" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,numPartitions:Int):org.apache.spark.streaming.dstream.DStream[(K,V)]"></a>
      <a id="reduceByKeyAndWindow((V,V)⇒V,Duration,Duration,Int):DStream[(K,V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span></span>, <span name="windowDuration">windowDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. This is similar to
<code>DStream.reduceByKey()</code> but applies it over a sliding window. Hash partitioning is used to
generate the RDDs with <code>numPartitions</code> partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>number of partitions of each RDD in the new DStream.
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKeyAndWindow" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.dstream.DStream[(K,V)]"></a>
      <a id="reduceByKeyAndWindow((V,V)⇒V,Duration,Duration):DStream[(K,V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span></span>, <span name="windowDuration">windowDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. This is similar to
<code>DStream.reduceByKey()</code> but applies it over a sliding window. Hash partitioning is used to
generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKeyAndWindow" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.dstream.DStream[(K,V)]"></a>
      <a id="reduceByKeyAndWindow((V,V)⇒V,Duration):DStream[(K,V)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>) ⇒ <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span></span>, <span name="windowDuration">windowDuration: <a href="../Duration.html" class="extype" name="org.apache.spark.streaming.Duration">Duration</a></span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.
Similar to <code>DStream.reduceByKey()</code>, but applies it over a sliding window. The new DStream
generates RDDs with the same interval as this DStream. Hash partitioning is used to generate
the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval
</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#rightOuterJoin" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="rightOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$21:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],W))]"></a>
      <a id="rightOuterJoin[W](DStream[(K,W)],Partitioner)(ClassTag[W]):DStream[(K,(Option[V],W))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rightOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W">W</span>)]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W">W</span>))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
the partitioning of each RDD.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#rightOuterJoin" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="rightOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$20:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],W))]"></a>
      <a id="rightOuterJoin[W](DStream[(K,W)],Int)(ClassTag[W]):DStream[(K,(Option[V],W))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rightOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W">W</span>)]</span>, <span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W">W</span>))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
partitions.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#rightOuterJoin" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="rightOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$19:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],W))]"></a>
      <a id="rightOuterJoin[W](DStream[(K,W)])(ClassTag[W]):DStream[(K,(Option[V],W))]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">rightOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W">W</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W">W</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, (<span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W">W</span>))]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
number of partitions.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#saveAsHadoopFiles" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="saveAsHadoopFiles(prefix:String,suffix:String,keyClass:Class[_],valueClass:Class[_],outputFormatClass:Class[_&lt;:org.apache.hadoop.mapred.OutputFormat[_,_]],conf:org.apache.hadoop.mapred.JobConf):Unit"></a>
      <a id="saveAsHadoopFiles(String,String,Class[_],Class[_],Class[_&lt;:OutputFormat[_,_]],JobConf):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsHadoopFiles</span><span class="params">(<span name="prefix">prefix: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="suffix">suffix: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="keyClass">keyClass: <span class="extype" name="scala.Predef.Class">Class</span>[_]</span>, <span name="valueClass">valueClass: <span class="extype" name="scala.Predef.Class">Class</span>[_]</span>, <span name="outputFormatClass">outputFormatClass: <span class="extype" name="scala.Predef.Class">Class</span>[_ &lt;: <span class="extype" name="org.apache.hadoop.mapred.OutputFormat">OutputFormat</span>[_, _]]</span>, <span name="conf">conf: <span class="extype" name="org.apache.hadoop.mapred.JobConf">JobConf</span> = <span class="defval" name='<span class="name"><a href="../StreamingContext.html#sparkContext:org.apache.spark.SparkContext">new JobConf(ssc.sparkContext.hadoopConfiguration)</a></span>'>...</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval
is generated based on <code>prefix</code> and <code>suffix</code>: &quot;prefix-TIME_IN_MS.suffix&quot;
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#saveAsHadoopFiles" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="saveAsHadoopFiles[F&lt;:org.apache.hadoop.mapred.OutputFormat[K,V]](prefix:String,suffix:String)(implicitfm:scala.reflect.ClassTag[F]):Unit"></a>
      <a id="saveAsHadoopFiles[F&lt;:OutputFormat[K,V]](String,String)(ClassTag[F]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsHadoopFiles</span><span class="tparams">[<span name="F">F &lt;: <span class="extype" name="org.apache.hadoop.mapred.OutputFormat">OutputFormat</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>]</span>]</span><span class="params">(<span name="prefix">prefix: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="suffix">suffix: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="fm">fm: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.saveAsHadoopFiles.F">F</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval
is generated based on <code>prefix</code> and <code>suffix</code>: &quot;prefix-TIME_IN_MS.suffix&quot;
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#saveAsNewAPIHadoopFiles" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="saveAsNewAPIHadoopFiles(prefix:String,suffix:String,keyClass:Class[_],valueClass:Class[_],outputFormatClass:Class[_&lt;:org.apache.hadoop.mapreduce.OutputFormat[_,_]],conf:org.apache.hadoop.conf.Configuration):Unit"></a>
      <a id="saveAsNewAPIHadoopFiles(String,String,Class[_],Class[_],Class[_&lt;:OutputFormat[_,_]],Configuration):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsNewAPIHadoopFiles</span><span class="params">(<span name="prefix">prefix: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="suffix">suffix: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="keyClass">keyClass: <span class="extype" name="scala.Predef.Class">Class</span>[_]</span>, <span name="valueClass">valueClass: <span class="extype" name="scala.Predef.Class">Class</span>[_]</span>, <span name="outputFormatClass">outputFormatClass: <span class="extype" name="scala.Predef.Class">Class</span>[_ &lt;: <span class="extype" name="org.apache.hadoop.mapreduce.OutputFormat">OutputFormat</span>[_, _]]</span>, <span name="conf">conf: <span class="extype" name="org.apache.hadoop.conf.Configuration">Configuration</span> = <span class="defval" name='<span class="name"><a href="../StreamingContext.html#sparkContext:org.apache.spark.SparkContext">ssc.sparkContext.hadoopConfiguration</a></span>'>...</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
generated based on <code>prefix</code> and <code>suffix</code>: &quot;prefix-TIME_IN_MS.suffix&quot;.
</p></div></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#saveAsNewAPIHadoopFiles" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="saveAsNewAPIHadoopFiles[F&lt;:org.apache.hadoop.mapreduce.OutputFormat[K,V]](prefix:String,suffix:String)(implicitfm:scala.reflect.ClassTag[F]):Unit"></a>
      <a id="saveAsNewAPIHadoopFiles[F&lt;:OutputFormat[K,V]](String,String)(ClassTag[F]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsNewAPIHadoopFiles</span><span class="tparams">[<span name="F">F &lt;: <span class="extype" name="org.apache.hadoop.mapreduce.OutputFormat">OutputFormat</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>]</span>]</span><span class="params">(<span name="prefix">prefix: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="suffix">suffix: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="fm">fm: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.saveAsNewAPIHadoopFiles.F">F</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
generated based on <code>prefix</code> and <code>suffix</code>: &quot;prefix-TIME_IN_MS.suffix&quot;.
</p></div></div>
    </li><li name="scala.AnyRef#synchronized" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="synchronized[T0](x$1:=&gt;T0):T0"></a>
      <a id="synchronized[T0](⇒T0):T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: ⇒ <span class="extype" name="java.lang.AnyRef.synchronized.T0">T0</span></span>)</span><span class="result">: <span class="extype" name="java.lang.AnyRef.synchronized.T0">T0</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#toString" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="toString():String"></a>
      <a id="toString():String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toString</span><span class="params">()</span><span class="result">: <span class="extype" name="java.lang.String">String</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#updateStateByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="updateStateByKey[S](updateFunc:Iterator[(K,Seq[V],Option[S])]=&gt;Iterator[(K,S)],partitioner:org.apache.spark.Partitioner,rememberPartitioner:Boolean,initialRDD:org.apache.spark.rdd.RDD[(K,S)])(implicitevidence$7:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]"></a>
      <a id="updateStateByKey[S]((Iterator[(K,Seq[V],Option[S])])⇒Iterator[(K,S)],Partitioner,Boolean,RDD[(K,S)])(ClassTag[S]):DStream[(K,S)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (<span class="extype" name="scala.Iterator">Iterator</span>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="scala.Seq">Seq</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>])]) ⇒ <span class="extype" name="scala.Iterator">Iterator</span>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>)]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>, <span name="rememberPartitioner">rememberPartitioner: <span class="extype" name="scala.Boolean">Boolean</span></span>, <span name="initialRDD">initialRDD: <a href="../../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.
org.apache.spark.Partitioner is used to control the partitioning of each RDD.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type
</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. Note, that this function may generate a different
                  tuple with a different key than the input key. Therefore keys may be removed
                  or added in this way. It is up to the developer to decide whether to
                  remember the  partitioner despite the key being changed.</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new
                   DStream</p></dd><dt class="param">rememberPartitioner</dt><dd class="cmt"><p>Whether to remember the paritioner object in the generated RDDs.</p></dd><dt class="param">initialRDD</dt><dd class="cmt"><p>initial state value of each key.</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#updateStateByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="updateStateByKey[S](updateFunc:(Seq[V],Option[S])=&gt;Option[S],partitioner:org.apache.spark.Partitioner,initialRDD:org.apache.spark.rdd.RDD[(K,S)])(implicitevidence$6:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]"></a>
      <a id="updateStateByKey[S]((Seq[V],Option[S])⇒Option[S],Partitioner,RDD[(K,S)])(ClassTag[S]):DStream[(K,S)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (<span class="extype" name="scala.Seq">Seq</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>]) ⇒ <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>, <span name="initialRDD">initialRDD: <a href="../../rdd/RDD.html" class="extype" name="org.apache.spark.rdd.RDD">RDD</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of the key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of the key.
org.apache.spark.Partitioner is used to control the partitioning of each RDD.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type
</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new
                   DStream.</p></dd><dt class="param">initialRDD</dt><dd class="cmt"><p>initial state value of each key.</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#updateStateByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="updateStateByKey[S](updateFunc:Iterator[(K,Seq[V],Option[S])]=&gt;Iterator[(K,S)],partitioner:org.apache.spark.Partitioner,rememberPartitioner:Boolean)(implicitevidence$5:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]"></a>
      <a id="updateStateByKey[S]((Iterator[(K,Seq[V],Option[S])])⇒Iterator[(K,S)],Partitioner,Boolean)(ClassTag[S]):DStream[(K,S)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (<span class="extype" name="scala.Iterator">Iterator</span>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="scala.Seq">Seq</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>])]) ⇒ <span class="extype" name="scala.Iterator">Iterator</span>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>)]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>, <span name="rememberPartitioner">rememberPartitioner: <span class="extype" name="scala.Boolean">Boolean</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.
org.apache.spark.Partitioner is used to control the partitioning of each RDD.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type
</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. Note, that this function may generate a different
                  tuple with a different key than the input key. Therefore keys may be removed
                  or added in this way. It is up to the developer to decide whether to
                  remember the partitioner despite the key being changed.</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new
                   DStream</p></dd><dt class="param">rememberPartitioner</dt><dd class="cmt"><p>Whether to remember the paritioner object in the generated RDDs.</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#updateStateByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="updateStateByKey[S](updateFunc:(Seq[V],Option[S])=&gt;Option[S],partitioner:org.apache.spark.Partitioner)(implicitevidence$4:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]"></a>
      <a id="updateStateByKey[S]((Seq[V],Option[S])⇒Option[S],Partitioner)(ClassTag[S]):DStream[(K,S)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (<span class="extype" name="scala.Seq">Seq</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>]) ⇒ <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" class="extype" name="org.apache.spark.Partitioner">Partitioner</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of the key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of the key.
org.apache.spark.Partitioner is used to control the partitioning of each RDD.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type
</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new
                   DStream.</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#updateStateByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="updateStateByKey[S](updateFunc:(Seq[V],Option[S])=&gt;Option[S],numPartitions:Int)(implicitevidence$3:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]"></a>
      <a id="updateStateByKey[S]((Seq[V],Option[S])⇒Option[S],Int)(ClassTag[S]):DStream[(K,S)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (<span class="extype" name="scala.Seq">Seq</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>]) ⇒ <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>]</span>, <span name="numPartitions">numPartitions: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type
</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>Number of partitions of each RDD in the new DStream.</p></dd></dl></div>
    </li><li name="org.apache.spark.streaming.dstream.PairDStreamFunctions#updateStateByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="updateStateByKey[S](updateFunc:(Seq[V],Option[S])=&gt;Option[S])(implicitevidence$2:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]"></a>
      <a id="updateStateByKey[S]((Seq[V],Option[S])⇒Option[S])(ClassTag[S]):DStream[(K,S)]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (<span class="extype" name="scala.Seq">Seq</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V">V</span>], <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>]) ⇒ <span class="extype" name="scala.Option">Option</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span class="extype" name="scala.reflect.ClassTag">ClassTag</span>[<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>]</span>)</span><span class="result">: <a href="DStream.html" class="extype" name="org.apache.spark.streaming.dstream.DStream">DStream</a>[(<span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K">K</span>, <span class="extype" name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S">S</span>)]</span>
      </span>
      </h4>
      <p class="shortcomment cmt">Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new &quot;state&quot; DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.
Hash partitioning is used to generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type
</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait():Unit"></a>
      <a id="wait():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait(x$1:Long,x$2:Int):Unit"></a>
      <a id="wait(Long,Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Long">Long</span></span>, <span name="arg1">arg1: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait(x$1:Long):Unit"></a>
      <a id="wait(Long):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li></ol>
            </div>

        

        
        </div>

        <div id="inheritedMembers">
        <div class="parent" name="scala.Serializable">
              <h3>Inherited from <span class="extype" name="scala.Serializable">Serializable</span></h3>
            </div><div class="parent" name="java.io.Serializable">
              <h3>Inherited from <span class="extype" name="java.io.Serializable">Serializable</span></h3>
            </div><div class="parent" name="scala.AnyRef">
              <h3>Inherited from <span class="extype" name="scala.AnyRef">AnyRef</span></h3>
            </div><div class="parent" name="scala.Any">
              <h3>Inherited from <span class="extype" name="scala.Any">Any</span></h3>
            </div>
        
        </div>

        <div id="groupedMembers">
        <div class="group" name="Ungrouped">
              <h3>Ungrouped</h3>
              
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>
      <script defer="defer" type="text/javascript" id="jquery-js" src="../../../../../lib/jquery.js"></script><script defer="defer" type="text/javascript" id="jquery-ui-js" src="../../../../../lib/jquery-ui.js"></script><script defer="defer" type="text/javascript" id="tools-tooltip-js" src="../../../../../lib/tools.tooltip.js"></script><script defer="defer" type="text/javascript" id="template-js" src="../../../../../lib/template.js"></script>
    </body>
      </html>