/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.spark.sql.streaming

import java.{util => ju}

import scala.collection.JavaConverters._

import org.apache.spark.annotation.Experimental

/**
 * :: Experimental ::
 * A class used to report information about the progress of a [[StreamingQuery]].
 *
 * @param name The query name. This name is unique across all active queries.
 * @param id The query id. This id is unique across
 *          all queries that have been started in the current process.
 * @param timestamp Timestamp (ms) of when this query was generated
 * @param inputRate Current rate (rows/sec) at which data is being generated by all the sources
 * @param processingRate Current rate (rows/sec) at which the query is processing data from
 *                       all the sources
 * @param latency  Current average latency between the data being available in source and the sink
 *                   writing the corresponding output
 * @param sourceStatuses Current statuses of the sources.
 * @param sinkStatus Current status of the sink.
 * @param triggerStatus Low-level detailed status of the last completed/currently active trigger
 * @since 2.0.0
 */
@Experimental
class StreamingQueryStatus private(
  val name: String,
  val id: Long,
  val timestamp: Long,
  val inputRate: Double,
  val processingRate: Double,
  val latency: Option[Double],
  val sourceStatuses: Array[SourceStatus],
  val sinkStatus: SinkStatus,
  val triggerStatus: ju.Map[String, String]) {

  import StreamingQueryStatus._

  override def toString: String = {
    val sourceStatusLines = sourceStatuses.zipWithIndex.map { case (s, i) =>
      s"Source ${i + 1}:" + indent(s.prettyString)
    }
    val sinkStatusLines = sinkStatus.prettyString
    val triggerStatusLines = triggerStatus.asScala.map { case (k, v) => s"$k: $v" }.toSeq.sorted
    val numSources = sourceStatuses.length
    val numSourcesString = s"$numSources source" + { if (numSources > 1) "s" else "" }

    val allLines = s"""
        |Query name: $name
        |Query id: $id
        |Status timestamp: $timestamp
        |Input rate: $inputRate rows/sec
        |Processing rate $processingRate rows/sec
        |Latency: ${latency.getOrElse("-")} ms
        |Trigger status:
        |${indent(triggerStatusLines)}
        |Source statuses [$numSourcesString]:
        |${indent(sourceStatusLines)}
        |Sink status: ${indent(sinkStatusLines)}""".stripMargin

    s"StreamingQueryStatus:${indent(allLines)}"
  }
}

/** Companion object, primarily for creating StreamingQueryInfo instances internally */
private[sql] object StreamingQueryStatus {
  def apply(
      name: String,
      id: Long,
      timestamp: Long,
      inputRate: Double,
      processingRate: Double,
      latency: Option[Double],
      sourceStatuses: Array[SourceStatus],
      sinkStatus: SinkStatus,
      triggerStatus: Map[String, String]): StreamingQueryStatus = {
    new StreamingQueryStatus(name, id, timestamp, inputRate, processingRate,
      latency, sourceStatuses, sinkStatus, triggerStatus.asJava)
  }

  def indent(strings: Iterable[String]): String = strings.map(indent).mkString("\n")
  def indent(string: String): String = string.split("\n").map("    " + _).mkString("\n")
}
