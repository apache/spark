-- Automatically generated by SQLQueryTestSuite
-- !query
SET spark.sql.ansi.enabled = true
-- !query analysis
SetCommand (spark.sql.ansi.enabled,Some(true))


-- !query
SELECT 'Test 1: Builtin function qualification' AS test_name
-- !query analysis
Project [Test 1: Builtin function qualification AS test_name#x]
+- OneRowRelation


-- !query
SELECT abs(-5) AS unqualified
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`abs`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 14,
    "fragment" : "abs(-5)"
  } ]
}


-- !query
SELECT builtin.abs(-5) AS schema_qualified
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`builtin`.`abs`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "builtin.abs(-5)"
  } ]
}


-- !query
SELECT system.builtin.abs(-5) AS fully_qualified
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "REQUIRES_SINGLE_PART_NAMESPACE",
  "sqlState" : "42K05",
  "messageParameters" : {
    "namespace" : "`system`.`builtin`",
    "sessionCatalog" : "spark_catalog"
  }
}


-- !query
SELECT BUILTIN.ABS(-5) AS uppercase
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`BUILTIN`.`ABS`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "BUILTIN.ABS(-5)"
  } ]
}


-- !query
SELECT System.Builtin.Abs(-5) AS mixed_case
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "REQUIRES_SINGLE_PART_NAMESPACE",
  "sqlState" : "42K05",
  "messageParameters" : {
    "namespace" : "`System`.`Builtin`",
    "sessionCatalog" : "spark_catalog"
  }
}


-- !query
SELECT 'Test 2: Temporary function without shadowing' AS test_name
-- !query analysis
Project [Test 2: Temporary function without shadowing AS test_name#x]
+- OneRowRelation


-- !query
CREATE TEMPORARY FUNCTION my_temp_upper() RETURNS STRING RETURN 'UPPERCASE'
-- !query analysis
CreateSQLFunctionCommand my_temp_upper, STRING, 'UPPERCASE', false, true, false, false


-- !query
SELECT my_temp_upper() AS unqualified
-- !query analysis
Project [my_temp_upper() AS unqualified#x]
+- Project
   +- OneRowRelation


-- !query
SELECT session.my_temp_upper() AS schema_qualified
-- !query analysis
Project [my_temp_upper() AS schema_qualified#x]
+- Project
   +- OneRowRelation


-- !query
SELECT system.session.my_temp_upper() AS fully_qualified
-- !query analysis
Project [my_temp_upper() AS fully_qualified#x]
+- Project
   +- OneRowRelation


-- !query
SELECT SESSION.my_temp_upper() AS uppercase
-- !query analysis
Project [my_temp_upper() AS uppercase#x]
+- Project
   +- OneRowRelation


-- !query
SELECT System.Session.my_temp_upper() AS mixed_case
-- !query analysis
Project [my_temp_upper() AS mixed_case#x]
+- Project
   +- OneRowRelation


-- !query
DROP TEMPORARY FUNCTION my_temp_upper
-- !query analysis
DropFunctionCommand my_temp_upper, false, true


-- !query
SELECT 'Test 3: Temporary function shadows builtin' AS test_name
-- !query analysis
Project [Test 3: Temporary function shadows builtin AS test_name#x]
+- OneRowRelation


-- !query
SELECT abs(-10) AS builtin_before
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`abs`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 15,
    "fragment" : "abs(-10)"
  } ]
}


-- !query
CREATE TEMPORARY FUNCTION my_abs(x INT) RETURNS INT RETURN x * 100
-- !query analysis
CreateSQLFunctionCommand my_abs, x INT, INT, x * 100, false, true, false, false


-- !query
SELECT my_abs(-10) AS unqualified_shadowed
-- !query analysis
Project [my_abs(x#x) AS unqualified_shadowed#x]
+- Project [cast(-10 as int) AS x#x]
   +- OneRowRelation


-- !query
SELECT builtin.abs(-10) AS builtin_still_works
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`builtin`.`abs`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 23,
    "fragment" : "builtin.abs(-10)"
  } ]
}


-- !query
SELECT system.builtin.abs(-10) AS builtin_fully_qualified
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "REQUIRES_SINGLE_PART_NAMESPACE",
  "sqlState" : "42K05",
  "messageParameters" : {
    "namespace" : "`system`.`builtin`",
    "sessionCatalog" : "spark_catalog"
  }
}


-- !query
DROP TEMPORARY FUNCTION my_abs
-- !query analysis
DropFunctionCommand my_abs, false, true


-- !query
SELECT abs(-10) AS builtin_after
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`abs`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 15,
    "fragment" : "abs(-10)"
  } ]
}


-- !query
SELECT 'Test 4: Multiple builtin functions' AS test_name
-- !query analysis
Project [Test 4: Multiple builtin functions AS test_name#x]
+- OneRowRelation


-- !query
SELECT
  builtin.abs(-5) AS abs_result,
  builtin.upper('hello') AS upper_result,
  builtin.length('test') AS length_result,
  builtin.round(3.14159, 2) AS round_result
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`builtin`.`abs`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 24,
    "fragment" : "builtin.abs(-5)"
  } ]
}


-- !query
SELECT 'Test 5: Temp and builtin registries are separate' AS test_name
-- !query analysis
Project [Test 5: Temp and builtin registries are separate AS test_name#x]
+- OneRowRelation


-- !query
CREATE TEMPORARY FUNCTION my_custom(s STRING) RETURNS STRING RETURN CONCAT('CUSTOM: ', s)
-- !query analysis
org.apache.spark.sql.catalyst.analysis.NoSuchFunctionException
{
  "errorClass" : "ROUTINE_NOT_FOUND",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`default`.`CONCAT`"
  }
}


-- !query
SELECT
  my_custom('test') AS temp_func,
  builtin.abs(-20) AS builtin_func,
  session.my_custom('test') AS temp_qualified
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`my_custom`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 26,
    "fragment" : "my_custom('test')"
  } ]
}


-- !query
DROP TEMPORARY FUNCTION my_custom
-- !query analysis
org.apache.spark.sql.catalyst.analysis.NoSuchTempFunctionException
{
  "errorClass" : "ROUTINE_NOT_FOUND",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`my_custom`"
  }
}


-- !query
SET spark.sql.ansi.enabled = false
-- !query analysis
SetCommand (spark.sql.ansi.enabled,Some(false))
