-- Automatically generated by SQLQueryTestSuite
-- !query
select null, Null, nUll
-- !query analysis
Project [null AS NULL#x, null AS NULL#x, null AS NULL#x]
+- OneRowRelation


-- !query
select true, tRue, false, fALse
-- !query analysis
Project [true AS true#x, true AS true#x, false AS false#x, false AS false#x]
+- OneRowRelation


-- !query
select 1Y
-- !query analysis
Project [1 AS 1#x]
+- OneRowRelation


-- !query
select 127Y, -128Y
-- !query analysis
Project [127 AS 127#x, -128 AS -128#x]
+- OneRowRelation


-- !query
select 128Y
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "condition" : "INVALID_NUMERIC_LITERAL_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxValue" : "127",
    "minValue" : "-128",
    "rawStrippedQualifier" : "128",
    "typeName" : "tinyint"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 11,
    "fragment" : "128Y"
  } ]
}


-- !query
select 1S
-- !query analysis
Project [1 AS 1#x]
+- OneRowRelation


-- !query
select 32767S, -32768S
-- !query analysis
Project [32767 AS 32767#x, -32768 AS -32768#x]
+- OneRowRelation


-- !query
select 32768S
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "condition" : "INVALID_NUMERIC_LITERAL_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxValue" : "32767",
    "minValue" : "-32768",
    "rawStrippedQualifier" : "32768",
    "typeName" : "smallint"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 13,
    "fragment" : "32768S"
  } ]
}


-- !query
select 1L, 2147483648L
-- !query analysis
Project [1 AS 1#xL, 2147483648 AS 2147483648#xL]
+- OneRowRelation


-- !query
select 9223372036854775807L, -9223372036854775808L
-- !query analysis
Project [9223372036854775807 AS 9223372036854775807#xL, -9223372036854775808 AS -9223372036854775808#xL]
+- OneRowRelation


-- !query
select 9223372036854775808L
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "condition" : "INVALID_NUMERIC_LITERAL_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxValue" : "9223372036854775807",
    "minValue" : "-9223372036854775808",
    "rawStrippedQualifier" : "9223372036854775808",
    "typeName" : "bigint"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 27,
    "fragment" : "9223372036854775808L"
  } ]
}


-- !query
select 1, -1
-- !query analysis
Project [1 AS 1#x, -1 AS -1#x]
+- OneRowRelation


-- !query
select 2147483647, -2147483648
-- !query analysis
Project [2147483647 AS 2147483647#x, -2147483648 AS -2147483648#x]
+- OneRowRelation


-- !query
select 9223372036854775807, -9223372036854775808
-- !query analysis
Project [9223372036854775807 AS 9223372036854775807#xL, -9223372036854775808 AS -9223372036854775808#xL]
+- OneRowRelation


-- !query
select 9223372036854775808, -9223372036854775809
-- !query analysis
Project [9223372036854775808 AS 9223372036854775808#x, -9223372036854775809 AS -9223372036854775809#x]
+- OneRowRelation


-- !query
select 1234567890123456789012345678901234567890
-- !query analysis
org.apache.spark.SparkArithmeticException
{
  "condition" : "DECIMAL_PRECISION_EXCEEDS_MAX_PRECISION",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxPrecision" : "38",
    "precision" : "40"
  }
}


-- !query
select 1234567890123456789012345678901234567890.0
-- !query analysis
org.apache.spark.SparkArithmeticException
{
  "condition" : "DECIMAL_PRECISION_EXCEEDS_MAX_PRECISION",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxPrecision" : "38",
    "precision" : "41"
  }
}


-- !query
select 1F, 1.2F, .10f, 0.10f
-- !query analysis
Project [1.0 AS 1.0#x, 1.2 AS 1.2#x, 0.1 AS 0.1#x, 0.1 AS 0.1#x]
+- OneRowRelation


-- !query
select -1F, -1.2F, -.10F, -0.10F
-- !query analysis
Project [-1.0 AS -1.0#x, -1.2 AS -1.2#x, -0.1 AS -0.1#x, -0.1 AS -0.1#x]
+- OneRowRelation


-- !query
select -3.4028235E39f
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "condition" : "INVALID_NUMERIC_LITERAL_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxValue" : "3.4028234663852886E+38",
    "minValue" : "-3.4028234663852886E+38",
    "rawStrippedQualifier" : "-3.4028235E39",
    "typeName" : "float"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 21,
    "fragment" : "-3.4028235E39f"
  } ]
}


-- !query
select 1D, 1.2D, 1e10, 1.5e5, .10D, 0.10D, .1e5, .9e+2, 0.9e+2, 900e-1, 9.e+1
-- !query analysis
Project [1.0 AS 1.0#x, 1.2 AS 1.2#x, 1.0E10 AS 1.0E10#x, 150000.0 AS 150000.0#x, 0.1 AS 0.1#x, 0.1 AS 0.1#x, 10000.0 AS 10000.0#x, 90.0 AS 90.0#x, 90.0 AS 90.0#x, 90.0 AS 90.0#x, 90.0 AS 90.0#x]
+- OneRowRelation


-- !query
select -1D, -1.2D, -1e10, -1.5e5, -.10D, -0.10D, -.1e5
-- !query analysis
Project [-1.0 AS -1.0#x, -1.2 AS -1.2#x, -1.0E10 AS -1.0E10#x, -150000.0 AS -150000.0#x, -0.1 AS -0.1#x, -0.1 AS -0.1#x, -10000.0 AS -10000.0#x]
+- OneRowRelation


-- !query
select .e3
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "condition" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'.'",
    "hint" : ""
  }
}


-- !query
select 1E309, -1E309
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "condition" : "INVALID_NUMERIC_LITERAL_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxValue" : "1.7976931348623157E+308",
    "minValue" : "-1.7976931348623157E+308",
    "rawStrippedQualifier" : "1E309",
    "typeName" : "double"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 12,
    "fragment" : "1E309"
  } ]
}


-- !query
select 0.3, -0.8, .5, -.18, 0.1111, .1111
-- !query analysis
Project [0.3 AS 0.3#x, -0.8 AS -0.8#x, 0.5 AS 0.5#x, -0.18 AS -0.18#x, 0.1111 AS 0.1111#x, 0.1111 AS 0.1111#x]
+- OneRowRelation


-- !query
select 0.3 F, 0.4 D, 0.5 BD
-- !query analysis
Project [0.3 AS F#x, 0.4 AS D#x, 0.5 AS BD#x]
+- OneRowRelation


-- !query
select 123456789012345678901234567890123456789e10d, 123456789012345678901234567890123456789.1e10d
-- !query analysis
Project [1.2345678901234568E48 AS 1.2345678901234568E48#x, 1.2345678901234568E48 AS 1.2345678901234568E48#x]
+- OneRowRelation


-- !query
select "Hello Peter!", 'hello lee!'
-- !query analysis
Project [Hello Peter! AS Hello Peter!#x, hello lee! AS hello lee!#x]
+- OneRowRelation


-- !query
select 'hello' 'world', 'hello' " " 'lee'
-- !query analysis
Project [helloworld AS helloworld#x, hello lee AS hello lee#x]
+- OneRowRelation


-- !query
select "hello 'peter'"
-- !query analysis
Project [hello 'peter' AS hello 'peter'#x]
+- OneRowRelation


-- !query
select 'pattern%', 'no-pattern\%', 'pattern\\%', 'pattern\\\%'
-- !query analysis
Project [pattern% AS pattern%#x, no-pattern\% AS no-pattern\%#x, pattern\% AS pattern\%#x, pattern\\% AS pattern\\%#x]
+- OneRowRelation


-- !query
select '\'', '"', '\n', '\r', '\t', 'Z'
-- !query analysis
Project [' AS '#x, " AS "#x, 
 AS 
#x,  AS #x, 	 AS 	#x, Z AS Z#x]
+- OneRowRelation


-- !query
select '\110\145\154\154\157\041'
-- !query analysis
Project [Hello! AS Hello!#x]
+- OneRowRelation


-- !query
select '\u0057\u006F\u0072\u006C\u0064\u0020\u003A\u0029'
-- !query analysis
Project [World :) AS World :)#x]
+- OneRowRelation


-- !query
select dAte '2016-03-12'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date 'mar 11 2016'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "condition" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'mar 11 2016'",
    "valueType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "date 'mar 11 2016'"
  } ]
}


-- !query
select tImEstAmp '2016-03-11 20:54:00.000'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestamp '2016-33-11 20:54:00.000'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "condition" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'2016-33-11 20:54:00.000'",
    "valueType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 42,
    "fragment" : "timestamp '2016-33-11 20:54:00.000'"
  } ]
}


-- !query
select GEO '(10,-6)'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "condition" : "UNSUPPORTED_TYPED_LITERAL",
  "sqlState" : "0A000",
  "messageParameters" : {
    "supportedTypes" : "\"DATE\", \"TIMESTAMP_NTZ\", \"TIMESTAMP_LTZ\", \"TIMESTAMP\", \"INTERVAL\", \"X\"",
    "unsupportedType" : "\"GEO\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 20,
    "fragment" : "GEO '(10,-6)'"
  } ]
}


-- !query
select 90912830918230182310293801923652346786BD, 123.0E-28BD, 123.08BD
-- !query analysis
Project [90912830918230182310293801923652346786 AS 90912830918230182310293801923652346786#x, 1.230E-26 AS 1.230E-26#x, 123.08 AS 123.08#x]
+- OneRowRelation


-- !query
select 1.20E-38BD
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "condition" : "DECIMAL_PRECISION_EXCEEDS_MAX_PRECISION",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxPrecision" : "38",
    "precision" : "40"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 17,
    "fragment" : "1.20E-38BD"
  } ]
}


-- !query
select x'2379ACFe'
-- !query analysis
Project [0x2379ACFE AS X'2379ACFE'#x]
+- OneRowRelation


-- !query
select X'XuZ'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "condition" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'XuZ'",
    "valueType" : "\"X\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 13,
    "fragment" : "X'XuZ'"
  } ]
}


-- !query
SELECT 3.14, -3.14, 3.14e8, 3.14e-8, -3.14e8, -3.14e-8, 3.14e+8, 3.14E8, 3.14E-8
-- !query analysis
Project [3.14 AS 3.14#x, -3.14 AS -3.14#x, 3.14E8 AS 3.14E8#x, 3.14E-8 AS 3.14E-8#x, -3.14E8 AS -3.14E8#x, -3.14E-8 AS -3.14E-8#x, 3.14E8 AS 3.14E8#x, 3.14E8 AS 3.14E8#x, 3.14E-8 AS 3.14E-8#x]
+- OneRowRelation


-- !query
select +date '1999-01-01'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"DATE '1999-01-01'\"",
    "inputType" : "\"DATE\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ DATE '1999-01-01')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "+date '1999-01-01'"
  } ]
}


-- !query
select +timestamp '1999-01-01'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"TIMESTAMP '1999-01-01 00:00:00'\"",
    "inputType" : "\"TIMESTAMP\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ TIMESTAMP '1999-01-01 00:00:00')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "+timestamp '1999-01-01'"
  } ]
}


-- !query
select +interval '1 day'
-- !query analysis
Project [positive(INTERVAL '1' DAY) AS (+ INTERVAL '1' DAY)#x]
+- OneRowRelation


-- !query
select +map(1, 2)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"map(1, 2)\"",
    "inputType" : "\"MAP<INT, INT>\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ map(1, 2))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 17,
    "fragment" : "+map(1, 2)"
  } ]
}


-- !query
select +array(1,2)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"array(1, 2)\"",
    "inputType" : "\"ARRAY<INT>\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ array(1, 2))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 18,
    "fragment" : "+array(1,2)"
  } ]
}


-- !query
select +named_struct('a', 1, 'b', 'spark')
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"named_struct(a, 1, b, spark)\"",
    "inputType" : "\"STRUCT<a: INT NOT NULL, b: STRING NOT NULL>\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ named_struct(a, 1, b, spark))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 42,
    "fragment" : "+named_struct('a', 1, 'b', 'spark')"
  } ]
}


-- !query
select +X'1'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"X'01'\"",
    "inputType" : "\"BINARY\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ X'01')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 12,
    "fragment" : "+X'1'"
  } ]
}


-- !query
select -date '1999-01-01'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"DATE '1999-01-01'\"",
    "inputType" : "\"DATE\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(- DATE '1999-01-01')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "-date '1999-01-01'"
  } ]
}


-- !query
select -timestamp '1999-01-01'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"TIMESTAMP '1999-01-01 00:00:00'\"",
    "inputType" : "\"TIMESTAMP\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(- TIMESTAMP '1999-01-01 00:00:00')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "-timestamp '1999-01-01'"
  } ]
}


-- !query
select -x'2379ACFe'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"X'2379ACFE'\"",
    "inputType" : "\"BINARY\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(- X'2379ACFE')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 19,
    "fragment" : "-x'2379ACFe'"
  } ]
}


-- !query
select -0, -0.0
-- !query analysis
Project [0 AS 0#x, 0.0 AS 0.0#x]
+- OneRowRelation
