-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TABLE t (a STRING, b INT, c STRING, d STRING) USING parquet
  OPTIONS (a '1', b '2', password 'password')
  PARTITIONED BY (c, d) CLUSTERED BY (a) SORTED BY (b ASC) INTO 2 BUCKETS
  COMMENT 'table_comment'
  TBLPROPERTIES (t 'test', password 'password')
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
CREATE TEMPORARY VIEW temp_v AS SELECT * FROM t
-- !query analysis
CreateViewCommand `temp_v`, SELECT * FROM t, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [a#x, b#x, c#x, d#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[a#x,b#x,c#x,d#x] parquet


-- !query
CREATE TEMPORARY VIEW temp_Data_Source_View
  USING org.apache.spark.sql.sources.DDLScanSource
  OPTIONS (
    From '1',
    To '10',
    Table 'test1')
-- !query analysis
CreateTempViewUsing [tableIdent:`temp_Data_Source_View` replace:false provider:org.apache.spark.sql.sources.DDLScanSource Map(From -> 1, To -> 10, Table -> test1)


-- !query
CREATE VIEW v AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, false, PersistedView, COMPENSATION, true
   +- Project [a#x, b#x, c#x, d#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[a#x,b#x,c#x,d#x] parquet


-- !query
ALTER TABLE t SET TBLPROPERTIES (e = '3')
-- !query analysis
AlterTableSetPropertiesCommand `spark_catalog`.`default`.`t`, [e=3], false


-- !query
ALTER TABLE t ADD PARTITION (c='Us', d=1)
-- !query analysis
AlterTableAddPartitionCommand `spark_catalog`.`default`.`t`, [(Map(c -> Us, d -> 1),None)], false


-- !query
DESCRIBE t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESCRIBE EXTENDED t AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`t`, true


-- !query
DESCRIBE t AS JSON
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DESCRIBE_JSON_NOT_EXTENDED",
  "sqlState" : "0A000"
}


-- !query
DESC default.t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED t AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`t`, true


-- !query
DESC EXTENDED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`t`, true


-- !query
ALTER TABLE t UNSET TBLPROPERTIES (e)
-- !query analysis
AlterTableUnsetPropertiesCommand `spark_catalog`.`default`.`t`, [e], false, false


-- !query
DESC EXTENDED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, [col_name#x, data_type#x, comment#x]


-- !query
ALTER TABLE t UNSET TBLPROPERTIES (comment)
-- !query analysis
AlterTableUnsetPropertiesCommand `spark_catalog`.`default`.`t`, [comment], false, false


-- !query
DESC EXTENDED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC t PARTITION (c='Us', d=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t PARTITION (c='Us', d=1) AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], true


-- !query
DESC EXTENDED t PARTITION (c='Us', d=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], true, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED t PARTITION (c='Us', d=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t PARTITION (C='Us', D=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [C=Us, D=1], true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t PARTITION (C='Us', D=1) AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`t`, [C=Us, D=1], true


-- !query
DESC t PARTITION (c='Us', d=2)
-- !query analysis
org.apache.spark.sql.catalyst.analysis.NoSuchPartitionException
{
  "errorClass" : "PARTITIONS_NOT_FOUND",
  "sqlState" : "428FT",
  "messageParameters" : {
    "partitionList" : "PARTITION (`c` = Us, `d` = 2)",
    "tableName" : "`default`.`t`"
  }
}


-- !query
DESC EXTENDED t PARTITION (c='Us', d=2) AS JSON
-- !query analysis
org.apache.spark.sql.catalyst.analysis.NoSuchPartitionException
{
  "errorClass" : "PARTITIONS_NOT_FOUND",
  "sqlState" : "428FT",
  "messageParameters" : {
    "partitionList" : "PARTITION (`c` = Us, `d` = 2)",
    "tableName" : "`default`.`t`"
  }
}


-- !query
DESC t PARTITION (c='Us')
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "c, d",
    "specKeys" : "c",
    "tableName" : "`spark_catalog`.`default`.`t`"
  }
}


-- !query
DESC t PARTITION (c='Us', d)
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_SQL_SYNTAX.EMPTY_PARTITION_VALUE",
  "sqlState" : "42000",
  "messageParameters" : {
    "partKey" : "`d`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 28,
    "fragment" : "DESC t PARTITION (c='Us', d)"
  } ]
}


-- !query
DESC temp_v
-- !query analysis
DescribeTableCommand `temp_v`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED temp_v AS JSON
-- !query analysis
DescribeTableJsonCommand `temp_v`, true


-- !query
DESC TABLE temp_v
-- !query analysis
DescribeTableCommand `temp_v`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED temp_v
-- !query analysis
DescribeTableCommand `temp_v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED temp_v
-- !query analysis
DescribeTableCommand `temp_v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC temp_Data_Source_View
-- !query analysis
DescribeTableCommand `temp_Data_Source_View`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC temp_v PARTITION (c='Us', d=1)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "FORBIDDEN_OPERATION",
  "sqlState" : "42809",
  "messageParameters" : {
    "objectName" : "`temp_v`",
    "objectType" : "TEMPORARY VIEW",
    "statement" : "DESC PARTITION"
  }
}


-- !query
DESC v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED v AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`v`, true


-- !query
DESC EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC v PARTITION (c='Us', d=1)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "FORBIDDEN_OPERATION",
  "sqlState" : "42809",
  "messageParameters" : {
    "objectName" : "`v`",
    "objectType" : "VIEW",
    "statement" : "DESC PARTITION"
  }
}


-- !query
EXPLAIN DESC t
-- !query analysis
ExplainCommand 'DescribeRelation false, false, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
EXPLAIN DESC EXTENDED t AS JSON
-- !query analysis
ExplainCommand 'DescribeRelation true, true, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
EXPLAIN DESC EXTENDED t
-- !query analysis
ExplainCommand 'DescribeRelation true, false, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
EXPLAIN EXTENDED DESC t
-- !query analysis
ExplainCommand 'DescribeRelation false, false, [col_name#x, data_type#x, comment#x], ExtendedMode


-- !query
EXPLAIN DESCRIBE t b
-- !query analysis
ExplainCommand 'DescribeColumn 'b, false, false, [info_name#x, info_value#x], SimpleMode


-- !query
EXPLAIN DESCRIBE t PARTITION (c='Us', d=2)
-- !query analysis
ExplainCommand 'DescribeRelation [c=Us, d=2], false, false, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
EXPLAIN DESCRIBE EXTENDED t PARTITION (c='Us', d=2) AS JSON
-- !query analysis
ExplainCommand 'DescribeRelation [c=Us, d=2], true, true, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
DROP TABLE t
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
DROP VIEW temp_v
-- !query analysis
DropTempViewCommand temp_v


-- !query
DROP VIEW temp_Data_Source_View
-- !query analysis
DropTempViewCommand temp_Data_Source_View


-- !query
DROP VIEW v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, false, true, false


-- !query
CREATE TABLE d (a STRING DEFAULT 'default-value', b INT DEFAULT 42) USING parquet COMMENT 'table_comment'
-- !query analysis
org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException
{
  "errorClass" : "TABLE_OR_VIEW_ALREADY_EXISTS",
  "sqlState" : "42P07",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`d`"
  }
}


-- !query
DESC d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE EXTENDED d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE EXTENDED d AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`d`, true


-- !query
DESC FORMATTED d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE TABLE e (a STRING DEFAULT CONCAT('a\n b\n ', 'c\n d'), b INT DEFAULT 42) USING parquet COMMENT 'table_comment'
-- !query analysis
org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException
{
  "errorClass" : "TABLE_OR_VIEW_ALREADY_EXISTS",
  "sqlState" : "42P07",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`e`"
  }
}


-- !query
DESC e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED e AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`e`, true


-- !query
DESC EXTENDED e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE EXTENDED e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE FORMATTED e AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`e`, true


-- !query
CREATE TABLE t2 (
    a STRING,
    b INT,
    c STRING,
    d STRING
)
USING parquet
OPTIONS (
    a '1',
    b '2',
    password 'password'
)
PARTITIONED BY (c, d)
CLUSTERED BY (a) SORTED BY (b ASC) INTO 2 BUCKETS
COMMENT 'table_comment'
TBLPROPERTIES (
    t 'test',
    password 'password'
)
-- !query analysis
org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException
{
  "errorClass" : "TABLE_OR_VIEW_ALREADY_EXISTS",
  "sqlState" : "42P07",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`t2`"
  }
}


-- !query
DESC t2
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t2`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED t2 as json
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`t2`, true


-- !query
CREATE TABLE c (
  id STRING,
  nested_struct STRUCT<
    name: STRING,
    age: INT,
    contact: STRUCT<
      email: STRING,
      phone_numbers: ARRAY<STRING>,
      addresses: ARRAY<STRUCT<
        street: STRING,
        city: STRING,
        zip: INT
      >>
    >
  >,
  preferences MAP<STRING, ARRAY<STRING>>
) USING parquet
  OPTIONS (option1 'value1', option2 'value2')
  PARTITIONED BY (id)
  COMMENT 'A table with nested complex types'
  TBLPROPERTIES ('property1' = 'value1', 'password' = 'password')
-- !query analysis
org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException
{
  "errorClass" : "TABLE_OR_VIEW_ALREADY_EXISTS",
  "sqlState" : "42P07",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`c`"
  }
}


-- !query
DESC FORMATTED c AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`c`, true


-- !query
CREATE TABLE customer(
        cust_id INT,
        state VARCHAR(20),
        name STRING COMMENT "Short name"
    )
    USING parquet
    PARTITIONED BY (state)
-- !query analysis
org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException
{
  "errorClass" : "TABLE_OR_VIEW_ALREADY_EXISTS",
  "sqlState" : "42P07",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`customer`"
  }
}


-- !query
INSERT INTO customer PARTITION (state = "AR") VALUES (100, "Mike")
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/customer, [state=AR], false, [state#x], Parquet, [path=file:[not included in comparison]/{warehouse_dir}/customer], Append, `spark_catalog`.`default`.`customer`, org.apache.spark.sql.execution.datasources.CatalogFileIndex(file:[not included in comparison]/{warehouse_dir}/customer), [cust_id, name, state]
+- Project [cust_id#x, name#x, cast(AR as string) AS state#x]
   +- Project [cast(col1#x as int) AS cust_id#x, cast(col2#x as string) AS name#x]
      +- LocalRelation [col1#x, col2#x]


-- !query
DESC FORMATTED customer
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`customer`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED customer AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`customer`, true


-- !query
ANALYZE TABLE customer COMPUTE STATISTICS FOR COLUMNS cust_id
-- !query analysis
AnalyzeColumnCommand `spark_catalog`.`default`.`customer`, List(cust_id), false


-- !query
DESCRIBE FORMATTED customer customer.cust_id
-- !query analysis
DescribeColumnCommand `spark_catalog`.`default`.`customer`, [spark_catalog, default, customer, cust_id], true, [info_name#x, info_value#x]


-- !query
DESCRIBE FORMATTED customer customer.cust_id AS JSON
-- !query analysis
DescribeColumnJsonCommand `spark_catalog`.`default`.`customer`, [spark_catalog, default, customer, cust_id], true
