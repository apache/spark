-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TABLE t (a STRING, b INT, c STRING, d STRING) USING parquet
  OPTIONS (a '1', b '2', password 'password')
  PARTITIONED BY (c, d) CLUSTERED BY (a) SORTED BY (b ASC) INTO 2 BUCKETS
  COMMENT 'table_comment'
  TBLPROPERTIES (t 'test', password 'password')
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
CREATE TEMPORARY VIEW temp_v AS SELECT * FROM t
-- !query analysis
CreateViewCommand `temp_v`, SELECT * FROM t, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [a#x, b#x, c#x, d#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[a#x,b#x,c#x,d#x] parquet


-- !query
CREATE TEMPORARY VIEW temp_Data_Source_View
  USING org.apache.spark.sql.sources.DDLScanSource
  OPTIONS (
    From '1',
    To '10',
    Table 'test1')
-- !query analysis
CreateTempViewUsing [tableIdent:`temp_Data_Source_View` replace:false provider:org.apache.spark.sql.sources.DDLScanSource Map(From -> 1, To -> 10, Table -> test1)


-- !query
CREATE VIEW v AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, false, PersistedView, COMPENSATION, true
   +- Project [a#x, b#x, c#x, d#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[a#x,b#x,c#x,d#x] parquet


-- !query
ALTER TABLE t SET TBLPROPERTIES (e = '3')
-- !query analysis
AlterTableSetPropertiesCommand `spark_catalog`.`default`.`t`, [e=3], false


-- !query
ALTER TABLE t ADD PARTITION (c='Us', d=1)
-- !query analysis
AlterTableAddPartitionCommand `spark_catalog`.`default`.`t`, [(Map(c -> Us, d -> 1),None)], false


-- !query
DESCRIBE t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESCRIBE EXTENDED t AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`t`, true


-- !query
DESCRIBE t AS JSON
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "DESCRIBE_JSON_NOT_EXTENDED",
  "sqlState" : "0A000"
}


-- !query
DESC FORMATTED t a AS JSON
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "UNSUPPORTED_FEATURE.DESC_TABLE_COLUMN_JSON",
  "sqlState" : "0A000"
}


-- !query
DESC default.t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED t AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`t`, true


-- !query
DESC EXTENDED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`t`, true


-- !query
ALTER TABLE t UNSET TBLPROPERTIES (e)
-- !query analysis
AlterTableUnsetPropertiesCommand `spark_catalog`.`default`.`t`, [e], false, false


-- !query
DESC EXTENDED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, [col_name#x, data_type#x, comment#x]


-- !query
ALTER TABLE t UNSET TBLPROPERTIES (comment)
-- !query analysis
AlterTableUnsetPropertiesCommand `spark_catalog`.`default`.`t`, [comment], false, false


-- !query
DESC EXTENDED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC t PARTITION (c='Us', d=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t PARTITION (c='Us', d=1) AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], true


-- !query
DESC EXTENDED t PARTITION (c='Us', d=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], true, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED t PARTITION (c='Us', d=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t PARTITION (C='Us', D=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [C=Us, D=1], true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t PARTITION (C='Us', D=1) AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`t`, [C=Us, D=1], true


-- !query
DESC t PARTITION (c='Us', d=2)
-- !query analysis
org.apache.spark.sql.catalyst.analysis.NoSuchPartitionException
{
  "errorClass" : "PARTITIONS_NOT_FOUND",
  "sqlState" : "428FT",
  "messageParameters" : {
    "partitionList" : "PARTITION (`c` = Us, `d` = 2)",
    "tableName" : "`default`.`t`"
  }
}


-- !query
DESC t PARTITION (c='Us')
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "c, d",
    "specKeys" : "c",
    "tableName" : "`spark_catalog`.`default`.`t`"
  }
}


-- !query
DESC t PARTITION (c='Us', d)
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_SQL_SYNTAX.EMPTY_PARTITION_VALUE",
  "sqlState" : "42000",
  "messageParameters" : {
    "partKey" : "`d`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 28,
    "fragment" : "DESC t PARTITION (c='Us', d)"
  } ]
}


-- !query
DESC temp_v
-- !query analysis
DescribeTableCommand `temp_v`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED temp_v AS JSON
-- !query analysis
DescribeTableJsonCommand `temp_v`, true


-- !query
DESC TABLE temp_v
-- !query analysis
DescribeTableCommand `temp_v`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED temp_v
-- !query analysis
DescribeTableCommand `temp_v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED temp_v
-- !query analysis
DescribeTableCommand `temp_v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC temp_Data_Source_View
-- !query analysis
DescribeTableCommand `temp_Data_Source_View`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC temp_v PARTITION (c='Us', d=1)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "FORBIDDEN_OPERATION",
  "sqlState" : "42809",
  "messageParameters" : {
    "objectName" : "`temp_v`",
    "objectType" : "TEMPORARY VIEW",
    "statement" : "DESC PARTITION"
  }
}


-- !query
DESC v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED v AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`v`, true


-- !query
DESC EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC v PARTITION (c='Us', d=1)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "FORBIDDEN_OPERATION",
  "sqlState" : "42809",
  "messageParameters" : {
    "objectName" : "`v`",
    "objectType" : "VIEW",
    "statement" : "DESC PARTITION"
  }
}


-- !query
EXPLAIN DESC t
-- !query analysis
ExplainCommand 'DescribeRelation false, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
EXPLAIN DESC EXTENDED t AS JSON
-- !query analysis
ExplainCommand 'DescribeRelationJson true, [json_metadata#x], SimpleMode


-- !query
EXPLAIN DESC EXTENDED t
-- !query analysis
ExplainCommand 'DescribeRelation true, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
EXPLAIN EXTENDED DESC t
-- !query analysis
ExplainCommand 'DescribeRelation false, [col_name#x, data_type#x, comment#x], ExtendedMode


-- !query
EXPLAIN DESCRIBE t b
-- !query analysis
ExplainCommand 'DescribeColumn 'b, false, [info_name#x, info_value#x], SimpleMode


-- !query
EXPLAIN DESCRIBE t PARTITION (c='Us', d=2)
-- !query analysis
ExplainCommand 'DescribeRelation [c=Us, d=2], false, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
EXPLAIN DESCRIBE EXTENDED t PARTITION (c='Us', d=2) AS JSON
-- !query analysis
ExplainCommand 'DescribeRelationJson [c=Us, d=2], true, [json_metadata#x], SimpleMode


-- !query
DROP TABLE t
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
DROP VIEW temp_v
-- !query analysis
DropTempViewCommand temp_v


-- !query
DROP VIEW temp_Data_Source_View
-- !query analysis
DropTempViewCommand temp_Data_Source_View


-- !query
DROP VIEW v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, false, true, false


-- !query
CREATE TABLE d (a STRING DEFAULT 'default-value', b INT DEFAULT 42) USING parquet COMMENT 'table_comment'
-- !query analysis
org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException
{
  "errorClass" : "TABLE_OR_VIEW_ALREADY_EXISTS",
  "sqlState" : "42P07",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`d`"
  }
}


-- !query
DESC d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE EXTENDED d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE EXTENDED d AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`d`, true


-- !query
DESC FORMATTED d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE TABLE e (a STRING DEFAULT CONCAT('a\n b\n ', 'c\n d'), b INT DEFAULT 42) USING parquet COMMENT 'table_comment'
-- !query analysis
org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException
{
  "errorClass" : "TABLE_OR_VIEW_ALREADY_EXISTS",
  "sqlState" : "42P07",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`e`"
  }
}


-- !query
DESC e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED e AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`e`, true


-- !query
DESC EXTENDED e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE EXTENDED e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE FORMATTED e AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`e`, true


-- !query
CREATE TABLE t2 (
    a STRING,
    b INT,
    c STRING,
    d STRING
)
USING parquet
OPTIONS (
    a '1',
    b '2',
    password 'password'
)
PARTITIONED BY (c, d)
CLUSTERED BY (a) SORTED BY (b ASC) INTO 2 BUCKETS
COMMENT 'table_comment'
TBLPROPERTIES (
    t 'test',
    password 'password'
)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t2`, false


-- !query
DESC t2
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t2`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED t2 as json
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`t2`, true


-- !query
DROP TABLE t2
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t2


-- !query
CREATE TABLE c (
  id STRING,
  nested_struct STRUCT<
    name: STRING,
    age: INT,
    contact: STRUCT<
      email: STRING,
      phone_numbers: ARRAY<STRING>,
      addresses: ARRAY<STRUCT<
        street: STRING,
        city: STRING,
        zip: INT
      >>
    >
  >,
  preferences MAP<STRING, ARRAY<STRING>>
) USING parquet
  OPTIONS (option1 'value1', option2 'value2')
  PARTITIONED BY (id)
  COMMENT 'A table with nested complex types'
  TBLPROPERTIES ('property1' = 'value1', 'password' = 'password')
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`c`, false


-- !query
DESC FORMATTED c AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`c`, true


-- !query
DROP TABLE c
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.c


-- !query
CREATE TABLE special_types_table (
  id STRING,
  salary DECIMAL(10, 2),
  short_description VARCHAR(255),
  char_code CHAR(10),
  timestamp_with_time_zone TIMESTAMP,
  timestamp_without_time_zone TIMESTAMP_NTZ,
  interval_year_to_month INTERVAL YEAR TO MONTH,
  interval_day_to_hour INTERVAL DAY TO HOUR,
  nested_struct STRUCT<
    detail: STRING,
    metrics: STRUCT<
      precision: DECIMAL(5, 2),
      scale: CHAR(5)
    >,
    time_info: STRUCT<
      timestamp_ltz: TIMESTAMP,
      timestamp_ntz: TIMESTAMP_NTZ
    >
  >,
  preferences MAP<STRING, ARRAY<VARCHAR(50)>>
) USING parquet
  OPTIONS ('compression' = 'snappy')
  COMMENT 'Table testing all special types'
  TBLPROPERTIES ('test_property' = 'test_value')
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`special_types_table`, false


-- !query
DESC FORMATTED special_types_table AS JSON
-- !query analysis
DescribeTableJsonCommand `spark_catalog`.`default`.`special_types_table`, true


-- !query
DROP TABLE special_types_table
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.special_types_table
