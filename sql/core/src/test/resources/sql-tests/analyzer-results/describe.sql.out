-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TABLE t (a STRING, b INT, c STRING, d STRING) USING parquet
  OPTIONS (a '1', b '2', password 'password')
  PARTITIONED BY (c, d) CLUSTERED BY (a) SORTED BY (b ASC) INTO 2 BUCKETS
  COMMENT 'table_comment'
  TBLPROPERTIES (t 'test', password 'password')
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
CREATE TEMPORARY VIEW temp_v AS SELECT * FROM t
-- !query analysis
CreateViewCommand `temp_v`, SELECT * FROM t, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [a#x, b#x, c#x, d#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[a#x,b#x,c#x,d#x] parquet


-- !query
CREATE TEMPORARY VIEW temp_Data_Source_View
  USING org.apache.spark.sql.sources.DDLScanSource
  OPTIONS (
    From '1',
    To '10',
    Table 'test1')
-- !query analysis
CreateTempViewUsing [tableIdent:`temp_Data_Source_View` replace:false provider:org.apache.spark.sql.sources.DDLScanSource Map(From -> 1, To -> 10, Table -> test1)


-- !query
CREATE VIEW v AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, false, PersistedView, COMPENSATION, true
   +- Project [a#x, b#x, c#x, d#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[a#x,b#x,c#x,d#x] parquet


-- !query
ALTER TABLE t SET TBLPROPERTIES (e = '3')
-- !query analysis
AlterTableSetPropertiesCommand `spark_catalog`.`default`.`t`, [e=3], false


-- !query
ALTER TABLE t ADD PARTITION (c='Us', d=1)
-- !query analysis
AlterTableAddPartitionCommand `spark_catalog`.`default`.`t`, [(Map(c -> Us, d -> 1),None)], false


-- !query
DESCRIBE t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESCRIBE EXTENDED t AS JSON
-- !query analysis
DescribeRelationJsonCommand true, [json_metadata#x]
+- ResolvedTable V2SessionCatalog(spark_catalog), default.t, V1Table(default.t), [a#x, b#x, c#x, d#x]


-- !query
DESCRIBE t AS JSON
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "DESCRIBE_JSON_NOT_EXTENDED",
  "sqlState" : "0A000",
  "messageParameters" : {
    "tableName" : "t"
  }
}


-- !query
DESC FORMATTED t a AS JSON
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "UNSUPPORTED_FEATURE.DESC_TABLE_COLUMN_JSON",
  "sqlState" : "0A000"
}


-- !query
DESC default.t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, [col_name#x, data_type#x, comment#x]


-- !query
ALTER TABLE t UNSET TBLPROPERTIES (e)
-- !query analysis
AlterTableUnsetPropertiesCommand `spark_catalog`.`default`.`t`, [e], false, false


-- !query
DESC EXTENDED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, [col_name#x, data_type#x, comment#x]


-- !query
ALTER TABLE t UNSET TBLPROPERTIES (comment)
-- !query analysis
AlterTableUnsetPropertiesCommand `spark_catalog`.`default`.`t`, [comment], false, false


-- !query
DESC EXTENDED t
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC t PARTITION (c='Us', d=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t PARTITION (c='Us', d=1) AS JSON
-- !query analysis
DescribeRelationJsonCommand [c=Us, d=1], true, [json_metadata#x]
+- ResolvedTable V2SessionCatalog(spark_catalog), default.t, V1Table(default.t), [a#x, b#x, c#x, d#x]


-- !query
DESC EXTENDED t PARTITION (c='Us', d=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], true, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED t PARTITION (c='Us', d=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [c=Us, d=1], true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED t PARTITION (C='Us', D=1)
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t`, [C=Us, D=1], true, [col_name#x, data_type#x, comment#x]


-- !query
DESC t PARTITION (c='Us', d=2)
-- !query analysis
org.apache.spark.sql.catalyst.analysis.NoSuchPartitionException
{
  "errorClass" : "PARTITIONS_NOT_FOUND",
  "sqlState" : "428FT",
  "messageParameters" : {
    "partitionList" : "PARTITION (`c` = Us, `d` = 2)",
    "tableName" : "`default`.`t`"
  }
}


-- !query
DESC t PARTITION (c='Us')
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1232",
  "messageParameters" : {
    "partitionColumnNames" : "c, d",
    "specKeys" : "c",
    "tableName" : "`spark_catalog`.`default`.`t`"
  }
}


-- !query
DESC t PARTITION (c='Us', d)
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_SQL_SYNTAX.EMPTY_PARTITION_VALUE",
  "sqlState" : "42000",
  "messageParameters" : {
    "partKey" : "`d`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 28,
    "fragment" : "DESC t PARTITION (c='Us', d)"
  } ]
}


-- !query
DESC temp_v
-- !query analysis
DescribeTableCommand `temp_v`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE temp_v
-- !query analysis
DescribeTableCommand `temp_v`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED temp_v
-- !query analysis
DescribeTableCommand `temp_v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED temp_v
-- !query analysis
DescribeTableCommand `temp_v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC temp_Data_Source_View
-- !query analysis
DescribeTableCommand `temp_Data_Source_View`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC temp_v PARTITION (c='Us', d=1)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "FORBIDDEN_OPERATION",
  "sqlState" : "42809",
  "messageParameters" : {
    "objectName" : "`temp_v`",
    "objectType" : "TEMPORARY VIEW",
    "statement" : "DESC PARTITION"
  }
}


-- !query
DESC v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC v PARTITION (c='Us', d=1)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "FORBIDDEN_OPERATION",
  "sqlState" : "42809",
  "messageParameters" : {
    "objectName" : "`v`",
    "objectType" : "VIEW",
    "statement" : "DESC PARTITION"
  }
}


-- !query
EXPLAIN DESC t
-- !query analysis
ExplainCommand 'DescribeRelation false, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
EXPLAIN DESC EXTENDED t
-- !query analysis
ExplainCommand 'DescribeRelation true, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
EXPLAIN EXTENDED DESC t
-- !query analysis
ExplainCommand 'DescribeRelation false, [col_name#x, data_type#x, comment#x], ExtendedMode


-- !query
EXPLAIN DESCRIBE t b
-- !query analysis
ExplainCommand 'DescribeColumn 'b, false, [info_name#x, info_value#x], SimpleMode


-- !query
EXPLAIN DESCRIBE t PARTITION (c='Us', d=2)
-- !query analysis
ExplainCommand 'DescribeRelation [c=Us, d=2], false, [col_name#x, data_type#x, comment#x], SimpleMode


-- !query
EXPLAIN DESCRIBE EXTENDED t PARTITION (c='Us', d=2) AS JSON
-- !query analysis
ExplainCommand 'DescribeRelationJsonCommand [c=Us, d=2], true, [json_metadata#x], SimpleMode


-- !query
CREATE TABLE d (a STRING DEFAULT 'default-value', b INT DEFAULT 42) USING parquet COMMENT 'table_comment'
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`d`, false


-- !query
DESC d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE EXTENDED d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED d
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`d`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE TABLE e (a STRING DEFAULT CONCAT('a\n b\n ', 'c\n d'), b INT DEFAULT 42) USING parquet COMMENT 'table_comment'
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`e`, false


-- !query
DESC e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC EXTENDED e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE EXTENDED e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, true, [col_name#x, data_type#x, comment#x]


-- !query
DESC FORMATTED e
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`e`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE TABLE f USING json PARTITIONED BY (B, C) AS SELECT 'APACHE' A, CAST('SPARK' AS BINARY) B, TIMESTAMP'2018-11-17 13:33:33' C
-- !query analysis
CreateDataSourceTableAsSelectCommand `spark_catalog`.`default`.`f`, ErrorIfExists, [A, B, C]
   +- Project [APACHE AS A#x, cast(SPARK as binary) AS B#x, 2018-11-17 13:33:33 AS C#x]
      +- OneRowRelation


-- !query
DESC FORMATTED f PARTITION (B='SPARK', C=TIMESTAMP'2018-11-17 13:33:33')
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`f`, [B=SPARK, C=2018-11-17 13:33:33], true, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE EXTENDED f PARTITION (B='SPARK', C=TIMESTAMP'2018-11-17 13:33:33') AS JSON
-- !query analysis
DescribeRelationJsonCommand [B=SPARK, C=2018-11-17 13:33:33], true, [json_metadata#x]
+- ResolvedTable V2SessionCatalog(spark_catalog), default.f, V1Table(default.f), [A#x, B#x, C#x]


-- !query
DROP VIEW temp_v
-- !query analysis
DropTempViewCommand temp_v


-- !query
DROP VIEW temp_Data_Source_View
-- !query analysis
DropTempViewCommand temp_Data_Source_View


-- !query
DROP VIEW v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, false, true, false


-- !query
DROP TABLE t
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
DROP TABLE d
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.d


-- !query
DROP TABLE e
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.e


-- !query
DROP TABLE f
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.f
