-- Automatically generated by SQLQueryTestSuite
-- !query
create temporary view date_view as select '2011-11-11' date_str, '1' int_str
-- !query analysis
CreateViewCommand `date_view`, select '2011-11-11' date_str, '1' int_str, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [2011-11-11 AS date_str#x, 1 AS int_str#x]
      +- OneRowRelation


-- !query
select date '2019-01-01\t'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date '2020-01-01中文'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'2020-01-01中文'",
    "valueType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 26,
    "fragment" : "date '2020-01-01中文'"
  } ]
}


-- !query
select make_date(2019, 1, 1), make_date(12, 12, 12)
-- !query analysis
Project [make_date(2019, 1, 1, true) AS make_date(2019, 1, 1)#x, make_date(12, 12, 12, true) AS make_date(12, 12, 12)#x]
+- OneRowRelation


-- !query
select make_date(2000, 13, 1)
-- !query analysis
Project [make_date(2000, 13, 1, true) AS make_date(2000, 13, 1)#x]
+- OneRowRelation


-- !query
select make_date(2000, 1, 33)
-- !query analysis
Project [make_date(2000, 1, 33, true) AS make_date(2000, 1, 33)#x]
+- OneRowRelation


-- !query
select date'015'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'015'",
    "valueType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 16,
    "fragment" : "date'015'"
  } ]
}


-- !query
select date'2021-4294967297-11'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'2021-4294967297-11'",
    "valueType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "date'2021-4294967297-11'"
  } ]
}


-- !query
select current_date = current_date
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select current_date() = current_date()
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select curdate(1)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITHOUT_SUGGESTION",
  "sqlState" : "42605",
  "messageParameters" : {
    "actualNum" : "1",
    "docroot" : "https://spark.apache.org/docs/latest",
    "expectedNum" : "0",
    "functionName" : "`curdate`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 17,
    "fragment" : "curdate(1)"
  } ]
}


-- !query
select DATE_FROM_UNIX_DATE(0), DATE_FROM_UNIX_DATE(1000), DATE_FROM_UNIX_DATE(null)
-- !query analysis
Project [date_from_unix_date(0) AS date_from_unix_date(0)#x, date_from_unix_date(1000) AS date_from_unix_date(1000)#x, date_from_unix_date(cast(null as int)) AS date_from_unix_date(NULL)#x]
+- OneRowRelation


-- !query
select UNIX_DATE(DATE('1970-01-01')), UNIX_DATE(DATE('2020-12-04')), UNIX_DATE(null)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select to_date(null), to_date('2016-12-31'), to_date('2016-12-31', 'yyyy-MM-dd')
-- !query analysis
Project [to_date(cast(null as string), None, Some(America/Los_Angeles), true) AS to_date(NULL)#x, to_date(2016-12-31, None, Some(America/Los_Angeles), true) AS to_date(2016-12-31)#x, to_date(2016-12-31, Some(yyyy-MM-dd), Some(America/Los_Angeles), true) AS to_date(2016-12-31, yyyy-MM-dd)#x]
+- OneRowRelation


-- !query
select to_date("16", "dd")
-- !query analysis
Project [to_date(16, Some(dd), Some(America/Los_Angeles), true) AS to_date(16, dd)#x]
+- OneRowRelation


-- !query
select to_date("02-29", "MM-dd")
-- !query analysis
Project [to_date(02-29, Some(MM-dd), Some(America/Los_Angeles), true) AS to_date(02-29, MM-dd)#x]
+- OneRowRelation


-- !query
select dayofweek('2007-02-03'), dayofweek('2009-07-30'), dayofweek('2017-05-27'), dayofweek(null),
  dayofweek('1582-10-15 13:10:15'), dayofweek(timestamp_ltz'1582-10-15 13:10:15'), dayofweek(timestamp_ntz'1582-10-15 13:10:15')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select weekday('2007-02-03'), weekday('2009-07-30'), weekday('2017-05-27'), weekday(null),
  weekday('1582-10-15 13:10:15'), weekday(timestamp_ltz'1582-10-15 13:10:15'), weekday(timestamp_ntz'1582-10-15 13:10:15')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select year('1500-01-01'), year('1582-10-15 13:10:15'), year(timestamp_ltz'1582-10-15 13:10:15'), year(timestamp_ntz'1582-10-15 13:10:15')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select month('1500-01-01'), month('1582-10-15 13:10:15'), month(timestamp_ltz'1582-10-15 13:10:15'), month(timestamp_ntz'1582-10-15 13:10:15')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select dayOfYear('1500-01-01'), dayOfYear('1582-10-15 13:10:15'), dayOfYear(timestamp_ltz'1582-10-15 13:10:15'), dayOfYear(timestamp_ntz'1582-10-15 13:10:15')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select next_day("2015-07-23", "Mon")
-- !query analysis
Project [next_day(cast(2015-07-23 as date), Mon, true) AS next_day(2015-07-23, Mon)#x]
+- OneRowRelation


-- !query
select next_day("2015-07-23", "xx")
-- !query analysis
Project [next_day(cast(2015-07-23 as date), xx, true) AS next_day(2015-07-23, xx)#x]
+- OneRowRelation


-- !query
select next_day("2015-07-23 12:12:12", "Mon")
-- !query analysis
Project [next_day(cast(2015-07-23 12:12:12 as date), Mon, true) AS next_day(2015-07-23 12:12:12, Mon)#x]
+- OneRowRelation


-- !query
select next_day(timestamp_ltz"2015-07-23 12:12:12", "Mon")
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select next_day(timestamp_ntz"2015-07-23 12:12:12", "Mon")
-- !query analysis
Project [next_day(cast(2015-07-23 12:12:12 as date), Mon, true) AS next_day(TIMESTAMP_NTZ '2015-07-23 12:12:12', Mon)#x]
+- OneRowRelation


-- !query
select next_day("xx", "Mon")
-- !query analysis
Project [next_day(cast(xx as date), Mon, true) AS next_day(xx, Mon)#x]
+- OneRowRelation


-- !query
select next_day(null, "Mon")
-- !query analysis
Project [next_day(cast(null as date), Mon, true) AS next_day(NULL, Mon)#x]
+- OneRowRelation


-- !query
select next_day(null, "xx")
-- !query analysis
Project [next_day(cast(null as date), xx, true) AS next_day(NULL, xx)#x]
+- OneRowRelation


-- !query
select date_add(date'2011-11-11', 1)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_add('2011-11-11', 1)
-- !query analysis
Project [date_add(cast(2011-11-11 as date), 1) AS date_add(2011-11-11, 1)#x]
+- OneRowRelation


-- !query
select date_add('2011-11-11', 1Y)
-- !query analysis
Project [date_add(cast(2011-11-11 as date), 1) AS date_add(2011-11-11, 1)#x]
+- OneRowRelation


-- !query
select date_add('2011-11-11', 1S)
-- !query analysis
Project [date_add(cast(2011-11-11 as date), 1) AS date_add(2011-11-11, 1)#x]
+- OneRowRelation


-- !query
select date_add('2011-11-11', 1L)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"1\"",
    "inputType" : "\"BIGINT\"",
    "paramIndex" : "second",
    "requiredType" : "(\"INT\" or \"SMALLINT\" or \"TINYINT\")",
    "sqlExpr" : "\"date_add(2011-11-11, 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 33,
    "fragment" : "date_add('2011-11-11', 1L)"
  } ]
}


-- !query
select date_add('2011-11-11', 1.0)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"1.0\"",
    "inputType" : "\"DECIMAL(2,1)\"",
    "paramIndex" : "second",
    "requiredType" : "(\"INT\" or \"SMALLINT\" or \"TINYINT\")",
    "sqlExpr" : "\"date_add(2011-11-11, 1.0)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 34,
    "fragment" : "date_add('2011-11-11', 1.0)"
  } ]
}


-- !query
select date_add('2011-11-11', 1E1)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"10.0\"",
    "inputType" : "\"DOUBLE\"",
    "paramIndex" : "second",
    "requiredType" : "(\"INT\" or \"SMALLINT\" or \"TINYINT\")",
    "sqlExpr" : "\"date_add(2011-11-11, 10.0)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 34,
    "fragment" : "date_add('2011-11-11', 1E1)"
  } ]
}


-- !query
select date_add('2011-11-11', '1')
-- !query analysis
Project [date_add(cast(2011-11-11 as date), cast(1 as int)) AS date_add(2011-11-11, 1)#x]
+- OneRowRelation


-- !query
select date_add('2011-11-11', '1.2')
-- !query analysis
Project [date_add(cast(2011-11-11 as date), cast(1.2 as int)) AS date_add(2011-11-11, 1.2)#x]
+- OneRowRelation


-- !query
select date_add(null, 1)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_add(date'2011-11-11', null)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_add(timestamp_ltz'2011-11-11 12:12:12', 1)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_add(timestamp_ntz'2011-11-11 12:12:12', 1)
-- !query analysis
Project [date_add(cast(2011-11-11 12:12:12 as date), 1) AS date_add(TIMESTAMP_NTZ '2011-11-11 12:12:12', 1)#x]
+- OneRowRelation


-- !query
select date_sub(date'2011-11-11', 1)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_sub('2011-11-11', 1)
-- !query analysis
Project [date_sub(cast(2011-11-11 as date), 1) AS date_sub(2011-11-11, 1)#x]
+- OneRowRelation


-- !query
select date_sub('2011-11-11', 1Y)
-- !query analysis
Project [date_sub(cast(2011-11-11 as date), 1) AS date_sub(2011-11-11, 1)#x]
+- OneRowRelation


-- !query
select date_sub('2011-11-11', 1S)
-- !query analysis
Project [date_sub(cast(2011-11-11 as date), 1) AS date_sub(2011-11-11, 1)#x]
+- OneRowRelation


-- !query
select date_sub('2011-11-11', 1L)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"1\"",
    "inputType" : "\"BIGINT\"",
    "paramIndex" : "second",
    "requiredType" : "(\"INT\" or \"SMALLINT\" or \"TINYINT\")",
    "sqlExpr" : "\"date_sub(2011-11-11, 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 33,
    "fragment" : "date_sub('2011-11-11', 1L)"
  } ]
}


-- !query
select date_sub('2011-11-11', 1.0)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"1.0\"",
    "inputType" : "\"DECIMAL(2,1)\"",
    "paramIndex" : "second",
    "requiredType" : "(\"INT\" or \"SMALLINT\" or \"TINYINT\")",
    "sqlExpr" : "\"date_sub(2011-11-11, 1.0)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 34,
    "fragment" : "date_sub('2011-11-11', 1.0)"
  } ]
}


-- !query
select date_sub('2011-11-11', 1E1)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"10.0\"",
    "inputType" : "\"DOUBLE\"",
    "paramIndex" : "second",
    "requiredType" : "(\"INT\" or \"SMALLINT\" or \"TINYINT\")",
    "sqlExpr" : "\"date_sub(2011-11-11, 10.0)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 34,
    "fragment" : "date_sub('2011-11-11', 1E1)"
  } ]
}


-- !query
select date_sub(date'2011-11-11', '1')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_sub(date'2011-11-11', '1.2')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_sub(null, 1)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_sub(date'2011-11-11', null)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_sub(timestamp_ltz'2011-11-11 12:12:12', 1)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_sub(timestamp_ntz'2011-11-11 12:12:12', 1)
-- !query analysis
Project [date_sub(cast(2011-11-11 12:12:12 as date), 1) AS date_sub(TIMESTAMP_NTZ '2011-11-11 12:12:12', 1)#x]
+- OneRowRelation


-- !query
select date_add('2011-11-11', int_str) from date_view
-- !query analysis
Project [date_add(cast(2011-11-11 as date), cast(int_str#x as int)) AS date_add(2011-11-11, int_str)#x]
+- SubqueryAlias date_view
   +- View (`date_view`, [date_str#x, int_str#x])
      +- Project [cast(date_str#x as string) AS date_str#x, cast(int_str#x as string) AS int_str#x]
         +- Project [2011-11-11 AS date_str#x, 1 AS int_str#x]
            +- OneRowRelation


-- !query
select date_sub('2011-11-11', int_str) from date_view
-- !query analysis
Project [date_sub(cast(2011-11-11 as date), cast(int_str#x as int)) AS date_sub(2011-11-11, int_str)#x]
+- SubqueryAlias date_view
   +- View (`date_view`, [date_str#x, int_str#x])
      +- Project [cast(date_str#x as string) AS date_str#x, cast(int_str#x as string) AS int_str#x]
         +- Project [2011-11-11 AS date_str#x, 1 AS int_str#x]
            +- OneRowRelation


-- !query
select date_add(date_str, 1) from date_view
-- !query analysis
Project [date_add(cast(date_str#x as date), 1) AS date_add(date_str, 1)#x]
+- SubqueryAlias date_view
   +- View (`date_view`, [date_str#x, int_str#x])
      +- Project [cast(date_str#x as string) AS date_str#x, cast(int_str#x as string) AS int_str#x]
         +- Project [2011-11-11 AS date_str#x, 1 AS int_str#x]
            +- OneRowRelation


-- !query
select date_sub(date_str, 1) from date_view
-- !query analysis
Project [date_sub(cast(date_str#x as date), 1) AS date_sub(date_str, 1)#x]
+- SubqueryAlias date_view
   +- View (`date_view`, [date_str#x, int_str#x])
      +- Project [cast(date_str#x as string) AS date_str#x, cast(int_str#x as string) AS int_str#x]
         +- Project [2011-11-11 AS date_str#x, 1 AS int_str#x]
            +- OneRowRelation


-- !query
select date '2011-11-11' + 1E1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"10.0\"",
    "inputType" : "\"DOUBLE\"",
    "paramIndex" : "second",
    "requiredType" : "(\"INT\" or \"SMALLINT\" or \"TINYINT\")",
    "sqlExpr" : "\"date_add(DATE '2011-11-11', 10.0)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "date '2011-11-11' + 1E1"
  } ]
}


-- !query
select date '2001-09-28' + 7Y
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select 7S + date '2001-09-28'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date '2001-10-01' - 7
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date '2001-10-01' - date '2001-09-28'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date '2001-10-01' - '2001-09-28'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select '2001-10-01' - date '2001-09-28'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date '2001-09-28' - null
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select null - date '2019-10-06'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_str - date '2001-09-28' from date_view
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date '2001-09-28' - date_str from date_view
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date'2011-11-11' + '1'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"1\"",
    "inputType" : "\"DATE\"",
    "paramIndex" : "second",
    "requiredType" : "(\"INT\" or \"SMALLINT\" or \"TINYINT\")",
    "sqlExpr" : "\"date_add(DATE '2011-11-11', 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "date'2011-11-11' + '1'"
  } ]
}


-- !query
select '1' + date'2011-11-11'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"DATE '2011-11-11'\"",
    "inputType" : "\"DATE\"",
    "paramIndex" : "second",
    "requiredType" : "(\"INT\" or \"SMALLINT\" or \"TINYINT\")",
    "sqlExpr" : "\"date_add(1, DATE '2011-11-11')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "'1' + date'2011-11-11'"
  } ]
}


-- !query
select date'2011-11-11' + null
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select null + date'2011-11-11'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date '2012-01-01' - interval '2-2' year to month,
       date '2011-11-11' - interval '2' day,
       date '2012-01-01' + interval '-2-2' year to month,
       date '2011-11-11' + interval '-2' month,
       - interval '2-2' year to month + date '2012-01-01',
       interval '-2' day + date '2011-11-11'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select to_date('26/October/2015', 'dd/MMMMM/yyyy')
-- !query analysis
Project [to_date(26/October/2015, Some(dd/MMMMM/yyyy), Some(America/Los_Angeles), true) AS to_date(26/October/2015, dd/MMMMM/yyyy)#x]
+- OneRowRelation


-- !query
select from_json('{"d":"26/October/2015"}', 'd Date', map('dateFormat', 'dd/MMMMM/yyyy'))
-- !query analysis
Project [from_json(StructField(d,DateType,true), (dateFormat,dd/MMMMM/yyyy), {"d":"26/October/2015"}, Some(America/Los_Angeles), false) AS from_json({"d":"26/October/2015"})#x]
+- OneRowRelation


-- !query
select from_csv('26/October/2015', 'd Date', map('dateFormat', 'dd/MMMMM/yyyy'))
-- !query analysis
Project [from_csv(StructField(d,DateType,true), (dateFormat,dd/MMMMM/yyyy), 26/October/2015, Some(America/Los_Angeles), None) AS from_csv(26/October/2015)#x]
+- OneRowRelation


-- !query
select dateadd(MICROSECOND, 1001, timestamp'2022-02-25 01:02:03.123')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_add(MILLISECOND, -1, timestamp'2022-02-25 01:02:03.456')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select dateadd(SECOND, 58, timestamp'2022-02-25 01:02:03')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_add(MINUTE, -100, date'2022-02-25')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select dateadd(HOUR, -1, timestamp'2022-02-25 01:02:03')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_add(DAY, 367, date'2022-02-25')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select dateadd(WEEK, -4, timestamp'2022-02-25 01:02:03')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_add(MONTH, -1, timestamp'2022-02-25 01:02:03')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select dateadd(QUARTER, 5, date'2022-02-25')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_add(YEAR, 1, date'2022-02-25')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select dateadd('MICROSECOND', 1001, timestamp'2022-02-25 01:02:03.123')
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_PARAMETER_VALUE.DATETIME_UNIT",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "`dateadd`",
    "invalidValue" : "'MICROSECOND'",
    "parameter" : "`unit`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 71,
    "fragment" : "dateadd('MICROSECOND', 1001, timestamp'2022-02-25 01:02:03.123')"
  } ]
}


-- !query
select date_add('QUARTER', 5, date'2022-02-25')
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_PARAMETER_VALUE.DATETIME_UNIT",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "`date_add`",
    "invalidValue" : "'QUARTER'",
    "parameter" : "`unit`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 47,
    "fragment" : "date_add('QUARTER', 5, date'2022-02-25')"
  } ]
}


-- !query
select datediff(MICROSECOND, timestamp'2022-02-25 01:02:03.123', timestamp'2022-02-25 01:02:03.124001')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_diff(MILLISECOND, timestamp'2022-02-25 01:02:03.456', timestamp'2022-02-25 01:02:03.455')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select datediff(SECOND, timestamp'2022-02-25 01:02:03', timestamp'2022-02-25 01:03:01')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_diff(MINUTE, date'2022-02-25', timestamp'2022-02-24 22:20:00')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select datediff(HOUR, timestamp'2022-02-25 01:02:03', timestamp'2022-02-25 00:02:03')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_diff(DAY, date'2022-02-25', timestamp'2023-02-27 00:00:00')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select datediff(WEEK, timestamp'2022-02-25 01:02:03', timestamp'2022-01-28 01:02:03')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_diff(MONTH, timestamp'2022-02-25 01:02:03', timestamp'2022-01-25 01:02:03')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select datediff(QUARTER, date'2022-02-25', date'2023-05-25')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_diff(YEAR, date'2022-02-25', date'2023-02-25')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date_diff('MILLISECOND', timestamp'2022-02-25 01:02:03.456', timestamp'2022-02-25 01:02:03.455')
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_PARAMETER_VALUE.DATETIME_UNIT",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "`date_diff`",
    "invalidValue" : "'MILLISECOND'",
    "parameter" : "`unit`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 103,
    "fragment" : "date_diff('MILLISECOND', timestamp'2022-02-25 01:02:03.456', timestamp'2022-02-25 01:02:03.455')"
  } ]
}


-- !query
select datediff('YEAR', date'2022-02-25', date'2023-02-25')
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_PARAMETER_VALUE.DATETIME_UNIT",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "`datediff`",
    "invalidValue" : "'YEAR'",
    "parameter" : "`unit`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 59,
    "fragment" : "datediff('YEAR', date'2022-02-25', date'2023-02-25')"
  } ]
}


-- !query
select timestamp '2019-01-01\t'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestamp '2019-01-01中文'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'2019-01-01中文'",
    "valueType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "timestamp '2019-01-01中文'"
  } ]
}


-- !query
select timestamp'4294967297'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'4294967297'",
    "valueType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 28,
    "fragment" : "timestamp'4294967297'"
  } ]
}


-- !query
select timestamp'2021-01-01T12:30:4294967297.123456'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'2021-01-01T12:30:4294967297.123456'",
    "valueType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 52,
    "fragment" : "timestamp'2021-01-01T12:30:4294967297.123456'"
  } ]
}


-- !query
select current_timestamp = current_timestamp
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select current_timestamp() = current_timestamp()
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select localtimestamp() = localtimestamp()
-- !query analysis
Project [(localtimestamp(Some(America/Los_Angeles)) = localtimestamp(Some(America/Los_Angeles))) AS (localtimestamp() = localtimestamp())#x]
+- OneRowRelation


-- !query
SELECT make_timestamp(2021, 07, 11, 6, 30, 45.678)
-- !query analysis
Project [make_timestamp(2021, 7, 11, 6, 30, cast(45.678 as decimal(16,6)), None, Some(America/Los_Angeles), true, TimestampType) AS make_timestamp(2021, 7, 11, 6, 30, 45.678)#x]
+- OneRowRelation


-- !query
SELECT make_timestamp(2021, 07, 11, 6, 30, 45.678, 'CET')
-- !query analysis
Project [make_timestamp(2021, 7, 11, 6, 30, cast(45.678 as decimal(16,6)), Some(CET), Some(America/Los_Angeles), true, TimestampType) AS make_timestamp(2021, 7, 11, 6, 30, 45.678, CET)#x]
+- OneRowRelation


-- !query
SELECT make_timestamp(2021, 07, 11, 6, 30, 60.007)
-- !query analysis
Project [make_timestamp(2021, 7, 11, 6, 30, cast(60.007 as decimal(16,6)), None, Some(America/Los_Angeles), true, TimestampType) AS make_timestamp(2021, 7, 11, 6, 30, 60.007)#x]
+- OneRowRelation


-- !query
SELECT make_timestamp(1, 1, 1, 1, 1, 1)
-- !query analysis
Project [make_timestamp(1, 1, 1, 1, 1, cast(1 as decimal(16,6)), None, Some(America/Los_Angeles), true, TimestampType) AS make_timestamp(1, 1, 1, 1, 1, 1)#x]
+- OneRowRelation


-- !query
SELECT make_timestamp(1, 1, 1, 1, 1, 60)
-- !query analysis
Project [make_timestamp(1, 1, 1, 1, 1, cast(60 as decimal(16,6)), None, Some(America/Los_Angeles), true, TimestampType) AS make_timestamp(1, 1, 1, 1, 1, 60)#x]
+- OneRowRelation


-- !query
SELECT make_timestamp(1, 1, 1, 1, 1, 61)
-- !query analysis
Project [make_timestamp(1, 1, 1, 1, 1, cast(61 as decimal(16,6)), None, Some(America/Los_Angeles), true, TimestampType) AS make_timestamp(1, 1, 1, 1, 1, 61)#x]
+- OneRowRelation


-- !query
SELECT make_timestamp(1, 1, 1, 1, 1, null)
-- !query analysis
Project [make_timestamp(1, 1, 1, 1, 1, cast(null as decimal(16,6)), None, Some(America/Los_Angeles), true, TimestampType) AS make_timestamp(1, 1, 1, 1, 1, NULL)#x]
+- OneRowRelation


-- !query
SELECT make_timestamp(1, 1, 1, 1, 1, 59.999999)
-- !query analysis
Project [make_timestamp(1, 1, 1, 1, 1, cast(59.999999 as decimal(16,6)), None, Some(America/Los_Angeles), true, TimestampType) AS make_timestamp(1, 1, 1, 1, 1, 59.999999)#x]
+- OneRowRelation


-- !query
SELECT make_timestamp(1, 1, 1, 1, 1, 99.999999)
-- !query analysis
Project [make_timestamp(1, 1, 1, 1, 1, cast(99.999999 as decimal(16,6)), None, Some(America/Los_Angeles), true, TimestampType) AS make_timestamp(1, 1, 1, 1, 1, 99.999999)#x]
+- OneRowRelation


-- !query
SELECT make_timestamp(1, 1, 1, 1, 1, 999.999999)
-- !query analysis
Project [make_timestamp(1, 1, 1, 1, 1, cast(999.999999 as decimal(16,6)), None, Some(America/Los_Angeles), true, TimestampType) AS make_timestamp(1, 1, 1, 1, 1, 999.999999)#x]
+- OneRowRelation


-- !query
select TIMESTAMP_SECONDS(1230219000),TIMESTAMP_SECONDS(-1230219000),TIMESTAMP_SECONDS(null)
-- !query analysis
Project [timestamp_seconds(1230219000) AS timestamp_seconds(1230219000)#x, timestamp_seconds(-1230219000) AS timestamp_seconds(-1230219000)#x, timestamp_seconds(null) AS timestamp_seconds(NULL)#x]
+- OneRowRelation


-- !query
select TIMESTAMP_SECONDS(1.23), TIMESTAMP_SECONDS(1.23d), TIMESTAMP_SECONDS(FLOAT(1.23))
-- !query analysis
Project [timestamp_seconds(1.23) AS timestamp_seconds(1.23)#x, timestamp_seconds(1.23) AS timestamp_seconds(1.23)#x, timestamp_seconds(cast(1.23 as float)) AS timestamp_seconds(1.23)#x]
+- OneRowRelation


-- !query
select TIMESTAMP_MILLIS(1230219000123),TIMESTAMP_MILLIS(-1230219000123),TIMESTAMP_MILLIS(null)
-- !query analysis
Project [timestamp_millis(1230219000123) AS timestamp_millis(1230219000123)#x, timestamp_millis(-1230219000123) AS timestamp_millis(-1230219000123)#x, timestamp_millis(null) AS timestamp_millis(NULL)#x]
+- OneRowRelation


-- !query
select TIMESTAMP_MICROS(1230219000123123),TIMESTAMP_MICROS(-1230219000123123),TIMESTAMP_MICROS(null)
-- !query analysis
Project [timestamp_micros(1230219000123123) AS timestamp_micros(1230219000123123)#x, timestamp_micros(-1230219000123123) AS timestamp_micros(-1230219000123123)#x, timestamp_micros(null) AS timestamp_micros(NULL)#x]
+- OneRowRelation


-- !query
select TIMESTAMP_SECONDS(1230219000123123)
-- !query analysis
Project [timestamp_seconds(1230219000123123) AS timestamp_seconds(1230219000123123)#x]
+- OneRowRelation


-- !query
select TIMESTAMP_SECONDS(-1230219000123123)
-- !query analysis
Project [timestamp_seconds(-1230219000123123) AS timestamp_seconds(-1230219000123123)#x]
+- OneRowRelation


-- !query
select TIMESTAMP_MILLIS(92233720368547758)
-- !query analysis
Project [timestamp_millis(92233720368547758) AS timestamp_millis(92233720368547758)#x]
+- OneRowRelation


-- !query
select TIMESTAMP_MILLIS(-92233720368547758)
-- !query analysis
Project [timestamp_millis(-92233720368547758) AS timestamp_millis(-92233720368547758)#x]
+- OneRowRelation


-- !query
select TIMESTAMP_SECONDS(0.1234567)
-- !query analysis
Project [timestamp_seconds(0.1234567) AS timestamp_seconds(0.1234567)#x]
+- OneRowRelation


-- !query
select TIMESTAMP_SECONDS(0.1234567d), TIMESTAMP_SECONDS(FLOAT(0.1234567))
-- !query analysis
Project [timestamp_seconds(0.1234567) AS timestamp_seconds(0.1234567)#x, timestamp_seconds(cast(0.1234567 as float)) AS timestamp_seconds(0.1234567)#x]
+- OneRowRelation


-- !query
create temporary view ttf1 as select * from values
  (1, 2),
  (2, 3)
  as ttf1(`current_date`, `current_timestamp`)
-- !query analysis
CreateViewCommand `ttf1`, select * from values
  (1, 2),
  (2, 3)
  as ttf1(`current_date`, `current_timestamp`), false, false, LocalTempView, UNSUPPORTED, true
   +- Project [current_date#x, current_timestamp#x]
      +- SubqueryAlias ttf1
         +- LocalRelation [current_date#x, current_timestamp#x]


-- !query
select typeof(current_date), typeof(current_timestamp) from ttf1
-- !query analysis
Project [typeof(current_date#x) AS typeof(current_date)#x, typeof(current_timestamp#x) AS typeof(current_timestamp)#x]
+- SubqueryAlias ttf1
   +- View (`ttf1`, [current_date#x, current_timestamp#x])
      +- Project [cast(current_date#x as int) AS current_date#x, cast(current_timestamp#x as int) AS current_timestamp#x]
         +- Project [current_date#x, current_timestamp#x]
            +- SubqueryAlias ttf1
               +- LocalRelation [current_date#x, current_timestamp#x]


-- !query
create temporary view ttf2 as select * from values
  (1, 2),
  (2, 3)
  as ttf2(a, b)
-- !query analysis
CreateViewCommand `ttf2`, select * from values
  (1, 2),
  (2, 3)
  as ttf2(a, b), false, false, LocalTempView, UNSUPPORTED, true
   +- Project [a#x, b#x]
      +- SubqueryAlias ttf2
         +- LocalRelation [a#x, b#x]


-- !query
select current_date = current_date(), current_timestamp = current_timestamp(), a, b from ttf2
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select a, b from ttf2 order by a, current_date
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select UNIX_SECONDS(timestamp'2020-12-01 14:30:08Z'), UNIX_SECONDS(timestamp'2020-12-01 14:30:08.999999Z'), UNIX_SECONDS(null)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select UNIX_MILLIS(timestamp'2020-12-01 14:30:08Z'), UNIX_MILLIS(timestamp'2020-12-01 14:30:08.999999Z'), UNIX_MILLIS(null)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select UNIX_MICROS(timestamp'2020-12-01 14:30:08Z'), UNIX_MICROS(timestamp'2020-12-01 14:30:08.999999Z'), UNIX_MICROS(null)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select to_timestamp(null), to_timestamp('2016-12-31 00:12:00'), to_timestamp('2016-12-31', 'yyyy-MM-dd')
-- !query analysis
Project [to_timestamp(cast(null as string), None, TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(NULL)#x, to_timestamp(2016-12-31 00:12:00, None, TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2016-12-31 00:12:00)#x, to_timestamp(2016-12-31, Some(yyyy-MM-dd), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2016-12-31, yyyy-MM-dd)#x]
+- OneRowRelation


-- !query
select to_timestamp(1)
-- !query analysis
Project [to_timestamp(1, None, TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(1)#x]
+- OneRowRelation


-- !query
select to_timestamp('2019-10-06 10:11:12.', 'yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]')
-- !query analysis
Project [to_timestamp(2019-10-06 10:11:12., Some(yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 10:11:12., yyyy-MM-dd HH:mm:ss.SSSSSS[zzz])#x]
+- OneRowRelation


-- !query
select to_timestamp('2019-10-06 10:11:12.0', 'yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]')
-- !query analysis
Project [to_timestamp(2019-10-06 10:11:12.0, Some(yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 10:11:12.0, yyyy-MM-dd HH:mm:ss.SSSSSS[zzz])#x]
+- OneRowRelation


-- !query
select to_timestamp('2019-10-06 10:11:12.1', 'yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]')
-- !query analysis
Project [to_timestamp(2019-10-06 10:11:12.1, Some(yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 10:11:12.1, yyyy-MM-dd HH:mm:ss.SSSSSS[zzz])#x]
+- OneRowRelation


-- !query
select to_timestamp('2019-10-06 10:11:12.12', 'yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]')
-- !query analysis
Project [to_timestamp(2019-10-06 10:11:12.12, Some(yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 10:11:12.12, yyyy-MM-dd HH:mm:ss.SSSSSS[zzz])#x]
+- OneRowRelation


-- !query
select to_timestamp('2019-10-06 10:11:12.123UTC', 'yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]')
-- !query analysis
Project [to_timestamp(2019-10-06 10:11:12.123UTC, Some(yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 10:11:12.123UTC, yyyy-MM-dd HH:mm:ss.SSSSSS[zzz])#x]
+- OneRowRelation


-- !query
select to_timestamp('2019-10-06 10:11:12.1234', 'yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]')
-- !query analysis
Project [to_timestamp(2019-10-06 10:11:12.1234, Some(yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 10:11:12.1234, yyyy-MM-dd HH:mm:ss.SSSSSS[zzz])#x]
+- OneRowRelation


-- !query
select to_timestamp('2019-10-06 10:11:12.12345CST', 'yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]')
-- !query analysis
Project [to_timestamp(2019-10-06 10:11:12.12345CST, Some(yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 10:11:12.12345CST, yyyy-MM-dd HH:mm:ss.SSSSSS[zzz])#x]
+- OneRowRelation


-- !query
select to_timestamp('2019-10-06 10:11:12.123456PST', 'yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]')
-- !query analysis
Project [to_timestamp(2019-10-06 10:11:12.123456PST, Some(yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 10:11:12.123456PST, yyyy-MM-dd HH:mm:ss.SSSSSS[zzz])#x]
+- OneRowRelation


-- !query
select to_timestamp('2019-10-06 10:11:12.1234567PST', 'yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]')
-- !query analysis
Project [to_timestamp(2019-10-06 10:11:12.1234567PST, Some(yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 10:11:12.1234567PST, yyyy-MM-dd HH:mm:ss.SSSSSS[zzz])#x]
+- OneRowRelation


-- !query
select to_timestamp('123456 2019-10-06 10:11:12.123456PST', 'SSSSSS yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]')
-- !query analysis
Project [to_timestamp(123456 2019-10-06 10:11:12.123456PST, Some(SSSSSS yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(123456 2019-10-06 10:11:12.123456PST, SSSSSS yyyy-MM-dd HH:mm:ss.SSSSSS[zzz])#x]
+- OneRowRelation


-- !query
select to_timestamp('223456 2019-10-06 10:11:12.123456PST', 'SSSSSS yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]')
-- !query analysis
Project [to_timestamp(223456 2019-10-06 10:11:12.123456PST, Some(SSSSSS yyyy-MM-dd HH:mm:ss.SSSSSS[zzz]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(223456 2019-10-06 10:11:12.123456PST, SSSSSS yyyy-MM-dd HH:mm:ss.SSSSSS[zzz])#x]
+- OneRowRelation


-- !query
select to_timestamp('2019-10-06 10:11:12.1234', 'yyyy-MM-dd HH:mm:ss.[SSSSSS]')
-- !query analysis
Project [to_timestamp(2019-10-06 10:11:12.1234, Some(yyyy-MM-dd HH:mm:ss.[SSSSSS]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 10:11:12.1234, yyyy-MM-dd HH:mm:ss.[SSSSSS])#x]
+- OneRowRelation


-- !query
select to_timestamp('2019-10-06 10:11:12.123', 'yyyy-MM-dd HH:mm:ss[.SSSSSS]')
-- !query analysis
Project [to_timestamp(2019-10-06 10:11:12.123, Some(yyyy-MM-dd HH:mm:ss[.SSSSSS]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 10:11:12.123, yyyy-MM-dd HH:mm:ss[.SSSSSS])#x]
+- OneRowRelation


-- !query
select to_timestamp('2019-10-06 10:11:12', 'yyyy-MM-dd HH:mm:ss[.SSSSSS]')
-- !query analysis
Project [to_timestamp(2019-10-06 10:11:12, Some(yyyy-MM-dd HH:mm:ss[.SSSSSS]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 10:11:12, yyyy-MM-dd HH:mm:ss[.SSSSSS])#x]
+- OneRowRelation


-- !query
select to_timestamp('2019-10-06 10:11:12.12', 'yyyy-MM-dd HH:mm[:ss.SSSSSS]')
-- !query analysis
Project [to_timestamp(2019-10-06 10:11:12.12, Some(yyyy-MM-dd HH:mm[:ss.SSSSSS]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 10:11:12.12, yyyy-MM-dd HH:mm[:ss.SSSSSS])#x]
+- OneRowRelation


-- !query
select to_timestamp('2019-10-06 10:11', 'yyyy-MM-dd HH:mm[:ss.SSSSSS]')
-- !query analysis
Project [to_timestamp(2019-10-06 10:11, Some(yyyy-MM-dd HH:mm[:ss.SSSSSS]), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 10:11, yyyy-MM-dd HH:mm[:ss.SSSSSS])#x]
+- OneRowRelation


-- !query
select to_timestamp("2019-10-06S10:11:12.12345", "yyyy-MM-dd'S'HH:mm:ss.SSSSSS")
-- !query analysis
Project [to_timestamp(2019-10-06S10:11:12.12345, Some(yyyy-MM-dd'S'HH:mm:ss.SSSSSS), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06S10:11:12.12345, yyyy-MM-dd'S'HH:mm:ss.SSSSSS)#x]
+- OneRowRelation


-- !query
select to_timestamp("12.12342019-10-06S10:11", "ss.SSSSyyyy-MM-dd'S'HH:mm")
-- !query analysis
Project [to_timestamp(12.12342019-10-06S10:11, Some(ss.SSSSyyyy-MM-dd'S'HH:mm), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(12.12342019-10-06S10:11, ss.SSSSyyyy-MM-dd'S'HH:mm)#x]
+- OneRowRelation


-- !query
select to_timestamp("12.1232019-10-06S10:11", "ss.SSSSyyyy-MM-dd'S'HH:mm")
-- !query analysis
Project [to_timestamp(12.1232019-10-06S10:11, Some(ss.SSSSyyyy-MM-dd'S'HH:mm), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(12.1232019-10-06S10:11, ss.SSSSyyyy-MM-dd'S'HH:mm)#x]
+- OneRowRelation


-- !query
select to_timestamp("12.1232019-10-06S10:11", "ss.SSSSyy-MM-dd'S'HH:mm")
-- !query analysis
Project [to_timestamp(12.1232019-10-06S10:11, Some(ss.SSSSyy-MM-dd'S'HH:mm), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(12.1232019-10-06S10:11, ss.SSSSyy-MM-dd'S'HH:mm)#x]
+- OneRowRelation


-- !query
select to_timestamp("12.1234019-10-06S10:11", "ss.SSSSy-MM-dd'S'HH:mm")
-- !query analysis
Project [to_timestamp(12.1234019-10-06S10:11, Some(ss.SSSSy-MM-dd'S'HH:mm), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(12.1234019-10-06S10:11, ss.SSSSy-MM-dd'S'HH:mm)#x]
+- OneRowRelation


-- !query
select to_timestamp("2019-10-06S", "yyyy-MM-dd'S'")
-- !query analysis
Project [to_timestamp(2019-10-06S, Some(yyyy-MM-dd'S'), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06S, yyyy-MM-dd'S')#x]
+- OneRowRelation


-- !query
select to_timestamp("S2019-10-06", "'S'yyyy-MM-dd")
-- !query analysis
Project [to_timestamp(S2019-10-06, Some('S'yyyy-MM-dd), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(S2019-10-06, 'S'yyyy-MM-dd)#x]
+- OneRowRelation


-- !query
select to_timestamp("2019-10-06T10:11:12'12", "yyyy-MM-dd'T'HH:mm:ss''SSSS")
-- !query analysis
Project [to_timestamp(2019-10-06T10:11:12'12, Some(yyyy-MM-dd'T'HH:mm:ss''SSSS), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06T10:11:12'12, yyyy-MM-dd'T'HH:mm:ss''SSSS)#x]
+- OneRowRelation


-- !query
select to_timestamp("2019-10-06T10:11:12'", "yyyy-MM-dd'T'HH:mm:ss''")
-- !query analysis
Project [to_timestamp(2019-10-06T10:11:12', Some(yyyy-MM-dd'T'HH:mm:ss''), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06T10:11:12', yyyy-MM-dd'T'HH:mm:ss'')#x]
+- OneRowRelation


-- !query
select to_timestamp("'2019-10-06T10:11:12", "''yyyy-MM-dd'T'HH:mm:ss")
-- !query analysis
Project [to_timestamp('2019-10-06T10:11:12, Some(''yyyy-MM-dd'T'HH:mm:ss), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp('2019-10-06T10:11:12, ''yyyy-MM-dd'T'HH:mm:ss)#x]
+- OneRowRelation


-- !query
select to_timestamp("P2019-10-06T10:11:12", "'P'yyyy-MM-dd'T'HH:mm:ss")
-- !query analysis
Project [to_timestamp(P2019-10-06T10:11:12, Some('P'yyyy-MM-dd'T'HH:mm:ss), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(P2019-10-06T10:11:12, 'P'yyyy-MM-dd'T'HH:mm:ss)#x]
+- OneRowRelation


-- !query
select to_timestamp("16", "dd")
-- !query analysis
Project [to_timestamp(16, Some(dd), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(16, dd)#x]
+- OneRowRelation


-- !query
select to_timestamp("02-29", "MM-dd")
-- !query analysis
Project [to_timestamp(02-29, Some(MM-dd), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(02-29, MM-dd)#x]
+- OneRowRelation


-- !query
select to_timestamp("2019 40", "yyyy mm")
-- !query analysis
Project [to_timestamp(2019 40, Some(yyyy mm), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019 40, yyyy mm)#x]
+- OneRowRelation


-- !query
select to_timestamp("2019 10:10:10", "yyyy hh:mm:ss")
-- !query analysis
Project [to_timestamp(2019 10:10:10, Some(yyyy hh:mm:ss), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019 10:10:10, yyyy hh:mm:ss)#x]
+- OneRowRelation


-- !query
select timestamp'2011-11-11 11:11:11' - timestamp'2011-11-11 11:11:10'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date'2020-01-01' - timestamp'2019-10-06 10:11:12.345678'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestamp'2019-10-06 10:11:12.345678' - date'2020-01-01'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestamp'2011-11-11 11:11:11' - '2011-11-11 11:11:10'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select '2011-11-11 11:11:11' - timestamp'2011-11-11 11:11:10'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestamp'2011-11-11 11:11:11' - null
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select null - timestamp'2011-11-11 11:11:11'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
create temporary view ts_view as select '2011-11-11 11:11:11' str
-- !query analysis
CreateViewCommand `ts_view`, select '2011-11-11 11:11:11' str, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [2011-11-11 11:11:11 AS str#x]
      +- OneRowRelation


-- !query
select str - timestamp'2011-11-11 11:11:11' from ts_view
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestamp'2011-11-11 11:11:11' - str from ts_view
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestamp'2011-11-11 11:11:11' + '1'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"TIMESTAMP\"",
    "inputType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(TIMESTAMP '2011-11-11 11:11:11' + 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 43,
    "fragment" : "timestamp'2011-11-11 11:11:11' + '1'"
  } ]
}


-- !query
select '1' + timestamp'2011-11-11 11:11:11'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"TIMESTAMP\"",
    "inputType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(1 + TIMESTAMP '2011-11-11 11:11:11')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 43,
    "fragment" : "'1' + timestamp'2011-11-11 11:11:11'"
  } ]
}


-- !query
select timestamp'2011-11-11 11:11:11' + null
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"TIMESTAMP\"",
    "right" : "\"VOID\"",
    "sqlExpr" : "\"(TIMESTAMP '2011-11-11 11:11:11' + NULL)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 44,
    "fragment" : "timestamp'2011-11-11 11:11:11' + null"
  } ]
}


-- !query
select null + timestamp'2011-11-11 11:11:11'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"VOID\"",
    "right" : "\"TIMESTAMP\"",
    "sqlExpr" : "\"(NULL + TIMESTAMP '2011-11-11 11:11:11')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 44,
    "fragment" : "null + timestamp'2011-11-11 11:11:11'"
  } ]
}


-- !query
select timestamp'2011-11-11 11:11:11' + interval '2' day,
       timestamp'2011-11-11 11:11:11' - interval '2-2' year to month,
       timestamp'2011-11-11 11:11:11' + interval '-2' second,
       timestamp'2011-11-11 11:11:11' - interval '12:12:12.123456789' hour to second,
       - interval 2 years + timestamp'2011-11-11 11:11:11',
       interval '1 12' day to hour + timestamp'2011-11-11 11:11:11'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select date '2012-01-01' - interval 3 hours,
       date '2012-01-01' + interval '12:12:12' hour to second,
       interval '2' minute + date '2012-01-01'
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select to_timestamp('2019-10-06 A', 'yyyy-MM-dd GGGGG')
-- !query analysis
Project [to_timestamp(2019-10-06 A, Some(yyyy-MM-dd GGGGG), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(2019-10-06 A, yyyy-MM-dd GGGGG)#x]
+- OneRowRelation


-- !query
select to_timestamp('22 05 2020 Friday', 'dd MM yyyy EEEEEE')
-- !query analysis
Project [to_timestamp(22 05 2020 Friday, Some(dd MM yyyy EEEEEE), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(22 05 2020 Friday, dd MM yyyy EEEEEE)#x]
+- OneRowRelation


-- !query
select to_timestamp('22 05 2020 Friday', 'dd MM yyyy EEEEE')
-- !query analysis
Project [to_timestamp(22 05 2020 Friday, Some(dd MM yyyy EEEEE), TimestampType, Some(America/Los_Angeles), true) AS to_timestamp(22 05 2020 Friday, dd MM yyyy EEEEE)#x]
+- OneRowRelation


-- !query
select unix_timestamp('22 05 2020 Friday', 'dd MM yyyy EEEEE')
-- !query analysis
Project [unix_timestamp(22 05 2020 Friday, dd MM yyyy EEEEE, Some(America/Los_Angeles), true) AS unix_timestamp(22 05 2020 Friday, dd MM yyyy EEEEE)#xL]
+- OneRowRelation


-- !query
select from_json('{"t":"26/October/2015"}', 't Timestamp', map('timestampFormat', 'dd/MMMMM/yyyy'))
-- !query analysis
Project [from_json(StructField(t,TimestampType,true), (timestampFormat,dd/MMMMM/yyyy), {"t":"26/October/2015"}, Some(America/Los_Angeles), false) AS from_json({"t":"26/October/2015"})#x]
+- OneRowRelation


-- !query
select from_csv('26/October/2015', 't Timestamp', map('timestampFormat', 'dd/MMMMM/yyyy'))
-- !query analysis
Project [from_csv(StructField(t,TimestampType,true), (timestampFormat,dd/MMMMM/yyyy), 26/October/2015, Some(America/Los_Angeles), None) AS from_csv(26/October/2015)#x]
+- OneRowRelation


-- !query
select timestampadd(MONTH, -1, timestamp'2022-02-14 01:02:03')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestampadd(MINUTE, 58, timestamp'2022-02-14 01:02:03')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestampadd(YEAR, 1, date'2022-02-15')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestampadd(SECOND, -1, date'2022-02-15')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestampadd('MONTH', -1, timestamp'2022-02-14 01:02:03')
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_PARAMETER_VALUE.DATETIME_UNIT",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "`timestampadd`",
    "invalidValue" : "'MONTH'",
    "parameter" : "`unit`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 64,
    "fragment" : "timestampadd('MONTH', -1, timestamp'2022-02-14 01:02:03')"
  } ]
}


-- !query
select timestampadd('SECOND', -1, date'2022-02-15')
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_PARAMETER_VALUE.DATETIME_UNIT",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "`timestampadd`",
    "invalidValue" : "'SECOND'",
    "parameter" : "`unit`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 51,
    "fragment" : "timestampadd('SECOND', -1, date'2022-02-15')"
  } ]
}


-- !query
select timestampdiff(MONTH, timestamp'2022-02-14 01:02:03', timestamp'2022-01-14 01:02:03')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestampdiff(MINUTE, timestamp'2022-02-14 01:02:03', timestamp'2022-02-14 02:00:03')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestampdiff(YEAR, date'2022-02-15', date'2023-02-15')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestampdiff(SECOND, date'2022-02-15', timestamp'2022-02-14 23:59:59')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timestampdiff('MINUTE', timestamp'2022-02-14 01:02:03', timestamp'2022-02-14 02:00:03')
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_PARAMETER_VALUE.DATETIME_UNIT",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "`timestampdiff`",
    "invalidValue" : "'MINUTE'",
    "parameter" : "`unit`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 94,
    "fragment" : "timestampdiff('MINUTE', timestamp'2022-02-14 01:02:03', timestamp'2022-02-14 02:00:03')"
  } ]
}


-- !query
select timestampdiff('YEAR', date'2022-02-15', date'2023-02-15')
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_PARAMETER_VALUE.DATETIME_UNIT",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "`timestampdiff`",
    "invalidValue" : "'YEAR'",
    "parameter" : "`unit`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 64,
    "fragment" : "timestampdiff('YEAR', date'2022-02-15', date'2023-02-15')"
  } ]
}


-- !query
select timediff(QUARTER, timestamp'2023-08-10 01:02:03', timestamp'2022-01-14 01:02:03')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timediff(HOUR, timestamp'2022-02-14 01:02:03', timestamp'2022-02-14 12:00:03')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timediff(DAY, date'2022-02-15', date'2023-02-15')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timediff(SECOND, date'2022-02-15', timestamp'2022-02-14 23:59:59')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select timediff('MINUTE', timestamp'2023-02-14 01:02:03', timestamp'2023-02-14 02:00:03')
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_PARAMETER_VALUE.DATETIME_UNIT",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "`timediff`",
    "invalidValue" : "'MINUTE'",
    "parameter" : "`unit`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 89,
    "fragment" : "timediff('MINUTE', timestamp'2023-02-14 01:02:03', timestamp'2023-02-14 02:00:03')"
  } ]
}


-- !query
select timediff('YEAR', date'2020-02-15', date'2023-02-15')
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_PARAMETER_VALUE.DATETIME_UNIT",
  "sqlState" : "22023",
  "messageParameters" : {
    "functionName" : "`timediff`",
    "invalidValue" : "'YEAR'",
    "parameter" : "`unit`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 59,
    "fragment" : "timediff('YEAR', date'2020-02-15', date'2023-02-15')"
  } ]
}
