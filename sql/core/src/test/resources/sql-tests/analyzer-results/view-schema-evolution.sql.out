-- Automatically generated by SQLQueryTestSuite
-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT NOT NULL, c2 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES (1, 2)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2]
+- Project [cast(col1#x as int) AS c1#x, cast(col2#x as int) AS c2#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
CREATE OR REPLACE VIEW v WITH SCHEMA EVOLUTION AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, true, PersistedView, EVOLUTION, true
   +- Project [c1#x, c2#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x, c2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x])
      +- Project [c1#x, c2#x]
         +- SubqueryAlias spark_catalog.default.t
            +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c4 STRING NOT NULL, c5 DOUBLE) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('1', 2.0)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c4, c5]
+- Project [cast(col1#x as string) AS c4#x, cast(col2#x as double) AS c5#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
SELECT * FROM v
-- !query analysis
Project [c4#x, c5#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c4#x, c5#x])
      +- Project [c4#x, c5#x]
         +- SubqueryAlias spark_catalog.default.t
            +- Relation spark_catalog.default.t[c4#x,c5#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c4 STRING, c5 DOUBLE, c6 DATE) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('1', 2.0, DATE'2022-01-01')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c4, c5, c6]
+- Project [cast(col1#x as string) AS c4#x, cast(col2#x as double) AS c5#x, cast(col3#x as date) AS c6#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
SELECT * FROM v
-- !query analysis
Project [c4#x, c5#x, c6#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c4#x, c5#x, c6#x])
      +- Project [c4#x, c5#x, c6#x]
         +- SubqueryAlias spark_catalog.default.t
            +- Relation spark_catalog.default.t[c4#x,c5#x,c6#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT, c2 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES (1, 2)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2]
+- Project [cast(col1#x as int) AS c1#x, cast(col2#x as int) AS c2#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
CREATE OR REPLACE VIEW v WITH SCHEMA EVOLUTION AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, true, PersistedView, EVOLUTION, true
   +- Project [c1#x, c2#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x, c2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x])
      +- Project [c1#x, c2#x]
         +- SubqueryAlias spark_catalog.default.t
            +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x])
      +- Project [c1#x]
         +- SubqueryAlias spark_catalog.default.t
            +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT NOT NULL, c2 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES (1, 2)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2]
+- Project [cast(col1#x as int) AS c1#x, cast(col2#x as int) AS c2#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
CREATE OR REPLACE VIEW v(a1, a2) WITH SCHEMA EVOLUTION AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, [(a1,None), (a2,None)], SELECT * FROM t, false, true, PersistedView, TYPE EVOLUTION, true
   +- Project [c1#x, c2#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT * FROM v
-- !query analysis
Project [a1#x, a2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [a1#x, a2#x])
      +- Project [c1#x AS a1#x, c2#x AS a2#x]
         +- Project [c1#x, c2#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 STRING NOT NULL, c2 DOUBLE) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('1', 2.0)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2]
+- Project [cast(col1#x as string) AS c1#x, cast(col2#x as double) AS c2#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
SELECT * FROM v
-- !query analysis
Project [a1#x, a2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [a1#x, a2#x])
      +- Project [c1#x AS a1#x, c2#x AS a2#x]
         +- Project [c1#x, c2#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 STRING, c2 DOUBLE, c3 DATE) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('1', 2.0, DATE'2022-01-01')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2, c3]
+- Project [cast(col1#x as string) AS c1#x, cast(col2#x as double) AS c2#x, cast(col3#x as date) AS c3#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
SELECT * FROM v
-- !query analysis
Project [a1#x, a2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [a1#x, a2#x])
      +- Project [c1#x AS a1#x, c2#x AS a2#x]
         +- Project [c1#x, c2#x, c3#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x,c2#x,c3#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT, c2 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES (1, 2)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2]
+- Project [cast(col1#x as int) AS c1#x, cast(col2#x as int) AS c2#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
CREATE OR REPLACE VIEW v(a1, a2) WITH SCHEMA EVOLUTION AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, [(a1,None), (a2,None)], SELECT * FROM t, false, true, PersistedView, TYPE EVOLUTION, true
   +- Project [c1#x, c2#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT * FROM v
-- !query analysis
Project [a1#x, a2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [a1#x, a2#x])
      +- Project [c1#x AS a1#x, c2#x AS a2#x]
         +- Project [c1#x, c2#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INCOMPATIBLE_VIEW_SCHEMA_CHANGE",
  "sqlState" : "51024",
  "messageParameters" : {
    "actualCols" : "[]",
    "colName" : "c2",
    "expectedNum" : "1",
    "suggestion" : "CREATE OR REPLACE VIEW spark_catalog.default.v (a1, a2) AS SELECT * FROM t",
    "viewName" : "`spark_catalog`.`default`.`v`"
  }
}


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c3 INT, c2 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INCOMPATIBLE_VIEW_SCHEMA_CHANGE",
  "sqlState" : "51024",
  "messageParameters" : {
    "actualCols" : "[]",
    "colName" : "c1",
    "expectedNum" : "1",
    "suggestion" : "CREATE OR REPLACE VIEW spark_catalog.default.v (a1, a2) AS SELECT * FROM t",
    "viewName" : "`spark_catalog`.`default`.`v`"
  }
}


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT COMMENT 'c1', c2 INT COMMENT 'c2') USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
CREATE OR REPLACE VIEW v(a1, a2) WITH SCHEMA TYPE EVOLUTION AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, [(a1,None), (a2,None)], SELECT * FROM t, false, true, PersistedView, TYPE EVOLUTION, true
   +- Project [c1#x, c2#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE OR REPLACE VIEW v(a1, a2) WITH SCHEMA EVOLUTION AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, [(a1,None), (a2,None)], SELECT * FROM t, false, true, PersistedView, TYPE EVOLUTION, true
   +- Project [c1#x, c2#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 BIGINT COMMENT 'c1 6c', c2 STRING COMMENT 'c2 6c') USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
Project [a1#xL, a2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [a1#xL, a2#x])
      +- Project [c1#xL AS a1#xL, c2#x AS a2#x]
         +- Project [c1#xL, c2#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#xL,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE OR REPLACE VIEW v(a1 COMMENT 'a1', a2 COMMENT 'a2') WITH SCHEMA EVOLUTION AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, [(a1,Some(a1)), (a2,Some(a2))], SELECT * FROM t, false, true, PersistedView, TYPE EVOLUTION, true
   +- Project [c1#xL, c2#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#xL,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 BIGINT COMMENT 'c1 6d', c2 STRING COMMENT 'c2 6d') USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
Project [a1#xL, a2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [a1#xL, a2#x])
      +- Project [c1#xL AS a1#xL, c2#x AS a2#x]
         +- Project [c1#xL, c2#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#xL,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE OR REPLACE VIEW v WITH SCHEMA EVOLUTION AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, true, PersistedView, EVOLUTION, true
   +- Project [c1#xL, c2#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#xL,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 BIGINT COMMENT 'c1 6e', c2 STRING COMMENT 'c2 6e') USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#xL, c2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#xL, c2#x])
      +- Project [c1#xL, c2#x]
         +- SubqueryAlias spark_catalog.default.t
            +- Relation spark_catalog.default.t[c1#xL,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t1
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
CREATE TABLE t1(c1 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
DROP TABLE IF EXISTS t2
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t2


-- !query
CREATE TABLE t2(c2 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t2`, false


-- !query
CREATE OR REPLACE VIEW v WITH SCHEMA EVOLUTION AS SELECT * FROM t1, t2
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t1, t2, false, true, PersistedView, EVOLUTION, true
   +- Project [c1#x, c2#x]
      +- Join Inner
         :- SubqueryAlias spark_catalog.default.t1
         :  +- Relation spark_catalog.default.t1[c1#x] parquet
         +- SubqueryAlias spark_catalog.default.t2
            +- Relation spark_catalog.default.t2[c2#x] parquet


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x, c2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x])
      +- Project [c1#x, c2#x]
         +- Join Inner
            :- SubqueryAlias spark_catalog.default.t1
            :  +- Relation spark_catalog.default.t1[c1#x] parquet
            +- SubqueryAlias spark_catalog.default.t2
               +- Relation spark_catalog.default.t2[c2#x] parquet


-- !query
DROP TABLE IF EXISTS t2
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t2


-- !query
CREATE TABLE t2(c1 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t2`, false


-- !query
SELECT * FROM v
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "COLUMN_ALREADY_EXISTS",
  "sqlState" : "42711",
  "messageParameters" : {
    "columnName" : "`c1`"
  }
}


-- !query
DROP TABLE IF EXISTS t1
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
DROP TABLE IF EXISTS t2
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t2


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES(1)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1]
+- Project [cast(col1#x as int) AS c1#x]
   +- LocalRelation [col1#x]


-- !query
CREATE OR REPLACE VIEW v AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, true, PersistedView, COMPENSATION, true
   +- Project [c1#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
ALTER VIEW v WITH SCHEMA EVOLUTION
-- !query analysis
AlterViewSchemaBindingCommand `spark_catalog`.`default`.`v`, EVOLUTION


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 STRING, c2 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x, c2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x])
      +- Project [c1#x, c2#x]
         +- SubqueryAlias spark_catalog.default.t
            +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, true, true, false


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t
