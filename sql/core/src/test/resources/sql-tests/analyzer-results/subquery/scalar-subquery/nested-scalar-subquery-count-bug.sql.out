-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE OR REPLACE VIEW t1(a1, a2) as values (0, 1), (1, 2)
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`t1`, [(a1,None), (a2,None)], values (0, 1), (1, 2), false, true, PersistedView, COMPENSATION, true
   +- LocalRelation [col1#x, col2#x]


-- !query
CREATE OR REPLACE VIEW t2(b1, b2) as values (0, 2), (0, 3)
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`t2`, [(b1,None), (b2,None)], values (0, 2), (0, 3), false, true, PersistedView, COMPENSATION, true
   +- LocalRelation [col1#x, col2#x]


-- !query
CREATE OR REPLACE VIEW t3(c1, c2) as values (0, 2), (0, 3)
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`t3`, [(c1,None), (c2,None)], values (0, 2), (0, 3), false, true, PersistedView, COMPENSATION, true
   +- LocalRelation [col1#x, col2#x]


-- !query
set spark.sql.optimizer.decorrelateInnerQuery.enabled=true
-- !query analysis
SetCommand (spark.sql.optimizer.decorrelateInnerQuery.enabled,Some(true))


-- !query
set spark.sql.legacy.scalarSubqueryCountBugBehavior=false
-- !query analysis
SetCommand (spark.sql.legacy.scalarSubqueryCountBugBehavior,Some(false))


-- !query
select ( select sum(cnt) from (select count(*) cnt from t2 where t1.a1 = t2.b1) ) a from t1 order by a desc
-- !query analysis
Sort [a#xL DESC NULLS LAST], true
+- Project [scalar-subquery#x [a1#x] AS a#xL]
   :  +- Aggregate [sum(cnt#xL) AS sum(cnt)#xL]
   :     +- SubqueryAlias __auto_generated_subquery_name
   :        +- Aggregate [count(1) AS cnt#xL]
   :           +- Filter (outer(a1#x) = b1#x)
   :              +- SubqueryAlias spark_catalog.default.t2
   :                 +- View (`spark_catalog`.`default`.`t2`, [b1#x, b2#x])
   :                    +- Project [cast(col1#x as int) AS b1#x, cast(col2#x as int) AS b2#x]
   :                       +- LocalRelation [col1#x, col2#x]
   +- SubqueryAlias spark_catalog.default.t1
      +- View (`spark_catalog`.`default`.`t1`, [a1#x, a2#x])
         +- Project [cast(col1#x as int) AS a1#x, cast(col2#x as int) AS a2#x]
            +- LocalRelation [col1#x, col2#x]


-- !query
select ( select count(*) from (select count(*) cnt from t2 where t1.a1 = t2.b1) ) a from t1 order by a desc
-- !query analysis
Sort [a#xL DESC NULLS LAST], true
+- Project [scalar-subquery#x [a1#x] AS a#xL]
   :  +- Aggregate [count(1) AS count(1)#xL]
   :     +- SubqueryAlias __auto_generated_subquery_name
   :        +- Aggregate [count(1) AS cnt#xL]
   :           +- Filter (outer(a1#x) = b1#x)
   :              +- SubqueryAlias spark_catalog.default.t2
   :                 +- View (`spark_catalog`.`default`.`t2`, [b1#x, b2#x])
   :                    +- Project [cast(col1#x as int) AS b1#x, cast(col2#x as int) AS b2#x]
   :                       +- LocalRelation [col1#x, col2#x]
   +- SubqueryAlias spark_catalog.default.t1
      +- View (`spark_catalog`.`default`.`t1`, [a1#x, a2#x])
         +- Project [cast(col1#x as int) AS a1#x, cast(col2#x as int) AS a2#x]
            +- LocalRelation [col1#x, col2#x]


-- !query
select (
  select SUM(l.cnt + r.cnt)
  from (select count(*) cnt from t2 where t1.a1 = t2.b1 having cnt = 0) l
  join (select count(*) cnt from t3 where t1.a1 = t3.c1 having cnt = 0) r
  on l.cnt = r.cnt
) a from t1 order by a desc
-- !query analysis
Sort [a#xL DESC NULLS LAST], true
+- Project [scalar-subquery#x [a1#x && a1#x] AS a#xL]
   :  +- Aggregate [sum((cnt#xL + cnt#xL)) AS sum((cnt + cnt))#xL]
   :     +- Join Inner, (cnt#xL = cnt#xL)
   :        :- SubqueryAlias l
   :        :  +- Filter (cnt#xL = cast(0 as bigint))
   :        :     +- Aggregate [count(1) AS cnt#xL]
   :        :        +- Filter (outer(a1#x) = b1#x)
   :        :           +- SubqueryAlias spark_catalog.default.t2
   :        :              +- View (`spark_catalog`.`default`.`t2`, [b1#x, b2#x])
   :        :                 +- Project [cast(col1#x as int) AS b1#x, cast(col2#x as int) AS b2#x]
   :        :                    +- LocalRelation [col1#x, col2#x]
   :        +- SubqueryAlias r
   :           +- Filter (cnt#xL = cast(0 as bigint))
   :              +- Aggregate [count(1) AS cnt#xL]
   :                 +- Filter (outer(a1#x) = c1#x)
   :                    +- SubqueryAlias spark_catalog.default.t3
   :                       +- View (`spark_catalog`.`default`.`t3`, [c1#x, c2#x])
   :                          +- Project [cast(col1#x as int) AS c1#x, cast(col2#x as int) AS c2#x]
   :                             +- LocalRelation [col1#x, col2#x]
   +- SubqueryAlias spark_catalog.default.t1
      +- View (`spark_catalog`.`default`.`t1`, [a1#x, a2#x])
         +- Project [cast(col1#x as int) AS a1#x, cast(col2#x as int) AS a2#x]
            +- LocalRelation [col1#x, col2#x]


-- !query
select (
  select sum(l.cnt + r.cnt)
  from (select count(*) cnt from t2 where t1.a1 = t2.b1) l
  join (select count(*) cnt from t3 where t1.a1 = t3.c1) r
  on l.cnt = r.cnt
) a from t1 order by a desc
-- !query analysis
Sort [a#xL DESC NULLS LAST], true
+- Project [scalar-subquery#x [a1#x && a1#x] AS a#xL]
   :  +- Aggregate [sum((cnt#xL + cnt#xL)) AS sum((cnt + cnt))#xL]
   :     +- Join Inner, (cnt#xL = cnt#xL)
   :        :- SubqueryAlias l
   :        :  +- Aggregate [count(1) AS cnt#xL]
   :        :     +- Filter (outer(a1#x) = b1#x)
   :        :        +- SubqueryAlias spark_catalog.default.t2
   :        :           +- View (`spark_catalog`.`default`.`t2`, [b1#x, b2#x])
   :        :              +- Project [cast(col1#x as int) AS b1#x, cast(col2#x as int) AS b2#x]
   :        :                 +- LocalRelation [col1#x, col2#x]
   :        +- SubqueryAlias r
   :           +- Aggregate [count(1) AS cnt#xL]
   :              +- Filter (outer(a1#x) = c1#x)
   :                 +- SubqueryAlias spark_catalog.default.t3
   :                    +- View (`spark_catalog`.`default`.`t3`, [c1#x, c2#x])
   :                       +- Project [cast(col1#x as int) AS c1#x, cast(col2#x as int) AS c2#x]
   :                          +- LocalRelation [col1#x, col2#x]
   +- SubqueryAlias spark_catalog.default.t1
      +- View (`spark_catalog`.`default`.`t1`, [a1#x, a2#x])
         +- Project [cast(col1#x as int) AS a1#x, cast(col2#x as int) AS a2#x]
            +- LocalRelation [col1#x, col2#x]


-- !query
reset spark.sql.optimizer.decorrelateInnerQuery.enabled
-- !query analysis
ResetCommand spark.sql.optimizer.decorrelateInnerQuery.enabled


-- !query
reset spark.sql.legacy.scalarSubqueryCountBugBehavior
-- !query analysis
ResetCommand spark.sql.legacy.scalarSubqueryCountBugBehavior


-- !query
DROP VIEW t1
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`t1`, false, true, false


-- !query
DROP VIEW t2
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`t2`, false, true, false


-- !query
DROP VIEW t3
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`t3`, false, true, false
