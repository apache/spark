-- Automatically generated by SQLQueryTestSuite
-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT NOT NULL, c2 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES (1, 2)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2]
+- Project [cast(col1#x as int) AS c1#x, cast(col2#x as int) AS c2#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
CREATE OR REPLACE VIEW v WITH SCHEMA TYPE EVOLUTION AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, true, PersistedView, TYPE EVOLUTION, true
   +- Project [c1#x, c2#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x, c2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x])
      +- Project [c1#x AS c1#x, c2#x AS c2#x]
         +- Project [c1#x, c2#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 STRING NOT NULL, c2 DOUBLE) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('1', 2.0)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2]
+- Project [cast(col1#x as string) AS c1#x, cast(col2#x as double) AS c2#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x, c2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x])
      +- Project [c1#x AS c1#x, c2#x AS c2#x]
         +- Project [c1#x, c2#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 STRING, c2 DOUBLE, c3 DATE) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('1', 2.0, DATE'2022-01-01')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2, c3]
+- Project [cast(col1#x as string) AS c1#x, cast(col2#x as double) AS c2#x, cast(col3#x as date) AS c3#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x, c2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x])
      +- Project [c1#x AS c1#x, c2#x AS c2#x]
         +- Project [c1#x, c2#x, c3#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x,c2#x,c3#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT, c2 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES (1, 2)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2]
+- Project [cast(col1#x as int) AS c1#x, cast(col2#x as int) AS c2#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
CREATE OR REPLACE VIEW v WITH SCHEMA TYPE EVOLUTION AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, true, PersistedView, TYPE EVOLUTION, true
   +- Project [c1#x, c2#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x, c2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x])
      +- Project [c1#x AS c1#x, c2#x AS c2#x]
         +- Project [c1#x, c2#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INCOMPATIBLE_VIEW_SCHEMA_CHANGE",
  "sqlState" : "51024",
  "messageParameters" : {
    "actualCols" : "[]",
    "colName" : "c2",
    "expectedNum" : "1",
    "suggestion" : "CREATE OR REPLACE VIEW spark_catalog.default.v AS SELECT * FROM t",
    "viewName" : "`spark_catalog`.`default`.`v`"
  }
}


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c3 INT, c2 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INCOMPATIBLE_VIEW_SCHEMA_CHANGE",
  "sqlState" : "51024",
  "messageParameters" : {
    "actualCols" : "[]",
    "colName" : "c1",
    "expectedNum" : "1",
    "suggestion" : "CREATE OR REPLACE VIEW spark_catalog.default.v AS SELECT * FROM t",
    "viewName" : "`spark_catalog`.`default`.`v`"
  }
}


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT COMMENT 'c1', c2 INT COMMENT 'c2') USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
CREATE OR REPLACE VIEW v(a1, a2) WITH SCHEMA TYPE EVOLUTION AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, [(a1,None), (a2,None)], SELECT * FROM t, false, true, PersistedView, TYPE EVOLUTION, true
   +- Project [c1#x, c2#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 BIGINT COMMENT 'c1 6a', c2 STRING COMMENT 'c2 6a') USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
Project [a1#xL, a2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [a1#xL, a2#x])
      +- Project [c1#xL AS a1#xL, c2#x AS a2#x]
         +- Project [c1#xL, c2#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#xL,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE OR REPLACE VIEW v(a1 COMMENT 'a1', a2 COMMENT 'a2') WITH SCHEMA TYPE EVOLUTION AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, [(a1,Some(a1)), (a2,Some(a2))], SELECT * FROM t, false, true, PersistedView, TYPE EVOLUTION, true
   +- Project [c1#xL, c2#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#xL,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 BIGINT COMMENT 'c1 6b', c2 STRING COMMENT 'c2 6b') USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
Project [a1#xL, a2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [a1#xL, a2#x])
      +- Project [c1#xL AS a1#xL, c2#x AS a2#x]
         +- Project [c1#xL, c2#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#xL,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES(1)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1]
+- Project [cast(col1#x as int) AS c1#x]
   +- LocalRelation [col1#x]


-- !query
CREATE OR REPLACE VIEW v WITH SCHEMA COMPENSATION AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, true, PersistedView, COMPENSATION, true
   +- Project [c1#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 STRING) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES('1')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1]
+- Project [cast(col1#x as string) AS c1#x]
   +- LocalRelation [col1#x]


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x])
      +- Project [cast(c1#x as int) AS c1#x]
         +- Project [c1#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
ALTER VIEW v WITH SCHEMA TYPE EVOLUTION
-- !query analysis
AlterViewSchemaBindingCommand `spark_catalog`.`default`.`v`, TYPE EVOLUTION


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x])
      +- Project [c1#x AS c1#x]
         +- Project [c1#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, true, true, false


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t
