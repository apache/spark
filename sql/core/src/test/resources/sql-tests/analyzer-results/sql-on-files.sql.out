-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE DATABASE IF NOT EXISTS sql_on_files
-- !query analysis
CreateNamespace true
+- ResolvedNamespace V2SessionCatalog(spark_catalog), [sql_on_files]


-- !query
CREATE TABLE sql_on_files.test_parquet USING PARQUET AS SELECT 1
-- !query analysis
CreateDataSourceTableAsSelectCommand `spark_catalog`.`sql_on_files`.`test_parquet`, ErrorIfExists, [1]
   +- Project [1 AS 1#x]
      +- OneRowRelation


-- !query
SELECT * FROM parquet.``
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INVALID_EMPTY_LOCATION",
  "sqlState" : "42K05",
  "messageParameters" : {
    "location" : ""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 24,
    "fragment" : "parquet.``"
  } ]
}


-- !query
SELECT * FROM parquet.`file:tmp`
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INVALID_LOCATION",
  "sqlState" : "42K05",
  "messageParameters" : {
    "location" : "file:tmp"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 32,
    "fragment" : "parquet.`file:tmp`"
  } ]
}


-- !query
SELECT * FROM parquet.`/file/not/found`
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "PATH_NOT_FOUND",
  "sqlState" : "42K03",
  "messageParameters" : {
    "path" : "file:/file/not/found"
  }
}


-- !query
SELECT * FROM parquet.`${spark.sql.warehouse.dir}/sql_on_files.db/test_parquet`
-- !query analysis
Project [1#x]
+- Relation [1#x] parquet


-- !query
DROP TABLE sql_on_files.test_parquet
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), sql_on_files.test_parquet


-- !query
CREATE TABLE sql_on_files.test_orc USING ORC AS SELECT 1
-- !query analysis
CreateDataSourceTableAsSelectCommand `spark_catalog`.`sql_on_files`.`test_orc`, ErrorIfExists, [1]
   +- Project [1 AS 1#x]
      +- OneRowRelation


-- !query
SELECT * FROM orc.``
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INVALID_EMPTY_LOCATION",
  "sqlState" : "42K05",
  "messageParameters" : {
    "location" : ""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 20,
    "fragment" : "orc.``"
  } ]
}


-- !query
SELECT * FROM orc.`file:tmp`
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INVALID_LOCATION",
  "sqlState" : "42K05",
  "messageParameters" : {
    "location" : "file:tmp"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 28,
    "fragment" : "orc.`file:tmp`"
  } ]
}


-- !query
SELECT * FROM orc.`/file/not/found`
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "PATH_NOT_FOUND",
  "sqlState" : "42K03",
  "messageParameters" : {
    "path" : "file:/file/not/found"
  }
}


-- !query
SELECT * FROM orc.`${spark.sql.warehouse.dir}/sql_on_files.db/test_orc`
-- !query analysis
Project [1#x]
+- Relation [1#x] orc


-- !query
DROP TABLE sql_on_files.test_orc
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), sql_on_files.test_orc


-- !query
CREATE TABLE sql_on_files.test_csv USING CSV AS SELECT 1
-- !query analysis
CreateDataSourceTableAsSelectCommand `spark_catalog`.`sql_on_files`.`test_csv`, ErrorIfExists, [1]
   +- Project [1 AS 1#x]
      +- OneRowRelation


-- !query
SELECT * FROM csv.``
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INVALID_EMPTY_LOCATION",
  "sqlState" : "42K05",
  "messageParameters" : {
    "location" : ""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 20,
    "fragment" : "csv.``"
  } ]
}


-- !query
SELECT * FROM csv.`file:tmp`
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INVALID_LOCATION",
  "sqlState" : "42K05",
  "messageParameters" : {
    "location" : "file:tmp"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 28,
    "fragment" : "csv.`file:tmp`"
  } ]
}


-- !query
SELECT * FROM csv.`/file/not/found`
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "PATH_NOT_FOUND",
  "sqlState" : "42K03",
  "messageParameters" : {
    "path" : "file:/file/not/found"
  }
}


-- !query
SELECT * FROM csv.`${spark.sql.warehouse.dir}/sql_on_files.db/test_csv`
-- !query analysis
Project [_c0#x]
+- Relation [_c0#x] csv


-- !query
DROP TABLE sql_on_files.test_csv
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), sql_on_files.test_csv


-- !query
CREATE TABLE sql_on_files.test_json USING JSON AS SELECT 1
-- !query analysis
CreateDataSourceTableAsSelectCommand `spark_catalog`.`sql_on_files`.`test_json`, ErrorIfExists, [1]
   +- Project [1 AS 1#x]
      +- OneRowRelation


-- !query
SELECT * FROM json.``
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INVALID_EMPTY_LOCATION",
  "sqlState" : "42K05",
  "messageParameters" : {
    "location" : ""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 21,
    "fragment" : "json.``"
  } ]
}


-- !query
SELECT * FROM json.`file:tmp`
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INVALID_LOCATION",
  "sqlState" : "42K05",
  "messageParameters" : {
    "location" : "file:tmp"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 29,
    "fragment" : "json.`file:tmp`"
  } ]
}


-- !query
SELECT * FROM json.`/file/not/found`
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "PATH_NOT_FOUND",
  "sqlState" : "42K03",
  "messageParameters" : {
    "path" : "file:/file/not/found"
  }
}


-- !query
SELECT * FROM json.`${spark.sql.warehouse.dir}/sql_on_files.db/test_json`
-- !query analysis
Project [1#xL]
+- Relation [1#xL] json


-- !query
DROP TABLE sql_on_files.test_json
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), sql_on_files.test_json


-- !query
DROP DATABASE sql_on_files
-- !query analysis
DropNamespace false, false
+- ResolvedNamespace V2SessionCatalog(spark_catalog), [sql_on_files]
