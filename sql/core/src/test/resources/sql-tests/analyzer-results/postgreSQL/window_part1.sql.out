-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TEMPORARY VIEW tenk2 AS SELECT * FROM tenk1
-- !query analysis
CreateViewCommand `tenk2`, SELECT * FROM tenk1, false, false, LocalTempView, true
   +- Project [unique1#x, unique2#x, two#x, four#x, ten#x, twenty#x, hundred#x, thousand#x, twothousand#x, fivethous#x, tenthous#x, odd#x, even#x, stringu1#x, stringu2#x, string4#x]
      +- SubqueryAlias spark_catalog.default.tenk1
         +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1
GROUP BY four, ten ORDER BY four, ten
-- !query analysis
Sort [four#x ASC NULLS FIRST, ten#x ASC NULLS FIRST], true
+- Project [four#x, ten#x, sum(sum(four)) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL, avg(ten)#x]
   +- Project [four#x, ten#x, avg(ten)#x, _w0#xL, sum(sum(four)) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL, sum(sum(four)) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL]
      +- Window [sum(_w0#xL) windowspecdefinition(four#x, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS sum(sum(four)) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL], [four#x]
         +- Aggregate [four#x, ten#x], [four#x, ten#x, avg(ten#x) AS avg(ten)#x, sum(four#x) AS _w0#xL]
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT COUNT(*) OVER () FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [count(1) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL]
+- Project [count(1) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL, count(1) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL]
   +- Window [count(1) windowspecdefinition(specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS count(1) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL]
      +- Project
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT COUNT(*) OVER w FROM tenk1 WHERE unique2 < 10 WINDOW w AS ()
-- !query analysis
Project [count(1) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL]
+- Project [count(1) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL, count(1) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL]
   +- Window [count(1) windowspecdefinition(specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS count(1) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL]
      +- Project
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT four FROM tenk1 WHERE FALSE WINDOW w AS (PARTITION BY ten)
-- !query analysis
Project [four#x]
+- Filter false
   +- SubqueryAlias spark_catalog.default.tenk1
      +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT sum(four) OVER (PARTITION BY ten ORDER BY unique2) AS sum_1, ten, four FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [sum_1#xL, ten#x, four#x]
+- Project [ten#x, four#x, unique2#x, sum_1#xL, sum_1#xL]
   +- Window [sum(four#x) windowspecdefinition(ten#x, unique2#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS sum_1#xL], [ten#x], [unique2#x ASC NULLS FIRST]
      +- Project [ten#x, four#x, unique2#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT row_number() OVER (ORDER BY unique2) FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [row_number() OVER (ORDER BY unique2 ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
+- Project [unique2#x, row_number() OVER (ORDER BY unique2 ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, row_number() OVER (ORDER BY unique2 ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
   +- Window [row_number() windowspecdefinition(unique2#x ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS row_number() OVER (ORDER BY unique2 ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x], [unique2#x ASC NULLS FIRST]
      +- Project [unique2#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT rank() OVER (PARTITION BY four ORDER BY ten) AS rank_1, ten, four FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [rank_1#x, ten#x, four#x]
+- Project [ten#x, four#x, rank_1#x, rank_1#x]
   +- Window [rank(ten#x) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_1#x], [four#x], [ten#x ASC NULLS FIRST]
      +- Project [ten#x, four#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT dense_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [DENSE_RANK() OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, ten#x, four#x]
+- Project [ten#x, four#x, DENSE_RANK() OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, DENSE_RANK() OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
   +- Window [dense_rank(ten#x) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS DENSE_RANK() OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x], [four#x], [ten#x ASC NULLS FIRST]
      +- Project [ten#x, four#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT percent_rank() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [PERCENT_RANK() OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, ten#x, four#x]
+- Project [ten#x, four#x, PERCENT_RANK() OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, PERCENT_RANK() OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
   +- Window [percent_rank(ten#x) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS PERCENT_RANK() OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x], [four#x], [ten#x ASC NULLS FIRST]
      +- Project [ten#x, four#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT cume_dist() OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [cume_dist() OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, ten#x, four#x]
+- Project [ten#x, four#x, cume_dist() OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, cume_dist() OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
   +- Window [cume_dist() windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS cume_dist() OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x], [four#x], [ten#x ASC NULLS FIRST]
      +- Project [ten#x, four#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT ntile(3) OVER (ORDER BY ten, four), ten, four FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [ntile(3) OVER (ORDER BY ten ASC NULLS FIRST, four ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, ten#x, four#x]
+- Project [ten#x, four#x, ntile(3) OVER (ORDER BY ten ASC NULLS FIRST, four ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, ntile(3) OVER (ORDER BY ten ASC NULLS FIRST, four ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
   +- Window [ntile(3) windowspecdefinition(ten#x ASC NULLS FIRST, four#x ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS ntile(3) OVER (ORDER BY ten ASC NULLS FIRST, four ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x], [ten#x ASC NULLS FIRST, four#x ASC NULLS FIRST]
      +- Project [ten#x, four#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT lag(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [lag(ten, 1, NULL) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN -1 FOLLOWING AND -1 FOLLOWING)#x, ten#x, four#x]
+- Project [ten#x, four#x, lag(ten, 1, NULL) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN -1 FOLLOWING AND -1 FOLLOWING)#x, lag(ten, 1, NULL) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN -1 FOLLOWING AND -1 FOLLOWING)#x]
   +- Window [lag(ten#x, -1, null) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, -1)) AS lag(ten, 1, NULL) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN -1 FOLLOWING AND -1 FOLLOWING)#x], [four#x], [ten#x ASC NULLS FIRST]
      +- Project [ten#x, four#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT lead(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [lead(ten, 1, NULL) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING)#x, ten#x, four#x]
+- Project [ten#x, four#x, lead(ten, 1, NULL) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING)#x, lead(ten, 1, NULL) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING)#x]
   +- Window [lead(ten#x, 1, null) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS lead(ten, 1, NULL) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING)#x], [four#x], [ten#x ASC NULLS FIRST]
      +- Project [ten#x, four#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT lead(ten * 2, 1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [lead((ten * 2), 1, NULL) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING)#x, ten#x, four#x]
+- Project [ten#x, four#x, _w0#x, lead((ten * 2), 1, NULL) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING)#x, lead((ten * 2), 1, NULL) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING)#x]
   +- Window [lead(_w0#x, 1, null) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS lead((ten * 2), 1, NULL) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING)#x], [four#x], [ten#x ASC NULLS FIRST]
      +- Project [ten#x, four#x, (ten#x * 2) AS _w0#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT lead(ten * 2, 1, -1) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [lead((ten * 2), 1, -1) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING)#x, ten#x, four#x]
+- Project [ten#x, four#x, _w0#x, lead((ten * 2), 1, -1) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING)#x, lead((ten * 2), 1, -1) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING)#x]
   +- Window [lead(_w0#x, 1, -1) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RowFrame, 1, 1)) AS lead((ten * 2), 1, -1) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST ROWS BETWEEN 1 FOLLOWING AND 1 FOLLOWING)#x], [four#x], [ten#x ASC NULLS FIRST]
      +- Project [ten#x, four#x, (ten#x * 2) AS _w0#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT first(ten) OVER (PARTITION BY four ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [first(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, ten#x, four#x]
+- Project [ten#x, four#x, first(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, first(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
   +- Window [first(ten#x, false) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS first(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x], [four#x], [ten#x ASC NULLS FIRST]
      +- Project [ten#x, four#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT last(four) OVER (ORDER BY ten), ten, four FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [last(four) OVER (ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, ten#x, four#x]
+- Project [ten#x, four#x, last(four) OVER (ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, last(four) OVER (ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
   +- Window [last(four#x, false) windowspecdefinition(ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS last(four) OVER (ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x], [ten#x ASC NULLS FIRST]
      +- Project [ten#x, four#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT last(ten) OVER (PARTITION BY four), ten, four FROM
(SELECT * FROM tenk1 WHERE unique2 < 10 ORDER BY four, ten)s
ORDER BY four, ten
-- !query analysis
Sort [four#x ASC NULLS FIRST, ten#x ASC NULLS FIRST], true
+- Project [last(ten) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#x, ten#x, four#x]
   +- Project [ten#x, four#x, last(ten) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#x, last(ten) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#x]
      +- Window [last(ten#x, false) windowspecdefinition(four#x, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS last(ten) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#x], [four#x]
         +- Project [ten#x, four#x]
            +- SubqueryAlias s
               +- Sort [four#x ASC NULLS FIRST, ten#x ASC NULLS FIRST], true
                  +- Project [unique1#x, unique2#x, two#x, four#x, ten#x, twenty#x, hundred#x, thousand#x, twothousand#x, fivethous#x, tenthous#x, odd#x, even#x, stringu1#x, stringu2#x, string4#x]
                     +- Filter (unique2#x < 10)
                        +- SubqueryAlias spark_catalog.default.tenk1
                           +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER (PARTITION BY two ORDER BY ten) AS wsum
FROM tenk1 GROUP BY ten, two
-- !query analysis
Project [ten#x, two#x, gsum#xL, wsum#xL]
+- Project [ten#x, two#x, gsum#xL, _w0#xL, wsum#xL, wsum#xL]
   +- Window [sum(_w0#xL) windowspecdefinition(two#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS wsum#xL], [two#x], [ten#x ASC NULLS FIRST]
      +- Aggregate [ten#x, two#x], [ten#x, two#x, sum(hundred#x) AS gsum#xL, sum(hundred#x) AS _w0#xL]
         +- SubqueryAlias spark_catalog.default.tenk1
            +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT count(*) OVER (PARTITION BY four), four FROM (SELECT * FROM tenk1 WHERE two = 1)s WHERE unique2 < 10
-- !query analysis
Project [count(1) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL, four#x]
+- Project [four#x, count(1) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL, count(1) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL]
   +- Window [count(1) windowspecdefinition(four#x, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS count(1) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL], [four#x]
      +- Project [four#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias s
               +- Project [unique1#x, unique2#x, two#x, four#x, ten#x, twenty#x, hundred#x, thousand#x, twothousand#x, fivethous#x, tenthous#x, odd#x, even#x, stringu1#x, stringu2#x, string4#x]
                  +- Filter (two#x = 1)
                     +- SubqueryAlias spark_catalog.default.tenk1
                        +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT (count(*) OVER (PARTITION BY four ORDER BY ten) +
  sum(hundred) OVER (PARTITION BY four ORDER BY ten)) AS cntsum
  FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [cntsum#xL]
+- Project [four#x, ten#x, hundred#x, _we0#xL, _we1#xL, (_we0#xL + _we1#xL) AS cntsum#xL]
   +- Window [count(1) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS _we0#xL, sum(hundred#x) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS _we1#xL], [four#x], [ten#x ASC NULLS FIRST]
      +- Project [four#x, ten#x, hundred#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT * FROM(
  SELECT count(*) OVER (PARTITION BY four ORDER BY ten) +
    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS total,
    count(*) OVER (PARTITION BY four ORDER BY ten) AS fourcount,
    sum(hundred) OVER (PARTITION BY two ORDER BY ten) AS twosum
    FROM tenk1
)sub WHERE total <> fourcount + twosum
-- !query analysis
Project [total#xL, fourcount#xL, twosum#xL]
+- Filter NOT (total#xL = (fourcount#xL + twosum#xL))
   +- SubqueryAlias sub
      +- Project [total#xL, fourcount#xL, twosum#xL]
         +- Project [four#x, ten#x, hundred#x, two#x, _we0#xL, fourcount#xL, _we1#xL, twosum#xL, (_we0#xL + _we1#xL) AS total#xL, fourcount#xL, twosum#xL]
            +- Window [sum(hundred#x) windowspecdefinition(two#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS _we1#xL, sum(hundred#x) windowspecdefinition(two#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS twosum#xL], [two#x], [ten#x ASC NULLS FIRST]
               +- Window [count(1) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS _we0#xL, count(1) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS fourcount#xL], [four#x], [ten#x ASC NULLS FIRST]
                  +- Project [four#x, ten#x, hundred#x, two#x]
                     +- SubqueryAlias spark_catalog.default.tenk1
                        +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT avg(four) OVER (PARTITION BY four ORDER BY thousand / 100) FROM tenk1 WHERE unique2 < 10
-- !query analysis
Project [avg(four) OVER (PARTITION BY four ORDER BY (thousand / 100) ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
+- Project [four#x, _w1#x, avg(four) OVER (PARTITION BY four ORDER BY (thousand / 100) ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, avg(four) OVER (PARTITION BY four ORDER BY (thousand / 100) ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
   +- Window [avg(four#x) windowspecdefinition(four#x, _w1#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS avg(four) OVER (PARTITION BY four ORDER BY (thousand / 100) ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x], [four#x], [_w1#x ASC NULLS FIRST]
      +- Project [four#x, (cast(thousand#x as double) / cast(100 as double)) AS _w1#x]
         +- Filter (unique2#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT ten, two, sum(hundred) AS gsum, sum(sum(hundred)) OVER win AS wsum
FROM tenk1 GROUP BY ten, two WINDOW win AS (PARTITION BY two ORDER BY ten)
-- !query analysis
Project [ten#x, two#x, gsum#xL, wsum#xL]
+- Project [ten#x, two#x, gsum#xL, _w0#xL, wsum#xL, wsum#xL]
   +- Window [sum(_w0#xL) windowspecdefinition(two#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS wsum#xL], [two#x], [ten#x ASC NULLS FIRST]
      +- Aggregate [ten#x, two#x], [ten#x, two#x, sum(hundred#x) AS gsum#xL, sum(hundred#x) AS _w0#xL]
         +- SubqueryAlias spark_catalog.default.tenk1
            +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT count(*) OVER (PARTITION BY four) FROM (SELECT * FROM tenk1 WHERE FALSE)s
-- !query analysis
Project [count(1) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL]
+- Project [four#x, count(1) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL, count(1) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL]
   +- Window [count(1) windowspecdefinition(four#x, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS count(1) OVER (PARTITION BY four ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL], [four#x]
      +- Project [four#x]
         +- SubqueryAlias s
            +- Project [unique1#x, unique2#x, two#x, four#x, ten#x, twenty#x, hundred#x, thousand#x, twothousand#x, fivethous#x, tenthous#x, odd#x, even#x, stringu1#x, stringu2#x, string4#x]
               +- Filter false
                  +- SubqueryAlias spark_catalog.default.tenk1
                     +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
create temporary view int4_tbl as select * from values
  (0),
  (123456),
  (-123456),
  (2147483647),
  (-2147483647)
  as int4_tbl(f1)
-- !query analysis
CreateViewCommand `int4_tbl`, select * from values
  (0),
  (123456),
  (-123456),
  (2147483647),
  (-2147483647)
  as int4_tbl(f1), false, false, LocalTempView, true
   +- Project [f1#x]
      +- SubqueryAlias int4_tbl
         +- LocalRelation [f1#x]


-- !query
SELECT SUM(COUNT(f1)) OVER () FROM int4_tbl WHERE f1=42
-- !query analysis
Project [sum(count(f1)) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL]
+- Project [_w0#xL, sum(count(f1)) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL, sum(count(f1)) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL]
   +- Window [sum(_w0#xL) windowspecdefinition(specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS sum(count(f1)) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL]
      +- Aggregate [count(f1#x) AS _w0#xL]
         +- Filter (f1#x = 42)
            +- SubqueryAlias int4_tbl
               +- View (`int4_tbl`, [f1#x])
                  +- Project [cast(f1#x as int) AS f1#x]
                     +- Project [f1#x]
                        +- SubqueryAlias int4_tbl
                           +- LocalRelation [f1#x]


-- !query
select ten,
  sum(unique1) + sum(unique2) as res,
  rank() over (order by sum(unique1) + sum(unique2)) as rank
from tenk1
group by ten order by ten
-- !query analysis
Sort [ten#x ASC NULLS FIRST], true
+- Project [ten#x, res#xL, rank#x]
   +- Project [ten#x, res#xL, _w0#xL, rank#x, rank#x]
      +- Window [rank(_w0#xL) windowspecdefinition(_w0#xL ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank#x], [_w0#xL ASC NULLS FIRST]
         +- Aggregate [ten#x], [ten#x, (sum(unique1#x) + sum(unique2#x)) AS res#xL, (sum(unique1#x) + sum(unique2#x)) AS _w0#xL]
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT four, ten,
sum(ten) over (partition by four order by ten),
last(ten) over (partition by four order by ten)
FROM (select distinct ten, four from tenk1) ss
-- !query analysis
Project [four#x, ten#x, sum(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#xL, last(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
+- Project [four#x, ten#x, sum(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#xL, last(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, sum(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#xL, last(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
   +- Window [sum(ten#x) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS sum(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#xL, last(ten#x, false) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS last(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x], [four#x], [ten#x ASC NULLS FIRST]
      +- Project [four#x, ten#x]
         +- SubqueryAlias ss
            +- Distinct
               +- Project [ten#x, four#x]
                  +- SubqueryAlias spark_catalog.default.tenk1
                     +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT four, ten,
sum(ten) over (partition by four order by ten range between unbounded preceding and current row),
last(ten) over (partition by four order by ten range between unbounded preceding and current row)
FROM (select distinct ten, four from tenk1) ss
-- !query analysis
Project [four#x, ten#x, sum(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#xL, last(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
+- Project [four#x, ten#x, sum(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#xL, last(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x, sum(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#xL, last(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x]
   +- Window [sum(ten#x) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS sum(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#xL, last(ten#x, false) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS last(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#x], [four#x], [ten#x ASC NULLS FIRST]
      +- Project [four#x, ten#x]
         +- SubqueryAlias ss
            +- Distinct
               +- Project [ten#x, four#x]
                  +- SubqueryAlias spark_catalog.default.tenk1
                     +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT four, ten,
sum(ten) over (partition by four order by ten range between unbounded preceding and unbounded following),
last(ten) over (partition by four order by ten range between unbounded preceding and unbounded following)
FROM (select distinct ten, four from tenk1) ss
-- !query analysis
Project [four#x, ten#x, sum(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL, last(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#x]
+- Project [four#x, ten#x, sum(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL, last(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#x, sum(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL, last(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#x]
   +- Window [sum(ten#x) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), unboundedfollowing$())) AS sum(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#xL, last(ten#x, false) windowspecdefinition(four#x, ten#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), unboundedfollowing$())) AS last(ten) OVER (PARTITION BY four ORDER BY ten ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)#x], [four#x], [ten#x ASC NULLS FIRST]
      +- Project [four#x, ten#x]
         +- SubqueryAlias ss
            +- Distinct
               +- Project [ten#x, four#x]
                  +- SubqueryAlias spark_catalog.default.tenk1
                     +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT sum(unique1) over (order by four range between current row and unbounded following),
unique1, four
FROM tenk1 WHERE unique1 < 10
-- !query analysis
Project [sum(unique1) OVER (ORDER BY four ASC NULLS FIRST RANGE BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)#xL, unique1#x, four#x]
+- Project [unique1#x, four#x, sum(unique1) OVER (ORDER BY four ASC NULLS FIRST RANGE BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)#xL, sum(unique1) OVER (ORDER BY four ASC NULLS FIRST RANGE BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)#xL]
   +- Window [sum(unique1#x) windowspecdefinition(four#x ASC NULLS FIRST, specifiedwindowframe(RangeFrame, currentrow$(), unboundedfollowing$())) AS sum(unique1) OVER (ORDER BY four ASC NULLS FIRST RANGE BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)#xL], [four#x ASC NULLS FIRST]
      +- Project [unique1#x, four#x]
         +- Filter (unique1#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT sum(unique1) over (rows between current row and unbounded following),
unique1, four
FROM tenk1 WHERE unique1 < 10
-- !query analysis
Project [sum(unique1) OVER (ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)#xL, unique1#x, four#x]
+- Project [unique1#x, four#x, sum(unique1) OVER (ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)#xL, sum(unique1) OVER (ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)#xL]
   +- Window [sum(unique1#x) windowspecdefinition(specifiedwindowframe(RowFrame, currentrow$(), unboundedfollowing$())) AS sum(unique1) OVER (ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)#xL]
      +- Project [unique1#x, four#x]
         +- Filter (unique1#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT sum(unique1) over (rows between 2 preceding and 2 following),
unique1, four
FROM tenk1 WHERE unique1 < 10
-- !query analysis
Project [sum(unique1) OVER (ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING)#xL, unique1#x, four#x]
+- Project [unique1#x, four#x, sum(unique1) OVER (ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING)#xL, sum(unique1) OVER (ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING)#xL]
   +- Window [sum(unique1#x) windowspecdefinition(specifiedwindowframe(RowFrame, -2, 2)) AS sum(unique1) OVER (ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING)#xL]
      +- Project [unique1#x, four#x]
         +- Filter (unique1#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT sum(unique1) over (rows between 2 preceding and 1 preceding),
unique1, four
FROM tenk1 WHERE unique1 < 10
-- !query analysis
Project [sum(unique1) OVER (ROWS BETWEEN 2 PRECEDING AND 1 PRECEDING)#xL, unique1#x, four#x]
+- Project [unique1#x, four#x, sum(unique1) OVER (ROWS BETWEEN 2 PRECEDING AND 1 PRECEDING)#xL, sum(unique1) OVER (ROWS BETWEEN 2 PRECEDING AND 1 PRECEDING)#xL]
   +- Window [sum(unique1#x) windowspecdefinition(specifiedwindowframe(RowFrame, -2, -1)) AS sum(unique1) OVER (ROWS BETWEEN 2 PRECEDING AND 1 PRECEDING)#xL]
      +- Project [unique1#x, four#x]
         +- Filter (unique1#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT sum(unique1) over (rows between 1 following and 3 following),
unique1, four
FROM tenk1 WHERE unique1 < 10
-- !query analysis
Project [sum(unique1) OVER (ROWS BETWEEN 1 FOLLOWING AND 3 FOLLOWING)#xL, unique1#x, four#x]
+- Project [unique1#x, four#x, sum(unique1) OVER (ROWS BETWEEN 1 FOLLOWING AND 3 FOLLOWING)#xL, sum(unique1) OVER (ROWS BETWEEN 1 FOLLOWING AND 3 FOLLOWING)#xL]
   +- Window [sum(unique1#x) windowspecdefinition(specifiedwindowframe(RowFrame, 1, 3)) AS sum(unique1) OVER (ROWS BETWEEN 1 FOLLOWING AND 3 FOLLOWING)#xL]
      +- Project [unique1#x, four#x]
         +- Filter (unique1#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT sum(unique1) over (rows between unbounded preceding and 1 following),
unique1, four
FROM tenk1 WHERE unique1 < 10
-- !query analysis
Project [sum(unique1) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING)#xL, unique1#x, four#x]
+- Project [unique1#x, four#x, sum(unique1) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING)#xL, sum(unique1) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING)#xL]
   +- Window [sum(unique1#x) windowspecdefinition(specifiedwindowframe(RowFrame, unboundedpreceding$(), 1)) AS sum(unique1) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING)#xL]
      +- Project [unique1#x, four#x]
         +- Filter (unique1#x < 10)
            +- SubqueryAlias spark_catalog.default.tenk1
               +- Relation spark_catalog.default.tenk1[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
CREATE TEMP VIEW v_window AS
SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows
FROM range(1, 11) i
-- !query analysis
CreateViewCommand `v_window`, SELECT i.id, sum(i.id) over (order by i.id rows between 1 preceding and 1 following) as sum_rows
FROM range(1, 11) i, false, false, LocalTempView, true
   +- Project [id#xL, sum_rows#xL]
      +- Project [id#xL, sum_rows#xL, sum_rows#xL]
         +- Window [sum(id#xL) windowspecdefinition(id#xL ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, 1)) AS sum_rows#xL], [id#xL ASC NULLS FIRST]
            +- Project [id#xL]
               +- SubqueryAlias i
                  +- Range (1, 11, step=1)


-- !query
SELECT * FROM v_window
-- !query analysis
Project [id#xL, sum_rows#xL]
+- SubqueryAlias v_window
   +- View (`v_window`, [id#xL, sum_rows#xL])
      +- Project [cast(id#xL as bigint) AS id#xL, cast(sum_rows#xL as bigint) AS sum_rows#xL]
         +- Project [id#xL, sum_rows#xL]
            +- Project [id#xL, sum_rows#xL, sum_rows#xL]
               +- Window [sum(id#xL) windowspecdefinition(id#xL ASC NULLS FIRST, specifiedwindowframe(RowFrame, -1, 1)) AS sum_rows#xL], [id#xL ASC NULLS FIRST]
                  +- Project [id#xL]
                     +- SubqueryAlias i
                        +- Range (1, 11, step=1)


-- !query
DROP VIEW v_window
-- !query analysis
DropTempViewCommand v_window


-- !query
DROP VIEW tenk2
-- !query analysis
DropTempViewCommand tenk2


-- !query
DROP VIEW int4_tbl
-- !query analysis
DropTempViewCommand int4_tbl
