-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TABLE INT8_TBL(q1 bigint, q2 bigint) USING parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`INT8_TBL`, false


-- !query
INSERT INTO INT8_TBL VALUES(bigint(trim('  123   ')),bigint(trim('  456')))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/int8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/int8_tbl], Append, `spark_catalog`.`default`.`int8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/int8_tbl), [q1, q2]
+- Project [cast(col1#xL as bigint) AS q1#xL, cast(col2#xL as bigint) AS q2#xL]
   +- LocalRelation [col1#xL, col2#xL]


-- !query
INSERT INTO INT8_TBL VALUES(bigint(trim('123   ')),bigint('4567890123456789'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/int8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/int8_tbl], Append, `spark_catalog`.`default`.`int8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/int8_tbl), [q1, q2]
+- Project [cast(col1#xL as bigint) AS q1#xL, cast(col2#xL as bigint) AS q2#xL]
   +- LocalRelation [col1#xL, col2#xL]


-- !query
INSERT INTO INT8_TBL VALUES(bigint('4567890123456789'),bigint('123'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/int8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/int8_tbl], Append, `spark_catalog`.`default`.`int8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/int8_tbl), [q1, q2]
+- Project [cast(col1#xL as bigint) AS q1#xL, cast(col2#xL as bigint) AS q2#xL]
   +- LocalRelation [col1#xL, col2#xL]


-- !query
INSERT INTO INT8_TBL VALUES(+4567890123456789,bigint('4567890123456789'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/int8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/int8_tbl], Append, `spark_catalog`.`default`.`int8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/int8_tbl), [q1, q2]
+- Project [cast(col1#xL as bigint) AS q1#xL, cast(col2#xL as bigint) AS q2#xL]
   +- LocalRelation [col1#xL, col2#xL]


-- !query
INSERT INTO INT8_TBL VALUES(bigint('+4567890123456789'),bigint('-4567890123456789'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/int8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/int8_tbl], Append, `spark_catalog`.`default`.`int8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/int8_tbl), [q1, q2]
+- Project [cast(col1#xL as bigint) AS q1#xL, cast(col2#xL as bigint) AS q2#xL]
   +- LocalRelation [col1#xL, col2#xL]


-- !query
SELECT * FROM INT8_TBL
-- !query analysis
Project [q1#xL, q2#xL]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 = 4567890123456789
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL = 4567890123456789)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 <> 4567890123456789
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter NOT (q2#xL = 4567890123456789)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 < 4567890123456789
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL < 4567890123456789)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 > 4567890123456789
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL > 4567890123456789)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 <= 4567890123456789
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL <= 4567890123456789)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 >= 4567890123456789
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL >= 4567890123456789)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 = 456
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL = cast(456 as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 <> 456
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter NOT (q2#xL = cast(456 as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 < 456
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL < cast(456 as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 > 456
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL > cast(456 as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 <= 456
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL <= cast(456 as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 >= 456
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL >= cast(456 as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE 123 = q1
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (cast(123 as bigint) = q1#xL)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE 123 <> q1
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter NOT (cast(123 as bigint) = q1#xL)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE 123 < q1
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (cast(123 as bigint) < q1#xL)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE 123 > q1
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (cast(123 as bigint) > q1#xL)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE 123 <= q1
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (cast(123 as bigint) <= q1#xL)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE 123 >= q1
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (cast(123 as bigint) >= q1#xL)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 = smallint('456')
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL = cast(cast(456 as smallint) as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 <> smallint('456')
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter NOT (q2#xL = cast(cast(456 as smallint) as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 < smallint('456')
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL < cast(cast(456 as smallint) as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 > smallint('456')
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL > cast(cast(456 as smallint) as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 <= smallint('456')
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL <= cast(cast(456 as smallint) as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE q2 >= smallint('456')
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (q2#xL >= cast(cast(456 as smallint) as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE smallint('123') = q1
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (cast(cast(123 as smallint) as bigint) = q1#xL)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE smallint('123') <> q1
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter NOT (cast(cast(123 as smallint) as bigint) = q1#xL)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE smallint('123') < q1
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (cast(cast(123 as smallint) as bigint) < q1#xL)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE smallint('123') > q1
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (cast(cast(123 as smallint) as bigint) > q1#xL)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE smallint('123') <= q1
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (cast(cast(123 as smallint) as bigint) <= q1#xL)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM INT8_TBL WHERE smallint('123') >= q1
-- !query analysis
Project [q1#xL, q2#xL]
+- Filter (cast(cast(123 as smallint) as bigint) >= q1#xL)
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS five, q1 AS plus, -q1 AS `minus` FROM INT8_TBL
-- !query analysis
Project [ AS five#x, q1#xL AS plus#xL, -q1#xL AS minus#xL]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS five, q1, q2, q1 + q2 AS plus FROM INT8_TBL
-- !query analysis
Project [ AS five#x, q1#xL, q2#xL, (q1#xL + q2#xL) AS plus#xL]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS five, q1, q2, q1 - q2 AS `minus` FROM INT8_TBL
-- !query analysis
Project [ AS five#x, q1#xL, q2#xL, (q1#xL - q2#xL) AS minus#xL]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS three, q1, q2, q1 * q2 AS multiply FROM INT8_TBL
-- !query analysis
Project [ AS three#x, q1#xL, q2#xL, (q1#xL * q2#xL) AS multiply#xL]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS three, q1, q2, q1 * q2 AS multiply FROM INT8_TBL
 WHERE q1 < 1000 or (q2 > 0 and q2 < 1000)
-- !query analysis
Project [ AS three#x, q1#xL, q2#xL, (q1#xL * q2#xL) AS multiply#xL]
+- Filter ((q1#xL < cast(1000 as bigint)) OR ((q2#xL > cast(0 as bigint)) AND (q2#xL < cast(1000 as bigint))))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS five, q1, q2, q1 / q2 AS divide, q1 % q2 AS mod FROM INT8_TBL
-- !query analysis
Project [ AS five#x, q1#xL, q2#xL, (cast(q1#xL as double) / cast(q2#xL as double)) AS divide#x, (q1#xL % q2#xL) AS mod#xL]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS five, q1, double(q1) FROM INT8_TBL
-- !query analysis
Project [ AS five#x, q1#xL, cast(q1#xL as double) AS q1#x]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS five, q2, double(q2) FROM INT8_TBL
-- !query analysis
Project [ AS five#x, q2#xL, cast(q2#xL as double) AS q2#x]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT 37 + q1 AS plus4 FROM INT8_TBL
-- !query analysis
Project [(cast(37 as bigint) + q1#xL) AS plus4#xL]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT 37 - q1 AS minus4 FROM INT8_TBL
-- !query analysis
Project [(cast(37 as bigint) - q1#xL) AS minus4#xL]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS five, 2 * q1 AS `twice int4` FROM INT8_TBL
-- !query analysis
Project [ AS five#x, (cast(2 as bigint) * q1#xL) AS twice int4#xL]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS five, q1 * 2 AS `twice int4` FROM INT8_TBL
-- !query analysis
Project [ AS five#x, (q1#xL * cast(2 as bigint)) AS twice int4#xL]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT q1 + int(42) AS `8plus4`, q1 - int(42) AS `8minus4`, q1 * int(42) AS `8mul4`, q1 / int(42) AS `8div4` FROM INT8_TBL
-- !query analysis
Project [(q1#xL + cast(cast(42 as int) as bigint)) AS 8plus4#xL, (q1#xL - cast(cast(42 as int) as bigint)) AS 8minus4#xL, (q1#xL * cast(cast(42 as int) as bigint)) AS 8mul4#xL, (cast(q1#xL as double) / cast(cast(42 as int) as double)) AS 8div4#x]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT int(246) + q1 AS `4plus8`, int(246) - q1 AS `4minus8`, int(246) * q1 AS `4mul8`, int(246) / q1 AS `4div8` FROM INT8_TBL
-- !query analysis
Project [(cast(cast(246 as int) as bigint) + q1#xL) AS 4plus8#xL, (cast(cast(246 as int) as bigint) - q1#xL) AS 4minus8#xL, (cast(cast(246 as int) as bigint) * q1#xL) AS 4mul8#xL, (cast(cast(246 as int) as double) / cast(q1#xL as double)) AS 4div8#x]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT q1 + smallint(42) AS `8plus2`, q1 - smallint(42) AS `8minus2`, q1 * smallint(42) AS `8mul2`, q1 / smallint(42) AS `8div2` FROM INT8_TBL
-- !query analysis
Project [(q1#xL + cast(cast(42 as smallint) as bigint)) AS 8plus2#xL, (q1#xL - cast(cast(42 as smallint) as bigint)) AS 8minus2#xL, (q1#xL * cast(cast(42 as smallint) as bigint)) AS 8mul2#xL, (cast(q1#xL as double) / cast(cast(42 as smallint) as double)) AS 8div2#x]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT smallint(246) + q1 AS `2plus8`, smallint(246) - q1 AS `2minus8`, smallint(246) * q1 AS `2mul8`, smallint(246) / q1 AS `2div8` FROM INT8_TBL
-- !query analysis
Project [(cast(cast(246 as smallint) as bigint) + q1#xL) AS 2plus8#xL, (cast(cast(246 as smallint) as bigint) - q1#xL) AS 2minus8#xL, (cast(cast(246 as smallint) as bigint) * q1#xL) AS 2mul8#xL, (cast(cast(246 as smallint) as double) / cast(q1#xL as double)) AS 2div8#x]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT q2, abs(q2) FROM INT8_TBL
-- !query analysis
Project [q2#xL, abs(q2#xL) AS abs(q2)#xL]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT min(q1), min(q2) FROM INT8_TBL
-- !query analysis
Aggregate [min(q1#xL) AS min(q1)#xL, min(q2#xL) AS min(q2)#xL]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT max(q1), max(q2) FROM INT8_TBL
-- !query analysis
Aggregate [max(q1#xL) AS max(q1)#xL, max(q2#xL) AS max(q2)#xL]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS to_char_1, to_char(q1, '9G999G999G999G999G999'), to_char(q2, '9,999,999,999,999,999')
FROM INT8_TBL
-- !query analysis
Project [ AS to_char_1#x, to_char(cast(q1#xL as decimal(20,0)), 9G999G999G999G999G999) AS to_char(q1, 9G999G999G999G999G999)#x, to_char(cast(q2#xL as decimal(20,0)), 9,999,999,999,999,999) AS to_char(q2, 9,999,999,999,999,999)#x]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS to_char_3, to_char( (q1 * -1), '9999999999999999PR'), to_char( (q2 * -1), '9999999999999999.999PR')
FROM INT8_TBL
-- !query analysis
Project [ AS to_char_3#x, to_char(cast((q1#xL * cast(-1 as bigint)) as decimal(20,0)), 9999999999999999PR) AS to_char((q1 * -1), 9999999999999999PR)#x, to_char(cast((q2#xL * cast(-1 as bigint)) as decimal(20,0)), 9999999999999999.999PR) AS to_char((q2 * -1), 9999999999999999.999PR)#x]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS to_char_4, to_char( (q1 * -1), '9999999999999999S'), to_char( (q2 * -1), 'S9999999999999999')
FROM INT8_TBL
-- !query analysis
Project [ AS to_char_4#x, to_char(cast((q1#xL * cast(-1 as bigint)) as decimal(20,0)), 9999999999999999S) AS to_char((q1 * -1), 9999999999999999S)#x, to_char(cast((q2#xL * cast(-1 as bigint)) as decimal(20,0)), S9999999999999999) AS to_char((q2 * -1), S9999999999999999)#x]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS to_char_5,  to_char(q2, 'MI9999999999999999')     FROM INT8_TBL
-- !query analysis
Project [ AS to_char_5#x, to_char(cast(q2#xL as decimal(20,0)), MI9999999999999999) AS to_char(q2, MI9999999999999999)#x]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS to_char_9,  to_char(q2, '0999999999999999')       FROM INT8_TBL
-- !query analysis
Project [ AS to_char_9#x, to_char(cast(q2#xL as decimal(20,0)), 0999999999999999) AS to_char(q2, 0999999999999999)#x]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT '' AS to_char_10, to_char(q2, 'S0999999999999999')      FROM INT8_TBL
-- !query analysis
Project [ AS to_char_10#x, to_char(cast(q2#xL as decimal(20,0)), S0999999999999999) AS to_char(q2, S0999999999999999)#x]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
select bigint('9223372036854775800') / bigint('0')
-- !query analysis
Project [(cast(cast(9223372036854775800 as bigint) as double) / cast(cast(0 as bigint) as double)) AS (9223372036854775800 / 0)#x]
+- OneRowRelation


-- !query
select bigint('-9223372036854775808') / smallint('0')
-- !query analysis
Project [(cast(cast(-9223372036854775808 as bigint) as double) / cast(cast(0 as smallint) as double)) AS (-9223372036854775808 / 0)#x]
+- OneRowRelation


-- !query
select smallint('100') / bigint('0')
-- !query analysis
Project [(cast(cast(100 as smallint) as double) / cast(cast(0 as bigint) as double)) AS (100 / 0)#x]
+- OneRowRelation


-- !query
SELECT CAST(q1 AS int) FROM int8_tbl WHERE q2 = 456
-- !query analysis
Project [cast(q1#xL as int) AS q1#x]
+- Filter (q2#xL = cast(456 as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT CAST(q1 AS int) FROM int8_tbl WHERE q2 <> 456
-- !query analysis
Project [cast(q1#xL as int) AS q1#x]
+- Filter NOT (q2#xL = cast(456 as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT CAST(q1 AS smallint) FROM int8_tbl WHERE q2 = 456
-- !query analysis
Project [cast(q1#xL as smallint) AS q1#x]
+- Filter (q2#xL = cast(456 as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT CAST(q1 AS smallint) FROM int8_tbl WHERE q2 <> 456
-- !query analysis
Project [cast(q1#xL as smallint) AS q1#x]
+- Filter NOT (q2#xL = cast(456 as bigint))
   +- SubqueryAlias spark_catalog.default.int8_tbl
      +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT CAST(smallint('42') AS bigint), CAST(smallint('-37') AS bigint)
-- !query analysis
Project [cast(cast(42 as smallint) as bigint) AS CAST(42 AS BIGINT)#xL, cast(cast(-37 as smallint) as bigint) AS CAST(-37 AS BIGINT)#xL]
+- OneRowRelation


-- !query
SELECT CAST(q1 AS float), CAST(q2 AS double) FROM INT8_TBL
-- !query analysis
Project [cast(q1#xL as float) AS q1#x, cast(q2#xL as double) AS q2#x]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT CAST(float('36854775807.0') AS bigint)
-- !query analysis
Project [cast(cast(36854775807.0 as float) as bigint) AS CAST(36854775807.0 AS BIGINT)#xL]
+- OneRowRelation


-- !query
SELECT CAST(double('922337203685477580700.0') AS bigint)
-- !query analysis
Project [cast(cast(922337203685477580700.0 as double) as bigint) AS CAST(922337203685477580700.0 AS BIGINT)#xL]
+- OneRowRelation


-- !query
SELECT q1, q2, q1 & q2 AS `and`, q1 | q2 AS `or`, ~q1 AS `not` FROM INT8_TBL
-- !query analysis
Project [q1#xL, q2#xL, (q1#xL & q2#xL) AS and#xL, (q1#xL | q2#xL) AS or#xL, ~q1#xL AS not#xL]
+- SubqueryAlias spark_catalog.default.int8_tbl
   +- Relation spark_catalog.default.int8_tbl[q1#xL,q2#xL] parquet


-- !query
SELECT * FROM range(bigint('+4567890123456789'), bigint('+4567890123456799'))
-- !query analysis
Project [id#xL]
+- Range (4567890123456789, 4567890123456799, step=1)


-- !query
SELECT * FROM range(bigint('+4567890123456789'), bigint('+4567890123456799'), 0)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "FAILED_FUNCTION_CALL",
  "sqlState" : "38000",
  "messageParameters" : {
    "funcName" : "`range`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 80,
    "fragment" : "range(bigint('+4567890123456789'), bigint('+4567890123456799'), 0)"
  } ]
}


-- !query
SELECT * FROM range(bigint('+4567890123456789'), bigint('+4567890123456799'), 2)
-- !query analysis
Project [id#xL]
+- Range (4567890123456789, 4567890123456799, step=2)


-- !query
SELECT string(shiftleft(bigint(-1), 63))
-- !query analysis
Project [cast(shiftleft(cast(-1 as bigint), 63) as string) AS shiftleft(-1, 63)#x]
+- OneRowRelation


-- !query
SELECT string(int(shiftleft(bigint(-1), 63))+1)
-- !query analysis
Project [cast((cast(shiftleft(cast(-1 as bigint), 63) as int) + 1) as string) AS (shiftleft(-1, 63) + 1)#x]
+- OneRowRelation


-- !query
SELECT bigint((-9223372036854775808)) * bigint((-1))
-- !query analysis
Project [(cast(-9223372036854775808 as bigint) * cast(-1 as bigint)) AS (-9223372036854775808 * -1)#xL]
+- OneRowRelation


-- !query
SELECT bigint((-9223372036854775808)) / bigint((-1))
-- !query analysis
Project [(cast(cast(-9223372036854775808 as bigint) as double) / cast(cast(-1 as bigint) as double)) AS (-9223372036854775808 / -1)#x]
+- OneRowRelation


-- !query
SELECT bigint((-9223372036854775808)) % bigint((-1))
-- !query analysis
Project [(cast(-9223372036854775808 as bigint) % cast(-1 as bigint)) AS (-9223372036854775808 % -1)#xL]
+- OneRowRelation


-- !query
SELECT bigint((-9223372036854775808)) * int((-1))
-- !query analysis
Project [(cast(-9223372036854775808 as bigint) * cast(cast(-1 as int) as bigint)) AS (-9223372036854775808 * -1)#xL]
+- OneRowRelation


-- !query
SELECT bigint((-9223372036854775808)) / int((-1))
-- !query analysis
Project [(cast(cast(-9223372036854775808 as bigint) as double) / cast(cast(-1 as int) as double)) AS (-9223372036854775808 / -1)#x]
+- OneRowRelation


-- !query
SELECT bigint((-9223372036854775808)) % int((-1))
-- !query analysis
Project [(cast(-9223372036854775808 as bigint) % cast(cast(-1 as int) as bigint)) AS (-9223372036854775808 % -1)#xL]
+- OneRowRelation


-- !query
SELECT bigint((-9223372036854775808)) * smallint((-1))
-- !query analysis
Project [(cast(-9223372036854775808 as bigint) * cast(cast(-1 as smallint) as bigint)) AS (-9223372036854775808 * -1)#xL]
+- OneRowRelation


-- !query
SELECT bigint((-9223372036854775808)) / smallint((-1))
-- !query analysis
Project [(cast(cast(-9223372036854775808 as bigint) as double) / cast(cast(-1 as smallint) as double)) AS (-9223372036854775808 / -1)#x]
+- OneRowRelation


-- !query
SELECT bigint((-9223372036854775808)) % smallint((-1))
-- !query analysis
Project [(cast(-9223372036854775808 as bigint) % cast(cast(-1 as smallint) as bigint)) AS (-9223372036854775808 % -1)#xL]
+- OneRowRelation


-- !query
SELECT x, bigint(x) AS int8_value
FROM (VALUES (double(-2.5)),
             (double(-1.5)),
             (double(-0.5)),
             (double(0.0)),
             (double(0.5)),
             (double(1.5)),
             (double(2.5))) t(x)
-- !query analysis
Project [x#x, cast(x#x as bigint) AS int8_value#xL]
+- SubqueryAlias t
   +- Project [col1#x AS x#x]
      +- LocalRelation [col1#x]


-- !query
SELECT x, bigint(x) AS int8_value
FROM (VALUES cast(-2.5 as decimal(38, 18)),
             cast(-1.5 as decimal(38, 18)),
             cast(-0.5 as decimal(38, 18)),
             cast(-0.0 as decimal(38, 18)),
             cast(0.5 as decimal(38, 18)),
             cast(1.5 as decimal(38, 18)),
             cast(2.5 as decimal(38, 18))) t(x)
-- !query analysis
Project [x#x, cast(x#x as bigint) AS int8_value#xL]
+- SubqueryAlias t
   +- Project [col1#x AS x#x]
      +- LocalRelation [col1#x]


-- !query
DROP TABLE INT8_TBL
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.INT8_TBL
