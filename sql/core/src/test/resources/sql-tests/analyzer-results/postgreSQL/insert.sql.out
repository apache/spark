-- Automatically generated by SQLQueryTestSuite
-- !query
create table inserttest (col1 int, col2 int /* NOT NULL */, col3 string /* default 'testing' */) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`inserttest`, false


-- !query
insert into inserttest  values (NULL, 3, 'testing')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/inserttest, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/inserttest], Append, `spark_catalog`.`default`.`inserttest`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/inserttest), [col1, col2, col3]
+- Project [cast(col1#x as int) AS col1#x, col2#x, col3#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into inserttest values (NULL, 5, 'testing')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/inserttest, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/inserttest], Append, `spark_catalog`.`default`.`inserttest`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/inserttest), [col1, col2, col3]
+- Project [cast(col1#x as int) AS col1#x, col2#x, col3#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into inserttest values (NULL, 5, 'test')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/inserttest, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/inserttest], Append, `spark_catalog`.`default`.`inserttest`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/inserttest), [col1, col2, col3]
+- Project [cast(col1#x as int) AS col1#x, col2#x, col3#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into inserttest values (NULL, 7, 'testing')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/inserttest, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/inserttest], Append, `spark_catalog`.`default`.`inserttest`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/inserttest), [col1, col2, col3]
+- Project [cast(col1#x as int) AS col1#x, col2#x, col3#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
select * from inserttest
-- !query analysis
Project [col1#x, col2#x, col3#x]
+- SubqueryAlias spark_catalog.default.inserttest
   +- Relation spark_catalog.default.inserttest[col1#x,col2#x,col3#x] parquet


-- !query
insert into inserttest values(30, 50, repeat('x', 10000))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/inserttest, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/inserttest], Append, `spark_catalog`.`default`.`inserttest`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/inserttest), [col1, col2, col3]
+- LocalRelation [col1#x, col2#x, col3#x]


-- !query
select col1, col2, char_length(col3) from inserttest
-- !query analysis
Project [col1#x, col2#x, char_length(col3#x) AS char_length(col3)#x]
+- SubqueryAlias spark_catalog.default.inserttest
   +- Relation spark_catalog.default.inserttest[col1#x,col2#x,col3#x] parquet


-- !query
drop table inserttest
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.inserttest
