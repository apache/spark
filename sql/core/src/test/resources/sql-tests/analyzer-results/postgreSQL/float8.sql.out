-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TABLE FLOAT8_TBL(f1 double) USING parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`FLOAT8_TBL`, false


-- !query
INSERT INTO FLOAT8_TBL VALUES (double('    0.0   '))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/float8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/float8_tbl], Append, `spark_catalog`.`default`.`float8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/float8_tbl), [f1]
+- Project [cast(col1#x as double) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO FLOAT8_TBL VALUES (double('1004.30  '))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/float8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/float8_tbl], Append, `spark_catalog`.`default`.`float8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/float8_tbl), [f1]
+- Project [cast(col1#x as double) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO FLOAT8_TBL VALUES (double('   -34.84'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/float8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/float8_tbl], Append, `spark_catalog`.`default`.`float8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/float8_tbl), [f1]
+- Project [cast(col1#x as double) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO FLOAT8_TBL VALUES (double('1.2345678901234e+200'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/float8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/float8_tbl], Append, `spark_catalog`.`default`.`float8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/float8_tbl), [f1]
+- Project [cast(col1#x as double) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO FLOAT8_TBL VALUES (double('1.2345678901234e-200'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/float8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/float8_tbl], Append, `spark_catalog`.`default`.`float8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/float8_tbl), [f1]
+- Project [cast(col1#x as double) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
SELECT double('10e400')
-- !query analysis
Project [cast(10e400 as double) AS 10e400#x]
+- OneRowRelation


-- !query
SELECT double('-10e400')
-- !query analysis
Project [cast(-10e400 as double) AS -10e400#x]
+- OneRowRelation


-- !query
SELECT double('10e-400')
-- !query analysis
Project [cast(10e-400 as double) AS 10e-400#x]
+- OneRowRelation


-- !query
SELECT double('-10e-400')
-- !query analysis
Project [cast(-10e-400 as double) AS -10e-400#x]
+- OneRowRelation


-- !query
SELECT double('NaN')
-- !query analysis
Project [cast(NaN as double) AS NaN#x]
+- OneRowRelation


-- !query
SELECT double('nan')
-- !query analysis
Project [cast(nan as double) AS nan#x]
+- OneRowRelation


-- !query
SELECT double('   NAN  ')
-- !query analysis
Project [cast(   NAN   as double) AS    NAN  #x]
+- OneRowRelation


-- !query
SELECT double('infinity')
-- !query analysis
Project [cast(infinity as double) AS infinity#x]
+- OneRowRelation


-- !query
SELECT double('          -INFINiTY   ')
-- !query analysis
Project [cast(          -INFINiTY    as double) AS           -INFINiTY   #x]
+- OneRowRelation


-- !query
SELECT double('N A N')
-- !query analysis
Project [cast(N A N as double) AS N A N#x]
+- OneRowRelation


-- !query
SELECT double('NaN x')
-- !query analysis
Project [cast(NaN x as double) AS NaN x#x]
+- OneRowRelation


-- !query
SELECT double(' INFINITY    x')
-- !query analysis
Project [cast( INFINITY    x as double) AS  INFINITY    x#x]
+- OneRowRelation


-- !query
SELECT double('Infinity') + 100.0
-- !query analysis
Project [(cast(Infinity as double) + cast(100.0 as double)) AS (Infinity + 100.0)#x]
+- OneRowRelation


-- !query
SELECT double('Infinity') / double('Infinity')
-- !query analysis
Project [(cast(Infinity as double) / cast(Infinity as double)) AS (Infinity / Infinity)#x]
+- OneRowRelation


-- !query
SELECT double('NaN') / double('NaN')
-- !query analysis
Project [(cast(NaN as double) / cast(NaN as double)) AS (NaN / NaN)#x]
+- OneRowRelation


-- !query
SELECT double(decimal('nan'))
-- !query analysis
Project [cast(cast(nan as decimal(10,0)) as double) AS nan#x]
+- OneRowRelation


-- !query
SELECT '' AS five, * FROM FLOAT8_TBL
-- !query analysis
Project [ AS five#x, f1#x]
+- SubqueryAlias spark_catalog.default.float8_tbl
   +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT '' AS four, f.* FROM FLOAT8_TBL f WHERE f.f1 <> '1004.3'
-- !query analysis
Project [ AS four#x, f1#x]
+- Filter NOT (f1#x = cast(1004.3 as double))
   +- SubqueryAlias f
      +- SubqueryAlias spark_catalog.default.float8_tbl
         +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT '' AS one, f.* FROM FLOAT8_TBL f WHERE f.f1 = '1004.3'
-- !query analysis
Project [ AS one#x, f1#x]
+- Filter (f1#x = cast(1004.3 as double))
   +- SubqueryAlias f
      +- SubqueryAlias spark_catalog.default.float8_tbl
         +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT '' AS three, f.* FROM FLOAT8_TBL f WHERE '1004.3' > f.f1
-- !query analysis
Project [ AS three#x, f1#x]
+- Filter (cast(1004.3 as double) > f1#x)
   +- SubqueryAlias f
      +- SubqueryAlias spark_catalog.default.float8_tbl
         +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT '' AS three, f.* FROM FLOAT8_TBL f WHERE  f.f1 < '1004.3'
-- !query analysis
Project [ AS three#x, f1#x]
+- Filter (f1#x < cast(1004.3 as double))
   +- SubqueryAlias f
      +- SubqueryAlias spark_catalog.default.float8_tbl
         +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT '' AS four, f.* FROM FLOAT8_TBL f WHERE '1004.3' >= f.f1
-- !query analysis
Project [ AS four#x, f1#x]
+- Filter (cast(1004.3 as double) >= f1#x)
   +- SubqueryAlias f
      +- SubqueryAlias spark_catalog.default.float8_tbl
         +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT '' AS four, f.* FROM FLOAT8_TBL f WHERE  f.f1 <= '1004.3'
-- !query analysis
Project [ AS four#x, f1#x]
+- Filter (f1#x <= cast(1004.3 as double))
   +- SubqueryAlias f
      +- SubqueryAlias spark_catalog.default.float8_tbl
         +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT '' AS three, f.f1, f.f1 * '-10' AS x
   FROM FLOAT8_TBL f
   WHERE f.f1 > '0.0'
-- !query analysis
Project [ AS three#x, f1#x, (f1#x * cast(-10 as double)) AS x#x]
+- Filter (f1#x > cast(0.0 as double))
   +- SubqueryAlias f
      +- SubqueryAlias spark_catalog.default.float8_tbl
         +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT '' AS three, f.f1, f.f1 + '-10' AS x
   FROM FLOAT8_TBL f
   WHERE f.f1 > '0.0'
-- !query analysis
Project [ AS three#x, f1#x, (f1#x + cast(-10 as double)) AS x#x]
+- Filter (f1#x > cast(0.0 as double))
   +- SubqueryAlias f
      +- SubqueryAlias spark_catalog.default.float8_tbl
         +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT '' AS three, f.f1, f.f1 / '-10' AS x
   FROM FLOAT8_TBL f
   WHERE f.f1 > '0.0'
-- !query analysis
Project [ AS three#x, f1#x, (f1#x / cast(-10 as double)) AS x#x]
+- Filter (f1#x > cast(0.0 as double))
   +- SubqueryAlias f
      +- SubqueryAlias spark_catalog.default.float8_tbl
         +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT '' AS three, f.f1, f.f1 - '-10' AS x
   FROM FLOAT8_TBL f
   WHERE f.f1 > '0.0'
-- !query analysis
Project [ AS three#x, f1#x, (f1#x - cast(-10 as double)) AS x#x]
+- Filter (f1#x > cast(0.0 as double))
   +- SubqueryAlias f
      +- SubqueryAlias spark_catalog.default.float8_tbl
         +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT '' AS five, f.f1, round(f.f1) AS round_f1
   FROM FLOAT8_TBL f
-- !query analysis
Project [ AS five#x, f1#x, round(f1#x, 0) AS round_f1#x]
+- SubqueryAlias f
   +- SubqueryAlias spark_catalog.default.float8_tbl
      +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
select ceil(f1) as ceil_f1 from float8_tbl f
-- !query analysis
Project [CEIL(f1#x) AS ceil_f1#xL]
+- SubqueryAlias f
   +- SubqueryAlias spark_catalog.default.float8_tbl
      +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
select ceiling(f1) as ceiling_f1 from float8_tbl f
-- !query analysis
Project [ceiling(f1#x) AS ceiling_f1#xL]
+- SubqueryAlias f
   +- SubqueryAlias spark_catalog.default.float8_tbl
      +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
select floor(f1) as floor_f1 from float8_tbl f
-- !query analysis
Project [FLOOR(f1#x) AS floor_f1#xL]
+- SubqueryAlias f
   +- SubqueryAlias spark_catalog.default.float8_tbl
      +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
select sign(f1) as sign_f1 from float8_tbl f
-- !query analysis
Project [sign(f1#x) AS sign_f1#x]
+- SubqueryAlias f
   +- SubqueryAlias spark_catalog.default.float8_tbl
      +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT sqrt(double('64')) AS eight
-- !query analysis
Project [SQRT(cast(64 as double)) AS eight#x]
+- OneRowRelation


-- !query
SELECT power(double('144'), double('0.5'))
-- !query analysis
Project [POWER(cast(144 as double), cast(0.5 as double)) AS POWER(144, 0.5)#x]
+- OneRowRelation


-- !query
SELECT power(double('NaN'), double('0.5'))
-- !query analysis
Project [POWER(cast(NaN as double), cast(0.5 as double)) AS POWER(NaN, 0.5)#x]
+- OneRowRelation


-- !query
SELECT power(double('144'), double('NaN'))
-- !query analysis
Project [POWER(cast(144 as double), cast(NaN as double)) AS POWER(144, NaN)#x]
+- OneRowRelation


-- !query
SELECT power(double('NaN'), double('NaN'))
-- !query analysis
Project [POWER(cast(NaN as double), cast(NaN as double)) AS POWER(NaN, NaN)#x]
+- OneRowRelation


-- !query
SELECT power(double('-1'), double('NaN'))
-- !query analysis
Project [POWER(cast(-1 as double), cast(NaN as double)) AS POWER(-1, NaN)#x]
+- OneRowRelation


-- !query
SELECT power(double('1'), double('NaN'))
-- !query analysis
Project [POWER(cast(1 as double), cast(NaN as double)) AS POWER(1, NaN)#x]
+- OneRowRelation


-- !query
SELECT power(double('NaN'), double('0'))
-- !query analysis
Project [POWER(cast(NaN as double), cast(0 as double)) AS POWER(NaN, 0)#x]
+- OneRowRelation


-- !query
SELECT '' AS three, f.f1, exp(ln(f.f1)) AS exp_ln_f1
   FROM FLOAT8_TBL f
   WHERE f.f1 > '0.0'
-- !query analysis
Project [ AS three#x, f1#x, EXP(ln(f1#x)) AS exp_ln_f1#x]
+- Filter (f1#x > cast(0.0 as double))
   +- SubqueryAlias f
      +- SubqueryAlias spark_catalog.default.float8_tbl
         +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT '' AS five, * FROM FLOAT8_TBL
-- !query analysis
Project [ AS five#x, f1#x]
+- SubqueryAlias spark_catalog.default.float8_tbl
   +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
CREATE TEMPORARY VIEW UPDATED_FLOAT8_TBL as
SELECT
  CASE WHEN FLOAT8_TBL.f1 > '0.0' THEN FLOAT8_TBL.f1 * '-1' ELSE FLOAT8_TBL.f1 END AS f1
FROM FLOAT8_TBL
-- !query analysis
CreateViewCommand `UPDATED_FLOAT8_TBL`, SELECT
  CASE WHEN FLOAT8_TBL.f1 > '0.0' THEN FLOAT8_TBL.f1 * '-1' ELSE FLOAT8_TBL.f1 END AS f1
FROM FLOAT8_TBL, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [CASE WHEN (f1#x > cast(0.0 as double)) THEN (f1#x * cast(-1 as double)) ELSE f1#x END AS f1#x]
      +- SubqueryAlias spark_catalog.default.float8_tbl
         +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT '' AS bad, f.f1 * '1e200' from UPDATED_FLOAT8_TBL f
-- !query analysis
Project [ AS bad#x, (f1#x * cast(1e200 as double)) AS (f1 * 1e200)#x]
+- SubqueryAlias f
   +- SubqueryAlias updated_float8_tbl
      +- View (`UPDATED_FLOAT8_TBL`, [f1#x])
         +- Project [cast(f1#x as double) AS f1#x]
            +- Project [CASE WHEN (f1#x > cast(0.0 as double)) THEN (f1#x * cast(-1 as double)) ELSE f1#x END AS f1#x]
               +- SubqueryAlias spark_catalog.default.float8_tbl
                  +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT '' AS five, * FROM UPDATED_FLOAT8_TBL
-- !query analysis
Project [ AS five#x, f1#x]
+- SubqueryAlias updated_float8_tbl
   +- View (`UPDATED_FLOAT8_TBL`, [f1#x])
      +- Project [cast(f1#x as double) AS f1#x]
         +- Project [CASE WHEN (f1#x > cast(0.0 as double)) THEN (f1#x * cast(-1 as double)) ELSE f1#x END AS f1#x]
            +- SubqueryAlias spark_catalog.default.float8_tbl
               +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT sinh(double('1'))
-- !query analysis
Project [SINH(cast(1 as double)) AS SINH(1)#x]
+- OneRowRelation


-- !query
SELECT cosh(double('1'))
-- !query analysis
Project [COSH(cast(1 as double)) AS COSH(1)#x]
+- OneRowRelation


-- !query
SELECT tanh(double('1'))
-- !query analysis
Project [TANH(cast(1 as double)) AS TANH(1)#x]
+- OneRowRelation


-- !query
SELECT asinh(double('1'))
-- !query analysis
Project [ASINH(cast(1 as double)) AS ASINH(1)#x]
+- OneRowRelation


-- !query
SELECT acosh(double('2'))
-- !query analysis
Project [ACOSH(cast(2 as double)) AS ACOSH(2)#x]
+- OneRowRelation


-- !query
SELECT atanh(double('0.5'))
-- !query analysis
Project [ATANH(cast(0.5 as double)) AS ATANH(0.5)#x]
+- OneRowRelation


-- !query
SELECT sinh(double('Infinity'))
-- !query analysis
Project [SINH(cast(Infinity as double)) AS SINH(Infinity)#x]
+- OneRowRelation


-- !query
SELECT sinh(double('-Infinity'))
-- !query analysis
Project [SINH(cast(-Infinity as double)) AS SINH(-Infinity)#x]
+- OneRowRelation


-- !query
SELECT sinh(double('NaN'))
-- !query analysis
Project [SINH(cast(NaN as double)) AS SINH(NaN)#x]
+- OneRowRelation


-- !query
SELECT cosh(double('Infinity'))
-- !query analysis
Project [COSH(cast(Infinity as double)) AS COSH(Infinity)#x]
+- OneRowRelation


-- !query
SELECT cosh(double('-Infinity'))
-- !query analysis
Project [COSH(cast(-Infinity as double)) AS COSH(-Infinity)#x]
+- OneRowRelation


-- !query
SELECT cosh(double('NaN'))
-- !query analysis
Project [COSH(cast(NaN as double)) AS COSH(NaN)#x]
+- OneRowRelation


-- !query
SELECT tanh(double('Infinity'))
-- !query analysis
Project [TANH(cast(Infinity as double)) AS TANH(Infinity)#x]
+- OneRowRelation


-- !query
SELECT tanh(double('-Infinity'))
-- !query analysis
Project [TANH(cast(-Infinity as double)) AS TANH(-Infinity)#x]
+- OneRowRelation


-- !query
SELECT tanh(double('NaN'))
-- !query analysis
Project [TANH(cast(NaN as double)) AS TANH(NaN)#x]
+- OneRowRelation


-- !query
SELECT asinh(double('Infinity'))
-- !query analysis
Project [ASINH(cast(Infinity as double)) AS ASINH(Infinity)#x]
+- OneRowRelation


-- !query
SELECT asinh(double('-Infinity'))
-- !query analysis
Project [ASINH(cast(-Infinity as double)) AS ASINH(-Infinity)#x]
+- OneRowRelation


-- !query
SELECT asinh(double('NaN'))
-- !query analysis
Project [ASINH(cast(NaN as double)) AS ASINH(NaN)#x]
+- OneRowRelation


-- !query
SELECT acosh(double('Infinity'))
-- !query analysis
Project [ACOSH(cast(Infinity as double)) AS ACOSH(Infinity)#x]
+- OneRowRelation


-- !query
SELECT acosh(double('-Infinity'))
-- !query analysis
Project [ACOSH(cast(-Infinity as double)) AS ACOSH(-Infinity)#x]
+- OneRowRelation


-- !query
SELECT acosh(double('NaN'))
-- !query analysis
Project [ACOSH(cast(NaN as double)) AS ACOSH(NaN)#x]
+- OneRowRelation


-- !query
SELECT atanh(double('Infinity'))
-- !query analysis
Project [ATANH(cast(Infinity as double)) AS ATANH(Infinity)#x]
+- OneRowRelation


-- !query
SELECT atanh(double('-Infinity'))
-- !query analysis
Project [ATANH(cast(-Infinity as double)) AS ATANH(-Infinity)#x]
+- OneRowRelation


-- !query
SELECT atanh(double('NaN'))
-- !query analysis
Project [ATANH(cast(NaN as double)) AS ATANH(NaN)#x]
+- OneRowRelation


-- !query
TRUNCATE TABLE FLOAT8_TBL
-- !query analysis
TruncateTableCommand `spark_catalog`.`default`.`float8_tbl`


-- !query
INSERT INTO FLOAT8_TBL VALUES (double('0.0'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/float8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/float8_tbl], Append, `spark_catalog`.`default`.`float8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/float8_tbl), [f1]
+- Project [cast(col1#x as double) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO FLOAT8_TBL VALUES (double('-34.84'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/float8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/float8_tbl], Append, `spark_catalog`.`default`.`float8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/float8_tbl), [f1]
+- Project [cast(col1#x as double) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO FLOAT8_TBL VALUES (double('-1004.30'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/float8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/float8_tbl], Append, `spark_catalog`.`default`.`float8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/float8_tbl), [f1]
+- Project [cast(col1#x as double) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO FLOAT8_TBL VALUES (double('-1.2345678901234e+200'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/float8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/float8_tbl], Append, `spark_catalog`.`default`.`float8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/float8_tbl), [f1]
+- Project [cast(col1#x as double) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO FLOAT8_TBL VALUES (double('-1.2345678901234e-200'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/float8_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/float8_tbl], Append, `spark_catalog`.`default`.`float8_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/float8_tbl), [f1]
+- Project [cast(col1#x as double) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
SELECT '' AS five, * FROM FLOAT8_TBL
-- !query analysis
Project [ AS five#x, f1#x]
+- SubqueryAlias spark_catalog.default.float8_tbl
   +- Relation spark_catalog.default.float8_tbl[f1#x] parquet


-- !query
SELECT smallint(double('32767.4'))
-- !query analysis
Project [cast(cast(32767.4 as double) as smallint) AS 32767.4#x]
+- OneRowRelation


-- !query
SELECT smallint(double('32767.6'))
-- !query analysis
Project [cast(cast(32767.6 as double) as smallint) AS 32767.6#x]
+- OneRowRelation


-- !query
SELECT smallint(double('-32768.4'))
-- !query analysis
Project [cast(cast(-32768.4 as double) as smallint) AS -32768.4#x]
+- OneRowRelation


-- !query
SELECT smallint(double('-32768.6'))
-- !query analysis
Project [cast(cast(-32768.6 as double) as smallint) AS -32768.6#x]
+- OneRowRelation


-- !query
SELECT int(double('2147483647.4'))
-- !query analysis
Project [cast(cast(2147483647.4 as double) as int) AS 2147483647.4#x]
+- OneRowRelation


-- !query
SELECT int(double('2147483647.6'))
-- !query analysis
Project [cast(cast(2147483647.6 as double) as int) AS 2147483647.6#x]
+- OneRowRelation


-- !query
SELECT int(double('-2147483648.4'))
-- !query analysis
Project [cast(cast(-2147483648.4 as double) as int) AS -2147483648.4#x]
+- OneRowRelation


-- !query
SELECT int(double('-2147483648.6'))
-- !query analysis
Project [cast(cast(-2147483648.6 as double) as int) AS -2147483648.6#x]
+- OneRowRelation


-- !query
SELECT bigint(double('9223372036854773760'))
-- !query analysis
Project [cast(cast(9223372036854773760 as double) as bigint) AS 9223372036854773760#xL]
+- OneRowRelation


-- !query
SELECT bigint(double('9223372036854775807'))
-- !query analysis
Project [cast(cast(9223372036854775807 as double) as bigint) AS 9223372036854775807#xL]
+- OneRowRelation


-- !query
SELECT bigint(double('-9223372036854775808.5'))
-- !query analysis
Project [cast(cast(-9223372036854775808.5 as double) as bigint) AS -9223372036854775808.5#xL]
+- OneRowRelation


-- !query
SELECT bigint(double('-9223372036854780000'))
-- !query analysis
Project [cast(cast(-9223372036854780000 as double) as bigint) AS -9223372036854780000#xL]
+- OneRowRelation


-- !query
DROP TABLE FLOAT8_TBL
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.FLOAT8_TBL
