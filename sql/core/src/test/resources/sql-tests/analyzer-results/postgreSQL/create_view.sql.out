-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TABLE emp (
  name string,
  age int,
  salary int,
  manager string
) USING parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`emp`, false


-- !query
CREATE VIEW toyemp AS
   SELECT name, age, /* location ,*/ 12*salary AS annualsal
   FROM emp
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`toyemp`, SELECT name, age, /* location ,*/ 12*salary AS annualsal
   FROM emp, false, false, PersistedView, COMPENSATION, true
   +- Project [name#x, age#x, (12 * salary#x) AS annualsal#x]
      +- SubqueryAlias spark_catalog.default.emp
         +- Relation spark_catalog.default.emp[name#x,age#x,salary#x,manager#x] parquet


-- !query
DROP VIEW toyemp
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`toyemp`, false, true, false


-- !query
DROP TABLE emp
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.emp


-- !query
CREATE TABLE view_base_table (key int /* PRIMARY KEY */, data varchar(20)) USING PARQUET
-- !query analysis
org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException
{
  "errorClass" : "TABLE_OR_VIEW_ALREADY_EXISTS",
  "sqlState" : "42P07",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`view_base_table`"
  }
}


-- !query
CREATE VIEW key_dependent_view AS
   SELECT * FROM view_base_table GROUP BY key
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "MISSING_AGGREGATION",
  "sqlState" : "42803",
  "messageParameters" : {
    "expression" : "\"data\"",
    "expressionAnyValue" : "\"any_value(data)\""
  }
}


-- !query
CREATE VIEW key_dependent_view_no_cols AS
   SELECT FROM view_base_table GROUP BY key HAVING length(data) > 0
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNRESOLVED_COLUMN.WITHOUT_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`FROM`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 53,
    "stopIndex" : 56,
    "fragment" : "FROM"
  } ]
}


-- !query
CREATE TABLE viewtest_tbl (a int, b int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`viewtest_tbl`, false


-- !query
INSERT INTO viewtest_tbl VALUES (5, 10), (10, 15), (15, 20), (20, 25)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/viewtest_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/viewtest_tbl], Append, `spark_catalog`.`default`.`viewtest_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/viewtest_tbl), [a, b]
+- Project [cast(col1#x as int) AS a#x, cast(col2#x as int) AS b#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
CREATE OR REPLACE VIEW viewtest AS
	SELECT * FROM viewtest_tbl
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`viewtest`, SELECT * FROM viewtest_tbl, false, true, PersistedView, COMPENSATION, true
   +- Project [a#x, b#x]
      +- SubqueryAlias spark_catalog.default.viewtest_tbl
         +- Relation spark_catalog.default.viewtest_tbl[a#x,b#x] parquet


-- !query
CREATE OR REPLACE VIEW viewtest AS
	SELECT * FROM viewtest_tbl WHERE a > 10
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`viewtest`, SELECT * FROM viewtest_tbl WHERE a > 10, false, true, PersistedView, COMPENSATION, true
   +- Project [a#x, b#x]
      +- Filter (a#x > 10)
         +- SubqueryAlias spark_catalog.default.viewtest_tbl
            +- Relation spark_catalog.default.viewtest_tbl[a#x,b#x] parquet


-- !query
SELECT * FROM viewtest
-- !query analysis
Project [a#x, b#x]
+- SubqueryAlias spark_catalog.default.viewtest
   +- View (`spark_catalog`.`default`.`viewtest`, [a#x, b#x])
      +- Project [cast(a#x as int) AS a#x, cast(b#x as int) AS b#x]
         +- Project [a#x, b#x]
            +- Filter (a#x > 10)
               +- SubqueryAlias spark_catalog.default.viewtest_tbl
                  +- Relation spark_catalog.default.viewtest_tbl[a#x,b#x] parquet


-- !query
CREATE OR REPLACE VIEW viewtest AS
	SELECT a, b FROM viewtest_tbl WHERE a > 5 ORDER BY b DESC
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`viewtest`, SELECT a, b FROM viewtest_tbl WHERE a > 5 ORDER BY b DESC, false, true, PersistedView, COMPENSATION, true
   +- Sort [b#x DESC NULLS LAST], true
      +- Project [a#x, b#x]
         +- Filter (a#x > 5)
            +- SubqueryAlias spark_catalog.default.viewtest_tbl
               +- Relation spark_catalog.default.viewtest_tbl[a#x,b#x] parquet


-- !query
SELECT * FROM viewtest
-- !query analysis
Project [a#x, b#x]
+- SubqueryAlias spark_catalog.default.viewtest
   +- View (`spark_catalog`.`default`.`viewtest`, [a#x, b#x])
      +- Project [cast(a#x as int) AS a#x, cast(b#x as int) AS b#x]
         +- Sort [b#x DESC NULLS LAST], true
            +- Project [a#x, b#x]
               +- Filter (a#x > 5)
                  +- SubqueryAlias spark_catalog.default.viewtest_tbl
                     +- Relation spark_catalog.default.viewtest_tbl[a#x,b#x] parquet


-- !query
CREATE OR REPLACE VIEW viewtest AS
	SELECT a FROM viewtest_tbl WHERE a <> 20
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`viewtest`, SELECT a FROM viewtest_tbl WHERE a <> 20, false, true, PersistedView, COMPENSATION, true
   +- Project [a#x]
      +- Filter NOT (a#x = 20)
         +- SubqueryAlias spark_catalog.default.viewtest_tbl
            +- Relation spark_catalog.default.viewtest_tbl[a#x,b#x] parquet


-- !query
CREATE OR REPLACE VIEW viewtest AS
	SELECT 1, * FROM viewtest_tbl
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`viewtest`, SELECT 1, * FROM viewtest_tbl, false, true, PersistedView, COMPENSATION, true
   +- Project [1 AS 1#x, a#x, b#x]
      +- SubqueryAlias spark_catalog.default.viewtest_tbl
         +- Relation spark_catalog.default.viewtest_tbl[a#x,b#x] parquet


-- !query
CREATE OR REPLACE VIEW viewtest AS
	SELECT a, decimal(b) FROM viewtest_tbl
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`viewtest`, SELECT a, decimal(b) FROM viewtest_tbl, false, true, PersistedView, COMPENSATION, true
   +- Project [a#x, cast(b#x as decimal(10,0)) AS b#x]
      +- SubqueryAlias spark_catalog.default.viewtest_tbl
         +- Relation spark_catalog.default.viewtest_tbl[a#x,b#x] parquet


-- !query
CREATE OR REPLACE VIEW viewtest AS
	SELECT a, b, 0 AS c FROM viewtest_tbl
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`viewtest`, SELECT a, b, 0 AS c FROM viewtest_tbl, false, true, PersistedView, COMPENSATION, true
   +- Project [a#x, b#x, 0 AS c#x]
      +- SubqueryAlias spark_catalog.default.viewtest_tbl
         +- Relation spark_catalog.default.viewtest_tbl[a#x,b#x] parquet


-- !query
DROP VIEW viewtest
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`viewtest`, false, true, false


-- !query
DROP TABLE viewtest_tbl
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.viewtest_tbl


-- !query
CREATE SCHEMA temp_view_test
-- !query analysis
CreateNamespace false
+- ResolvedNamespace V2SessionCatalog(spark_catalog), [temp_view_test]


-- !query
CREATE TABLE temp_view_test.base_table (a int, id int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`temp_view_test`.`base_table`, false


-- !query
CREATE TABLE temp_view_test.base_table2 (a int, id int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`temp_view_test`.`base_table2`, false


-- !query
USE temp_view_test
-- !query analysis
SetCatalogAndNamespace
+- ResolvedNamespace V2SessionCatalog(spark_catalog), [temp_view_test]


-- !query
CREATE TEMPORARY VIEW temp_table AS SELECT * FROM VALUES
  (1, 1) as temp_table(a, id)
-- !query analysis
CreateViewCommand `temp_table`, SELECT * FROM VALUES
  (1, 1) as temp_table(a, id), false, false, LocalTempView, UNSUPPORTED, true
   +- Project [a#x, id#x]
      +- SubqueryAlias temp_table
         +- LocalRelation [a#x, id#x]


-- !query
CREATE VIEW v1 AS SELECT * FROM base_table
-- !query analysis
CreateViewCommand `spark_catalog`.`temp_view_test`.`v1`, SELECT * FROM base_table, false, false, PersistedView, COMPENSATION, true
   +- Project [a#x, id#x]
      +- SubqueryAlias spark_catalog.temp_view_test.base_table
         +- Relation spark_catalog.temp_view_test.base_table[a#x,id#x] parquet


-- !query
DESC TABLE EXTENDED v1
-- !query analysis
DescribeTableCommand `spark_catalog`.`temp_view_test`.`v1`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE VIEW v1_temp AS SELECT * FROM temp_table
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_TEMP_OBJ_REFERENCE",
  "sqlState" : "42K0F",
  "messageParameters" : {
    "obj" : "VIEW",
    "objName" : "`spark_catalog`.`temp_view_test`.`v1_temp`",
    "tempObj" : "VIEW",
    "tempObjName" : "`temp_table`"
  }
}


-- !query
CREATE TEMP VIEW v2_temp AS SELECT * FROM base_table
-- !query analysis
CreateViewCommand `v2_temp`, SELECT * FROM base_table, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [a#x, id#x]
      +- SubqueryAlias spark_catalog.temp_view_test.base_table
         +- Relation spark_catalog.temp_view_test.base_table[a#x,id#x] parquet


-- !query
DESC TABLE EXTENDED v2_temp
-- !query analysis
DescribeTableCommand `v2_temp`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE VIEW temp_view_test.v2 AS SELECT * FROM base_table
-- !query analysis
CreateViewCommand `spark_catalog`.`temp_view_test`.`v2`, SELECT * FROM base_table, false, false, PersistedView, COMPENSATION, true
   +- Project [a#x, id#x]
      +- SubqueryAlias spark_catalog.temp_view_test.base_table
         +- Relation spark_catalog.temp_view_test.base_table[a#x,id#x] parquet


-- !query
DESC TABLE EXTENDED temp_view_test.v2
-- !query analysis
DescribeTableCommand `spark_catalog`.`temp_view_test`.`v2`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE VIEW temp_view_test.v3_temp AS SELECT * FROM temp_table
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_TEMP_OBJ_REFERENCE",
  "sqlState" : "42K0F",
  "messageParameters" : {
    "obj" : "VIEW",
    "objName" : "`spark_catalog`.`temp_view_test`.`v3_temp`",
    "tempObj" : "VIEW",
    "tempObjName" : "`temp_table`"
  }
}


-- !query
CREATE VIEW v3 AS
    SELECT t1.a AS t1_a, t2.a AS t2_a
    FROM base_table t1, base_table2 t2
    WHERE t1.id = t2.id
-- !query analysis
CreateViewCommand `spark_catalog`.`temp_view_test`.`v3`, SELECT t1.a AS t1_a, t2.a AS t2_a
    FROM base_table t1, base_table2 t2
    WHERE t1.id = t2.id, false, false, PersistedView, COMPENSATION, true
   +- Project [a#x AS t1_a#x, a#x AS t2_a#x]
      +- Filter (id#x = id#x)
         +- Join Inner
            :- SubqueryAlias t1
            :  +- SubqueryAlias spark_catalog.temp_view_test.base_table
            :     +- Relation spark_catalog.temp_view_test.base_table[a#x,id#x] parquet
            +- SubqueryAlias t2
               +- SubqueryAlias spark_catalog.temp_view_test.base_table2
                  +- Relation spark_catalog.temp_view_test.base_table2[a#x,id#x] parquet


-- !query
DESC TABLE EXTENDED v3
-- !query analysis
DescribeTableCommand `spark_catalog`.`temp_view_test`.`v3`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE VIEW v4_temp AS
    SELECT t1.a AS t1_a, t2.a AS t2_a
    FROM base_table t1, temp_table t2
    WHERE t1.id = t2.id
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_TEMP_OBJ_REFERENCE",
  "sqlState" : "42K0F",
  "messageParameters" : {
    "obj" : "VIEW",
    "objName" : "`spark_catalog`.`temp_view_test`.`v4_temp`",
    "tempObj" : "VIEW",
    "tempObjName" : "`temp_table`"
  }
}


-- !query
CREATE VIEW v5_temp AS
    SELECT t1.a AS t1_a, t2.a AS t2_a, t3.a AS t3_a
    FROM base_table t1, base_table2 t2, temp_table t3
    WHERE t1.id = t2.id and t2.id = t3.id
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_TEMP_OBJ_REFERENCE",
  "sqlState" : "42K0F",
  "messageParameters" : {
    "obj" : "VIEW",
    "objName" : "`spark_catalog`.`temp_view_test`.`v5_temp`",
    "tempObj" : "VIEW",
    "tempObjName" : "`temp_table`"
  }
}


-- !query
CREATE VIEW v4 AS SELECT * FROM base_table WHERE id IN (SELECT id FROM base_table2)
-- !query analysis
CreateViewCommand `spark_catalog`.`temp_view_test`.`v4`, SELECT * FROM base_table WHERE id IN (SELECT id FROM base_table2), false, false, PersistedView, COMPENSATION, true
   +- Project [a#x, id#x]
      +- Filter id#x IN (list#x [])
         :  +- Project [id#x]
         :     +- SubqueryAlias spark_catalog.temp_view_test.base_table2
         :        +- Relation spark_catalog.temp_view_test.base_table2[a#x,id#x] parquet
         +- SubqueryAlias spark_catalog.temp_view_test.base_table
            +- Relation spark_catalog.temp_view_test.base_table[a#x,id#x] parquet


-- !query
DESC TABLE EXTENDED v4
-- !query analysis
DescribeTableCommand `spark_catalog`.`temp_view_test`.`v4`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE VIEW v5 AS SELECT t1.id, t2.a FROM base_table t1, (SELECT * FROM base_table2) t2
-- !query analysis
CreateViewCommand `spark_catalog`.`temp_view_test`.`v5`, SELECT t1.id, t2.a FROM base_table t1, (SELECT * FROM base_table2) t2, false, false, PersistedView, COMPENSATION, true
   +- Project [id#x, a#x]
      +- Join Inner
         :- SubqueryAlias t1
         :  +- SubqueryAlias spark_catalog.temp_view_test.base_table
         :     +- Relation spark_catalog.temp_view_test.base_table[a#x,id#x] parquet
         +- SubqueryAlias t2
            +- Project [a#x, id#x]
               +- SubqueryAlias spark_catalog.temp_view_test.base_table2
                  +- Relation spark_catalog.temp_view_test.base_table2[a#x,id#x] parquet


-- !query
DESC TABLE EXTENDED v5
-- !query analysis
DescribeTableCommand `spark_catalog`.`temp_view_test`.`v5`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE VIEW v6 AS SELECT * FROM base_table WHERE EXISTS (SELECT 1 FROM base_table2)
-- !query analysis
CreateViewCommand `spark_catalog`.`temp_view_test`.`v6`, SELECT * FROM base_table WHERE EXISTS (SELECT 1 FROM base_table2), false, false, PersistedView, COMPENSATION, true
   +- Project [a#x, id#x]
      +- Filter exists#x []
         :  +- Project [1 AS 1#x]
         :     +- SubqueryAlias spark_catalog.temp_view_test.base_table2
         :        +- Relation spark_catalog.temp_view_test.base_table2[a#x,id#x] parquet
         +- SubqueryAlias spark_catalog.temp_view_test.base_table
            +- Relation spark_catalog.temp_view_test.base_table[a#x,id#x] parquet


-- !query
DESC TABLE EXTENDED v6
-- !query analysis
DescribeTableCommand `spark_catalog`.`temp_view_test`.`v6`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE VIEW v7 AS SELECT * FROM base_table WHERE NOT EXISTS (SELECT 1 FROM base_table2)
-- !query analysis
CreateViewCommand `spark_catalog`.`temp_view_test`.`v7`, SELECT * FROM base_table WHERE NOT EXISTS (SELECT 1 FROM base_table2), false, false, PersistedView, COMPENSATION, true
   +- Project [a#x, id#x]
      +- Filter NOT exists#x []
         :  +- Project [1 AS 1#x]
         :     +- SubqueryAlias spark_catalog.temp_view_test.base_table2
         :        +- Relation spark_catalog.temp_view_test.base_table2[a#x,id#x] parquet
         +- SubqueryAlias spark_catalog.temp_view_test.base_table
            +- Relation spark_catalog.temp_view_test.base_table[a#x,id#x] parquet


-- !query
DESC TABLE EXTENDED v7
-- !query analysis
DescribeTableCommand `spark_catalog`.`temp_view_test`.`v7`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE VIEW v8 AS SELECT * FROM base_table WHERE EXISTS (SELECT 1)
-- !query analysis
CreateViewCommand `spark_catalog`.`temp_view_test`.`v8`, SELECT * FROM base_table WHERE EXISTS (SELECT 1), false, false, PersistedView, COMPENSATION, true
   +- Project [a#x, id#x]
      +- Filter exists#x []
         :  +- Project [1 AS 1#x]
         :     +- OneRowRelation
         +- SubqueryAlias spark_catalog.temp_view_test.base_table
            +- Relation spark_catalog.temp_view_test.base_table[a#x,id#x] parquet


-- !query
DESC TABLE EXTENDED v8
-- !query analysis
DescribeTableCommand `spark_catalog`.`temp_view_test`.`v8`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE VIEW v6_temp AS SELECT * FROM base_table WHERE id IN (SELECT id FROM temp_table)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_TEMP_OBJ_REFERENCE",
  "sqlState" : "42K0F",
  "messageParameters" : {
    "obj" : "VIEW",
    "objName" : "`spark_catalog`.`temp_view_test`.`v6_temp`",
    "tempObj" : "VIEW",
    "tempObjName" : "`temp_table`"
  }
}


-- !query
CREATE VIEW v7_temp AS SELECT t1.id, t2.a FROM base_table t1, (SELECT * FROM temp_table) t2
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_TEMP_OBJ_REFERENCE",
  "sqlState" : "42K0F",
  "messageParameters" : {
    "obj" : "VIEW",
    "objName" : "`spark_catalog`.`temp_view_test`.`v7_temp`",
    "tempObj" : "VIEW",
    "tempObjName" : "`temp_table`"
  }
}


-- !query
CREATE VIEW v8_temp AS SELECT * FROM base_table WHERE EXISTS (SELECT 1 FROM temp_table)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_TEMP_OBJ_REFERENCE",
  "sqlState" : "42K0F",
  "messageParameters" : {
    "obj" : "VIEW",
    "objName" : "`spark_catalog`.`temp_view_test`.`v8_temp`",
    "tempObj" : "VIEW",
    "tempObjName" : "`temp_table`"
  }
}


-- !query
CREATE VIEW v9_temp AS SELECT * FROM base_table WHERE NOT EXISTS (SELECT 1 FROM temp_table)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_TEMP_OBJ_REFERENCE",
  "sqlState" : "42K0F",
  "messageParameters" : {
    "obj" : "VIEW",
    "objName" : "`spark_catalog`.`temp_view_test`.`v9_temp`",
    "tempObj" : "VIEW",
    "tempObjName" : "`temp_table`"
  }
}


-- !query
CREATE VIEW v10_temp AS SELECT * FROM v7_temp
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`v7_temp`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 39,
    "stopIndex" : 45,
    "fragment" : "v7_temp"
  } ]
}


-- !query
CREATE VIEW v11_temp AS SELECT t1.id, t2.a FROM base_table t1, v10_temp t2
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`v10_temp`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 64,
    "stopIndex" : 71,
    "fragment" : "v10_temp"
  } ]
}


-- !query
CREATE VIEW v12_temp AS SELECT true FROM v11_temp
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`v11_temp`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 42,
    "stopIndex" : 49,
    "fragment" : "v11_temp"
  } ]
}


-- !query
CREATE SCHEMA testviewschm2
-- !query analysis
CreateNamespace false
+- ResolvedNamespace V2SessionCatalog(spark_catalog), [testviewschm2]


-- !query
USE testviewschm2
-- !query analysis
SetCatalogAndNamespace
+- ResolvedNamespace V2SessionCatalog(spark_catalog), [testviewschm2]


-- !query
CREATE TABLE t1 (num int, name string) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`t1`, false


-- !query
CREATE TABLE t2 (num2 int, value string) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`t2`, false


-- !query
CREATE TEMP VIEW tt AS SELECT * FROM VALUES
  (1, 'a') AS tt(num2, value)
-- !query analysis
CreateViewCommand `tt`, SELECT * FROM VALUES
  (1, 'a') AS tt(num2, value), false, false, LocalTempView, UNSUPPORTED, true
   +- Project [num2#x, value#x]
      +- SubqueryAlias tt
         +- LocalRelation [num2#x, value#x]


-- !query
CREATE VIEW nontemp1 AS SELECT * FROM t1 CROSS JOIN t2
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`nontemp1`, SELECT * FROM t1 CROSS JOIN t2, false, false, PersistedView, COMPENSATION, true
   +- Project [num#x, name#x, num2#x, value#x]
      +- Join Cross
         :- SubqueryAlias spark_catalog.testviewschm2.t1
         :  +- Relation spark_catalog.testviewschm2.t1[num#x,name#x] parquet
         +- SubqueryAlias spark_catalog.testviewschm2.t2
            +- Relation spark_catalog.testviewschm2.t2[num2#x,value#x] parquet


-- !query
DESC TABLE EXTENDED nontemp1
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`nontemp1`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE VIEW temporal1 AS SELECT * FROM t1 CROSS JOIN tt
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_TEMP_OBJ_REFERENCE",
  "sqlState" : "42K0F",
  "messageParameters" : {
    "obj" : "VIEW",
    "objName" : "`spark_catalog`.`testviewschm2`.`temporal1`",
    "tempObj" : "VIEW",
    "tempObjName" : "`tt`"
  }
}


-- !query
CREATE VIEW nontemp2 AS SELECT * FROM t1 INNER JOIN t2 ON t1.num = t2.num2
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`nontemp2`, SELECT * FROM t1 INNER JOIN t2 ON t1.num = t2.num2, false, false, PersistedView, COMPENSATION, true
   +- Project [num#x, name#x, num2#x, value#x]
      +- Join Inner, (num#x = num2#x)
         :- SubqueryAlias spark_catalog.testviewschm2.t1
         :  +- Relation spark_catalog.testviewschm2.t1[num#x,name#x] parquet
         +- SubqueryAlias spark_catalog.testviewschm2.t2
            +- Relation spark_catalog.testviewschm2.t2[num2#x,value#x] parquet


-- !query
DESC TABLE EXTENDED nontemp2
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`nontemp2`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE VIEW temporal2 AS SELECT * FROM t1 INNER JOIN tt ON t1.num = tt.num2
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_TEMP_OBJ_REFERENCE",
  "sqlState" : "42K0F",
  "messageParameters" : {
    "obj" : "VIEW",
    "objName" : "`spark_catalog`.`testviewschm2`.`temporal2`",
    "tempObj" : "VIEW",
    "tempObjName" : "`tt`"
  }
}


-- !query
CREATE VIEW nontemp3 AS SELECT * FROM t1 LEFT JOIN t2 ON t1.num = t2.num2
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`nontemp3`, SELECT * FROM t1 LEFT JOIN t2 ON t1.num = t2.num2, false, false, PersistedView, COMPENSATION, true
   +- Project [num#x, name#x, num2#x, value#x]
      +- Join LeftOuter, (num#x = num2#x)
         :- SubqueryAlias spark_catalog.testviewschm2.t1
         :  +- Relation spark_catalog.testviewschm2.t1[num#x,name#x] parquet
         +- SubqueryAlias spark_catalog.testviewschm2.t2
            +- Relation spark_catalog.testviewschm2.t2[num2#x,value#x] parquet


-- !query
DESC TABLE EXTENDED nontemp3
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`nontemp3`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE VIEW temporal3 AS SELECT * FROM t1 LEFT JOIN tt ON t1.num = tt.num2
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_TEMP_OBJ_REFERENCE",
  "sqlState" : "42K0F",
  "messageParameters" : {
    "obj" : "VIEW",
    "objName" : "`spark_catalog`.`testviewschm2`.`temporal3`",
    "tempObj" : "VIEW",
    "tempObjName" : "`tt`"
  }
}


-- !query
CREATE VIEW nontemp4 AS SELECT * FROM t1 LEFT JOIN t2 ON t1.num = t2.num2 AND t2.value = 'xxx'
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`nontemp4`, SELECT * FROM t1 LEFT JOIN t2 ON t1.num = t2.num2 AND t2.value = 'xxx', false, false, PersistedView, COMPENSATION, true
   +- Project [num#x, name#x, num2#x, value#x]
      +- Join LeftOuter, ((num#x = num2#x) AND (value#x = xxx))
         :- SubqueryAlias spark_catalog.testviewschm2.t1
         :  +- Relation spark_catalog.testviewschm2.t1[num#x,name#x] parquet
         +- SubqueryAlias spark_catalog.testviewschm2.t2
            +- Relation spark_catalog.testviewschm2.t2[num2#x,value#x] parquet


-- !query
DESC TABLE EXTENDED nontemp4
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`nontemp4`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE VIEW temporal4 AS SELECT * FROM t1 LEFT JOIN tt ON t1.num = tt.num2 AND tt.value = 'xxx'
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_TEMP_OBJ_REFERENCE",
  "sqlState" : "42K0F",
  "messageParameters" : {
    "obj" : "VIEW",
    "objName" : "`spark_catalog`.`testviewschm2`.`temporal4`",
    "tempObj" : "VIEW",
    "tempObjName" : "`tt`"
  }
}


-- !query
CREATE VIEW temporal5 AS SELECT * FROM t1 WHERE num IN (SELECT num FROM t1 WHERE EXISTS (SELECT 1 FROM tt))
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_TEMP_OBJ_REFERENCE",
  "sqlState" : "42K0F",
  "messageParameters" : {
    "obj" : "VIEW",
    "objName" : "`spark_catalog`.`testviewschm2`.`temporal5`",
    "tempObj" : "VIEW",
    "tempObjName" : "`tt`"
  }
}


-- !query
CREATE TABLE tbl1 ( a int, b int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tbl1`, false


-- !query
CREATE TABLE tbl2 (c int, d int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tbl2`, false


-- !query
CREATE TABLE tbl3 (e int, f int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tbl3`, false


-- !query
CREATE TABLE tbl4 (g int, h int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tbl4`, false


-- !query
CREATE TABLE tmptbl (i int, j int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tmptbl`, false


-- !query
INSERT INTO tmptbl VALUES (1, 1)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/testviewschm2.db/tmptbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/testviewschm2.db/tmptbl], Append, `spark_catalog`.`testviewschm2`.`tmptbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/testviewschm2.db/tmptbl), [i, j]
+- Project [cast(col1#x as int) AS i#x, cast(col2#x as int) AS j#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
CREATE   VIEW  pubview AS SELECT * FROM tbl1 WHERE tbl1.a
BETWEEN (SELECT d FROM tbl2 WHERE c = 1) AND (SELECT e FROM tbl3 WHERE f = 2)
AND EXISTS (SELECT g FROM tbl4 LEFT JOIN tbl3 ON tbl4.h = tbl3.f)
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`pubview`, SELECT * FROM tbl1 WHERE tbl1.a
BETWEEN (SELECT d FROM tbl2 WHERE c = 1) AND (SELECT e FROM tbl3 WHERE f = 2)
AND EXISTS (SELECT g FROM tbl4 LEFT JOIN tbl3 ON tbl4.h = tbl3.f), false, false, PersistedView, COMPENSATION, true
   +- Project [a#x, b#x]
      +- Filter (between(a#x, scalar-subquery#x [], scalar-subquery#x []) AND exists#x [])
         :  :- Project [d#x]
         :  :  +- Filter (c#x = 1)
         :  :     +- SubqueryAlias spark_catalog.testviewschm2.tbl2
         :  :        +- Relation spark_catalog.testviewschm2.tbl2[c#x,d#x] parquet
         :  :- Project [e#x]
         :  :  +- Filter (f#x = 2)
         :  :     +- SubqueryAlias spark_catalog.testviewschm2.tbl3
         :  :        +- Relation spark_catalog.testviewschm2.tbl3[e#x,f#x] parquet
         :  +- Project [g#x]
         :     +- Join LeftOuter, (h#x = f#x)
         :        :- SubqueryAlias spark_catalog.testviewschm2.tbl4
         :        :  +- Relation spark_catalog.testviewschm2.tbl4[g#x,h#x] parquet
         :        +- SubqueryAlias spark_catalog.testviewschm2.tbl3
         :           +- Relation spark_catalog.testviewschm2.tbl3[e#x,f#x] parquet
         +- SubqueryAlias spark_catalog.testviewschm2.tbl1
            +- Relation spark_catalog.testviewschm2.tbl1[a#x,b#x] parquet


-- !query
DESC TABLE EXTENDED pubview
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`pubview`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE   VIEW  mytempview AS SELECT * FROM tbl1 WHERE tbl1.a
BETWEEN (SELECT d FROM tbl2 WHERE c = 1) AND (SELECT e FROM tbl3 WHERE f = 2)
AND EXISTS (SELECT g FROM tbl4 LEFT JOIN tbl3 ON tbl4.h = tbl3.f)
AND NOT EXISTS (SELECT g FROM tbl4 LEFT JOIN tmptbl ON tbl4.h = tmptbl.j)
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`mytempview`, SELECT * FROM tbl1 WHERE tbl1.a
BETWEEN (SELECT d FROM tbl2 WHERE c = 1) AND (SELECT e FROM tbl3 WHERE f = 2)
AND EXISTS (SELECT g FROM tbl4 LEFT JOIN tbl3 ON tbl4.h = tbl3.f)
AND NOT EXISTS (SELECT g FROM tbl4 LEFT JOIN tmptbl ON tbl4.h = tmptbl.j), false, false, PersistedView, COMPENSATION, true
   +- Project [a#x, b#x]
      +- Filter ((between(a#x, scalar-subquery#x [], scalar-subquery#x []) AND exists#x []) AND NOT exists#x [])
         :  :- Project [d#x]
         :  :  +- Filter (c#x = 1)
         :  :     +- SubqueryAlias spark_catalog.testviewschm2.tbl2
         :  :        +- Relation spark_catalog.testviewschm2.tbl2[c#x,d#x] parquet
         :  :- Project [e#x]
         :  :  +- Filter (f#x = 2)
         :  :     +- SubqueryAlias spark_catalog.testviewschm2.tbl3
         :  :        +- Relation spark_catalog.testviewschm2.tbl3[e#x,f#x] parquet
         :  :- Project [g#x]
         :  :  +- Join LeftOuter, (h#x = f#x)
         :  :     :- SubqueryAlias spark_catalog.testviewschm2.tbl4
         :  :     :  +- Relation spark_catalog.testviewschm2.tbl4[g#x,h#x] parquet
         :  :     +- SubqueryAlias spark_catalog.testviewschm2.tbl3
         :  :        +- Relation spark_catalog.testviewschm2.tbl3[e#x,f#x] parquet
         :  +- Project [g#x]
         :     +- Join LeftOuter, (h#x = j#x)
         :        :- SubqueryAlias spark_catalog.testviewschm2.tbl4
         :        :  +- Relation spark_catalog.testviewschm2.tbl4[g#x,h#x] parquet
         :        +- SubqueryAlias spark_catalog.testviewschm2.tmptbl
         :           +- Relation spark_catalog.testviewschm2.tmptbl[i#x,j#x] parquet
         +- SubqueryAlias spark_catalog.testviewschm2.tbl1
            +- Relation spark_catalog.testviewschm2.tbl1[a#x,b#x] parquet


-- !query
DESC TABLE EXTENDED mytempview
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`mytempview`, true, [col_name#x, data_type#x, comment#x]


-- !query
CREATE VIEW tt1 AS
  SELECT * FROM (
    VALUES
       ('abc', '0123456789', 42, 'abcd'),
       ('0123456789', 'abc', 42.12, 'abc')
  ) vv(a,b,c,d)
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`tt1`, SELECT * FROM (
    VALUES
       ('abc', '0123456789', 42, 'abcd'),
       ('0123456789', 'abc', 42.12, 'abc')
  ) vv(a,b,c,d), false, false, PersistedView, COMPENSATION, true
   +- Project [a#x, b#x, c#x, d#x]
      +- SubqueryAlias vv
         +- Project [col1#x AS a#x, col2#x AS b#x, col3#x AS c#x, col4#x AS d#x]
            +- LocalRelation [col1#x, col2#x, col3#x, col4#x]


-- !query
SELECT * FROM tt1
-- !query analysis
Project [a#x, b#x, c#x, d#x]
+- SubqueryAlias spark_catalog.testviewschm2.tt1
   +- View (`spark_catalog`.`testviewschm2`.`tt1`, [a#x, b#x, c#x, d#x])
      +- Project [cast(a#x as string) AS a#x, cast(b#x as string) AS b#x, cast(c#x as decimal(12,2)) AS c#x, cast(d#x as string) AS d#x]
         +- Project [a#x, b#x, c#x, d#x]
            +- SubqueryAlias vv
               +- Project [col1#x AS a#x, col2#x AS b#x, col3#x AS c#x, col4#x AS d#x]
                  +- LocalRelation [col1#x, col2#x, col3#x, col4#x]


-- !query
SELECT string(a) FROM tt1
-- !query analysis
Project [cast(a#x as string) AS a#x]
+- SubqueryAlias spark_catalog.testviewschm2.tt1
   +- View (`spark_catalog`.`testviewschm2`.`tt1`, [a#x, b#x, c#x, d#x])
      +- Project [cast(a#x as string) AS a#x, cast(b#x as string) AS b#x, cast(c#x as decimal(12,2)) AS c#x, cast(d#x as string) AS d#x]
         +- Project [a#x, b#x, c#x, d#x]
            +- SubqueryAlias vv
               +- Project [col1#x AS a#x, col2#x AS b#x, col3#x AS c#x, col4#x AS d#x]
                  +- LocalRelation [col1#x, col2#x, col3#x, col4#x]


-- !query
DROP VIEW tt1
-- !query analysis
DropTableCommand `spark_catalog`.`testviewschm2`.`tt1`, false, true, false


-- !query
CREATE TABLE tt1 (f1 int, f2 int, f3 string) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt1`, false


-- !query
CREATE TABLE tx1 (x1 int, x2 int, x3 string) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tx1`, false


-- !query
CREATE TABLE temp_view_test.tt1 (y1 int, f2 int, f3 string) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`temp_view_test`.`tt1`, false


-- !query
CREATE VIEW aliased_view_1 AS
  select * from tt1
    where exists (select 1 from tx1 where tt1.f1 = tx1.x1)
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`aliased_view_1`, select * from tt1
    where exists (select 1 from tx1 where tt1.f1 = tx1.x1), false, false, PersistedView, COMPENSATION, true
   +- Project [f1#x, f2#x, f3#x]
      +- Filter exists#x [f1#x]
         :  +- Project [1 AS 1#x]
         :     +- Filter (outer(f1#x) = x1#x)
         :        +- SubqueryAlias spark_catalog.testviewschm2.tx1
         :           +- Relation spark_catalog.testviewschm2.tx1[x1#x,x2#x,x3#x] parquet
         +- SubqueryAlias spark_catalog.testviewschm2.tt1
            +- Relation spark_catalog.testviewschm2.tt1[f1#x,f2#x,f3#x] parquet


-- !query
CREATE VIEW aliased_view_2 AS
  select * from tt1 a1
    where exists (select 1 from tx1 where a1.f1 = tx1.x1)
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`aliased_view_2`, select * from tt1 a1
    where exists (select 1 from tx1 where a1.f1 = tx1.x1), false, false, PersistedView, COMPENSATION, true
   +- Project [f1#x, f2#x, f3#x]
      +- Filter exists#x [f1#x]
         :  +- Project [1 AS 1#x]
         :     +- Filter (outer(f1#x) = x1#x)
         :        +- SubqueryAlias spark_catalog.testviewschm2.tx1
         :           +- Relation spark_catalog.testviewschm2.tx1[x1#x,x2#x,x3#x] parquet
         +- SubqueryAlias a1
            +- SubqueryAlias spark_catalog.testviewschm2.tt1
               +- Relation spark_catalog.testviewschm2.tt1[f1#x,f2#x,f3#x] parquet


-- !query
CREATE VIEW aliased_view_3 AS
  select * from tt1
    where exists (select 1 from tx1 a2 where tt1.f1 = a2.x1)
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`aliased_view_3`, select * from tt1
    where exists (select 1 from tx1 a2 where tt1.f1 = a2.x1), false, false, PersistedView, COMPENSATION, true
   +- Project [f1#x, f2#x, f3#x]
      +- Filter exists#x [f1#x]
         :  +- Project [1 AS 1#x]
         :     +- Filter (outer(f1#x) = x1#x)
         :        +- SubqueryAlias a2
         :           +- SubqueryAlias spark_catalog.testviewschm2.tx1
         :              +- Relation spark_catalog.testviewschm2.tx1[x1#x,x2#x,x3#x] parquet
         +- SubqueryAlias spark_catalog.testviewschm2.tt1
            +- Relation spark_catalog.testviewschm2.tt1[f1#x,f2#x,f3#x] parquet


-- !query
CREATE VIEW aliased_view_4 AS
  select * from temp_view_test.tt1
    where exists (select 1 from tt1 where temp_view_test.tt1.y1 = tt1.f1)
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`aliased_view_4`, select * from temp_view_test.tt1
    where exists (select 1 from tt1 where temp_view_test.tt1.y1 = tt1.f1), false, false, PersistedView, COMPENSATION, true
   +- Project [y1#x, f2#x, f3#x]
      +- Filter exists#x [y1#x]
         :  +- Project [1 AS 1#x]
         :     +- Filter (outer(y1#x) = f1#x)
         :        +- SubqueryAlias spark_catalog.testviewschm2.tt1
         :           +- Relation spark_catalog.testviewschm2.tt1[f1#x,f2#x,f3#x] parquet
         +- SubqueryAlias spark_catalog.temp_view_test.tt1
            +- Relation spark_catalog.temp_view_test.tt1[y1#x,f2#x,f3#x] parquet


-- !query
DESC TABLE aliased_view_1
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_1`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE aliased_view_2
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_2`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE aliased_view_3
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_3`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE aliased_view_4
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_4`, false, [col_name#x, data_type#x, comment#x]


-- !query
ALTER TABLE tx1 RENAME TO a1
-- !query analysis
AlterTableRenameCommand `spark_catalog`.`testviewschm2`.`tx1`, `a1`, false


-- !query
DESC TABLE aliased_view_1
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_1`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE aliased_view_2
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_2`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE aliased_view_3
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_3`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE aliased_view_4
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_4`, false, [col_name#x, data_type#x, comment#x]


-- !query
ALTER TABLE tt1 RENAME TO a2
-- !query analysis
AlterTableRenameCommand `spark_catalog`.`testviewschm2`.`tt1`, `a2`, false


-- !query
DESC TABLE aliased_view_1
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_1`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE aliased_view_2
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_2`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE aliased_view_3
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_3`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE aliased_view_4
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_4`, false, [col_name#x, data_type#x, comment#x]


-- !query
ALTER TABLE a1 RENAME TO tt1
-- !query analysis
AlterTableRenameCommand `spark_catalog`.`testviewschm2`.`a1`, `tt1`, false


-- !query
DESC TABLE aliased_view_1
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_1`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE aliased_view_2
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_2`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE aliased_view_3
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_3`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE aliased_view_4
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`aliased_view_4`, false, [col_name#x, data_type#x, comment#x]


-- !query
ALTER TABLE a2 RENAME TO tx1
-- !query analysis
AlterTableRenameCommand `spark_catalog`.`testviewschm2`.`a2`, `tx1`, false


-- !query
create view view_of_joins as
select * from
  (select * from (tbl1 cross join tbl2) same) ss,
  (tbl3 cross join tbl4) same
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`view_of_joins`, select * from
  (select * from (tbl1 cross join tbl2) same) ss,
  (tbl3 cross join tbl4) same, false, false, PersistedView, COMPENSATION, true
   +- Project [a#x, b#x, c#x, d#x, e#x, f#x, g#x, h#x]
      +- Join Inner
         :- SubqueryAlias ss
         :  +- Project [a#x, b#x, c#x, d#x]
         :     +- SubqueryAlias same
         :        +- Join Cross
         :           :- SubqueryAlias spark_catalog.testviewschm2.tbl1
         :           :  +- Relation spark_catalog.testviewschm2.tbl1[a#x,b#x] parquet
         :           +- SubqueryAlias spark_catalog.testviewschm2.tbl2
         :              +- Relation spark_catalog.testviewschm2.tbl2[c#x,d#x] parquet
         +- SubqueryAlias same
            +- Join Cross
               :- SubqueryAlias spark_catalog.testviewschm2.tbl3
               :  +- Relation spark_catalog.testviewschm2.tbl3[e#x,f#x] parquet
               +- SubqueryAlias spark_catalog.testviewschm2.tbl4
                  +- Relation spark_catalog.testviewschm2.tbl4[g#x,h#x] parquet


-- !query
create table tt2 (a int, b int, c int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt2`, false


-- !query
create table tt3 (ax bigint, b short, c decimal) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt3`, false


-- !query
create table tt4 (ay int, b int, q int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt4`, false


-- !query
create view v1 as select * from tt2 natural join tt3
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`v1`, select * from tt2 natural join tt3, false, false, PersistedView, COMPENSATION, true
   +- Project [b#x, c#x, a#x, ax#xL]
      +- Project [b#x, c#x, a#x, ax#xL]
         +- Join Inner, ((b#x = cast(b#x as int)) AND (cast(c#x as decimal(10,0)) = c#x))
            :- SubqueryAlias spark_catalog.testviewschm2.tt2
            :  +- Relation spark_catalog.testviewschm2.tt2[a#x,b#x,c#x] parquet
            +- SubqueryAlias spark_catalog.testviewschm2.tt3
               +- Relation spark_catalog.testviewschm2.tt3[ax#xL,b#x,c#x] parquet


-- !query
create view v1a as select * from (tt2 natural join tt3) j
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`v1a`, select * from (tt2 natural join tt3) j, false, false, PersistedView, COMPENSATION, true
   +- Project [b#x, c#x, a#x, ax#xL]
      +- SubqueryAlias j
         +- Project [b#x, c#x, a#x, ax#xL]
            +- Join Inner, ((b#x = cast(b#x as int)) AND (cast(c#x as decimal(10,0)) = c#x))
               :- SubqueryAlias spark_catalog.testviewschm2.tt2
               :  +- Relation spark_catalog.testviewschm2.tt2[a#x,b#x,c#x] parquet
               +- SubqueryAlias spark_catalog.testviewschm2.tt3
                  +- Relation spark_catalog.testviewschm2.tt3[ax#xL,b#x,c#x] parquet


-- !query
create view v2 as select * from tt2 join tt3 using (b,c) join tt4 using (b)
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`v2`, select * from tt2 join tt3 using (b,c) join tt4 using (b), false, false, PersistedView, COMPENSATION, true
   +- Project [b#x, c#x, a#x, ax#xL, ay#x, q#x]
      +- Project [b#x, c#x, a#x, ax#xL, ay#x, q#x]
         +- Join Inner, (b#x = b#x)
            :- Project [b#x, c#x, a#x, ax#xL]
            :  +- Join Inner, ((b#x = cast(b#x as int)) AND (cast(c#x as decimal(10,0)) = c#x))
            :     :- SubqueryAlias spark_catalog.testviewschm2.tt2
            :     :  +- Relation spark_catalog.testviewschm2.tt2[a#x,b#x,c#x] parquet
            :     +- SubqueryAlias spark_catalog.testviewschm2.tt3
            :        +- Relation spark_catalog.testviewschm2.tt3[ax#xL,b#x,c#x] parquet
            +- SubqueryAlias spark_catalog.testviewschm2.tt4
               +- Relation spark_catalog.testviewschm2.tt4[ay#x,b#x,q#x] parquet


-- !query
create view v2a as select * from (tt2 join tt3 using (b,c) join tt4 using (b)) j
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`v2a`, select * from (tt2 join tt3 using (b,c) join tt4 using (b)) j, false, false, PersistedView, COMPENSATION, true
   +- Project [b#x, c#x, a#x, ax#xL, ay#x, q#x]
      +- SubqueryAlias j
         +- Project [b#x, c#x, a#x, ax#xL, ay#x, q#x]
            +- Join Inner, (b#x = b#x)
               :- Project [b#x, c#x, a#x, ax#xL]
               :  +- Join Inner, ((b#x = cast(b#x as int)) AND (cast(c#x as decimal(10,0)) = c#x))
               :     :- SubqueryAlias spark_catalog.testviewschm2.tt2
               :     :  +- Relation spark_catalog.testviewschm2.tt2[a#x,b#x,c#x] parquet
               :     +- SubqueryAlias spark_catalog.testviewschm2.tt3
               :        +- Relation spark_catalog.testviewschm2.tt3[ax#xL,b#x,c#x] parquet
               +- SubqueryAlias spark_catalog.testviewschm2.tt4
                  +- Relation spark_catalog.testviewschm2.tt4[ay#x,b#x,q#x] parquet


-- !query
create view v3 as select * from tt2 join tt3 using (b,c) full join tt4 using (b)
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`v3`, select * from tt2 join tt3 using (b,c) full join tt4 using (b), false, false, PersistedView, COMPENSATION, true
   +- Project [b#x, c#x, a#x, ax#xL, ay#x, q#x]
      +- Project [coalesce(b#x, b#x) AS b#x, c#x, a#x, ax#xL, ay#x, q#x]
         +- Join FullOuter, (b#x = b#x)
            :- Project [b#x, c#x, a#x, ax#xL]
            :  +- Join Inner, ((b#x = cast(b#x as int)) AND (cast(c#x as decimal(10,0)) = c#x))
            :     :- SubqueryAlias spark_catalog.testviewschm2.tt2
            :     :  +- Relation spark_catalog.testviewschm2.tt2[a#x,b#x,c#x] parquet
            :     +- SubqueryAlias spark_catalog.testviewschm2.tt3
            :        +- Relation spark_catalog.testviewschm2.tt3[ax#xL,b#x,c#x] parquet
            +- SubqueryAlias spark_catalog.testviewschm2.tt4
               +- Relation spark_catalog.testviewschm2.tt4[ay#x,b#x,q#x] parquet


-- !query
DESC TABLE v1
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v1`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v1a
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v1a`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v2
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v2`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v2a
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v2a`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v3
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v3`, false, [col_name#x, data_type#x, comment#x]


-- !query
alter table tt2 add column d int
-- !query analysis
AlterTableAddColumnsCommand `spark_catalog`.`testviewschm2`.`tt2`, [StructField(d,IntegerType,true)]


-- !query
alter table tt2 add column e int
-- !query analysis
AlterTableAddColumnsCommand `spark_catalog`.`testviewschm2`.`tt2`, [StructField(e,IntegerType,true)]


-- !query
DESC TABLE v1
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v1`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v1a
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v1a`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v2
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v2`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v2a
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v2a`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v3
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v3`, false, [col_name#x, data_type#x, comment#x]


-- !query
drop table tt3
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), testviewschm2.tt3


-- !query
create table tt3 (ax bigint, b short, d decimal) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt3`, false


-- !query
alter table tt3 add column c int
-- !query analysis
AlterTableAddColumnsCommand `spark_catalog`.`testviewschm2`.`tt3`, [StructField(c,IntegerType,true)]


-- !query
alter table tt3 add column e int
-- !query analysis
AlterTableAddColumnsCommand `spark_catalog`.`testviewschm2`.`tt3`, [StructField(e,IntegerType,true)]


-- !query
DESC TABLE v1
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v1`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v1a
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v1a`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v2
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v2`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v2a
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v2a`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE v3
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`v3`, false, [col_name#x, data_type#x, comment#x]


-- !query
create table tt5 (a int, b int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt5`, false


-- !query
create table tt6 (c int, d int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt6`, false


-- !query
create view vv1 as select * from (tt5 cross join tt6) j(aa,bb,cc,dd)
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`vv1`, select * from (tt5 cross join tt6) j(aa,bb,cc,dd), false, false, PersistedView, COMPENSATION, true
   +- Project [aa#x, bb#x, cc#x, dd#x]
      +- SubqueryAlias j
         +- Project [a#x AS aa#x, b#x AS bb#x, c#x AS cc#x, d#x AS dd#x]
            +- Join Cross
               :- SubqueryAlias spark_catalog.testviewschm2.tt5
               :  +- Relation spark_catalog.testviewschm2.tt5[a#x,b#x] parquet
               +- SubqueryAlias spark_catalog.testviewschm2.tt6
                  +- Relation spark_catalog.testviewschm2.tt6[c#x,d#x] parquet


-- !query
DESC TABLE vv1
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv1`, false, [col_name#x, data_type#x, comment#x]


-- !query
alter table tt5 add column c int
-- !query analysis
AlterTableAddColumnsCommand `spark_catalog`.`testviewschm2`.`tt5`, [StructField(c,IntegerType,true)]


-- !query
DESC TABLE vv1
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv1`, false, [col_name#x, data_type#x, comment#x]


-- !query
alter table tt5 add column cc int
-- !query analysis
AlterTableAddColumnsCommand `spark_catalog`.`testviewschm2`.`tt5`, [StructField(cc,IntegerType,true)]


-- !query
DESC TABLE vv1
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv1`, false, [col_name#x, data_type#x, comment#x]


-- !query
create table tt7 (x int, /* xx int, */ y int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt7`, false


-- !query
create table tt8 (x int, z int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt8`, false


-- !query
create view vv2 as
select * from (values(1,2,3,4,5)) v(a,b,c,d,e)
union all
select * from tt7 full join tt8 using (x), tt8 tt8x
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`vv2`, select * from (values(1,2,3,4,5)) v(a,b,c,d,e)
union all
select * from tt7 full join tt8 using (x), tt8 tt8x, false, false, PersistedView, COMPENSATION, true
   +- Union false, false
      :- Project [a#x, b#x, c#x, d#x, e#x]
      :  +- SubqueryAlias v
      :     +- Project [col1#x AS a#x, col2#x AS b#x, col3#x AS c#x, col4#x AS d#x, col5#x AS e#x]
      :        +- LocalRelation [col1#x, col2#x, col3#x, col4#x, col5#x]
      +- Project [x#x, y#x, z#x, x#x, z#x]
         +- Join Inner
            :- Project [coalesce(x#x, x#x) AS x#x, y#x, z#x]
            :  +- Join FullOuter, (x#x = x#x)
            :     :- SubqueryAlias spark_catalog.testviewschm2.tt7
            :     :  +- Relation spark_catalog.testviewschm2.tt7[x#x,y#x] parquet
            :     +- SubqueryAlias spark_catalog.testviewschm2.tt8
            :        +- Relation spark_catalog.testviewschm2.tt8[x#x,z#x] parquet
            +- SubqueryAlias tt8x
               +- SubqueryAlias spark_catalog.testviewschm2.tt8
                  +- Relation spark_catalog.testviewschm2.tt8[x#x,z#x] parquet


-- !query
DESC TABLE vv2
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv2`, false, [col_name#x, data_type#x, comment#x]


-- !query
create view vv3 as
select * from (values(1,2,3,4,5,6)) v(a,b,c,x,e,f)
union all
select * from
  tt7 full join tt8 using (x),
  tt7 tt7x full join tt8 tt8x using (x)
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`vv3`, select * from (values(1,2,3,4,5,6)) v(a,b,c,x,e,f)
union all
select * from
  tt7 full join tt8 using (x),
  tt7 tt7x full join tt8 tt8x using (x), false, false, PersistedView, COMPENSATION, true
   +- Union false, false
      :- Project [a#x, b#x, c#x, x#x, e#x, f#x]
      :  +- SubqueryAlias v
      :     +- Project [col1#x AS a#x, col2#x AS b#x, col3#x AS c#x, col4#x AS x#x, col5#x AS e#x, col6#x AS f#x]
      :        +- LocalRelation [col1#x, col2#x, col3#x, col4#x, col5#x, col6#x]
      +- Project [x#x, y#x, z#x, x#x, y#x, z#x]
         +- Project [coalesce(x#x, x#x) AS x#x, y#x, z#x, x#x, y#x, z#x]
            +- Join FullOuter, (x#x = x#x)
               :- Join Inner
               :  :- Project [coalesce(x#x, x#x) AS x#x, y#x, z#x]
               :  :  +- Join FullOuter, (x#x = x#x)
               :  :     :- SubqueryAlias spark_catalog.testviewschm2.tt7
               :  :     :  +- Relation spark_catalog.testviewschm2.tt7[x#x,y#x] parquet
               :  :     +- SubqueryAlias spark_catalog.testviewschm2.tt8
               :  :        +- Relation spark_catalog.testviewschm2.tt8[x#x,z#x] parquet
               :  +- SubqueryAlias tt7x
               :     +- SubqueryAlias spark_catalog.testviewschm2.tt7
               :        +- Relation spark_catalog.testviewschm2.tt7[x#x,y#x] parquet
               +- SubqueryAlias tt8x
                  +- SubqueryAlias spark_catalog.testviewschm2.tt8
                     +- Relation spark_catalog.testviewschm2.tt8[x#x,z#x] parquet


-- !query
DESC TABLE vv3
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv3`, false, [col_name#x, data_type#x, comment#x]


-- !query
create view vv4 as
select * from (values(1,2,3,4,5,6,7)) v(a,b,c,x,e,f,g)
union all
select * from
  tt7 full join tt8 using (x),
  tt7 tt7x full join tt8 tt8x using (x) full join tt8 tt8y using (x)
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`vv4`, select * from (values(1,2,3,4,5,6,7)) v(a,b,c,x,e,f,g)
union all
select * from
  tt7 full join tt8 using (x),
  tt7 tt7x full join tt8 tt8x using (x) full join tt8 tt8y using (x), false, false, PersistedView, COMPENSATION, true
   +- Union false, false
      :- Project [a#x, b#x, c#x, x#x, e#x, f#x, g#x]
      :  +- SubqueryAlias v
      :     +- Project [col1#x AS a#x, col2#x AS b#x, col3#x AS c#x, col4#x AS x#x, col5#x AS e#x, col6#x AS f#x, col7#x AS g#x]
      :        +- LocalRelation [col1#x, col2#x, col3#x, col4#x, col5#x, col6#x, col7#x]
      +- Project [x#x, y#x, z#x, x#x, y#x, z#x, z#x]
         +- Project [coalesce(x#x, x#x) AS x#x, y#x, z#x, x#x, y#x, z#x, z#x]
            +- Join FullOuter, (x#x = x#x)
               :- Project [coalesce(x#x, x#x) AS x#x, y#x, z#x, x#x, y#x, z#x]
               :  +- Join FullOuter, (x#x = x#x)
               :     :- Join Inner
               :     :  :- Project [coalesce(x#x, x#x) AS x#x, y#x, z#x]
               :     :  :  +- Join FullOuter, (x#x = x#x)
               :     :  :     :- SubqueryAlias spark_catalog.testviewschm2.tt7
               :     :  :     :  +- Relation spark_catalog.testviewschm2.tt7[x#x,y#x] parquet
               :     :  :     +- SubqueryAlias spark_catalog.testviewschm2.tt8
               :     :  :        +- Relation spark_catalog.testviewschm2.tt8[x#x,z#x] parquet
               :     :  +- SubqueryAlias tt7x
               :     :     +- SubqueryAlias spark_catalog.testviewschm2.tt7
               :     :        +- Relation spark_catalog.testviewschm2.tt7[x#x,y#x] parquet
               :     +- SubqueryAlias tt8x
               :        +- SubqueryAlias spark_catalog.testviewschm2.tt8
               :           +- Relation spark_catalog.testviewschm2.tt8[x#x,z#x] parquet
               +- SubqueryAlias tt8y
                  +- SubqueryAlias spark_catalog.testviewschm2.tt8
                     +- Relation spark_catalog.testviewschm2.tt8[x#x,z#x] parquet


-- !query
DESC TABLE vv4
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv4`, false, [col_name#x, data_type#x, comment#x]


-- !query
alter table tt7 add column zz int
-- !query analysis
AlterTableAddColumnsCommand `spark_catalog`.`testviewschm2`.`tt7`, [StructField(zz,IntegerType,true)]


-- !query
alter table tt7 add column z int
-- !query analysis
AlterTableAddColumnsCommand `spark_catalog`.`testviewschm2`.`tt7`, [StructField(z,IntegerType,true)]


-- !query
alter table tt8 add column z2 int
-- !query analysis
AlterTableAddColumnsCommand `spark_catalog`.`testviewschm2`.`tt8`, [StructField(z2,IntegerType,true)]


-- !query
DESC TABLE vv2
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv2`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE vv3
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv3`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE vv4
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv4`, false, [col_name#x, data_type#x, comment#x]


-- !query
create table tt7a (x date, /* xx int, */ y int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt7a`, false


-- !query
create table tt8a (x timestamp, z int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt8a`, false


-- !query
create view vv2a as
select * from (values(now(),2,3,now(),5)) v(a,b,c,d,e)
union all
select * from tt7a left join tt8a using (x), tt8a tt8ax
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`vv2a`, select * from (values(now(),2,3,now(),5)) v(a,b,c,d,e)
union all
select * from tt7a left join tt8a using (x), tt8a tt8ax, false, false, PersistedView, COMPENSATION, true
   +- Union false, false
      :- Project [a#x, b#x, c#x, d#x, e#x]
      :  +- SubqueryAlias v
      :     +- Project [col1#x AS a#x, col2#x AS b#x, col3#x AS c#x, col4#x AS d#x, col5#x AS e#x]
      :        +- ResolvedInlineTable [[now(), 2, 3, now(), 5]], [col1#x, col2#x, col3#x, col4#x, col5#x]
      +- Project [cast(x#x as timestamp) AS x#x, y#x, z#x, x#x, z#x]
         +- Project [x#x, y#x, z#x, x#x, z#x]
            +- Join Inner
               :- Project [x#x, y#x, z#x]
               :  +- Join LeftOuter, (cast(x#x as timestamp) = x#x)
               :     :- SubqueryAlias spark_catalog.testviewschm2.tt7a
               :     :  +- Relation spark_catalog.testviewschm2.tt7a[x#x,y#x] parquet
               :     +- SubqueryAlias spark_catalog.testviewschm2.tt8a
               :        +- Relation spark_catalog.testviewschm2.tt8a[x#x,z#x] parquet
               +- SubqueryAlias tt8ax
                  +- SubqueryAlias spark_catalog.testviewschm2.tt8a
                     +- Relation spark_catalog.testviewschm2.tt8a[x#x,z#x] parquet


-- !query
DESC TABLE vv4
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv4`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE vv2a
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv2a`, false, [col_name#x, data_type#x, comment#x]


-- !query
create table tt9 (x int, xx int, y int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt9`, false


-- !query
create table tt10 (x int, z int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt10`, false


-- !query
create view vv5 as select x,y,z from tt9 join tt10 using(x)
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`vv5`, select x,y,z from tt9 join tt10 using(x), false, false, PersistedView, COMPENSATION, true
   +- Project [x#x, y#x, z#x]
      +- Project [x#x, xx#x, y#x, z#x]
         +- Join Inner, (x#x = x#x)
            :- SubqueryAlias spark_catalog.testviewschm2.tt9
            :  +- Relation spark_catalog.testviewschm2.tt9[x#x,xx#x,y#x] parquet
            +- SubqueryAlias spark_catalog.testviewschm2.tt10
               +- Relation spark_catalog.testviewschm2.tt10[x#x,z#x] parquet


-- !query
DESC TABLE vv5
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv5`, false, [col_name#x, data_type#x, comment#x]


-- !query
DESC TABLE vv5
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv5`, false, [col_name#x, data_type#x, comment#x]


-- !query
create table tt11 (x int, y int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt11`, false


-- !query
create table tt12 (x int, z int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt12`, false


-- !query
create table tt13 (z int, q int) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`tt13`, false


-- !query
create view vv6 as select x,y,z,q from
  (tt11 join tt12 using(x)) join tt13 using(z)
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`vv6`, select x,y,z,q from
  (tt11 join tt12 using(x)) join tt13 using(z), false, false, PersistedView, COMPENSATION, true
   +- Project [x#x, y#x, z#x, q#x]
      +- Project [z#x, x#x, y#x, q#x]
         +- Join Inner, (z#x = z#x)
            :- Project [x#x, y#x, z#x]
            :  +- Join Inner, (x#x = x#x)
            :     :- SubqueryAlias spark_catalog.testviewschm2.tt11
            :     :  +- Relation spark_catalog.testviewschm2.tt11[x#x,y#x] parquet
            :     +- SubqueryAlias spark_catalog.testviewschm2.tt12
            :        +- Relation spark_catalog.testviewschm2.tt12[x#x,z#x] parquet
            +- SubqueryAlias spark_catalog.testviewschm2.tt13
               +- Relation spark_catalog.testviewschm2.tt13[z#x,q#x] parquet


-- !query
DESC TABLE vv6
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv6`, false, [col_name#x, data_type#x, comment#x]


-- !query
alter table tt11 add column z int
-- !query analysis
AlterTableAddColumnsCommand `spark_catalog`.`testviewschm2`.`tt11`, [StructField(z,IntegerType,true)]


-- !query
DESC TABLE vv6
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`vv6`, false, [col_name#x, data_type#x, comment#x]


-- !query
CREATE TABLE int8_tbl (q1 int, q2 int) USING parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`testviewschm2`.`int8_tbl`, false


-- !query
create view tt18v as
  select * from int8_tbl xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxy
  union all
  select * from int8_tbl xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxz
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`tt18v`, select * from int8_tbl xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxy
  union all
  select * from int8_tbl xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxz, false, false, PersistedView, COMPENSATION, true
   +- Union false, false
      :- Project [q1#x, q2#x]
      :  +- SubqueryAlias xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxy
      :     +- SubqueryAlias spark_catalog.testviewschm2.int8_tbl
      :        +- Relation spark_catalog.testviewschm2.int8_tbl[q1#x,q2#x] parquet
      +- Project [q1#x, q2#x]
         +- SubqueryAlias xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxz
            +- SubqueryAlias spark_catalog.testviewschm2.int8_tbl
               +- Relation spark_catalog.testviewschm2.int8_tbl[q1#x,q2#x] parquet


-- !query
DESC TABLE tt18v
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`tt18v`, false, [col_name#x, data_type#x, comment#x]


-- !query
create view tt21v as
select * from tt5 natural inner join tt6
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`tt21v`, select * from tt5 natural inner join tt6, false, false, PersistedView, COMPENSATION, true
   +- Project [c#x, a#x, b#x, cc#x, d#x]
      +- Project [c#x, a#x, b#x, cc#x, d#x]
         +- Join Inner, (c#x = c#x)
            :- SubqueryAlias spark_catalog.testviewschm2.tt5
            :  +- Relation spark_catalog.testviewschm2.tt5[a#x,b#x,c#x,cc#x] parquet
            +- SubqueryAlias spark_catalog.testviewschm2.tt6
               +- Relation spark_catalog.testviewschm2.tt6[c#x,d#x] parquet


-- !query
DESC TABLE tt21v
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`tt21v`, false, [col_name#x, data_type#x, comment#x]


-- !query
create view tt22v as
select * from tt5 natural left join tt6
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`tt22v`, select * from tt5 natural left join tt6, false, false, PersistedView, COMPENSATION, true
   +- Project [c#x, a#x, b#x, cc#x, d#x]
      +- Project [c#x, a#x, b#x, cc#x, d#x]
         +- Join LeftOuter, (c#x = c#x)
            :- SubqueryAlias spark_catalog.testviewschm2.tt5
            :  +- Relation spark_catalog.testviewschm2.tt5[a#x,b#x,c#x,cc#x] parquet
            +- SubqueryAlias spark_catalog.testviewschm2.tt6
               +- Relation spark_catalog.testviewschm2.tt6[c#x,d#x] parquet


-- !query
DESC TABLE tt22v
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`tt22v`, false, [col_name#x, data_type#x, comment#x]


-- !query
create view tt23v (col_a, col_b) as
select q1 as other_name1, q2 as other_name2 from int8_tbl
union
select 42, 43
-- !query analysis
CreateViewCommand `spark_catalog`.`testviewschm2`.`tt23v`, [(col_a,None), (col_b,None)], select q1 as other_name1, q2 as other_name2 from int8_tbl
union
select 42, 43, false, false, PersistedView, COMPENSATION, true
   +- Distinct
      +- Union false, false
         :- Project [q1#x AS other_name1#x, q2#x AS other_name2#x]
         :  +- SubqueryAlias spark_catalog.testviewschm2.int8_tbl
         :     +- Relation spark_catalog.testviewschm2.int8_tbl[q1#x,q2#x] parquet
         +- Project [42 AS 42#x, 43 AS 43#x]
            +- OneRowRelation


-- !query
DESC TABLE tt23v
-- !query analysis
DescribeTableCommand `spark_catalog`.`testviewschm2`.`tt23v`, false, [col_name#x, data_type#x, comment#x]


-- !query
DROP SCHEMA temp_view_test CASCADE
-- !query analysis
DropNamespace false, true
+- ResolvedNamespace V2SessionCatalog(spark_catalog), [temp_view_test]


-- !query
DROP SCHEMA testviewschm2 CASCADE
-- !query analysis
DropNamespace false, true
+- ResolvedNamespace V2SessionCatalog(spark_catalog), [testviewschm2]


-- !query
DROP VIEW temp_table
-- !query analysis
DropTempViewCommand temp_table


-- !query
DROP VIEW tt
-- !query analysis
DropTempViewCommand tt
