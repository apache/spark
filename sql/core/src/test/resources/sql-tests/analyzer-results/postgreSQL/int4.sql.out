-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TABLE INT4_TBL(f1 int) USING parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`INT4_TBL`, false


-- !query
INSERT INTO INT4_TBL VALUES (int(trim('   0  ')))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/int4_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/int4_tbl], Append, `spark_catalog`.`default`.`int4_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/int4_tbl), [f1]
+- Project [cast(col1#x as int) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO INT4_TBL VALUES (int(trim('123456     ')))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/int4_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/int4_tbl], Append, `spark_catalog`.`default`.`int4_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/int4_tbl), [f1]
+- Project [cast(col1#x as int) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO INT4_TBL VALUES (int(trim('    -123456')))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/int4_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/int4_tbl], Append, `spark_catalog`.`default`.`int4_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/int4_tbl), [f1]
+- Project [cast(col1#x as int) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO INT4_TBL VALUES (int('2147483647'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/int4_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/int4_tbl], Append, `spark_catalog`.`default`.`int4_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/int4_tbl), [f1]
+- Project [cast(col1#x as int) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO INT4_TBL VALUES (int('-2147483647'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/int4_tbl, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/int4_tbl], Append, `spark_catalog`.`default`.`int4_tbl`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/int4_tbl), [f1]
+- Project [cast(col1#x as int) AS f1#x]
   +- LocalRelation [col1#x]


-- !query
SELECT '' AS five, * FROM INT4_TBL
-- !query analysis
Project [ AS five#x, f1#x]
+- SubqueryAlias spark_catalog.default.int4_tbl
   +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS four, i.* FROM INT4_TBL i WHERE i.f1 <> smallint('0')
-- !query analysis
Project [ AS four#x, f1#x]
+- Filter NOT (f1#x = cast(cast(0 as smallint) as int))
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS four, i.* FROM INT4_TBL i WHERE i.f1 <> int('0')
-- !query analysis
Project [ AS four#x, f1#x]
+- Filter NOT (f1#x = cast(0 as int))
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS one, i.* FROM INT4_TBL i WHERE i.f1 = smallint('0')
-- !query analysis
Project [ AS one#x, f1#x]
+- Filter (f1#x = cast(cast(0 as smallint) as int))
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS one, i.* FROM INT4_TBL i WHERE i.f1 = int('0')
-- !query analysis
Project [ AS one#x, f1#x]
+- Filter (f1#x = cast(0 as int))
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS two, i.* FROM INT4_TBL i WHERE i.f1 < smallint('0')
-- !query analysis
Project [ AS two#x, f1#x]
+- Filter (f1#x < cast(cast(0 as smallint) as int))
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS two, i.* FROM INT4_TBL i WHERE i.f1 < int('0')
-- !query analysis
Project [ AS two#x, f1#x]
+- Filter (f1#x < cast(0 as int))
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS three, i.* FROM INT4_TBL i WHERE i.f1 <= smallint('0')
-- !query analysis
Project [ AS three#x, f1#x]
+- Filter (f1#x <= cast(cast(0 as smallint) as int))
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS three, i.* FROM INT4_TBL i WHERE i.f1 <= int('0')
-- !query analysis
Project [ AS three#x, f1#x]
+- Filter (f1#x <= cast(0 as int))
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS two, i.* FROM INT4_TBL i WHERE i.f1 > smallint('0')
-- !query analysis
Project [ AS two#x, f1#x]
+- Filter (f1#x > cast(cast(0 as smallint) as int))
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS two, i.* FROM INT4_TBL i WHERE i.f1 > int('0')
-- !query analysis
Project [ AS two#x, f1#x]
+- Filter (f1#x > cast(0 as int))
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS three, i.* FROM INT4_TBL i WHERE i.f1 >= smallint('0')
-- !query analysis
Project [ AS three#x, f1#x]
+- Filter (f1#x >= cast(cast(0 as smallint) as int))
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS three, i.* FROM INT4_TBL i WHERE i.f1 >= int('0')
-- !query analysis
Project [ AS three#x, f1#x]
+- Filter (f1#x >= cast(0 as int))
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS one, i.* FROM INT4_TBL i WHERE (i.f1 % smallint('2')) = smallint('1')
-- !query analysis
Project [ AS one#x, f1#x]
+- Filter ((f1#x % cast(cast(2 as smallint) as int)) = cast(cast(1 as smallint) as int))
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS three, i.* FROM INT4_TBL i WHERE (i.f1 % int('2')) = smallint('0')
-- !query analysis
Project [ AS three#x, f1#x]
+- Filter ((f1#x % cast(2 as int)) = cast(cast(0 as smallint) as int))
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS five, i.f1, i.f1 * smallint('2') AS x FROM INT4_TBL i
-- !query analysis
Project [ AS five#x, f1#x, (f1#x * cast(cast(2 as smallint) as int)) AS x#x]
+- SubqueryAlias i
   +- SubqueryAlias spark_catalog.default.int4_tbl
      +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS five, i.f1, i.f1 * smallint('2') AS x FROM INT4_TBL i
WHERE abs(f1) < 1073741824
-- !query analysis
Project [ AS five#x, f1#x, (f1#x * cast(cast(2 as smallint) as int)) AS x#x]
+- Filter (abs(f1#x) < 1073741824)
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS five, i.f1, i.f1 * int('2') AS x FROM INT4_TBL i
-- !query analysis
Project [ AS five#x, f1#x, (f1#x * cast(2 as int)) AS x#x]
+- SubqueryAlias i
   +- SubqueryAlias spark_catalog.default.int4_tbl
      +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS five, i.f1, i.f1 * int('2') AS x FROM INT4_TBL i
WHERE abs(f1) < 1073741824
-- !query analysis
Project [ AS five#x, f1#x, (f1#x * cast(2 as int)) AS x#x]
+- Filter (abs(f1#x) < 1073741824)
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS five, i.f1, i.f1 + smallint('2') AS x FROM INT4_TBL i
-- !query analysis
Project [ AS five#x, f1#x, (f1#x + cast(cast(2 as smallint) as int)) AS x#x]
+- SubqueryAlias i
   +- SubqueryAlias spark_catalog.default.int4_tbl
      +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS five, i.f1, i.f1 + smallint('2') AS x FROM INT4_TBL i
WHERE f1 < 2147483646
-- !query analysis
Project [ AS five#x, f1#x, (f1#x + cast(cast(2 as smallint) as int)) AS x#x]
+- Filter (f1#x < 2147483646)
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS five, i.f1, i.f1 + int('2') AS x FROM INT4_TBL i
-- !query analysis
Project [ AS five#x, f1#x, (f1#x + cast(2 as int)) AS x#x]
+- SubqueryAlias i
   +- SubqueryAlias spark_catalog.default.int4_tbl
      +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS five, i.f1, i.f1 + int('2') AS x FROM INT4_TBL i
WHERE f1 < 2147483646
-- !query analysis
Project [ AS five#x, f1#x, (f1#x + cast(2 as int)) AS x#x]
+- Filter (f1#x < 2147483646)
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS five, i.f1, i.f1 - smallint('2') AS x FROM INT4_TBL i
-- !query analysis
Project [ AS five#x, f1#x, (f1#x - cast(cast(2 as smallint) as int)) AS x#x]
+- SubqueryAlias i
   +- SubqueryAlias spark_catalog.default.int4_tbl
      +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS five, i.f1, i.f1 - smallint('2') AS x FROM INT4_TBL i
WHERE f1 > -2147483647
-- !query analysis
Project [ AS five#x, f1#x, (f1#x - cast(cast(2 as smallint) as int)) AS x#x]
+- Filter (f1#x > -2147483647)
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS five, i.f1, i.f1 - int('2') AS x FROM INT4_TBL i
-- !query analysis
Project [ AS five#x, f1#x, (f1#x - cast(2 as int)) AS x#x]
+- SubqueryAlias i
   +- SubqueryAlias spark_catalog.default.int4_tbl
      +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS five, i.f1, i.f1 - int('2') AS x FROM INT4_TBL i
WHERE f1 > -2147483647
-- !query analysis
Project [ AS five#x, f1#x, (f1#x - cast(2 as int)) AS x#x]
+- Filter (f1#x > -2147483647)
   +- SubqueryAlias i
      +- SubqueryAlias spark_catalog.default.int4_tbl
         +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS five, i.f1, i.f1 / smallint('2') AS x FROM INT4_TBL i
-- !query analysis
Project [ AS five#x, f1#x, (cast(f1#x as double) / cast(cast(2 as smallint) as double)) AS x#x]
+- SubqueryAlias i
   +- SubqueryAlias spark_catalog.default.int4_tbl
      +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT '' AS five, i.f1, i.f1 / int('2') AS x FROM INT4_TBL i
-- !query analysis
Project [ AS five#x, f1#x, (cast(f1#x as double) / cast(cast(2 as int) as double)) AS x#x]
+- SubqueryAlias i
   +- SubqueryAlias spark_catalog.default.int4_tbl
      +- Relation spark_catalog.default.int4_tbl[f1#x] parquet


-- !query
SELECT -2+3 AS one
-- !query analysis
Project [(-2 + 3) AS one#x]
+- OneRowRelation


-- !query
SELECT 4-2 AS two
-- !query analysis
Project [(4 - 2) AS two#x]
+- OneRowRelation


-- !query
SELECT 2- -1 AS three
-- !query analysis
Project [(2 - -1) AS three#x]
+- OneRowRelation


-- !query
SELECT 2 - -2 AS four
-- !query analysis
Project [(2 - -2) AS four#x]
+- OneRowRelation


-- !query
SELECT smallint('2') * smallint('2') = smallint('16') / smallint('4') AS true
-- !query analysis
Project [(cast((cast(2 as smallint) * cast(2 as smallint)) as double) = (cast(cast(16 as smallint) as double) / cast(cast(4 as smallint) as double))) AS true#x]
+- OneRowRelation


-- !query
SELECT int('2') * smallint('2') = smallint('16') / int('4') AS true
-- !query analysis
Project [(cast((cast(2 as int) * cast(cast(2 as smallint) as int)) as double) = (cast(cast(16 as smallint) as double) / cast(cast(4 as int) as double))) AS true#x]
+- OneRowRelation


-- !query
SELECT smallint('2') * int('2') = int('16') / smallint('4') AS true
-- !query analysis
Project [(cast((cast(cast(2 as smallint) as int) * cast(2 as int)) as double) = (cast(cast(16 as int) as double) / cast(cast(4 as smallint) as double))) AS true#x]
+- OneRowRelation


-- !query
SELECT int('1000') < int('999') AS `false`
-- !query analysis
Project [(cast(1000 as int) < cast(999 as int)) AS false#x]
+- OneRowRelation


-- !query
SELECT 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 AS ten
-- !query analysis
Project [(((((((((1 + 1) + 1) + 1) + 1) + 1) + 1) + 1) + 1) + 1) AS ten#x]
+- OneRowRelation


-- !query
SELECT 2 + 2 / 2 AS three
-- !query analysis
Project [(cast(2 as double) + (cast(2 as double) / cast(2 as double))) AS three#x]
+- OneRowRelation


-- !query
SELECT (2 + 2) / 2 AS two
-- !query analysis
Project [(cast((2 + 2) as double) / cast(2 as double)) AS two#x]
+- OneRowRelation


-- !query
SELECT string(shiftleft(int(-1), 31))
-- !query analysis
Project [cast(shiftleft(cast(-1 as int), 31) as string) AS shiftleft(-1, 31)#x]
+- OneRowRelation


-- !query
SELECT string(int(shiftleft(int(-1), 31))+1)
-- !query analysis
Project [cast((cast(shiftleft(cast(-1 as int), 31) as int) + 1) as string) AS (shiftleft(-1, 31) + 1)#x]
+- OneRowRelation


-- !query
SELECT int(-2147483648) % int(-1)
-- !query analysis
Project [(cast(-2147483648 as int) % cast(-1 as int)) AS (-2147483648 % -1)#x]
+- OneRowRelation


-- !query
SELECT int(-2147483648) % smallint(-1)
-- !query analysis
Project [(cast(-2147483648 as int) % cast(cast(-1 as smallint) as int)) AS (-2147483648 % -1)#x]
+- OneRowRelation


-- !query
SELECT x, int(x) AS int4_value
FROM (VALUES double(-2.5),
             double(-1.5),
             double(-0.5),
             double(0.0),
             double(0.5),
             double(1.5),
             double(2.5)) t(x)
-- !query analysis
Project [x#x, cast(x#x as int) AS int4_value#x]
+- SubqueryAlias t
   +- Project [col1#x AS x#x]
      +- LocalRelation [col1#x]


-- !query
SELECT x, int(x) AS int4_value
FROM (VALUES cast(-2.5 as decimal(38, 18)),
             cast(-1.5 as decimal(38, 18)),
             cast(-0.5 as decimal(38, 18)),
             cast(-0.0 as decimal(38, 18)),
             cast(0.5 as decimal(38, 18)),
             cast(1.5 as decimal(38, 18)),
             cast(2.5 as decimal(38, 18))) t(x)
-- !query analysis
Project [x#x, cast(x#x as int) AS int4_value#x]
+- SubqueryAlias t
   +- Project [col1#x AS x#x]
      +- LocalRelation [col1#x]


-- !query
DROP TABLE INT4_TBL
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.INT4_TBL
