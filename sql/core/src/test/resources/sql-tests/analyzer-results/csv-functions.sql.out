-- Automatically generated by SQLQueryTestSuite
-- !query
select from_csv('1, 3.14', 'a INT, f FLOAT')
-- !query analysis
Project [from_csv(StructField(a,IntegerType,true), StructField(f,FloatType,true), 1, 3.14, Some(America/Los_Angeles), None) AS from_csv(1, 3.14)#x]
+- OneRowRelation


-- !query
select from_csv('26/08/2015', 'time Timestamp', map('timestampFormat', 'dd/MM/yyyy'))
-- !query analysis
Project [from_csv(StructField(time,TimestampType,true), (timestampFormat,dd/MM/yyyy), 26/08/2015, Some(America/Los_Angeles), None) AS from_csv(26/08/2015)#x]
+- OneRowRelation


-- !query
select from_csv('1', 1)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INVALID_SCHEMA.NON_STRING_LITERAL",
  "sqlState" : "42K07",
  "messageParameters" : {
    "inputSchema" : "\"1\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 23,
    "fragment" : "from_csv('1', 1)"
  } ]
}


-- !query
select from_csv('1', 'a InvalidType')
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'InvalidType'",
    "hint" : ": extra input 'InvalidType'"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 37,
    "fragment" : "from_csv('1', 'a InvalidType')"
  } ]
}


-- !query
select from_csv('1', 'Array<int>')
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INVALID_SCHEMA.NON_STRUCT_TYPE",
  "sqlState" : "42K07",
  "messageParameters" : {
    "dataType" : "\"ARRAY<INT>\"",
    "inputSchema" : "\"Array<int>\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 34,
    "fragment" : "from_csv('1', 'Array<int>')"
  } ]
}


-- !query
select from_csv('1', 'a INT', named_struct('mode', 'PERMISSIVE'))
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INVALID_OPTIONS.NON_MAP_FUNCTION",
  "sqlState" : "42K06",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 65,
    "fragment" : "from_csv('1', 'a INT', named_struct('mode', 'PERMISSIVE'))"
  } ]
}


-- !query
select from_csv('1', 'a INT', map('mode', 1))
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INVALID_OPTIONS.NON_STRING_TYPE",
  "sqlState" : "42K06",
  "messageParameters" : {
    "mapType" : "\"MAP<STRING, INT>\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 45,
    "fragment" : "from_csv('1', 'a INT', map('mode', 1))"
  } ]
}


-- !query
select from_csv()
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "WRONG_NUM_ARGS.WITHOUT_SUGGESTION",
  "sqlState" : "42605",
  "messageParameters" : {
    "actualNum" : "0",
    "docroot" : "https://spark.apache.org/docs/latest",
    "expectedNum" : "[2, 3]",
    "functionName" : "`from_csv`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 17,
    "fragment" : "from_csv()"
  } ]
}


-- !query
select from_csv('1,abc', schema_of_csv('1,abc'))
-- !query analysis
Project [from_csv(StructField(_c0,IntegerType,true), StructField(_c1,StringType,true), 1,abc, Some(America/Los_Angeles), None) AS from_csv(1,abc)#x]
+- OneRowRelation


-- !query
select schema_of_csv('1|abc', map('delimiter', '|'))
-- !query analysis
Project [schema_of_csv(1|abc, (delimiter,|)) AS schema_of_csv(1|abc)#x]
+- OneRowRelation


-- !query
select schema_of_csv(null)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "DATATYPE_MISMATCH.UNEXPECTED_NULL",
  "sqlState" : "42K09",
  "messageParameters" : {
    "exprName" : "csv",
    "sqlExpr" : "\"schema_of_csv(NULL)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 26,
    "fragment" : "schema_of_csv(null)"
  } ]
}


-- !query
CREATE TEMPORARY VIEW csvTable(csvField, a) AS SELECT * FROM VALUES ('1,abc', 'a')
-- !query analysis
CreateViewCommand `csvTable`, [(csvField,None), (a,None)], SELECT * FROM VALUES ('1,abc', 'a'), false, false, LocalTempView, UNSUPPORTED, true
   +- Project [col1#x, col2#x]
      +- LocalRelation [col1#x, col2#x]


-- !query
SELECT schema_of_csv(csvField) FROM csvTable
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "DATATYPE_MISMATCH.NON_FOLDABLE_INPUT",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputExpr" : "\"csvField\"",
    "inputName" : "`csv`",
    "inputType" : "\"STRING\"",
    "sqlExpr" : "\"schema_of_csv(csvField)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "schema_of_csv(csvField)"
  } ]
}


-- !query
DROP VIEW IF EXISTS csvTable
-- !query analysis
DropTempViewCommand csvTable


-- !query
select to_csv(named_struct('a', 1, 'b', 2))
-- !query analysis
Project [to_csv(named_struct(a, 1, b, 2), Some(America/Los_Angeles)) AS to_csv(named_struct(a, 1, b, 2))#x]
+- OneRowRelation


-- !query
select to_csv(named_struct('time', to_timestamp('2015-08-26', 'yyyy-MM-dd')), map('timestampFormat', 'dd/MM/yyyy'))
-- !query analysis
Project [to_csv((timestampFormat,dd/MM/yyyy), named_struct(time, to_timestamp(2015-08-26, Some(yyyy-MM-dd), TimestampType, Some(America/Los_Angeles), false)), Some(America/Los_Angeles)) AS to_csv(named_struct(time, to_timestamp(2015-08-26, yyyy-MM-dd)))#x]
+- OneRowRelation


-- !query
select to_csv(named_struct('a', 1, 'b', 2), named_struct('mode', 'PERMISSIVE'))
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INVALID_OPTIONS.NON_MAP_FUNCTION",
  "sqlState" : "42K06",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 79,
    "fragment" : "to_csv(named_struct('a', 1, 'b', 2), named_struct('mode', 'PERMISSIVE'))"
  } ]
}


-- !query
select to_csv(named_struct('a', 1, 'b', 2), map('mode', 1))
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "INVALID_OPTIONS.NON_STRING_TYPE",
  "sqlState" : "42K06",
  "messageParameters" : {
    "mapType" : "\"MAP<STRING, INT>\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 59,
    "fragment" : "to_csv(named_struct('a', 1, 'b', 2), map('mode', 1))"
  } ]
}
