-- Automatically generated by SQLQueryTestSuite
-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, true, true, false


-- !query
CREATE VIEW v DEFAULT COLLATION UNICODE AS SELECT 'a'
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, UNICODE, SELECT 'a', false, false, PersistedView, COMPENSATION, true
   +- Project [a AS 'a' collate UNICODE#x]
      +- OneRowRelation


-- !query
SELECT * FROM v
-- !query analysis
Project ['a' collate UNICODE#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, ['a' collate UNICODE#x])
      +- Project [cast('a' collate UNICODE#x as string collate UNICODE) AS 'a' collate UNICODE#x]
         +- Project [a AS 'a' collate UNICODE#x]
            +- OneRowRelation


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, true, true, false


-- !query
CREATE VIEW v DEFAULT COLLATION UTF8_LCASE AS SELECT 'a' AS c1
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, UTF8_LCASE, SELECT 'a' AS c1, false, false, PersistedView, COMPENSATION, true
   +- Project [a AS c1#x]
      +- OneRowRelation


-- !query
SELECT COUNT(*) FROM v WHERE c1 = 'A'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c1#x = A)
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x])
         +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x]
            +- Project [a AS c1#x]
               +- OneRowRelation


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, true, true, false


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t (c1 STRING COLLATE UTF8_LCASE)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('a'), ('A')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1]
+- Project [cast(col1#x as string collate UTF8_LCASE) AS c1#x]
   +- LocalRelation [col1#x]


-- !query
CREATE VIEW v DEFAULT COLLATION SR_AI_CI AS SELECT c1 FROM t WHERE 'ć' = 'č'
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, sr_CI_AI, SELECT c1 FROM t WHERE 'ć' = 'č', false, false, PersistedView, COMPENSATION, true
   +- Project [c1#x]
      +- Filter (ć = č)
         +- SubqueryAlias spark_catalog.default.t
            +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT COUNT(*) FROM v
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x])
      +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x]
         +- Project [c1#x]
            +- Filter (ć = č)
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT COUNT(*) FROM v WHERE c1 = 'A'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c1#x = A)
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x])
         +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x]
            +- Project [c1#x]
               +- Filter (ć = č)
                  +- SubqueryAlias spark_catalog.default.t
                     +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, true, true, false


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t (c1 STRING COLLATE UTF8_LCASE)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('ć'), ('č')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1]
+- Project [cast(col1#x as string collate UTF8_LCASE) AS c1#x]
   +- LocalRelation [col1#x]


-- !query
CREATE VIEW v DEFAULT COLLATION UNICODE AS SELECT CAST(c1 AS STRING COLLATE SR_AI) FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, UNICODE, SELECT CAST(c1 AS STRING COLLATE SR_AI) FROM t, false, false, PersistedView, COMPENSATION, true
   +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT DISTINCT COLLATION(c1) FROM v
-- !query analysis
Distinct
+- Project [collation(c1#x) AS collation(c1)#x]
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x])
         +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
            +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT COUNT(*) FROM v WHERE c1 = 'c'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c1#x = c)
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x])
         +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
            +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, true, true, false


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t (c1 STRING COLLATE UTF8_LCASE)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('ć'), ('č')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1]
+- Project [cast(col1#x as string collate UTF8_LCASE) AS c1#x]
   +- LocalRelation [col1#x]


-- !query
CREATE VIEW v DEFAULT COLLATION UNICODE AS SELECT CAST(c1 AS STRING COLLATE SR_AI) FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, UNICODE, SELECT CAST(c1 AS STRING COLLATE SR_AI) FROM t, false, false, PersistedView, COMPENSATION, true
   +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT DISTINCT COLLATION(c1) FROM v
-- !query analysis
Distinct
+- Project [collation(c1#x) AS collation(c1)#x]
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x])
         +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
            +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT COUNT(*) FROM v WHERE c1 = 'c'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c1#x = c)
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x])
         +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
            +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, true, true, false


-- !query
CREATE VIEW v DEFAULT COLLATION UTF8_LCASE
AS SELECT 'a' AS c1, (SELECT (SELECT CASE 'a' = 'A' WHEN TRUE THEN 'a' ELSE 'b' END) WHERE (SELECT 'b' WHERE 'c' = 'C') = 'B') AS c2, 'c'
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, UTF8_LCASE, SELECT 'a' AS c1, (SELECT (SELECT CASE 'a' = 'A' WHEN TRUE THEN 'a' ELSE 'b' END) WHERE (SELECT 'b' WHERE 'c' = 'C') = 'B') AS c2, 'c', false, false, PersistedView, COMPENSATION, true
   +- Project [a AS c1#x, scalar-subquery#x [] AS c2#x, c AS 'c' collate UTF8_LCASE#x]
      :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
      :     :  +- Project [CASE WHEN ((a = A) = true) THEN a ELSE b END AS CASE WHEN (('a' collate UTF8_LCASE = 'A' collate UTF8_LCASE) = true) THEN 'a' collate UTF8_LCASE ELSE 'b' collate UTF8_LCASE END#x]
      :     :     +- OneRowRelation
      :     +- Filter (scalar-subquery#x [] = B)
      :        :  +- Project [b AS 'b' collate UTF8_LCASE#x]
      :        :     +- Filter (c = C)
      :        :        +- OneRowRelation
      :        +- OneRowRelation
      +- OneRowRelation


-- !query
SELECT COUNT(*) FROM v WHERE c1 = 'A'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c1#x = A)
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x, 'c' collate UTF8_LCASE#x])
         +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast('c' collate UTF8_LCASE#x as string collate UTF8_LCASE) AS 'c' collate UTF8_LCASE#x]
            +- Project [a AS c1#x, scalar-subquery#x [] AS c2#x, c AS 'c' collate UTF8_LCASE#x]
               :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
               :     :  +- Project [CASE WHEN ((a = A) = true) THEN a ELSE b END AS CASE WHEN (('a' collate UTF8_LCASE = 'A' collate UTF8_LCASE) = true) THEN 'a' collate UTF8_LCASE ELSE 'b' collate UTF8_LCASE END#x]
               :     :     +- OneRowRelation
               :     +- Filter (scalar-subquery#x [] = B)
               :        :  +- Project [b AS 'b' collate UTF8_LCASE#x]
               :        :     +- Filter (c = C)
               :        :        +- OneRowRelation
               :        +- OneRowRelation
               +- OneRowRelation


-- !query
SELECT COUNT(*) FROM v WHERE c2 = 'a'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c2#x = a)
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x, 'c' collate UTF8_LCASE#x])
         +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast('c' collate UTF8_LCASE#x as string collate UTF8_LCASE) AS 'c' collate UTF8_LCASE#x]
            +- Project [a AS c1#x, scalar-subquery#x [] AS c2#x, c AS 'c' collate UTF8_LCASE#x]
               :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
               :     :  +- Project [CASE WHEN ((a = A) = true) THEN a ELSE b END AS CASE WHEN (('a' collate UTF8_LCASE = 'A' collate UTF8_LCASE) = true) THEN 'a' collate UTF8_LCASE ELSE 'b' collate UTF8_LCASE END#x]
               :     :     +- OneRowRelation
               :     +- Filter (scalar-subquery#x [] = B)
               :        :  +- Project [b AS 'b' collate UTF8_LCASE#x]
               :        :     +- Filter (c = C)
               :        :        +- OneRowRelation
               :        +- OneRowRelation
               +- OneRowRelation


-- !query
SELECT COUNT(*) FROM v WHERE c2 = 'b'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c2#x = b)
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x, 'c' collate UTF8_LCASE#x])
         +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast('c' collate UTF8_LCASE#x as string collate UTF8_LCASE) AS 'c' collate UTF8_LCASE#x]
            +- Project [a AS c1#x, scalar-subquery#x [] AS c2#x, c AS 'c' collate UTF8_LCASE#x]
               :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
               :     :  +- Project [CASE WHEN ((a = A) = true) THEN a ELSE b END AS CASE WHEN (('a' collate UTF8_LCASE = 'A' collate UTF8_LCASE) = true) THEN 'a' collate UTF8_LCASE ELSE 'b' collate UTF8_LCASE END#x]
               :     :     +- OneRowRelation
               :     +- Filter (scalar-subquery#x [] = B)
               :        :  +- Project [b AS 'b' collate UTF8_LCASE#x]
               :        :     +- Filter (c = C)
               :        :        +- OneRowRelation
               :        +- OneRowRelation
               +- OneRowRelation


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x, c2#x, 'c' collate UTF8_LCASE#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x, 'c' collate UTF8_LCASE#x])
      +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast('c' collate UTF8_LCASE#x as string collate UTF8_LCASE) AS 'c' collate UTF8_LCASE#x]
         +- Project [a AS c1#x, scalar-subquery#x [] AS c2#x, c AS 'c' collate UTF8_LCASE#x]
            :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
            :     :  +- Project [CASE WHEN ((a = A) = true) THEN a ELSE b END AS CASE WHEN (('a' collate UTF8_LCASE = 'A' collate UTF8_LCASE) = true) THEN 'a' collate UTF8_LCASE ELSE 'b' collate UTF8_LCASE END#x]
            :     :     +- OneRowRelation
            :     +- Filter (scalar-subquery#x [] = B)
            :        :  +- Project [b AS 'b' collate UTF8_LCASE#x]
            :        :     +- Filter (c = C)
            :        :        +- OneRowRelation
            :        +- OneRowRelation
            +- OneRowRelation


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t (c1 STRING, c2 STRING COLLATE UTF8_LCASE)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('a', 'a'), ('A', 'A'), ('b', 'b')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2]
+- Project [cast(col1#x as string) AS c1#x, cast(col2#x as string collate UTF8_LCASE) AS c2#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
CREATE OR REPLACE VIEW v DEFAULT COLLATION sr_ci_ai AS SELECT *, 'ć' AS c3 FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, sr_CI_AI, SELECT *, 'ć' AS c3 FROM t, false, true, PersistedView, COMPENSATION, true
   +- Project [c1#x, c2#x, ć AS c3#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT DISTINCT COLLATION(c1) FROM v
-- !query analysis
Distinct
+- Project [collation(c1#x) AS collation(c1)#x]
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x, c3#x])
         +- Project [cast(c1#x as string) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast(c3#x as string collate sr_CI_AI) AS c3#x]
            +- Project [c1#x, c2#x, ć AS c3#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT DISTINCT COLLATION(c2) FROM v
-- !query analysis
Distinct
+- Project [collation(c2#x) AS collation(c2)#x]
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x, c3#x])
         +- Project [cast(c1#x as string) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast(c3#x as string collate sr_CI_AI) AS c3#x]
            +- Project [c1#x, c2#x, ć AS c3#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT DISTINCT COLLATION(c3) FROM v
-- !query analysis
Distinct
+- Project [collation(c3#x) AS collation(c3)#x]
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x, c3#x])
         +- Project [cast(c1#x as string) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast(c3#x as string collate sr_CI_AI) AS c3#x]
            +- Project [c1#x, c2#x, ć AS c3#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT COUNT(*) FROM v WHERE c1 = 'A'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c1#x = A)
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x, c3#x])
         +- Project [cast(c1#x as string) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast(c3#x as string collate sr_CI_AI) AS c3#x]
            +- Project [c1#x, c2#x, ć AS c3#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT COUNT(*) FROM v WHERE c2 = 'a'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c2#x = a)
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x, c3#x])
         +- Project [cast(c1#x as string) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast(c3#x as string collate sr_CI_AI) AS c3#x]
            +- Project [c1#x, c2#x, ć AS c3#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT COUNT(*) FROM v WHERE c3 = 'Č'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c3#x = Č)
   +- SubqueryAlias spark_catalog.default.v
      +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x, c3#x])
         +- Project [cast(c1#x as string) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast(c3#x as string collate sr_CI_AI) AS c3#x]
            +- Project [c1#x, c2#x, ć AS c3#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, true, true, false


-- !query
CREATE VIEW v DEFAULT COLLATION UTF8_LCASE AS SELECT 1
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, UTF8_LCASE, SELECT 1, false, false, PersistedView, COMPENSATION, true
   +- Project [1 AS 1#x]
      +- OneRowRelation


-- !query
ALTER VIEW v AS SELECT 'a' AS c1, 'b' AS c2
-- !query analysis
AlterViewAsCommand `spark_catalog`.`default`.`v`, SELECT 'a' AS c1, 'b' AS c2, true
   +- Project [a AS c1#x, b AS c2#x]
      +- OneRowRelation


-- !query
SELECT COLLATION(c1) FROM v
-- !query analysis
Project [collation(c1#x) AS collation(c1)#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x])
      +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x]
         +- Project [a AS c1#x, b AS c2#x]
            +- OneRowRelation


-- !query
SELECT COLLATION(c2) FROM v
-- !query analysis
Project [collation(c2#x) AS collation(c2)#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x])
      +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x]
         +- Project [a AS c1#x, b AS c2#x]
            +- OneRowRelation


-- !query
ALTER VIEW v AS SELECT 'c' AS c3 WHERE 'a' = 'A'
-- !query analysis
AlterViewAsCommand `spark_catalog`.`default`.`v`, SELECT 'c' AS c3 WHERE 'a' = 'A', true
   +- Project [c AS c3#x]
      +- Filter (a = A)
         +- OneRowRelation


-- !query
SELECT COLLATION(c3) FROM v
-- !query analysis
Project [collation(c3#x) AS collation(c3)#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c3#x])
      +- Project [cast(c3#x as string collate UTF8_LCASE) AS c3#x]
         +- Project [c AS c3#x]
            +- Filter (a = A)
               +- OneRowRelation


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, true, true, false


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t (c1 STRING COLLATE UTF8_LCASE, c2 STRING, c3 INT)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('a', 'b', 1)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2, c3]
+- Project [cast(col1#x as string collate UTF8_LCASE) AS c1#x, cast(col2#x as string) AS c2#x, cast(col3#x as int) AS c3#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
CREATE VIEW v DEFAULT COLLATION sr_AI_CI AS SELECT 'a' AS c1
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, sr_CI_AI, SELECT 'a' AS c1, false, false, PersistedView, COMPENSATION, true
   +- Project [a AS c1#x]
      +- OneRowRelation


-- !query
ALTER VIEW v AS
    SELECT *, 'c' AS c4, (SELECT (SELECT CASE 'š' = 'S' WHEN TRUE THEN 'd' ELSE 'b' END)) AS c5
    FROM t
    WHERE c1 = 'A' AND 'ć' = 'Č'
-- !query analysis
AlterViewAsCommand `spark_catalog`.`default`.`v`, SELECT *, 'c' AS c4, (SELECT (SELECT CASE 'š' = 'S' WHEN TRUE THEN 'd' ELSE 'b' END)) AS c5
    FROM t
    WHERE c1 = 'A' AND 'ć' = 'Č', true
   +- Project [c1#x, c2#x, c3#x, c AS c4#x, scalar-subquery#x [] AS c5#x]
      :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
      :     :  +- Project [CASE WHEN ((š = S) = true) THEN d ELSE b END AS CASE WHEN (('š' collate sr_CI_AI = 'S' collate sr_CI_AI) = true) THEN 'd' collate sr_CI_AI ELSE 'b' collate sr_CI_AI END#x]
      :     :     +- OneRowRelation
      :     +- OneRowRelation
      +- Filter ((c1#x = A) AND (ć = Č))
         +- SubqueryAlias spark_catalog.default.t
            +- Relation spark_catalog.default.t[c1#x,c2#x,c3#x] parquet


-- !query
SELECT COLLATION(c4) FROM v
-- !query analysis
Project [collation(c4#x) AS collation(c4)#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x, c3#x, c4#x, c5#x])
      +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string) AS c2#x, cast(c3#x as int) AS c3#x, cast(c4#x as string collate sr_CI_AI) AS c4#x, cast(c5#x as string collate sr_CI_AI) AS c5#x]
         +- Project [c1#x, c2#x, c3#x, c AS c4#x, scalar-subquery#x [] AS c5#x]
            :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
            :     :  +- Project [CASE WHEN ((š = S) = true) THEN d ELSE b END AS CASE WHEN (('š' collate sr_CI_AI = 'S' collate sr_CI_AI) = true) THEN 'd' collate sr_CI_AI ELSE 'b' collate sr_CI_AI END#x]
            :     :     +- OneRowRelation
            :     +- OneRowRelation
            +- Filter ((c1#x = A) AND (ć = Č))
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x,c3#x] parquet


-- !query
SELECT COLLATION(c5) FROM v
-- !query analysis
Project [collation(c5#x) AS collation(c5)#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x, c3#x, c4#x, c5#x])
      +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string) AS c2#x, cast(c3#x as int) AS c3#x, cast(c4#x as string collate sr_CI_AI) AS c4#x, cast(c5#x as string collate sr_CI_AI) AS c5#x]
         +- Project [c1#x, c2#x, c3#x, c AS c4#x, scalar-subquery#x [] AS c5#x]
            :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
            :     :  +- Project [CASE WHEN ((š = S) = true) THEN d ELSE b END AS CASE WHEN (('š' collate sr_CI_AI = 'S' collate sr_CI_AI) = true) THEN 'd' collate sr_CI_AI ELSE 'b' collate sr_CI_AI END#x]
            :     :     +- OneRowRelation
            :     +- OneRowRelation
            +- Filter ((c1#x = A) AND (ć = Č))
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x,c3#x] parquet


-- !query
SELECT c5 FROM v
-- !query analysis
Project [c5#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x, c3#x, c4#x, c5#x])
      +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string) AS c2#x, cast(c3#x as int) AS c3#x, cast(c4#x as string collate sr_CI_AI) AS c4#x, cast(c5#x as string collate sr_CI_AI) AS c5#x]
         +- Project [c1#x, c2#x, c3#x, c AS c4#x, scalar-subquery#x [] AS c5#x]
            :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
            :     :  +- Project [CASE WHEN ((š = S) = true) THEN d ELSE b END AS CASE WHEN (('š' collate sr_CI_AI = 'S' collate sr_CI_AI) = true) THEN 'd' collate sr_CI_AI ELSE 'b' collate sr_CI_AI END#x]
            :     :     +- OneRowRelation
            :     +- OneRowRelation
            +- Filter ((c1#x = A) AND (ć = Č))
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x,c3#x] parquet


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, true, true, false


-- !query
CREATE TEMPORARY VIEW v DEFAULT COLLATION UNICODE AS SELECT 'a'
-- !query analysis
CreateViewCommand `v`, UNICODE, SELECT 'a', false, false, LocalTempView, UNSUPPORTED, true
   +- Project [a AS 'a' collate UNICODE#x]
      +- OneRowRelation


-- !query
SELECT * FROM v
-- !query analysis
Project ['a' collate UNICODE#x]
+- SubqueryAlias v
   +- View (`v`, ['a' collate UNICODE#x])
      +- Project [cast('a' collate UNICODE#x as string collate UNICODE) AS 'a' collate UNICODE#x]
         +- Project [a AS 'a' collate UNICODE#x]
            +- OneRowRelation


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTempViewCommand v


-- !query
CREATE TEMPORARY VIEW v DEFAULT COLLATION UTF8_LCASE AS SELECT 'a' AS c1
-- !query analysis
CreateViewCommand `v`, UTF8_LCASE, SELECT 'a' AS c1, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [a AS c1#x]
      +- OneRowRelation


-- !query
SELECT COUNT(*) FROM v WHERE c1 = 'A'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c1#x = A)
   +- SubqueryAlias v
      +- View (`v`, [c1#x])
         +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x]
            +- Project [a AS c1#x]
               +- OneRowRelation


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTempViewCommand v


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t (c1 STRING COLLATE UTF8_LCASE)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('a'), ('A')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1]
+- Project [cast(col1#x as string collate UTF8_LCASE) AS c1#x]
   +- LocalRelation [col1#x]


-- !query
CREATE TEMPORARY VIEW v DEFAULT COLLATION SR_AI_CI AS SELECT c1 FROM t WHERE 'ć' = 'č'
-- !query analysis
CreateViewCommand `v`, sr_CI_AI, SELECT c1 FROM t WHERE 'ć' = 'č', false, false, LocalTempView, UNSUPPORTED, true
   +- Project [c1#x]
      +- Filter (ć = č)
         +- SubqueryAlias spark_catalog.default.t
            +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT COUNT(*) FROM v
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- SubqueryAlias v
   +- View (`v`, [c1#x])
      +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x]
         +- Project [c1#x]
            +- Filter (ć = č)
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT COUNT(*) FROM v WHERE c1 = 'A'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c1#x = A)
   +- SubqueryAlias v
      +- View (`v`, [c1#x])
         +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x]
            +- Project [c1#x]
               +- Filter (ć = č)
                  +- SubqueryAlias spark_catalog.default.t
                     +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTempViewCommand v


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t (c1 STRING COLLATE UTF8_LCASE)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('ć'), ('č')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1]
+- Project [cast(col1#x as string collate UTF8_LCASE) AS c1#x]
   +- LocalRelation [col1#x]


-- !query
CREATE TEMPORARY VIEW v DEFAULT COLLATION UNICODE AS SELECT CAST(c1 AS STRING COLLATE SR_AI) FROM t
-- !query analysis
CreateViewCommand `v`, UNICODE, SELECT CAST(c1 AS STRING COLLATE SR_AI) FROM t, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT DISTINCT COLLATION(c1) FROM v
-- !query analysis
Distinct
+- Project [collation(c1#x) AS collation(c1)#x]
   +- SubqueryAlias v
      +- View (`v`, [c1#x])
         +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
            +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT COUNT(*) FROM v WHERE c1 = 'c'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c1#x = c)
   +- SubqueryAlias v
      +- View (`v`, [c1#x])
         +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
            +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTempViewCommand v


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t (c1 STRING COLLATE UTF8_LCASE)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('ć'), ('č')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1]
+- Project [cast(col1#x as string collate UTF8_LCASE) AS c1#x]
   +- LocalRelation [col1#x]


-- !query
CREATE TEMPORARY VIEW v DEFAULT COLLATION UNICODE AS SELECT CAST(c1 AS STRING COLLATE SR_AI) FROM t
-- !query analysis
CreateViewCommand `v`, UNICODE, SELECT CAST(c1 AS STRING COLLATE SR_AI) FROM t, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT DISTINCT COLLATION(c1) FROM v
-- !query analysis
Distinct
+- Project [collation(c1#x) AS collation(c1)#x]
   +- SubqueryAlias v
      +- View (`v`, [c1#x])
         +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
            +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT COUNT(*) FROM v WHERE c1 = 'c'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c1#x = c)
   +- SubqueryAlias v
      +- View (`v`, [c1#x])
         +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
            +- Project [cast(c1#x as string collate sr_AI) AS c1#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTempViewCommand v


-- !query
CREATE TEMPORARY VIEW v DEFAULT COLLATION UTF8_LCASE
AS SELECT 'a' AS c1, (SELECT (SELECT CASE 'a' = 'A' WHEN TRUE THEN 'a' ELSE 'b' END) WHERE (SELECT 'b' WHERE 'c' = 'C') = 'B') AS c2, 'c'
-- !query analysis
CreateViewCommand `v`, UTF8_LCASE, SELECT 'a' AS c1, (SELECT (SELECT CASE 'a' = 'A' WHEN TRUE THEN 'a' ELSE 'b' END) WHERE (SELECT 'b' WHERE 'c' = 'C') = 'B') AS c2, 'c', false, false, LocalTempView, UNSUPPORTED, true
   +- Project [a AS c1#x, scalar-subquery#x [] AS c2#x, c AS 'c' collate UTF8_LCASE#x]
      :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
      :     :  +- Project [CASE WHEN ((a = A) = true) THEN a ELSE b END AS CASE WHEN (('a' collate UTF8_LCASE = 'A' collate UTF8_LCASE) = true) THEN 'a' collate UTF8_LCASE ELSE 'b' collate UTF8_LCASE END#x]
      :     :     +- OneRowRelation
      :     +- Filter (scalar-subquery#x [] = B)
      :        :  +- Project [b AS 'b' collate UTF8_LCASE#x]
      :        :     +- Filter (c = C)
      :        :        +- OneRowRelation
      :        +- OneRowRelation
      +- OneRowRelation


-- !query
SELECT COUNT(*) FROM v WHERE c1 = 'A'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c1#x = A)
   +- SubqueryAlias v
      +- View (`v`, [c1#x, c2#x, 'c' collate UTF8_LCASE#x])
         +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast('c' collate UTF8_LCASE#x as string collate UTF8_LCASE) AS 'c' collate UTF8_LCASE#x]
            +- Project [a AS c1#x, scalar-subquery#x [] AS c2#x, c AS 'c' collate UTF8_LCASE#x]
               :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
               :     :  +- Project [CASE WHEN ((a = A) = true) THEN a ELSE b END AS CASE WHEN (('a' collate UTF8_LCASE = 'A' collate UTF8_LCASE) = true) THEN 'a' collate UTF8_LCASE ELSE 'b' collate UTF8_LCASE END#x]
               :     :     +- OneRowRelation
               :     +- Filter (scalar-subquery#x [] = B)
               :        :  +- Project [b AS 'b' collate UTF8_LCASE#x]
               :        :     +- Filter (c = C)
               :        :        +- OneRowRelation
               :        +- OneRowRelation
               +- OneRowRelation


-- !query
SELECT COUNT(*) FROM v WHERE c2 = 'a'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c2#x = a)
   +- SubqueryAlias v
      +- View (`v`, [c1#x, c2#x, 'c' collate UTF8_LCASE#x])
         +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast('c' collate UTF8_LCASE#x as string collate UTF8_LCASE) AS 'c' collate UTF8_LCASE#x]
            +- Project [a AS c1#x, scalar-subquery#x [] AS c2#x, c AS 'c' collate UTF8_LCASE#x]
               :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
               :     :  +- Project [CASE WHEN ((a = A) = true) THEN a ELSE b END AS CASE WHEN (('a' collate UTF8_LCASE = 'A' collate UTF8_LCASE) = true) THEN 'a' collate UTF8_LCASE ELSE 'b' collate UTF8_LCASE END#x]
               :     :     +- OneRowRelation
               :     +- Filter (scalar-subquery#x [] = B)
               :        :  +- Project [b AS 'b' collate UTF8_LCASE#x]
               :        :     +- Filter (c = C)
               :        :        +- OneRowRelation
               :        +- OneRowRelation
               +- OneRowRelation


-- !query
SELECT COUNT(*) FROM v WHERE c2 = 'b'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c2#x = b)
   +- SubqueryAlias v
      +- View (`v`, [c1#x, c2#x, 'c' collate UTF8_LCASE#x])
         +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast('c' collate UTF8_LCASE#x as string collate UTF8_LCASE) AS 'c' collate UTF8_LCASE#x]
            +- Project [a AS c1#x, scalar-subquery#x [] AS c2#x, c AS 'c' collate UTF8_LCASE#x]
               :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
               :     :  +- Project [CASE WHEN ((a = A) = true) THEN a ELSE b END AS CASE WHEN (('a' collate UTF8_LCASE = 'A' collate UTF8_LCASE) = true) THEN 'a' collate UTF8_LCASE ELSE 'b' collate UTF8_LCASE END#x]
               :     :     +- OneRowRelation
               :     +- Filter (scalar-subquery#x [] = B)
               :        :  +- Project [b AS 'b' collate UTF8_LCASE#x]
               :        :     +- Filter (c = C)
               :        :        +- OneRowRelation
               :        +- OneRowRelation
               +- OneRowRelation


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x, c2#x, 'c' collate UTF8_LCASE#x]
+- SubqueryAlias v
   +- View (`v`, [c1#x, c2#x, 'c' collate UTF8_LCASE#x])
      +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast('c' collate UTF8_LCASE#x as string collate UTF8_LCASE) AS 'c' collate UTF8_LCASE#x]
         +- Project [a AS c1#x, scalar-subquery#x [] AS c2#x, c AS 'c' collate UTF8_LCASE#x]
            :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
            :     :  +- Project [CASE WHEN ((a = A) = true) THEN a ELSE b END AS CASE WHEN (('a' collate UTF8_LCASE = 'A' collate UTF8_LCASE) = true) THEN 'a' collate UTF8_LCASE ELSE 'b' collate UTF8_LCASE END#x]
            :     :     +- OneRowRelation
            :     +- Filter (scalar-subquery#x [] = B)
            :        :  +- Project [b AS 'b' collate UTF8_LCASE#x]
            :        :     +- Filter (c = C)
            :        :        +- OneRowRelation
            :        +- OneRowRelation
            +- OneRowRelation


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t (c1 STRING, c2 STRING COLLATE UTF8_LCASE)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('a', 'a'), ('A', 'A'), ('b', 'b')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2]
+- Project [cast(col1#x as string) AS c1#x, cast(col2#x as string collate UTF8_LCASE) AS c2#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
CREATE OR REPLACE TEMPORARY VIEW v DEFAULT COLLATION sr_ci_ai AS SELECT *, 'ć' AS c3 FROM t
-- !query analysis
CreateViewCommand `v`, sr_CI_AI, SELECT *, 'ć' AS c3 FROM t, false, true, LocalTempView, UNSUPPORTED, true
   +- Project [c1#x, c2#x, ć AS c3#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT DISTINCT COLLATION(c1) FROM v
-- !query analysis
Distinct
+- Project [collation(c1#x) AS collation(c1)#x]
   +- SubqueryAlias v
      +- View (`v`, [c1#x, c2#x, c3#x])
         +- Project [cast(c1#x as string) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast(c3#x as string collate sr_CI_AI) AS c3#x]
            +- Project [c1#x, c2#x, ć AS c3#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT DISTINCT COLLATION(c2) FROM v
-- !query analysis
Distinct
+- Project [collation(c2#x) AS collation(c2)#x]
   +- SubqueryAlias v
      +- View (`v`, [c1#x, c2#x, c3#x])
         +- Project [cast(c1#x as string) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast(c3#x as string collate sr_CI_AI) AS c3#x]
            +- Project [c1#x, c2#x, ć AS c3#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT DISTINCT COLLATION(c3) FROM v
-- !query analysis
Distinct
+- Project [collation(c3#x) AS collation(c3)#x]
   +- SubqueryAlias v
      +- View (`v`, [c1#x, c2#x, c3#x])
         +- Project [cast(c1#x as string) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast(c3#x as string collate sr_CI_AI) AS c3#x]
            +- Project [c1#x, c2#x, ć AS c3#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT COUNT(*) FROM v WHERE c1 = 'A'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c1#x = A)
   +- SubqueryAlias v
      +- View (`v`, [c1#x, c2#x, c3#x])
         +- Project [cast(c1#x as string) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast(c3#x as string collate sr_CI_AI) AS c3#x]
            +- Project [c1#x, c2#x, ć AS c3#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT COUNT(*) FROM v WHERE c2 = 'a'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c2#x = a)
   +- SubqueryAlias v
      +- View (`v`, [c1#x, c2#x, c3#x])
         +- Project [cast(c1#x as string) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast(c3#x as string collate sr_CI_AI) AS c3#x]
            +- Project [c1#x, c2#x, ć AS c3#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT COUNT(*) FROM v WHERE c3 = 'Č'
-- !query analysis
Aggregate [count(1) AS count(1)#xL]
+- Filter (c3#x = Č)
   +- SubqueryAlias v
      +- View (`v`, [c1#x, c2#x, c3#x])
         +- Project [cast(c1#x as string) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x, cast(c3#x as string collate sr_CI_AI) AS c3#x]
            +- Project [c1#x, c2#x, ć AS c3#x]
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTempViewCommand v


-- !query
CREATE TEMPORARY VIEW v DEFAULT COLLATION UTF8_LCASE AS SELECT 1
-- !query analysis
CreateViewCommand `v`, UTF8_LCASE, SELECT 1, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [1 AS 1#x]
      +- OneRowRelation


-- !query
ALTER VIEW v AS SELECT 'a' AS c1, 'b' AS c2
-- !query analysis
AlterViewAsCommand `v`, SELECT 'a' AS c1, 'b' AS c2, true
   +- Project [a AS c1#x, b AS c2#x]
      +- OneRowRelation


-- !query
SELECT COLLATION(c1) FROM v
-- !query analysis
Project [collation(c1#x) AS collation(c1)#x]
+- SubqueryAlias v
   +- View (`v`, [c1#x, c2#x])
      +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x]
         +- Project [a AS c1#x, b AS c2#x]
            +- OneRowRelation


-- !query
SELECT COLLATION(c2) FROM v
-- !query analysis
Project [collation(c2#x) AS collation(c2)#x]
+- SubqueryAlias v
   +- View (`v`, [c1#x, c2#x])
      +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string collate UTF8_LCASE) AS c2#x]
         +- Project [a AS c1#x, b AS c2#x]
            +- OneRowRelation


-- !query
ALTER VIEW v AS SELECT 'c' AS c3 WHERE 'a' = 'A'
-- !query analysis
AlterViewAsCommand `v`, SELECT 'c' AS c3 WHERE 'a' = 'A', true
   +- Project [c AS c3#x]
      +- Filter (a = A)
         +- OneRowRelation


-- !query
SELECT COLLATION(c3) FROM v
-- !query analysis
Project [collation(c3#x) AS collation(c3)#x]
+- SubqueryAlias v
   +- View (`v`, [c3#x])
      +- Project [cast(c3#x as string collate UTF8_LCASE) AS c3#x]
         +- Project [c AS c3#x]
            +- Filter (a = A)
               +- OneRowRelation


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTempViewCommand v


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t (c1 STRING COLLATE UTF8_LCASE, c2 STRING, c3 INT)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('a', 'b', 1)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2, c3]
+- Project [cast(col1#x as string collate UTF8_LCASE) AS c1#x, cast(col2#x as string) AS c2#x, cast(col3#x as int) AS c3#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
CREATE TEMPORARY VIEW v DEFAULT COLLATION sr_AI_CI AS SELECT 'a' AS c1
-- !query analysis
CreateViewCommand `v`, sr_CI_AI, SELECT 'a' AS c1, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [a AS c1#x]
      +- OneRowRelation


-- !query
ALTER VIEW v AS
    SELECT *, 'c' AS c4, (SELECT (SELECT CASE 'š' = 'S' WHEN TRUE THEN 'd' ELSE 'b' END)) AS c5
    FROM t
    WHERE c1 = 'A' AND 'ć' = 'Č'
-- !query analysis
AlterViewAsCommand `v`, SELECT *, 'c' AS c4, (SELECT (SELECT CASE 'š' = 'S' WHEN TRUE THEN 'd' ELSE 'b' END)) AS c5
    FROM t
    WHERE c1 = 'A' AND 'ć' = 'Č', true
   +- Project [c1#x, c2#x, c3#x, c AS c4#x, scalar-subquery#x [] AS c5#x]
      :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
      :     :  +- Project [CASE WHEN ((š = S) = true) THEN d ELSE b END AS CASE WHEN (('š' collate sr_CI_AI = 'S' collate sr_CI_AI) = true) THEN 'd' collate sr_CI_AI ELSE 'b' collate sr_CI_AI END#x]
      :     :     +- OneRowRelation
      :     +- OneRowRelation
      +- Filter ((c1#x = A) AND (ć = Č))
         +- SubqueryAlias spark_catalog.default.t
            +- Relation spark_catalog.default.t[c1#x,c2#x,c3#x] parquet


-- !query
SELECT COLLATION(c4) FROM v
-- !query analysis
Project [collation(c4#x) AS collation(c4)#x]
+- SubqueryAlias v
   +- View (`v`, [c1#x, c2#x, c3#x, c4#x, c5#x])
      +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string) AS c2#x, cast(c3#x as int) AS c3#x, cast(c4#x as string collate sr_CI_AI) AS c4#x, cast(c5#x as string collate sr_CI_AI) AS c5#x]
         +- Project [c1#x, c2#x, c3#x, c AS c4#x, scalar-subquery#x [] AS c5#x]
            :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
            :     :  +- Project [CASE WHEN ((š = S) = true) THEN d ELSE b END AS CASE WHEN (('š' collate sr_CI_AI = 'S' collate sr_CI_AI) = true) THEN 'd' collate sr_CI_AI ELSE 'b' collate sr_CI_AI END#x]
            :     :     +- OneRowRelation
            :     +- OneRowRelation
            +- Filter ((c1#x = A) AND (ć = Č))
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x,c3#x] parquet


-- !query
SELECT COLLATION(c5) FROM v
-- !query analysis
Project [collation(c5#x) AS collation(c5)#x]
+- SubqueryAlias v
   +- View (`v`, [c1#x, c2#x, c3#x, c4#x, c5#x])
      +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string) AS c2#x, cast(c3#x as int) AS c3#x, cast(c4#x as string collate sr_CI_AI) AS c4#x, cast(c5#x as string collate sr_CI_AI) AS c5#x]
         +- Project [c1#x, c2#x, c3#x, c AS c4#x, scalar-subquery#x [] AS c5#x]
            :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
            :     :  +- Project [CASE WHEN ((š = S) = true) THEN d ELSE b END AS CASE WHEN (('š' collate sr_CI_AI = 'S' collate sr_CI_AI) = true) THEN 'd' collate sr_CI_AI ELSE 'b' collate sr_CI_AI END#x]
            :     :     +- OneRowRelation
            :     +- OneRowRelation
            +- Filter ((c1#x = A) AND (ć = Č))
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x,c3#x] parquet


-- !query
SELECT c5 FROM v
-- !query analysis
Project [c5#x]
+- SubqueryAlias v
   +- View (`v`, [c1#x, c2#x, c3#x, c4#x, c5#x])
      +- Project [cast(c1#x as string collate UTF8_LCASE) AS c1#x, cast(c2#x as string) AS c2#x, cast(c3#x as int) AS c3#x, cast(c4#x as string collate sr_CI_AI) AS c4#x, cast(c5#x as string collate sr_CI_AI) AS c5#x]
         +- Project [c1#x, c2#x, c3#x, c AS c4#x, scalar-subquery#x [] AS c5#x]
            :  +- Project [scalar-subquery#x [] AS scalarsubquery()#x]
            :     :  +- Project [CASE WHEN ((š = S) = true) THEN d ELSE b END AS CASE WHEN (('š' collate sr_CI_AI = 'S' collate sr_CI_AI) = true) THEN 'd' collate sr_CI_AI ELSE 'b' collate sr_CI_AI END#x]
            :     :     +- OneRowRelation
            :     +- OneRowRelation
            +- Filter ((c1#x = A) AND (ć = Č))
               +- SubqueryAlias spark_catalog.default.t
                  +- Relation spark_catalog.default.t[c1#x,c2#x,c3#x] parquet


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTempViewCommand v


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t
