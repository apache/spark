-- Automatically generated by SQLQueryTestSuite
-- !query
create table t1(s string, utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('Spark', 'Spark', 'SQL')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaAAaA', 'aaAaAAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaAAaA', 'aaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaAAaA', 'aaAaaAaAaaAaaAaAaaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('bbAbaAbA', 'bbAbAAbA', 'a')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('İo', 'İo', 'İo')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('İo', 'İo', 'İo ')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('İo', 'İo ', 'İo')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('İo', 'İo', 'i̇o')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('efd2', 'efd2', 'efd2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('Hello, world! Nice day.', 'Hello, world! Nice day.', 'Hello, world! Nice day.')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('Something else. Nothing here.', 'Something else. Nothing here.', 'Something else. Nothing here.')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('kitten', 'kitten', 'sitTing')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('abc', 'abc', 'abc')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('abcdcba', 'abcdcba', 'aBcDCbA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
select rpad(utf8_binary, 8, utf8_lcase) from t1
-- !query analysis
Project [rpad(cast(utf8_binary#x as string collate null), 8, cast(utf8_lcase#x as string collate null)) AS rpad(utf8_binary, 8, utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select rpad(s, 8, utf8_binary) from t1
-- !query analysis
Project [rpad(s#x, 8, utf8_binary#x) AS rpad(s, 8, utf8_binary)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select rpad(utf8_binary collate utf8_binary, 8, s collate utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.EXPLICIT",
  "sqlState" : "42P21",
  "messageParameters" : {
    "explicitTypes" : "\"STRING\", \"STRING COLLATE UTF8_LCASE\""
  }
}


-- !query
select rpad(utf8_binary, 8, utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [rpad(utf8_binary#x, 8, collate(utf8_lcase#x, utf8_binary)) AS rpad(utf8_binary, 8, collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select rpad(utf8_binary collate utf8_lcase, 8, utf8_lcase collate utf8_lcase) from t1
-- !query analysis
Project [rpad(collate(utf8_binary#x, utf8_lcase), 8, collate(utf8_lcase#x, utf8_lcase)) AS rpad(collate(utf8_binary, utf8_lcase), 8, collate(utf8_lcase, utf8_lcase))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select lpad(utf8_binary collate utf8_binary_rtrim, 8, utf8_lcase collate utf8_binary_rtrim) from t1
-- !query analysis
Project [lpad(collate(utf8_binary#x, utf8_binary_rtrim), 8, collate(utf8_lcase#x, utf8_binary_rtrim)) AS lpad(collate(utf8_binary, utf8_binary_rtrim), 8, collate(utf8_lcase, utf8_binary_rtrim))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select rpad(utf8_binary, 8, 'a'), rpad(utf8_lcase, 8, 'a') from t1
-- !query analysis
Project [rpad(utf8_binary#x, 8, a) AS rpad(utf8_binary, 8, a)#x, rpad(utf8_lcase#x, 8, a) AS rpad(utf8_lcase, 8, 'a' collate UTF8_LCASE)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select rpad(utf8_binary, 8, 'AaAA' collate utf8_lcase), rpad(utf8_lcase, 8, 'AAa' collate utf8_binary) from t1
-- !query analysis
Project [rpad(cast(utf8_binary#x as string collate UTF8_LCASE), 8, collate(AaAA, utf8_lcase)) AS rpad(utf8_binary, 8, collate(AaAA, utf8_lcase))#x, rpad(cast(utf8_lcase#x as string), 8, collate(AAa, utf8_binary)) AS rpad(utf8_lcase, 8, collate(AAa, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select lpad(utf8_binary, 8, utf8_lcase) from t1
-- !query analysis
Project [lpad(cast(utf8_binary#x as string collate null), 8, cast(utf8_lcase#x as string collate null)) AS lpad(utf8_binary, 8, utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select lpad(s, 8, utf8_binary) from t1
-- !query analysis
Project [lpad(s#x, 8, utf8_binary#x) AS lpad(s, 8, utf8_binary)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select lpad(utf8_binary collate utf8_binary, 8, s collate utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.EXPLICIT",
  "sqlState" : "42P21",
  "messageParameters" : {
    "explicitTypes" : "\"STRING\", \"STRING COLLATE UTF8_LCASE\""
  }
}


-- !query
select lpad(utf8_binary, 8, utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [lpad(utf8_binary#x, 8, collate(utf8_lcase#x, utf8_binary)) AS lpad(utf8_binary, 8, collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select lpad(utf8_binary collate utf8_lcase, 8, utf8_lcase collate utf8_lcase) from t1
-- !query analysis
Project [lpad(collate(utf8_binary#x, utf8_lcase), 8, collate(utf8_lcase#x, utf8_lcase)) AS lpad(collate(utf8_binary, utf8_lcase), 8, collate(utf8_lcase, utf8_lcase))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select lpad(utf8_binary collate utf8_binary_rtrim, 8, utf8_lcase collate utf8_binary_rtrim) from t1
-- !query analysis
Project [lpad(collate(utf8_binary#x, utf8_binary_rtrim), 8, collate(utf8_lcase#x, utf8_binary_rtrim)) AS lpad(collate(utf8_binary, utf8_binary_rtrim), 8, collate(utf8_lcase, utf8_binary_rtrim))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select lpad(utf8_binary, 8, 'a'), lpad(utf8_lcase, 8, 'a') from t1
-- !query analysis
Project [lpad(utf8_binary#x, 8, a) AS lpad(utf8_binary, 8, a)#x, lpad(utf8_lcase#x, 8, a) AS lpad(utf8_lcase, 8, 'a' collate UTF8_LCASE)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select lpad(utf8_binary, 8, 'AaAA' collate utf8_lcase), lpad(utf8_lcase, 8, 'AAa' collate utf8_binary) from t1
-- !query analysis
Project [lpad(cast(utf8_binary#x as string collate UTF8_LCASE), 8, collate(AaAA, utf8_lcase)) AS lpad(utf8_binary, 8, collate(AaAA, utf8_lcase))#x, lpad(cast(utf8_lcase#x as string), 8, collate(AAa, utf8_binary)) AS lpad(utf8_lcase, 8, collate(AAa, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select TRIM(utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INDETERMINATE_COLLATION_IN_EXPRESSION",
  "sqlState" : "42P22",
  "messageParameters" : {
    "expr" : "\"TRIM(BOTH utf8_binary FROM utf8_lcase)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 36,
    "fragment" : "TRIM(utf8_binary, utf8_lcase)"
  } ]
}


-- !query
select TRIM(s, utf8_binary) from t1
-- !query analysis
Project [trim(utf8_binary#x, Some(s#x)) AS TRIM(BOTH s FROM utf8_binary)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select TRIM(utf8_binary collate utf8_binary, s collate utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.EXPLICIT",
  "sqlState" : "42P21",
  "messageParameters" : {
    "explicitTypes" : "\"STRING COLLATE UTF8_LCASE\", \"STRING\""
  }
}


-- !query
select TRIM(utf8_binary, utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [trim(collate(utf8_lcase#x, utf8_binary), Some(utf8_binary#x)) AS TRIM(BOTH utf8_binary FROM collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select TRIM(utf8_binary collate utf8_lcase, utf8_lcase collate utf8_lcase) from t1
-- !query analysis
Project [trim(collate(utf8_lcase#x, utf8_lcase), Some(collate(utf8_binary#x, utf8_lcase))) AS TRIM(BOTH collate(utf8_binary, utf8_lcase) FROM collate(utf8_lcase, utf8_lcase))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select TRIM(utf8_binary collate unicode_ai, utf8_lcase collate unicode_ai) from t1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"collate(utf8_lcase, unicode_ai)\"",
    "inputType" : "\"STRING COLLATE UNICODE_AI\"",
    "paramIndex" : "first",
    "requiredType" : "\"STRING\"",
    "sqlExpr" : "\"TRIM(BOTH collate(utf8_binary, unicode_ai) FROM collate(utf8_lcase, unicode_ai))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 74,
    "fragment" : "TRIM(utf8_binary collate unicode_ai, utf8_lcase collate unicode_ai)"
  } ]
}


-- !query
select TRIM(utf8_binary collate utf8_binary_rtrim, utf8_lcase collate utf8_binary_rtrim) from t1
-- !query analysis
Project [trim(collate(utf8_lcase#x, utf8_binary_rtrim), Some(collate(utf8_binary#x, utf8_binary_rtrim))) AS TRIM(BOTH collate(utf8_binary, utf8_binary_rtrim) FROM collate(utf8_lcase, utf8_binary_rtrim))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select TRIM('ABc', utf8_binary), TRIM('ABc', utf8_lcase) from t1
-- !query analysis
Project [trim(utf8_binary#x, Some(ABc)) AS TRIM(BOTH ABc FROM utf8_binary)#x, trim(utf8_lcase#x, Some(ABc)) AS TRIM(BOTH 'ABc' collate UTF8_LCASE FROM utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select TRIM('ABc' collate utf8_lcase, utf8_binary), TRIM('AAa' collate utf8_binary, utf8_lcase) from t1
-- !query analysis
Project [trim(cast(utf8_binary#x as string collate UTF8_LCASE), Some(collate(ABc, utf8_lcase))) AS TRIM(BOTH collate(ABc, utf8_lcase) FROM utf8_binary)#x, trim(cast(utf8_lcase#x as string), Some(collate(AAa, utf8_binary))) AS TRIM(BOTH collate(AAa, utf8_binary) FROM utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select BTRIM(utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INDETERMINATE_COLLATION_IN_EXPRESSION",
  "sqlState" : "42P22",
  "messageParameters" : {
    "expr" : "\"TRIM(BOTH utf8_lcase FROM utf8_binary)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 37,
    "fragment" : "BTRIM(utf8_binary, utf8_lcase)"
  } ]
}


-- !query
select BTRIM(s, utf8_binary) from t1
-- !query analysis
Project [btrim(s#x, utf8_binary#x) AS btrim(s, utf8_binary)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select BTRIM(utf8_binary collate utf8_binary, s collate utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.EXPLICIT",
  "sqlState" : "42P21",
  "messageParameters" : {
    "explicitTypes" : "\"STRING\", \"STRING COLLATE UTF8_LCASE\""
  }
}


-- !query
select BTRIM(utf8_binary, utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [btrim(utf8_binary#x, collate(utf8_lcase#x, utf8_binary)) AS btrim(utf8_binary, collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select BTRIM(utf8_binary collate utf8_lcase, utf8_lcase collate utf8_lcase) from t1
-- !query analysis
Project [btrim(collate(utf8_binary#x, utf8_lcase), collate(utf8_lcase#x, utf8_lcase)) AS btrim(collate(utf8_binary, utf8_lcase), collate(utf8_lcase, utf8_lcase))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select BTRIM(utf8_binary collate unicode_ai, utf8_lcase collate unicode_ai) from t1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"collate(utf8_binary, unicode_ai)\"",
    "inputType" : "\"STRING COLLATE UNICODE_AI\"",
    "paramIndex" : "first",
    "requiredType" : "\"STRING\"",
    "sqlExpr" : "\"TRIM(BOTH collate(utf8_lcase, unicode_ai) FROM collate(utf8_binary, unicode_ai))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 75,
    "fragment" : "BTRIM(utf8_binary collate unicode_ai, utf8_lcase collate unicode_ai)"
  } ]
}


-- !query
select BTRIM(utf8_binary collate utf8_binary_rtrim, utf8_lcase collate utf8_binary_rtrim) from t1
-- !query analysis
Project [btrim(collate(utf8_binary#x, utf8_binary_rtrim), collate(utf8_lcase#x, utf8_binary_rtrim)) AS btrim(collate(utf8_binary, utf8_binary_rtrim), collate(utf8_lcase, utf8_binary_rtrim))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select BTRIM('ABc', utf8_binary), BTRIM('ABc', utf8_lcase) from t1
-- !query analysis
Project [btrim(ABc, utf8_binary#x) AS btrim(ABc, utf8_binary)#x, btrim(ABc, utf8_lcase#x) AS btrim(ABc, utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select BTRIM('ABc' collate utf8_lcase, utf8_binary), BTRIM('AAa' collate utf8_binary, utf8_lcase) from t1
-- !query analysis
Project [btrim(collate(ABc, utf8_lcase), utf8_binary#x) AS btrim(collate(ABc, utf8_lcase), utf8_binary)#x, btrim(collate(AAa, utf8_binary), utf8_lcase#x) AS btrim(collate(AAa, utf8_binary), utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select LTRIM(utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INDETERMINATE_COLLATION_IN_EXPRESSION",
  "sqlState" : "42P22",
  "messageParameters" : {
    "expr" : "\"TRIM(LEADING utf8_binary FROM utf8_lcase)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 37,
    "fragment" : "LTRIM(utf8_binary, utf8_lcase)"
  } ]
}


-- !query
select LTRIM(s, utf8_binary) from t1
-- !query analysis
Project [ltrim(utf8_binary#x, Some(s#x)) AS TRIM(LEADING s FROM utf8_binary)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select LTRIM(utf8_binary collate utf8_binary, s collate utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.EXPLICIT",
  "sqlState" : "42P21",
  "messageParameters" : {
    "explicitTypes" : "\"STRING COLLATE UTF8_LCASE\", \"STRING\""
  }
}


-- !query
select LTRIM(utf8_binary, utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [ltrim(collate(utf8_lcase#x, utf8_binary), Some(utf8_binary#x)) AS TRIM(LEADING utf8_binary FROM collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select LTRIM(utf8_binary collate utf8_lcase, utf8_lcase collate utf8_lcase) from t1
-- !query analysis
Project [ltrim(collate(utf8_lcase#x, utf8_lcase), Some(collate(utf8_binary#x, utf8_lcase))) AS TRIM(LEADING collate(utf8_binary, utf8_lcase) FROM collate(utf8_lcase, utf8_lcase))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select LTRIM(utf8_binary collate unicode_ai, utf8_lcase collate unicode_ai) from t1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"collate(utf8_lcase, unicode_ai)\"",
    "inputType" : "\"STRING COLLATE UNICODE_AI\"",
    "paramIndex" : "first",
    "requiredType" : "\"STRING\"",
    "sqlExpr" : "\"TRIM(LEADING collate(utf8_binary, unicode_ai) FROM collate(utf8_lcase, unicode_ai))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 75,
    "fragment" : "LTRIM(utf8_binary collate unicode_ai, utf8_lcase collate unicode_ai)"
  } ]
}


-- !query
select LTRIM(utf8_binary collate utf8_binary_rtrim, utf8_lcase collate utf8_binary_rtrim) from t1
-- !query analysis
Project [ltrim(collate(utf8_lcase#x, utf8_binary_rtrim), Some(collate(utf8_binary#x, utf8_binary_rtrim))) AS TRIM(LEADING collate(utf8_binary, utf8_binary_rtrim) FROM collate(utf8_lcase, utf8_binary_rtrim))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select LTRIM('ABc', utf8_binary), LTRIM('ABc', utf8_lcase) from t1
-- !query analysis
Project [ltrim(utf8_binary#x, Some(ABc)) AS TRIM(LEADING ABc FROM utf8_binary)#x, ltrim(utf8_lcase#x, Some(ABc)) AS TRIM(LEADING 'ABc' collate UTF8_LCASE FROM utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select LTRIM('ABc' collate utf8_lcase, utf8_binary), LTRIM('AAa' collate utf8_binary, utf8_lcase) from t1
-- !query analysis
Project [ltrim(cast(utf8_binary#x as string collate UTF8_LCASE), Some(collate(ABc, utf8_lcase))) AS TRIM(LEADING collate(ABc, utf8_lcase) FROM utf8_binary)#x, ltrim(cast(utf8_lcase#x as string), Some(collate(AAa, utf8_binary))) AS TRIM(LEADING collate(AAa, utf8_binary) FROM utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select RTRIM(utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INDETERMINATE_COLLATION_IN_EXPRESSION",
  "sqlState" : "42P22",
  "messageParameters" : {
    "expr" : "\"TRIM(TRAILING utf8_binary FROM utf8_lcase)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 37,
    "fragment" : "RTRIM(utf8_binary, utf8_lcase)"
  } ]
}


-- !query
select RTRIM(s, utf8_binary) from t1
-- !query analysis
Project [rtrim(utf8_binary#x, Some(s#x)) AS TRIM(TRAILING s FROM utf8_binary)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select RTRIM(utf8_binary collate utf8_binary, s collate utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.EXPLICIT",
  "sqlState" : "42P21",
  "messageParameters" : {
    "explicitTypes" : "\"STRING COLLATE UTF8_LCASE\", \"STRING\""
  }
}


-- !query
select RTRIM(utf8_binary, utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [rtrim(collate(utf8_lcase#x, utf8_binary), Some(utf8_binary#x)) AS TRIM(TRAILING utf8_binary FROM collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select RTRIM(utf8_binary collate utf8_lcase, utf8_lcase collate utf8_lcase) from t1
-- !query analysis
Project [rtrim(collate(utf8_lcase#x, utf8_lcase), Some(collate(utf8_binary#x, utf8_lcase))) AS TRIM(TRAILING collate(utf8_binary, utf8_lcase) FROM collate(utf8_lcase, utf8_lcase))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select RTRIM(utf8_binary collate unicode_ai, utf8_lcase collate unicode_ai) from t1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"collate(utf8_lcase, unicode_ai)\"",
    "inputType" : "\"STRING COLLATE UNICODE_AI\"",
    "paramIndex" : "first",
    "requiredType" : "\"STRING\"",
    "sqlExpr" : "\"TRIM(TRAILING collate(utf8_binary, unicode_ai) FROM collate(utf8_lcase, unicode_ai))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 75,
    "fragment" : "RTRIM(utf8_binary collate unicode_ai, utf8_lcase collate unicode_ai)"
  } ]
}


-- !query
select RTRIM(utf8_binary collate utf8_binary_rtrim, utf8_lcase collate utf8_binary_rtrim) from t1
-- !query analysis
Project [rtrim(collate(utf8_lcase#x, utf8_binary_rtrim), Some(collate(utf8_binary#x, utf8_binary_rtrim))) AS TRIM(TRAILING collate(utf8_binary, utf8_binary_rtrim) FROM collate(utf8_lcase, utf8_binary_rtrim))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select RTRIM('ABc', utf8_binary), RTRIM('ABc', utf8_lcase) from t1
-- !query analysis
Project [rtrim(utf8_binary#x, Some(ABc)) AS TRIM(TRAILING ABc FROM utf8_binary)#x, rtrim(utf8_lcase#x, Some(ABc)) AS TRIM(TRAILING 'ABc' collate UTF8_LCASE FROM utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select RTRIM('ABc' collate utf8_lcase, utf8_binary), RTRIM('AAa' collate utf8_binary, utf8_lcase) from t1
-- !query analysis
Project [rtrim(cast(utf8_binary#x as string collate UTF8_LCASE), Some(collate(ABc, utf8_lcase))) AS TRIM(TRAILING collate(ABc, utf8_lcase) FROM utf8_binary)#x, rtrim(cast(utf8_lcase#x as string), Some(collate(AAa, utf8_binary))) AS TRIM(TRAILING collate(AAa, utf8_binary) FROM utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1
