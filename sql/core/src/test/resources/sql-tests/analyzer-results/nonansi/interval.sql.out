-- Automatically generated by SQLQueryTestSuite
-- !query
select 3 * (timestamp'2019-10-15 10:11:12.001002' - date'2019-10-15')
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select interval 4 month 2 weeks 3 microseconds * 1.5
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0029",
  "messageParameters" : {
    "literal" : "interval 4 month 2 weeks 3 microseconds"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 46,
    "fragment" : "interval 4 month 2 weeks 3 microseconds"
  } ]
}


-- !query
select interval 2 years 4 months
-- !query analysis
Project [INTERVAL '2-4' YEAR TO MONTH AS INTERVAL '2-4' YEAR TO MONTH#x]
+- OneRowRelation


-- !query
select interval 2 weeks 3 microseconds * 1.5
-- !query analysis
Project [(INTERVAL '14 00:00:00.000003' DAY TO SECOND * 1.5) AS (INTERVAL '14 00:00:00.000003' DAY TO SECOND * 1.5)#x]
+- OneRowRelation


-- !query
select (timestamp'2019-10-15' - timestamp'2019-10-14') / 1.5
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
select interval 2147483647 month * 2
-- !query analysis
Project [(INTERVAL '2147483647' MONTH * 2) AS (INTERVAL '2147483647' MONTH * 2)#x]
+- OneRowRelation


-- !query
select interval 2147483647 month / 0.5
-- !query analysis
Project [(INTERVAL '2147483647' MONTH / 0.5) AS (INTERVAL '2147483647' MONTH / 0.5)#x]
+- OneRowRelation


-- !query
select interval 2147483647 day * 2
-- !query analysis
java.lang.ArithmeticException
long overflow


-- !query
select interval 2147483647 day / 0.5
-- !query analysis
java.lang.ArithmeticException
long overflow


-- !query
select interval 2 second * '2'
-- !query analysis
Project [(INTERVAL '02' SECOND * cast(2 as double)) AS (INTERVAL '02' SECOND * 2)#x]
+- OneRowRelation


-- !query
select interval 2 second / '2'
-- !query analysis
Project [(INTERVAL '02' SECOND / cast(2 as double)) AS (INTERVAL '02' SECOND / 2)#x]
+- OneRowRelation


-- !query
select interval 2 year * '2'
-- !query analysis
Project [(INTERVAL '2' YEAR * cast(2 as double)) AS (INTERVAL '2' YEAR * 2)#x]
+- OneRowRelation


-- !query
select interval 2 year / '2'
-- !query analysis
Project [(INTERVAL '2' YEAR / cast(2 as double)) AS (INTERVAL '2' YEAR / 2)#x]
+- OneRowRelation


-- !query
select interval 2 second * 'a'
-- !query analysis
Project [(INTERVAL '02' SECOND * cast(a as double)) AS (INTERVAL '02' SECOND * a)#x]
+- OneRowRelation


-- !query
select interval 2 second / 'a'
-- !query analysis
Project [(INTERVAL '02' SECOND / cast(a as double)) AS (INTERVAL '02' SECOND / a)#x]
+- OneRowRelation


-- !query
select interval 2 year * 'a'
-- !query analysis
Project [(INTERVAL '2' YEAR * cast(a as double)) AS (INTERVAL '2' YEAR * a)#x]
+- OneRowRelation


-- !query
select interval 2 year / 'a'
-- !query analysis
Project [(INTERVAL '2' YEAR / cast(a as double)) AS (INTERVAL '2' YEAR / a)#x]
+- OneRowRelation


-- !query
select '2' * interval 2 second
-- !query analysis
Project [(INTERVAL '02' SECOND * cast(2 as double)) AS (INTERVAL '02' SECOND * 2)#x]
+- OneRowRelation


-- !query
select '2' * interval 2 year
-- !query analysis
Project [(INTERVAL '2' YEAR * cast(2 as double)) AS (INTERVAL '2' YEAR * 2)#x]
+- OneRowRelation


-- !query
select 'a' * interval 2 second
-- !query analysis
Project [(INTERVAL '02' SECOND * cast(a as double)) AS (INTERVAL '02' SECOND * a)#x]
+- OneRowRelation


-- !query
select 'a' * interval 2 year
-- !query analysis
Project [(INTERVAL '2' YEAR * cast(a as double)) AS (INTERVAL '2' YEAR * a)#x]
+- OneRowRelation


-- !query
select '2' / interval 2 second
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL SECOND\"",
    "sqlExpr" : "\"(2 / INTERVAL '02' SECOND)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "'2' / interval 2 second"
  } ]
}


-- !query
select '2' / interval 2 year
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL YEAR\"",
    "sqlExpr" : "\"(2 / INTERVAL '2' YEAR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 28,
    "fragment" : "'2' / interval 2 year"
  } ]
}


-- !query
select interval '2 seconds' / 0
-- !query analysis
Project [(INTERVAL '02' SECOND / 0) AS (INTERVAL '02' SECOND / 0)#x]
+- OneRowRelation


-- !query
select interval '2 seconds' / null
-- !query analysis
Project [(INTERVAL '02' SECOND / cast(null as double)) AS (INTERVAL '02' SECOND / NULL)#x]
+- OneRowRelation


-- !query
select interval '2 seconds' * null
-- !query analysis
Project [(INTERVAL '02' SECOND * cast(null as double)) AS (INTERVAL '02' SECOND * NULL)#x]
+- OneRowRelation


-- !query
select null * interval '2 seconds'
-- !query analysis
Project [(INTERVAL '02' SECOND * cast(null as double)) AS (INTERVAL '02' SECOND * NULL)#x]
+- OneRowRelation


-- !query
select interval '2' year / 0
-- !query analysis
Project [(INTERVAL '2' YEAR / 0) AS (INTERVAL '2' YEAR / 0)#x]
+- OneRowRelation


-- !query
select interval '2' year / null
-- !query analysis
Project [(INTERVAL '2' YEAR / cast(null as double)) AS (INTERVAL '2' YEAR / NULL)#x]
+- OneRowRelation


-- !query
select interval '2' year * null
-- !query analysis
Project [(INTERVAL '2' YEAR * cast(null as double)) AS (INTERVAL '2' YEAR * NULL)#x]
+- OneRowRelation


-- !query
select null * interval '2' year
-- !query analysis
Project [(INTERVAL '2' YEAR * cast(null as double)) AS (INTERVAL '2' YEAR * NULL)#x]
+- OneRowRelation


-- !query
select 2 / interval '2' year
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INT\"",
    "right" : "\"INTERVAL YEAR\"",
    "sqlExpr" : "\"(2 / INTERVAL '2' YEAR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 28,
    "fragment" : "2 / interval '2' year"
  } ]
}


-- !query
select 2 / interval '2' hour
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INT\"",
    "right" : "\"INTERVAL HOUR\"",
    "sqlExpr" : "\"(2 / INTERVAL '02' HOUR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 28,
    "fragment" : "2 / interval '2' hour"
  } ]
}


-- !query
select null / interval '2' year
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"VOID\"",
    "right" : "\"INTERVAL YEAR\"",
    "sqlExpr" : "\"(NULL / INTERVAL '2' YEAR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "null / interval '2' year"
  } ]
}


-- !query
select null / interval '2' hour
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"VOID\"",
    "right" : "\"INTERVAL HOUR\"",
    "sqlExpr" : "\"(NULL / INTERVAL '02' HOUR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "null / interval '2' hour"
  } ]
}


-- !query
select -interval '-1 month 1 day -1 second'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0029",
  "messageParameters" : {
    "literal" : "interval '-1 month 1 day -1 second'"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 9,
    "stopIndex" : 43,
    "fragment" : "interval '-1 month 1 day -1 second'"
  } ]
}


-- !query
select -interval '-1 year 1 month'
-- !query analysis
Project [-INTERVAL '-0-11' YEAR TO MONTH AS (- INTERVAL '-0-11' YEAR TO MONTH)#x]
+- OneRowRelation


-- !query
select -interval '-1 day 1 hour -1 minute 1 second'
-- !query analysis
Project [-INTERVAL '-0 23:00:59' DAY TO SECOND AS (- INTERVAL '-0 23:00:59' DAY TO SECOND)#x]
+- OneRowRelation


-- !query
select -interval -1 month 1 day -1 second
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0029",
  "messageParameters" : {
    "literal" : "interval -1 month 1 day -1 second"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 9,
    "stopIndex" : 41,
    "fragment" : "interval -1 month 1 day -1 second"
  } ]
}


-- !query
select -interval -1 year 1 month
-- !query analysis
Project [-INTERVAL '-0-11' YEAR TO MONTH AS (- INTERVAL '-0-11' YEAR TO MONTH)#x]
+- OneRowRelation


-- !query
select -interval -1 day 1 hour -1 minute 1 second
-- !query analysis
Project [-INTERVAL '-0 23:00:59' DAY TO SECOND AS (- INTERVAL '-0 23:00:59' DAY TO SECOND)#x]
+- OneRowRelation


-- !query
select +interval '-1 month 1 day -1 second'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0029",
  "messageParameters" : {
    "literal" : "interval '-1 month 1 day -1 second'"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 9,
    "stopIndex" : 43,
    "fragment" : "interval '-1 month 1 day -1 second'"
  } ]
}


-- !query
select +interval '-1 year 1 month'
-- !query analysis
Project [positive(INTERVAL '-0-11' YEAR TO MONTH) AS (+ INTERVAL '-0-11' YEAR TO MONTH)#x]
+- OneRowRelation


-- !query
select +interval '-1 day 1 hour -1 minute 1 second'
-- !query analysis
Project [positive(INTERVAL '-0 23:00:59' DAY TO SECOND) AS (+ INTERVAL '-0 23:00:59' DAY TO SECOND)#x]
+- OneRowRelation


-- !query
select +interval -1 month 1 day -1 second
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0029",
  "messageParameters" : {
    "literal" : "interval -1 month 1 day -1 second"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 9,
    "stopIndex" : 41,
    "fragment" : "interval -1 month 1 day -1 second"
  } ]
}


-- !query
select +interval -1 year 1 month
-- !query analysis
Project [positive(INTERVAL '-0-11' YEAR TO MONTH) AS (+ INTERVAL '-0-11' YEAR TO MONTH)#x]
+- OneRowRelation


-- !query
select +interval -1 day 1 hour -1 minute 1 second
-- !query analysis
Project [positive(INTERVAL '-0 23:00:59' DAY TO SECOND) AS (+ INTERVAL '-0 23:00:59' DAY TO SECOND)#x]
+- OneRowRelation


-- !query
select interval -'1-1' year to month
-- !query analysis
Project [INTERVAL '-1-1' YEAR TO MONTH AS INTERVAL '-1-1' YEAR TO MONTH#x]
+- OneRowRelation


-- !query
select interval -'-1-1' year to month
-- !query analysis
Project [INTERVAL '1-1' YEAR TO MONTH AS INTERVAL '1-1' YEAR TO MONTH#x]
+- OneRowRelation


-- !query
select interval +'-1-1' year to month
-- !query analysis
Project [INTERVAL '-1-1' YEAR TO MONTH AS INTERVAL '-1-1' YEAR TO MONTH#x]
+- OneRowRelation


-- !query
select interval - '1 2:3:4.001' day to second
-- !query analysis
Project [INTERVAL '-1 02:03:04.001' DAY TO SECOND AS INTERVAL '-1 02:03:04.001' DAY TO SECOND#x]
+- OneRowRelation


-- !query
select interval +'1 2:3:4.001' day to second
-- !query analysis
Project [INTERVAL '1 02:03:04.001' DAY TO SECOND AS INTERVAL '1 02:03:04.001' DAY TO SECOND#x]
+- OneRowRelation


-- !query
select interval -'-1 2:3:4.001' day to second
-- !query analysis
Project [INTERVAL '1 02:03:04.001' DAY TO SECOND AS INTERVAL '1 02:03:04.001' DAY TO SECOND#x]
+- OneRowRelation


-- !query
select interval -'1' year
-- !query analysis
Project [INTERVAL '-1' YEAR AS INTERVAL '-1' YEAR#x]
+- OneRowRelation


-- !query
select interval -'-1' year
-- !query analysis
Project [INTERVAL '1' YEAR AS INTERVAL '1' YEAR#x]
+- OneRowRelation


-- !query
select interval -'11' month
-- !query analysis
Project [INTERVAL '-11' MONTH AS INTERVAL '-11' MONTH#x]
+- OneRowRelation


-- !query
select interval -'-11' month
-- !query analysis
Project [INTERVAL '11' MONTH AS INTERVAL '11' MONTH#x]
+- OneRowRelation


-- !query
select interval -'1' day
-- !query analysis
Project [INTERVAL '-1' DAY AS INTERVAL '-1' DAY#x]
+- OneRowRelation


-- !query
select interval -'-1' day
-- !query analysis
Project [INTERVAL '1' DAY AS INTERVAL '1' DAY#x]
+- OneRowRelation


-- !query
select interval -'23' hour
-- !query analysis
Project [INTERVAL '-23' HOUR AS INTERVAL '-23' HOUR#x]
+- OneRowRelation


-- !query
select interval -'-23' hour
-- !query analysis
Project [INTERVAL '23' HOUR AS INTERVAL '23' HOUR#x]
+- OneRowRelation


-- !query
select interval -'59' minute
-- !query analysis
Project [INTERVAL '-59' MINUTE AS INTERVAL '-59' MINUTE#x]
+- OneRowRelation


-- !query
select interval -'-59' minute
-- !query analysis
Project [INTERVAL '59' MINUTE AS INTERVAL '59' MINUTE#x]
+- OneRowRelation


-- !query
select interval -'59' second
-- !query analysis
Project [INTERVAL '-59' SECOND AS INTERVAL '-59' SECOND#x]
+- OneRowRelation


-- !query
select interval -'-59' second
-- !query analysis
Project [INTERVAL '59' SECOND AS INTERVAL '59' SECOND#x]
+- OneRowRelation


-- !query
select make_interval(1)
-- !query analysis
Project [make_interval(1, 0, 0, 0, 0, 0, 0.000000, false) AS make_interval(1, 0, 0, 0, 0, 0, 0.000000)#x]
+- OneRowRelation


-- !query
select make_interval(1, 2)
-- !query analysis
Project [make_interval(1, 2, 0, 0, 0, 0, 0.000000, false) AS make_interval(1, 2, 0, 0, 0, 0, 0.000000)#x]
+- OneRowRelation


-- !query
select make_interval(1, 2, 3)
-- !query analysis
Project [make_interval(1, 2, 3, 0, 0, 0, 0.000000, false) AS make_interval(1, 2, 3, 0, 0, 0, 0.000000)#x]
+- OneRowRelation


-- !query
select make_interval(1, 2, 3, 4)
-- !query analysis
Project [make_interval(1, 2, 3, 4, 0, 0, 0.000000, false) AS make_interval(1, 2, 3, 4, 0, 0, 0.000000)#x]
+- OneRowRelation


-- !query
select make_interval(1, 2, 3, 4, 5)
-- !query analysis
Project [make_interval(1, 2, 3, 4, 5, 0, 0.000000, false) AS make_interval(1, 2, 3, 4, 5, 0, 0.000000)#x]
+- OneRowRelation


-- !query
select make_interval(1, 2, 3, 4, 5, 6)
-- !query analysis
Project [make_interval(1, 2, 3, 4, 5, 6, 0.000000, false) AS make_interval(1, 2, 3, 4, 5, 6, 0.000000)#x]
+- OneRowRelation


-- !query
select make_interval(1, 2, 3, 4, 5, 6, 7.008009)
-- !query analysis
Project [make_interval(1, 2, 3, 4, 5, 6, cast(7.008009 as decimal(18,6)), false) AS make_interval(1, 2, 3, 4, 5, 6, 7.008009)#x]
+- OneRowRelation


-- !query
select make_interval(1, 2, 3, 4, 0, 0, 123456789012.123456)
-- !query analysis
Project [make_interval(1, 2, 3, 4, 0, 0, 123456789012.123456, false) AS make_interval(1, 2, 3, 4, 0, 0, 123456789012.123456)#x]
+- OneRowRelation


-- !query
select make_interval(0, 0, 0, 0, 0, 0, 1234567890123456789)
-- !query analysis
Project [make_interval(0, 0, 0, 0, 0, 0, cast(1234567890123456789 as decimal(18,6)), false) AS make_interval(0, 0, 0, 0, 0, 0, 1234567890123456789)#x]
+- OneRowRelation


-- !query
select make_dt_interval(1)
-- !query analysis
Project [make_dt_interval(1, 0, 0, 0.000000) AS make_dt_interval(1, 0, 0, 0.000000)#x]
+- OneRowRelation


-- !query
select make_dt_interval(1, 2)
-- !query analysis
Project [make_dt_interval(1, 2, 0, 0.000000) AS make_dt_interval(1, 2, 0, 0.000000)#x]
+- OneRowRelation


-- !query
select make_dt_interval(1, 2, 3)
-- !query analysis
Project [make_dt_interval(1, 2, 3, 0.000000) AS make_dt_interval(1, 2, 3, 0.000000)#x]
+- OneRowRelation


-- !query
select make_dt_interval(1, 2, 3, 4.005006)
-- !query analysis
Project [make_dt_interval(1, 2, 3, cast(4.005006 as decimal(18,6))) AS make_dt_interval(1, 2, 3, 4.005006)#x]
+- OneRowRelation


-- !query
select make_dt_interval(1, 0, 0, 123456789012.123456)
-- !query analysis
Project [make_dt_interval(1, 0, 0, 123456789012.123456) AS make_dt_interval(1, 0, 0, 123456789012.123456)#x]
+- OneRowRelation


-- !query
select make_dt_interval(2147483647)
-- !query analysis
Project [make_dt_interval(2147483647, 0, 0, 0.000000) AS make_dt_interval(2147483647, 0, 0, 0.000000)#x]
+- OneRowRelation


-- !query
select make_ym_interval(1)
-- !query analysis
Project [make_ym_interval(1, 0) AS make_ym_interval(1, 0)#x]
+- OneRowRelation


-- !query
select make_ym_interval(1, 2)
-- !query analysis
Project [make_ym_interval(1, 2) AS make_ym_interval(1, 2)#x]
+- OneRowRelation


-- !query
select make_ym_interval(0, 1)
-- !query analysis
Project [make_ym_interval(0, 1) AS make_ym_interval(0, 1)#x]
+- OneRowRelation


-- !query
select make_ym_interval(178956970, 7)
-- !query analysis
Project [make_ym_interval(178956970, 7) AS make_ym_interval(178956970, 7)#x]
+- OneRowRelation


-- !query
select make_ym_interval(178956970, 8)
-- !query analysis
Project [make_ym_interval(178956970, 8) AS make_ym_interval(178956970, 8)#x]
+- OneRowRelation


-- !query
select make_ym_interval(-178956970, -8)
-- !query analysis
Project [make_ym_interval(-178956970, -8) AS make_ym_interval(-178956970, -8)#x]
+- OneRowRelation


-- !query
select make_ym_interval(-178956970, -9)
-- !query analysis
Project [make_ym_interval(-178956970, -9) AS make_ym_interval(-178956970, -9)#x]
+- OneRowRelation


-- !query
select cast('1 second' as interval)
-- !query analysis
Project [cast(1 second as interval) AS CAST(1 second AS INTERVAL)#x]
+- OneRowRelation


-- !query
select cast('+1 second' as interval)
-- !query analysis
Project [cast(+1 second as interval) AS CAST(+1 second AS INTERVAL)#x]
+- OneRowRelation


-- !query
select cast('-1 second' as interval)
-- !query analysis
Project [cast(-1 second as interval) AS CAST(-1 second AS INTERVAL)#x]
+- OneRowRelation


-- !query
select cast('+     1 second' as interval)
-- !query analysis
Project [cast(+     1 second as interval) AS CAST(+     1 second AS INTERVAL)#x]
+- OneRowRelation


-- !query
select cast('-     1 second' as interval)
-- !query analysis
Project [cast(-     1 second as interval) AS CAST(-     1 second AS INTERVAL)#x]
+- OneRowRelation


-- !query
select cast('- -1 second' as interval)
-- !query analysis
Project [cast(- -1 second as interval) AS CAST(- -1 second AS INTERVAL)#x]
+- OneRowRelation


-- !query
select cast('- +1 second' as interval)
-- !query analysis
Project [cast(- +1 second as interval) AS CAST(- +1 second AS INTERVAL)#x]
+- OneRowRelation


-- !query
select interval 13.123456789 seconds, interval -13.123456789 second
-- !query analysis
Project [INTERVAL '13.123456' SECOND AS INTERVAL '13.123456' SECOND#x, INTERVAL '-13.123456' SECOND AS INTERVAL '-13.123456' SECOND#x]
+- OneRowRelation


-- !query
select interval 1 year 2 month 3 week 4 day 5 hour 6 minute 7 seconds 8 millisecond 9 microsecond
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0029",
  "messageParameters" : {
    "literal" : "interval 1 year 2 month 3 week 4 day 5 hour 6 minute 7 seconds 8 millisecond 9 microsecond"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 97,
    "fragment" : "interval 1 year 2 month 3 week 4 day 5 hour 6 minute 7 seconds 8 millisecond 9 microsecond"
  } ]
}


-- !query
select interval 1 year 2 month
-- !query analysis
Project [INTERVAL '1-2' YEAR TO MONTH AS INTERVAL '1-2' YEAR TO MONTH#x]
+- OneRowRelation


-- !query
select interval 4 day 5 hour 6 minute 7 seconds
-- !query analysis
Project [INTERVAL '4 05:06:07' DAY TO SECOND AS INTERVAL '4 05:06:07' DAY TO SECOND#x]
+- OneRowRelation


-- !query
select interval 3 week 8 millisecond 9 microsecond
-- !query analysis
Project [INTERVAL '21 00:00:00.008009' DAY TO SECOND AS INTERVAL '21 00:00:00.008009' DAY TO SECOND#x]
+- OneRowRelation


-- !query
select interval '30' year '25' month '-100' day '40' hour '80' minute '299.889987299' second
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0029",
  "messageParameters" : {
    "literal" : "interval '30' year '25' month '-100' day '40' hour '80' minute '299.889987299' second"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 92,
    "fragment" : "interval '30' year '25' month '-100' day '40' hour '80' minute '299.889987299' second"
  } ]
}


-- !query
select interval '30' year '25' month
-- !query analysis
Project [INTERVAL '32-1' YEAR TO MONTH AS INTERVAL '32-1' YEAR TO MONTH#x]
+- OneRowRelation


-- !query
select interval '-100' day '40' hour '80' minute '299.889987299' second
-- !query analysis
Project [INTERVAL '-98 06:35:00.110013' DAY TO SECOND AS INTERVAL '-98 06:35:00.110013' DAY TO SECOND#x]
+- OneRowRelation


-- !query
select interval '0-0' year to month
-- !query analysis
Project [INTERVAL '0-0' YEAR TO MONTH AS INTERVAL '0-0' YEAR TO MONTH#x]
+- OneRowRelation


-- !query
select interval '0 0:0:0' day to second
-- !query analysis
Project [INTERVAL '0 00:00:00' DAY TO SECOND AS INTERVAL '0 00:00:00' DAY TO SECOND#x]
+- OneRowRelation


-- !query
select interval '0 0:0:0.1' day to second
-- !query analysis
Project [INTERVAL '0 00:00:00.1' DAY TO SECOND AS INTERVAL '0 00:00:00.1' DAY TO SECOND#x]
+- OneRowRelation


-- !query
select interval '10-9' year to month
-- !query analysis
Project [INTERVAL '10-9' YEAR TO MONTH AS INTERVAL '10-9' YEAR TO MONTH#x]
+- OneRowRelation


-- !query
select interval '20 15' day to hour
-- !query analysis
Project [INTERVAL '20 15' DAY TO HOUR AS INTERVAL '20 15' DAY TO HOUR#x]
+- OneRowRelation


-- !query
select interval '20 15:40' day to minute
-- !query analysis
Project [INTERVAL '20 15:40' DAY TO MINUTE AS INTERVAL '20 15:40' DAY TO MINUTE#x]
+- OneRowRelation


-- !query
select interval '20 15:40:32.99899999' day to second
-- !query analysis
Project [INTERVAL '20 15:40:32.998999' DAY TO SECOND AS INTERVAL '20 15:40:32.998999' DAY TO SECOND#x]
+- OneRowRelation


-- !query
select interval '15:40' hour to minute
-- !query analysis
Project [INTERVAL '15:40' HOUR TO MINUTE AS INTERVAL '15:40' HOUR TO MINUTE#x]
+- OneRowRelation


-- !query
select interval '15:40:32.99899999' hour to second
-- !query analysis
Project [INTERVAL '15:40:32.998999' HOUR TO SECOND AS INTERVAL '15:40:32.998999' HOUR TO SECOND#x]
+- OneRowRelation


-- !query
select interval '40:32.99899999' minute to second
-- !query analysis
Project [INTERVAL '40:32.998999' MINUTE TO SECOND AS INTERVAL '40:32.998999' MINUTE TO SECOND#x]
+- OneRowRelation


-- !query
select interval '40:32' minute to second
-- !query analysis
Project [INTERVAL '40:32' MINUTE TO SECOND AS INTERVAL '40:32' MINUTE TO SECOND#x]
+- OneRowRelation


-- !query
select interval 30 day day
-- !query analysis
Project [INTERVAL '30' DAY AS day#x]
+- OneRowRelation


-- !query
select interval 30 days days
-- !query analysis
Project [INTERVAL '30' DAY AS days#x]
+- OneRowRelation


-- !query
select interval '20 15:40:32.99899999' day to hour
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_INTERVAL_FORMAT.UNMATCHED_FORMAT_STRING_WITH_NOTICE",
  "sqlState" : "22006",
  "messageParameters" : {
    "input" : "20 15:40:32.99899999",
    "intervalStr" : "day-time",
    "supportedFormat" : "`[+|-]d h`, `INTERVAL [+|-]'[+|-]d h' DAY TO HOUR`",
    "typeName" : "interval day to hour"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 50,
    "fragment" : "'20 15:40:32.99899999' day to hour"
  } ]
}


-- !query
select interval '20 15:40:32.99899999' day to minute
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_INTERVAL_FORMAT.UNMATCHED_FORMAT_STRING_WITH_NOTICE",
  "sqlState" : "22006",
  "messageParameters" : {
    "input" : "20 15:40:32.99899999",
    "intervalStr" : "day-time",
    "supportedFormat" : "`[+|-]d h:m`, `INTERVAL [+|-]'[+|-]d h:m' DAY TO MINUTE`",
    "typeName" : "interval day to minute"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 52,
    "fragment" : "'20 15:40:32.99899999' day to minute"
  } ]
}


-- !query
select interval '15:40:32.99899999' hour to minute
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_INTERVAL_FORMAT.UNMATCHED_FORMAT_STRING_WITH_NOTICE",
  "sqlState" : "22006",
  "messageParameters" : {
    "input" : "15:40:32.99899999",
    "intervalStr" : "day-time",
    "supportedFormat" : "`[+|-]h:m`, `INTERVAL [+|-]'[+|-]h:m' HOUR TO MINUTE`",
    "typeName" : "interval hour to minute"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 50,
    "fragment" : "'15:40:32.99899999' hour to minute"
  } ]
}


-- !query
select interval '15:40.99899999' hour to second
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_INTERVAL_FORMAT.UNMATCHED_FORMAT_STRING_WITH_NOTICE",
  "sqlState" : "22006",
  "messageParameters" : {
    "input" : "15:40.99899999",
    "intervalStr" : "day-time",
    "supportedFormat" : "`[+|-]h:m:s.n`, `INTERVAL [+|-]'[+|-]h:m:s.n' HOUR TO SECOND`",
    "typeName" : "interval hour to second"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 47,
    "fragment" : "'15:40.99899999' hour to second"
  } ]
}


-- !query
select interval '15:40' hour to second
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_INTERVAL_FORMAT.UNMATCHED_FORMAT_STRING_WITH_NOTICE",
  "sqlState" : "22006",
  "messageParameters" : {
    "input" : "15:40",
    "intervalStr" : "day-time",
    "supportedFormat" : "`[+|-]h:m:s.n`, `INTERVAL [+|-]'[+|-]h:m:s.n' HOUR TO SECOND`",
    "typeName" : "interval hour to second"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 38,
    "fragment" : "'15:40' hour to second"
  } ]
}


-- !query
select interval '20 40:32.99899999' minute to second
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_INTERVAL_FORMAT.UNMATCHED_FORMAT_STRING_WITH_NOTICE",
  "sqlState" : "22006",
  "messageParameters" : {
    "input" : "20 40:32.99899999",
    "intervalStr" : "day-time",
    "supportedFormat" : "`[+|-]m:s.n`, `INTERVAL [+|-]'[+|-]m:s.n' MINUTE TO SECOND`",
    "typeName" : "interval minute to second"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 52,
    "fragment" : "'20 40:32.99899999' minute to second"
  } ]
}


-- !query
select interval 10 nanoseconds
-- !query analysis
org.apache.spark.SparkIllegalArgumentException
{
  "errorClass" : "INVALID_INTERVAL_FORMAT.INVALID_UNIT",
  "sqlState" : "22006",
  "messageParameters" : {
    "input" : " 10 nanoseconds",
    "unit" : "nanoseconds"
  }
}


-- !query
select map(1, interval 1 day, 2, interval 3 week)
-- !query analysis
Project [map(1, INTERVAL '1' DAY, 2, INTERVAL '21' DAY) AS map(1, INTERVAL '1' DAY, 2, INTERVAL '21' DAY)#x]
+- OneRowRelation


-- !query
select map(1, interval 1 day, 2, interval 2 day)
-- !query analysis
Project [map(1, INTERVAL '1' DAY, 2, INTERVAL '2' DAY) AS map(1, INTERVAL '1' DAY, 2, INTERVAL '2' DAY)#x]
+- OneRowRelation


-- !query
select map(1, interval 1 year, 2, interval 2 month)
-- !query analysis
Project [map(1, cast(INTERVAL '1' YEAR as interval year to month), 2, cast(INTERVAL '2' MONTH as interval year to month)) AS map(1, INTERVAL '1' YEAR, 2, INTERVAL '2' MONTH)#x]
+- OneRowRelation


-- !query
select map(1, interval 1 month, 2, interval 2 month)
-- !query analysis
Project [map(1, INTERVAL '1' MONTH, 2, INTERVAL '2' MONTH) AS map(1, INTERVAL '1' MONTH, 2, INTERVAL '2' MONTH)#x]
+- OneRowRelation


-- !query
select map(1, interval 1 week, 2, interval 2 day)
-- !query analysis
Project [map(1, INTERVAL '7' DAY, 2, INTERVAL '2' DAY) AS map(1, INTERVAL '7' DAY, 2, INTERVAL '2' DAY)#x]
+- OneRowRelation


-- !query
select map(1, interval 2 millisecond, 3, interval 3 microsecond)
-- !query analysis
Project [map(1, INTERVAL '00.002' SECOND, 3, INTERVAL '00.000003' SECOND) AS map(1, INTERVAL '00.002' SECOND, 3, INTERVAL '00.000003' SECOND)#x]
+- OneRowRelation


-- !query
select interval 'interval 3 year 1 month'
-- !query analysis
Project [INTERVAL '3-1' YEAR TO MONTH AS INTERVAL '3-1' YEAR TO MONTH#x]
+- OneRowRelation


-- !query
select interval '3 year 1 month'
-- !query analysis
Project [INTERVAL '3-1' YEAR TO MONTH AS INTERVAL '3-1' YEAR TO MONTH#x]
+- OneRowRelation


-- !query
SELECT interval 'interval 2 weeks 2 days 1 hour 3 minutes 2 seconds 100 millisecond 200 microseconds'
-- !query analysis
Project [INTERVAL '16 01:03:02.1002' DAY TO SECOND AS INTERVAL '16 01:03:02.1002' DAY TO SECOND#x]
+- OneRowRelation


-- !query
SELECT interval '2 weeks 2 days 1 hour 3 minutes 2 seconds 100 millisecond 200 microseconds'
-- !query analysis
Project [INTERVAL '16 01:03:02.1002' DAY TO SECOND AS INTERVAL '16 01:03:02.1002' DAY TO SECOND#x]
+- OneRowRelation


-- !query
select interval 1 fake_unit
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'fake_unit'",
    "hint" : ""
  }
}


-- !query
select interval 1 year to month
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0027",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 31,
    "fragment" : "1 year to month"
  } ]
}


-- !query
select interval '1' year to second
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_INTERVAL_FORMAT.UNSUPPORTED_FROM_TO_EXPRESSION",
  "sqlState" : "22006",
  "messageParameters" : {
    "from" : "year",
    "input" : "1",
    "to" : "second"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 34,
    "fragment" : "'1' year to second"
  } ]
}


-- !query
select interval '10-9' year to month '2-1' year to month
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0024",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 56,
    "fragment" : "interval '10-9' year to month '2-1' year to month"
  } ]
}


-- !query
select interval '10-9' year to month '12:11:10' hour to second
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0024",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 62,
    "fragment" : "interval '10-9' year to month '12:11:10' hour to second"
  } ]
}


-- !query
select interval '1 15:11' day to minute '12:11:10' hour to second
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0024",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 65,
    "fragment" : "interval '1 15:11' day to minute '12:11:10' hour to second"
  } ]
}


-- !query
select interval 1 year '2-1' year to month
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0024",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 42,
    "fragment" : "interval 1 year '2-1' year to month"
  } ]
}


-- !query
select interval 1 year '12:11:10' hour to second
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0024",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 48,
    "fragment" : "interval 1 year '12:11:10' hour to second"
  } ]
}


-- !query
select interval '10-9' year to month '1' year
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0024",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 45,
    "fragment" : "interval '10-9' year to month '1' year"
  } ]
}


-- !query
select interval '12:11:10' hour to second '1' year
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0024",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 50,
    "fragment" : "interval '12:11:10' hour to second '1' year"
  } ]
}


-- !query
select interval (-30) day
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`interval`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 21,
    "fragment" : "interval (-30)"
  } ]
}


-- !query
select interval (a + 1) day
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`interval`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 23,
    "fragment" : "interval (a + 1)"
  } ]
}


-- !query
select interval 30 day day day
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'day'",
    "hint" : ": extra input 'day'"
  }
}


-- !query
select interval (-30) days
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`interval`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 21,
    "fragment" : "interval (-30)"
  } ]
}


-- !query
select interval (a + 1) days
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`interval`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 23,
    "fragment" : "interval (a + 1)"
  } ]
}


-- !query
select interval 30 days days days
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'days'",
    "hint" : ": extra input 'days'"
  }
}


-- !query
SELECT INTERVAL '178956970-7' YEAR TO MONTH
-- !query analysis
Project [INTERVAL '178956970-7' YEAR TO MONTH AS INTERVAL '178956970-7' YEAR TO MONTH#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '178956970-8' YEAR TO MONTH
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_INTERVAL_FORMAT.INTERVAL_PARSING",
  "sqlState" : "22006",
  "messageParameters" : {
    "input" : "178956970-8",
    "interval" : "year-month"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 43,
    "fragment" : "'178956970-8' YEAR TO MONTH"
  } ]
}


-- !query
SELECT INTERVAL '-178956970-8' YEAR TO MONTH
-- !query analysis
Project [INTERVAL '-178956970-8' YEAR TO MONTH AS INTERVAL '-178956970-8' YEAR TO MONTH#x]
+- OneRowRelation


-- !query
SELECT INTERVAL -'178956970-8' YEAR TO MONTH
-- !query analysis
Project [INTERVAL '-178956970-8' YEAR TO MONTH AS INTERVAL '-178956970-8' YEAR TO MONTH#x]
+- OneRowRelation


-- !query
select
  interval '2-2' year to month + interval '3' month,
  interval '2' year - interval '3-3' year to month,
  interval '99 11:22:33.123456789' day to second + interval '10 9:8' day to minute,
  interval '22:33.123456789' minute to second - interval '10' day
-- !query analysis
Project [(INTERVAL '2-2' YEAR TO MONTH + cast(INTERVAL '3' MONTH as interval year to month)) AS (INTERVAL '2-2' YEAR TO MONTH + INTERVAL '3' MONTH)#x, (cast(INTERVAL '2' YEAR as interval year to month) - INTERVAL '3-3' YEAR TO MONTH) AS (INTERVAL '2' YEAR - INTERVAL '3-3' YEAR TO MONTH)#x, (INTERVAL '99 11:22:33.123456' DAY TO SECOND + cast(INTERVAL '10 09:08' DAY TO MINUTE as interval day to second)) AS (INTERVAL '99 11:22:33.123456' DAY TO SECOND + INTERVAL '10 09:08' DAY TO MINUTE)#x, (cast(INTERVAL '22:33.123456' MINUTE TO SECOND as interval day to second) - cast(INTERVAL '10' DAY as interval day to second)) AS (INTERVAL '22:33.123456' MINUTE TO SECOND - INTERVAL '10' DAY)#x]
+- OneRowRelation


-- !query
select
  interval '2' year + '3-3 year to month',
  interval '2' year - '3 month',
  '3-2 year to month' + interval '2-2' year to month,
  '3 year' - interval '2-2' year to month,
  interval '99 11:22:33.123456789' day to second + '12:12 hour to second',
  interval '99 11:22:33.123456789' day to second - '12 hour',
  '4 day' + interval '10' day,
  '4 22 day to hour' - interval '10' day
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '2' YEAR + 3-3 year to month)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 48,
    "fragment" : "interval '2' year + '3-3 year to month'"
  } ]
}


-- !query
select
  interval '2' year + null,
  interval '2' year - null,
  interval '2' hour + null,
  interval '2' hour - null,
  null + interval '2' year,
  null - interval '2' year,
  null + interval '2' hour,
  null - interval '2' hour
-- !query analysis
Project [(INTERVAL '2' YEAR + cast(null as interval year)) AS (INTERVAL '2' YEAR + NULL)#x, (INTERVAL '2' YEAR - cast(null as interval year)) AS (INTERVAL '2' YEAR - NULL)#x, (INTERVAL '02' HOUR + cast(null as interval hour)) AS (INTERVAL '02' HOUR + NULL)#x, (INTERVAL '02' HOUR - cast(null as interval hour)) AS (INTERVAL '02' HOUR - NULL)#x, (cast(null as interval year) + INTERVAL '2' YEAR) AS (NULL + INTERVAL '2' YEAR)#x, (cast(null as interval year) - INTERVAL '2' YEAR) AS (NULL - INTERVAL '2' YEAR)#x, (cast(null as interval hour) + INTERVAL '02' HOUR) AS (NULL + INTERVAL '02' HOUR)#x, (cast(null as interval hour) - INTERVAL '02' HOUR) AS (NULL - INTERVAL '02' HOUR)#x]
+- OneRowRelation


-- !query
select interval '2' year + '3-3'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '2' YEAR + 3-3)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 32,
    "fragment" : "interval '2' year + '3-3'"
  } ]
}


-- !query
select interval '2' year - '4'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '2' YEAR - 4)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "interval '2' year - '4'"
  } ]
}


-- !query
select '4 11:11' - interval '4 22:12' day to minute
-- !query analysis
Project [cast(4 11:11 - INTERVAL '4 22:12' DAY TO MINUTE as string) AS 4 11:11 - INTERVAL '4 22:12' DAY TO MINUTE#x]
+- OneRowRelation


-- !query
select '4 12:12:12' + interval '4 22:12' day to minute
-- !query analysis
Project [cast(cast(4 12:12:12 as timestamp) + INTERVAL '4 22:12' DAY TO MINUTE as string) AS 4 12:12:12 + INTERVAL '4 22:12' DAY TO MINUTE#x]
+- OneRowRelation


-- !query
create temporary view interval_view as select '1' str
-- !query analysis
CreateViewCommand `interval_view`, select '1' str, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [1 AS str#x]
      +- OneRowRelation


-- !query
select interval '2' year + str from interval_view
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '2' YEAR + str)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "interval '2' year + str"
  } ]
}


-- !query
select interval '2' year - str from interval_view
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '2' YEAR - str)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "interval '2' year - str"
  } ]
}


-- !query
select str - interval '4 22:12' day to minute from interval_view
-- !query analysis
Project [cast(str#x - INTERVAL '4 22:12' DAY TO MINUTE as string) AS str - INTERVAL '4 22:12' DAY TO MINUTE#x]
+- SubqueryAlias interval_view
   +- View (`interval_view`, [str#x])
      +- Project [cast(str#x as string) AS str#x]
         +- Project [1 AS str#x]
            +- OneRowRelation


-- !query
select str + interval '4 22:12' day to minute from interval_view
-- !query analysis
Project [cast(cast(str#x as timestamp) + INTERVAL '4 22:12' DAY TO MINUTE as string) AS str + INTERVAL '4 22:12' DAY TO MINUTE#x]
+- SubqueryAlias interval_view
   +- View (`interval_view`, [str#x])
      +- Project [cast(str#x as string) AS str#x]
         +- Project [1 AS str#x]
            +- OneRowRelation


-- !query
select interval '2-2' year to month + interval '3' day
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"INTERVAL '2-2' YEAR TO MONTH\"",
    "inputType" : "\"INTERVAL YEAR TO MONTH\"",
    "paramIndex" : "first",
    "requiredType" : "\"(TIMESTAMP OR TIMESTAMP WITHOUT TIME ZONE)\"",
    "sqlExpr" : "\"INTERVAL '2-2' YEAR TO MONTH + INTERVAL '3' DAY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 54,
    "fragment" : "interval '2-2' year to month + interval '3' day"
  } ]
}


-- !query
select interval '3' day + interval '2-2' year to month
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"INTERVAL '2-2' YEAR TO MONTH\"",
    "inputType" : "\"INTERVAL YEAR TO MONTH\"",
    "paramIndex" : "first",
    "requiredType" : "\"(TIMESTAMP OR TIMESTAMP WITHOUT TIME ZONE)\"",
    "sqlExpr" : "\"INTERVAL '2-2' YEAR TO MONTH + INTERVAL '3' DAY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 54,
    "fragment" : "interval '3' day + interval '2-2' year to month"
  } ]
}


-- !query
select interval '2-2' year to month - interval '3' day
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"INTERVAL '2-2' YEAR TO MONTH\"",
    "inputType" : "\"INTERVAL YEAR TO MONTH\"",
    "paramIndex" : "first",
    "requiredType" : "\"(TIMESTAMP OR TIMESTAMP WITHOUT TIME ZONE)\"",
    "sqlExpr" : "\"INTERVAL '2-2' YEAR TO MONTH + (- INTERVAL '3' DAY)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 54,
    "fragment" : "interval '2-2' year to month - interval '3' day"
  } ]
}


-- !query
select interval '3' day - interval '2-2' year to month
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL DAY\"",
    "right" : "\"INTERVAL YEAR TO MONTH\"",
    "sqlExpr" : "\"(INTERVAL '3' DAY - INTERVAL '2-2' YEAR TO MONTH)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 54,
    "fragment" : "interval '3' day - interval '2-2' year to month"
  } ]
}


-- !query
select 1 - interval '2' second
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"1\"",
    "inputType" : "\"INT\"",
    "paramIndex" : "first",
    "requiredType" : "\"(TIMESTAMP OR TIMESTAMP WITHOUT TIME ZONE)\"",
    "sqlExpr" : "\"1 + (- INTERVAL '02' SECOND)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "1 - interval '2' second"
  } ]
}


-- !query
select 1 + interval '2' month
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INT\"",
    "right" : "\"INTERVAL MONTH\"",
    "sqlExpr" : "\"(1 + INTERVAL '2' MONTH)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "1 + interval '2' month"
  } ]
}


-- !query
select interval '2' second + 1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"1\"",
    "inputType" : "\"INT\"",
    "paramIndex" : "first",
    "requiredType" : "\"(TIMESTAMP OR TIMESTAMP WITHOUT TIME ZONE)\"",
    "sqlExpr" : "\"1 + INTERVAL '02' SECOND\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "interval '2' second + 1"
  } ]
}


-- !query
select interval '2' month - 1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL MONTH\"",
    "right" : "\"INT\"",
    "sqlExpr" : "\"(INTERVAL '2' MONTH - 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "interval '2' month - 1"
  } ]
}


-- !query
select interval '\t interval 1 day'
-- !query analysis
Project [INTERVAL '1' DAY AS INTERVAL '1' DAY#x]
+- OneRowRelation


-- !query
select interval 'interval \t 1\tday'
-- !query analysis
Project [INTERVAL '1' DAY AS INTERVAL '1' DAY#x]
+- OneRowRelation


-- !query
select interval 'interval\t1\tday'
-- !query analysis
Project [INTERVAL '1' DAY AS INTERVAL '1' DAY#x]
+- OneRowRelation


-- !query
select interval '1\t' day
-- !query analysis
Project [INTERVAL '1' DAY AS INTERVAL '1' DAY#x]
+- OneRowRelation


-- !query
select interval '1 ' day
-- !query analysis
Project [INTERVAL '1' DAY AS INTERVAL '1' DAY#x]
+- OneRowRelation


-- !query
select interval '2-2\t' year to month
-- !query analysis
Project [INTERVAL '2-2' YEAR TO MONTH AS INTERVAL '2-2' YEAR TO MONTH#x]
+- OneRowRelation


-- !query
select interval '-\t2-2\t' year to month
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_INTERVAL_FORMAT.UNMATCHED_FORMAT_STRING",
  "sqlState" : "22006",
  "messageParameters" : {
    "input" : "-\t2-2\t",
    "intervalStr" : "year-month",
    "supportedFormat" : "`[+|-]y-m`, `INTERVAL [+|-]'[+|-]y-m' YEAR TO MONTH`",
    "typeName" : "interval year to month"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 40,
    "fragment" : "'-\\t2-2\\t' year to month"
  } ]
}


-- !query
select interval '\n0 12:34:46.789\t' day to second
-- !query analysis
Project [INTERVAL '0 12:34:46.789' DAY TO SECOND AS INTERVAL '0 12:34:46.789' DAY TO SECOND#x]
+- OneRowRelation


-- !query
select interval '\n-\t10\t 12:34:46.789\t' day to second
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_INTERVAL_FORMAT.UNMATCHED_FORMAT_STRING_WITH_NOTICE",
  "sqlState" : "22006",
  "messageParameters" : {
    "input" : "\n-\t10\t 12:34:46.789\t",
    "intervalStr" : "day-time",
    "supportedFormat" : "`[+|-]d h:m:s.n`, `INTERVAL [+|-]'[+|-]d h:m:s.n' DAY TO SECOND`",
    "typeName" : "interval day to second"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 56,
    "fragment" : "'\\n-\\t10\\t 12:34:46.789\\t' day to second"
  } ]
}


-- !query
select interval '中文 interval 1 day'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'中文 interval 1 day'",
    "valueType" : "\"INTERVAL\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 35,
    "fragment" : "interval '中文 interval 1 day'"
  } ]
}


-- !query
select interval 'interval中文 1 day'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'interval中文 1 day'",
    "valueType" : "\"INTERVAL\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 34,
    "fragment" : "interval 'interval中文 1 day'"
  } ]
}


-- !query
select interval 'interval 1中文day'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'interval 1中文day'",
    "valueType" : "\"INTERVAL\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 33,
    "fragment" : "interval 'interval 1中文day'"
  } ]
}


-- !query
select -(a) from values (interval '-2147483648 months', interval '2147483647 months') t(a, b)
-- !query analysis
Project [-a#x AS (- a)#x]
+- SubqueryAlias t
   +- LocalRelation [a#x, b#x]


-- !query
select a - b from values (interval '-2147483648 months', interval '2147483647 months') t(a, b)
-- !query analysis
Project [(a#x - b#x) AS (a - b)#x]
+- SubqueryAlias t
   +- LocalRelation [a#x, b#x]


-- !query
select b + interval '1 month' from values (interval '-2147483648 months', interval '2147483647 months') t(a, b)
-- !query analysis
Project [(b#x + INTERVAL '1' MONTH) AS (b + INTERVAL '1' MONTH)#x]
+- SubqueryAlias t
   +- LocalRelation [a#x, b#x]


-- !query
select a * 1.1 from values (interval '-2147483648 months', interval '2147483647 months') t(a, b)
-- !query analysis
Project [(a#x * 1.1) AS (a * 1.1)#x]
+- SubqueryAlias t
   +- LocalRelation [a#x, b#x]


-- !query
select a / 0.5 from values (interval '-2147483648 months', interval '2147483647 months') t(a, b)
-- !query analysis
Project [(a#x / 0.5) AS (a / 0.5)#x]
+- SubqueryAlias t
   +- LocalRelation [a#x, b#x]


-- !query
SELECT
  from_csv('1, 1 day', 'a INT, b interval'),
  from_csv('1, 1', 'a INT, b interval day'),
  to_csv(from_csv('1, 1 day', 'a INT, b interval')),
  to_csv(from_csv('1, 1', 'a INT, b interval day')),
  to_csv(named_struct('a', interval 32 hour, 'b', interval 70 minute)),
  from_csv(to_csv(named_struct('a', interval 32 hour, 'b', interval 70 minute)), 'a interval hour, b interval minute')
-- !query analysis
Project [from_csv(StructField(a,IntegerType,true), StructField(b,CalendarIntervalType,true), 1, 1 day, Some(America/Los_Angeles), None) AS from_csv(1, 1 day)#x, from_csv(StructField(a,IntegerType,true), StructField(b,DayTimeIntervalType(0,0),true), 1, 1, Some(America/Los_Angeles), None) AS from_csv(1, 1)#x, to_csv(from_csv(StructField(a,IntegerType,true), StructField(b,CalendarIntervalType,true), 1, 1 day, Some(America/Los_Angeles), None), Some(America/Los_Angeles)) AS to_csv(from_csv(1, 1 day))#x, to_csv(from_csv(StructField(a,IntegerType,true), StructField(b,DayTimeIntervalType(0,0),true), 1, 1, Some(America/Los_Angeles), None), Some(America/Los_Angeles)) AS to_csv(from_csv(1, 1))#x, to_csv(named_struct(a, INTERVAL '32' HOUR, b, INTERVAL '70' MINUTE), Some(America/Los_Angeles)) AS to_csv(named_struct(a, INTERVAL '32' HOUR, b, INTERVAL '70' MINUTE))#x, from_csv(StructField(a,DayTimeIntervalType(1,1),true), StructField(b,DayTimeIntervalType(2,2),true), to_csv(named_struct(a, INTERVAL '32' HOUR, b, INTERVAL '70' MINUTE), Some(America/Los_Angeles)), Some(America/Los_Angeles), None) AS from_csv(to_csv(named_struct(a, INTERVAL '32' HOUR, b, INTERVAL '70' MINUTE)))#x]
+- OneRowRelation


-- !query
SELECT
  from_json('{"a":"1 days"}', 'a interval'),
  from_csv('1, 1', 'a INT, b interval year'),
  to_json(from_json('{"a":"1 days"}', 'a interval')),
  to_csv(from_csv('1, 1', 'a INT, b interval year')),
  to_csv(named_struct('a', interval 32 year, 'b', interval 10 month)),
  from_csv(to_csv(named_struct('a', interval 32 year, 'b', interval 10 month)), 'a interval year, b interval month')
-- !query analysis
Project [from_json(StructField(a,CalendarIntervalType,true), {"a":"1 days"}, Some(America/Los_Angeles), false) AS from_json({"a":"1 days"})#x, from_csv(StructField(a,IntegerType,true), StructField(b,YearMonthIntervalType(0,0),true), 1, 1, Some(America/Los_Angeles), None) AS from_csv(1, 1)#x, to_json(from_json(StructField(a,CalendarIntervalType,true), {"a":"1 days"}, Some(America/Los_Angeles), false), Some(America/Los_Angeles)) AS to_json(from_json({"a":"1 days"}))#x, to_csv(from_csv(StructField(a,IntegerType,true), StructField(b,YearMonthIntervalType(0,0),true), 1, 1, Some(America/Los_Angeles), None), Some(America/Los_Angeles)) AS to_csv(from_csv(1, 1))#x, to_csv(named_struct(a, INTERVAL '32' YEAR, b, INTERVAL '10' MONTH), Some(America/Los_Angeles)) AS to_csv(named_struct(a, INTERVAL '32' YEAR, b, INTERVAL '10' MONTH))#x, from_csv(StructField(a,YearMonthIntervalType(0,0),true), StructField(b,YearMonthIntervalType(1,1),true), to_csv(named_struct(a, INTERVAL '32' YEAR, b, INTERVAL '10' MONTH), Some(America/Los_Angeles)), Some(America/Los_Angeles), None) AS from_csv(to_csv(named_struct(a, INTERVAL '32' YEAR, b, INTERVAL '10' MONTH)))#x]
+- OneRowRelation


-- !query
SELECT
  from_json('{"a":"1"}', 'a interval day'),
  to_json(from_json('{"a":"1"}', 'a interval day')),
  to_json(map('a', interval 100 day 130 minute)),
  from_json(to_json(map('a', interval 100 day 130 minute)), 'a interval day to minute')
-- !query analysis
Project [from_json(StructField(a,DayTimeIntervalType(0,0),true), {"a":"1"}, Some(America/Los_Angeles), false) AS from_json({"a":"1"})#x, to_json(from_json(StructField(a,DayTimeIntervalType(0,0),true), {"a":"1"}, Some(America/Los_Angeles), false), Some(America/Los_Angeles)) AS to_json(from_json({"a":"1"}))#x, to_json(map(a, INTERVAL '100 02:10' DAY TO MINUTE), Some(America/Los_Angeles)) AS to_json(map(a, INTERVAL '100 02:10' DAY TO MINUTE))#x, from_json(StructField(a,DayTimeIntervalType(0,2),true), to_json(map(a, INTERVAL '100 02:10' DAY TO MINUTE), Some(America/Los_Angeles)), Some(America/Los_Angeles), false) AS from_json(to_json(map(a, INTERVAL '100 02:10' DAY TO MINUTE)))#x]
+- OneRowRelation


-- !query
SELECT
  from_json('{"a":"1"}', 'a interval year'),
  to_json(from_json('{"a":"1"}', 'a interval year')),
  to_json(map('a', interval 32 year 10 month)),
  from_json(to_json(map('a', interval 32 year 10 month)), 'a interval year to month')
-- !query analysis
Project [from_json(StructField(a,YearMonthIntervalType(0,0),true), {"a":"1"}, Some(America/Los_Angeles), false) AS from_json({"a":"1"})#x, to_json(from_json(StructField(a,YearMonthIntervalType(0,0),true), {"a":"1"}, Some(America/Los_Angeles), false), Some(America/Los_Angeles)) AS to_json(from_json({"a":"1"}))#x, to_json(map(a, INTERVAL '32-10' YEAR TO MONTH), Some(America/Los_Angeles)) AS to_json(map(a, INTERVAL '32-10' YEAR TO MONTH))#x, from_json(StructField(a,YearMonthIntervalType(0,1),true), to_json(map(a, INTERVAL '32-10' YEAR TO MONTH), Some(America/Los_Angeles)), Some(America/Los_Angeles), false) AS from_json(to_json(map(a, INTERVAL '32-10' YEAR TO MONTH)))#x]
+- OneRowRelation


-- !query
select interval '+'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'+'",
    "valueType" : "\"INTERVAL\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 19,
    "fragment" : "interval '+'"
  } ]
}


-- !query
select interval '+.'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'+.'",
    "valueType" : "\"INTERVAL\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 20,
    "fragment" : "interval '+.'"
  } ]
}


-- !query
select interval '1'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'1'",
    "valueType" : "\"INTERVAL\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 19,
    "fragment" : "interval '1'"
  } ]
}


-- !query
select interval '1.2'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'1.2'",
    "valueType" : "\"INTERVAL\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 21,
    "fragment" : "interval '1.2'"
  } ]
}


-- !query
select interval '- 2'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'- 2'",
    "valueType" : "\"INTERVAL\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 21,
    "fragment" : "interval '- 2'"
  } ]
}


-- !query
select interval '1 day -'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'1 day -'",
    "valueType" : "\"INTERVAL\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "interval '1 day -'"
  } ]
}


-- !query
select interval '1 day 1'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'1 day 1'",
    "valueType" : "\"INTERVAL\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "interval '1 day 1'"
  } ]
}


-- !query
select interval '1 day 2' day
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0026",
  "messageParameters" : {
    "value" : "1 day 2"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 29,
    "fragment" : "'1 day 2' day"
  } ]
}


-- !query
select interval 'interval 1' day
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0026",
  "messageParameters" : {
    "value" : "interval 1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 32,
    "fragment" : "'interval 1' day"
  } ]
}


-- !query
select interval '-\t 1' day
-- !query analysis
Project [INTERVAL '-1' DAY AS INTERVAL '-1' DAY#x]
+- OneRowRelation


-- !query
SELECT (INTERVAL '-178956970-8' YEAR TO MONTH) / 2
-- !query analysis
Project [(INTERVAL '-178956970-8' YEAR TO MONTH / 2) AS (INTERVAL '-178956970-8' YEAR TO MONTH / 2)#x]
+- OneRowRelation


-- !query
SELECT (INTERVAL '-178956970-8' YEAR TO MONTH) / 5
-- !query analysis
Project [(INTERVAL '-178956970-8' YEAR TO MONTH / 5) AS (INTERVAL '-178956970-8' YEAR TO MONTH / 5)#x]
+- OneRowRelation


-- !query
SELECT (INTERVAL '-178956970-8' YEAR TO MONTH) / -1
-- !query analysis
Project [(INTERVAL '-178956970-8' YEAR TO MONTH / -1) AS (INTERVAL '-178956970-8' YEAR TO MONTH / -1)#x]
+- OneRowRelation


-- !query
SELECT (INTERVAL '-178956970-8' YEAR TO MONTH) / -1L
-- !query analysis
Project [(INTERVAL '-178956970-8' YEAR TO MONTH / -1) AS (INTERVAL '-178956970-8' YEAR TO MONTH / -1)#x]
+- OneRowRelation


-- !query
SELECT (INTERVAL '-178956970-8' YEAR TO MONTH) / -1.0
-- !query analysis
Project [(INTERVAL '-178956970-8' YEAR TO MONTH / -1.0) AS (INTERVAL '-178956970-8' YEAR TO MONTH / -1.0)#x]
+- OneRowRelation


-- !query
SELECT (INTERVAL '-178956970-8' YEAR TO MONTH) / -1.0D
-- !query analysis
Project [(INTERVAL '-178956970-8' YEAR TO MONTH / -1.0) AS (INTERVAL '-178956970-8' YEAR TO MONTH / -1.0)#x]
+- OneRowRelation


-- !query
SELECT (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND) / 2
-- !query analysis
Project [(INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND / 2) AS (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND / 2)#x]
+- OneRowRelation


-- !query
SELECT (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND) / 5
-- !query analysis
Project [(INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND / 5) AS (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND / 5)#x]
+- OneRowRelation


-- !query
SELECT (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND) / -1
-- !query analysis
Project [(INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND / -1) AS (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND / -1)#x]
+- OneRowRelation


-- !query
SELECT (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND) / -1L
-- !query analysis
Project [(INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND / -1) AS (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND / -1)#x]
+- OneRowRelation


-- !query
SELECT (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND) / -1.0
-- !query analysis
Project [(INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND / -1.0) AS (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND / -1.0)#x]
+- OneRowRelation


-- !query
SELECT (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND) / -1.0D
-- !query analysis
Project [(INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND / -1.0) AS (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND / -1.0)#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '106751991 04' DAY TO HOUR
-- !query analysis
Project [INTERVAL '106751991 04' DAY TO HOUR AS INTERVAL '106751991 04' DAY TO HOUR#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '106751991 04:00' DAY TO MINUTE
-- !query analysis
Project [INTERVAL '106751991 04:00' DAY TO MINUTE AS INTERVAL '106751991 04:00' DAY TO MINUTE#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '106751991 04:00:54.775807' DAY TO SECOND
-- !query analysis
Project [INTERVAL '106751991 04:00:54.775807' DAY TO SECOND AS INTERVAL '106751991 04:00:54.775807' DAY TO SECOND#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '2562047788:00' HOUR TO MINUTE
-- !query analysis
Project [INTERVAL '2562047788:00' HOUR TO MINUTE AS INTERVAL '2562047788:00' HOUR TO MINUTE#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '2562047788:00:54.775807' HOUR TO SECOND
-- !query analysis
Project [INTERVAL '2562047788:00:54.775807' HOUR TO SECOND AS INTERVAL '2562047788:00:54.775807' HOUR TO SECOND#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '153722867280:54.775807' MINUTE TO SECOND
-- !query analysis
Project [INTERVAL '153722867280:54.775807' MINUTE TO SECOND AS INTERVAL '153722867280:54.775807' MINUTE TO SECOND#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '-106751991 04' DAY TO HOUR
-- !query analysis
Project [INTERVAL '-106751991 04' DAY TO HOUR AS INTERVAL '-106751991 04' DAY TO HOUR#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '-106751991 04:00' DAY TO MINUTE
-- !query analysis
Project [INTERVAL '-106751991 04:00' DAY TO MINUTE AS INTERVAL '-106751991 04:00' DAY TO MINUTE#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND
-- !query analysis
Project [INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND AS INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '-2562047788:00' HOUR TO MINUTE
-- !query analysis
Project [INTERVAL '-2562047788:00' HOUR TO MINUTE AS INTERVAL '-2562047788:00' HOUR TO MINUTE#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '-2562047788:00:54.775808' HOUR TO SECOND
-- !query analysis
Project [INTERVAL '-2562047788:00:54.775808' HOUR TO SECOND AS INTERVAL '-2562047788:00:54.775808' HOUR TO SECOND#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '-153722867280:54.775808' MINUTE TO SECOND
-- !query analysis
Project [INTERVAL '-153722867280:54.775808' MINUTE TO SECOND AS INTERVAL '-153722867280:54.775808' MINUTE TO SECOND#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '106751992 04' DAY TO HOUR
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0063",
  "messageParameters" : {
    "msg" : "requirement failed: day 106751992 outside range [0, 106751991]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 42,
    "fragment" : "'106751992 04' DAY TO HOUR"
  } ]
}


-- !query
SELECT INTERVAL '-106751992 04' DAY TO HOUR
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0063",
  "messageParameters" : {
    "msg" : "requirement failed: day 106751992 outside range [0, 106751991]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 43,
    "fragment" : "'-106751992 04' DAY TO HOUR"
  } ]
}


-- !query
SELECT INTERVAL '2562047789:00' HOUR TO MINUTE
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0063",
  "messageParameters" : {
    "msg" : "requirement failed: hour 2562047789 outside range [0, 2562047788]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 46,
    "fragment" : "'2562047789:00' HOUR TO MINUTE"
  } ]
}


-- !query
SELECT INTERVAL '-2562047789:00' HOUR TO MINUTE
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0063",
  "messageParameters" : {
    "msg" : "requirement failed: hour 2562047789 outside range [0, 2562047788]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 47,
    "fragment" : "'-2562047789:00' HOUR TO MINUTE"
  } ]
}


-- !query
SELECT INTERVAL '153722867281:54.775808' MINUTE TO SECOND
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0063",
  "messageParameters" : {
    "msg" : "requirement failed: minute 153722867281 outside range [0, 153722867280]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 57,
    "fragment" : "'153722867281:54.775808' MINUTE TO SECOND"
  } ]
}


-- !query
SELECT INTERVAL '-153722867281:54.775808' MINUTE TO SECOND
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0063",
  "messageParameters" : {
    "msg" : "requirement failed: minute 153722867281 outside range [0, 153722867280]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 58,
    "fragment" : "'-153722867281:54.775808' MINUTE TO SECOND"
  } ]
}


-- !query
SELECT INTERVAL '178956970' YEAR
-- !query analysis
Project [INTERVAL '178956970' YEAR AS INTERVAL '178956970' YEAR#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '-178956970' YEAR
-- !query analysis
Project [INTERVAL '-178956970' YEAR AS INTERVAL '-178956970' YEAR#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '2147483647' MONTH
-- !query analysis
Project [INTERVAL '2147483647' MONTH AS INTERVAL '2147483647' MONTH#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '-2147483647' MONTH
-- !query analysis
Project [INTERVAL '-2147483647' MONTH AS INTERVAL '-2147483647' MONTH#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '106751991' DAY
-- !query analysis
Project [INTERVAL '106751991' DAY AS INTERVAL '106751991' DAY#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '-106751991' DAY
-- !query analysis
Project [INTERVAL '-106751991' DAY AS INTERVAL '-106751991' DAY#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '2562047788' HOUR
-- !query analysis
Project [INTERVAL '2562047788' HOUR AS INTERVAL '2562047788' HOUR#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '-2562047788' HOUR
-- !query analysis
Project [INTERVAL '-2562047788' HOUR AS INTERVAL '-2562047788' HOUR#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '153722867280' MINUTE
-- !query analysis
Project [INTERVAL '153722867280' MINUTE AS INTERVAL '153722867280' MINUTE#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '-153722867280' MINUTE
-- !query analysis
Project [INTERVAL '-153722867280' MINUTE AS INTERVAL '-153722867280' MINUTE#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '54.775807' SECOND
-- !query analysis
Project [INTERVAL '54.775807' SECOND AS INTERVAL '54.775807' SECOND#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '-54.775807' SECOND
-- !query analysis
Project [INTERVAL '-54.775807' SECOND AS INTERVAL '-54.775807' SECOND#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '1' DAY > INTERVAL '1' HOUR
-- !query analysis
Project [(cast(INTERVAL '1' DAY as interval day to hour) > cast(INTERVAL '01' HOUR as interval day to hour)) AS (INTERVAL '1' DAY > INTERVAL '01' HOUR)#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '1 02' DAY TO HOUR = INTERVAL '02:10:55' HOUR TO SECOND
-- !query analysis
Project [(cast(INTERVAL '1 02' DAY TO HOUR as interval day to second) = cast(INTERVAL '02:10:55' HOUR TO SECOND as interval day to second)) AS (INTERVAL '1 02' DAY TO HOUR = INTERVAL '02:10:55' HOUR TO SECOND)#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '1' YEAR < INTERVAL '1' MONTH
-- !query analysis
Project [(cast(INTERVAL '1' YEAR as interval year to month) < cast(INTERVAL '1' MONTH as interval year to month)) AS (INTERVAL '1' YEAR < INTERVAL '1' MONTH)#x]
+- OneRowRelation


-- !query
SELECT INTERVAL '-1-1' YEAR TO MONTH = INTERVAL '-13' MONTH
-- !query analysis
Project [(INTERVAL '-1-1' YEAR TO MONTH = cast(INTERVAL '-13' MONTH as interval year to month)) AS (INTERVAL '-1-1' YEAR TO MONTH = INTERVAL '-13' MONTH)#x]
+- OneRowRelation


-- !query
SELECT INTERVAL 1 MONTH > INTERVAL 20 DAYS
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL MONTH\"",
    "right" : "\"INTERVAL DAY\"",
    "sqlExpr" : "\"(INTERVAL '1' MONTH > INTERVAL '20' DAY)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 42,
    "fragment" : "INTERVAL 1 MONTH > INTERVAL 20 DAYS"
  } ]
}


-- !query
SELECT INTERVAL '1' DAY < '1'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL DAY\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '1' DAY < 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "INTERVAL '1' DAY < '1'"
  } ]
}


-- !query
SELECT INTERVAL '1' DAY = '1'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL DAY\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '1' DAY = 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "INTERVAL '1' DAY = '1'"
  } ]
}


-- !query
SELECT INTERVAL '1' DAY > '1'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL DAY\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '1' DAY > 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "INTERVAL '1' DAY > '1'"
  } ]
}


-- !query
SELECT '1' < INTERVAL '1' DAY
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL DAY\"",
    "sqlExpr" : "\"(1 < INTERVAL '1' DAY)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "'1' < INTERVAL '1' DAY"
  } ]
}


-- !query
SELECT '1' = INTERVAL '1' DAY
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL DAY\"",
    "sqlExpr" : "\"(1 = INTERVAL '1' DAY)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "'1' = INTERVAL '1' DAY"
  } ]
}


-- !query
SELECT '1' > INTERVAL '1' DAY
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL DAY\"",
    "sqlExpr" : "\"(1 > INTERVAL '1' DAY)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "'1' > INTERVAL '1' DAY"
  } ]
}


-- !query
SELECT INTERVAL '1' YEAR < '1'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '1' YEAR < 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "INTERVAL '1' YEAR < '1'"
  } ]
}


-- !query
SELECT INTERVAL '1' YEAR = '1'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '1' YEAR = 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "INTERVAL '1' YEAR = '1'"
  } ]
}


-- !query
SELECT INTERVAL '1' YEAR > '1'
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '1' YEAR > 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "INTERVAL '1' YEAR > '1'"
  } ]
}


-- !query
SELECT '1' < INTERVAL '1' YEAR
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL YEAR\"",
    "sqlExpr" : "\"(1 < INTERVAL '1' YEAR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "'1' < INTERVAL '1' YEAR"
  } ]
}


-- !query
SELECT '1' = INTERVAL '1' YEAR
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL YEAR\"",
    "sqlExpr" : "\"(1 = INTERVAL '1' YEAR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "'1' = INTERVAL '1' YEAR"
  } ]
}


-- !query
SELECT '1' > INTERVAL '1' YEAR
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL YEAR\"",
    "sqlExpr" : "\"(1 > INTERVAL '1' YEAR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "'1' > INTERVAL '1' YEAR"
  } ]
}


-- !query
SELECT array(INTERVAL '1' YEAR, INTERVAL '1' MONTH)
-- !query analysis
Project [array(cast(INTERVAL '1' YEAR as interval year to month), cast(INTERVAL '1' MONTH as interval year to month)) AS array(INTERVAL '1' YEAR, INTERVAL '1' MONTH)#x]
+- OneRowRelation


-- !query
SELECT array(INTERVAL '1' DAY, INTERVAL '01:01' HOUR TO MINUTE)
-- !query analysis
Project [array(cast(INTERVAL '1' DAY as interval day to minute), cast(INTERVAL '01:01' HOUR TO MINUTE as interval day to minute)) AS array(INTERVAL '1' DAY, INTERVAL '01:01' HOUR TO MINUTE)#x]
+- OneRowRelation


-- !query
SELECT array(INTERVAL 1 MONTH, INTERVAL 20 DAYS)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.DATA_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "dataType" : "(\"INTERVAL MONTH\" or \"INTERVAL DAY\")",
    "functionName" : "`array`",
    "sqlExpr" : "\"array(INTERVAL '1' MONTH, INTERVAL '20' DAY)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 48,
    "fragment" : "array(INTERVAL 1 MONTH, INTERVAL 20 DAYS)"
  } ]
}


-- !query
SELECT coalesce(INTERVAL '1' YEAR, INTERVAL '1' MONTH)
-- !query analysis
Project [coalesce(cast(INTERVAL '1' YEAR as interval year to month), cast(INTERVAL '1' MONTH as interval year to month)) AS coalesce(INTERVAL '1' YEAR, INTERVAL '1' MONTH)#x]
+- OneRowRelation


-- !query
SELECT coalesce(INTERVAL '1' DAY, INTERVAL '01:01' HOUR TO MINUTE)
-- !query analysis
Project [coalesce(cast(INTERVAL '1' DAY as interval day to minute), cast(INTERVAL '01:01' HOUR TO MINUTE as interval day to minute)) AS coalesce(INTERVAL '1' DAY, INTERVAL '01:01' HOUR TO MINUTE)#x]
+- OneRowRelation


-- !query
SELECT coalesce(INTERVAL 1 MONTH, INTERVAL 20 DAYS)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.DATA_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "dataType" : "(\"INTERVAL MONTH\" or \"INTERVAL DAY\")",
    "functionName" : "`coalesce`",
    "sqlExpr" : "\"coalesce(INTERVAL '1' MONTH, INTERVAL '20' DAY)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 51,
    "fragment" : "coalesce(INTERVAL 1 MONTH, INTERVAL 20 DAYS)"
  } ]
}


-- !query
SELECT abs(INTERVAL '-10' YEAR)
-- !query analysis
Project [abs(INTERVAL '-10' YEAR) AS abs(INTERVAL '-10' YEAR)#x]
+- OneRowRelation


-- !query
SELECT abs(INTERVAL -'1 02:03:04.123' DAY TO SECOND)
-- !query analysis
Project [abs(INTERVAL '-1 02:03:04.123' DAY TO SECOND) AS abs(INTERVAL '-1 02:03:04.123' DAY TO SECOND)#x]
+- OneRowRelation


-- !query
SELECT div(INTERVAL '1-1' YEAR TO MONTH, INTERVAL '1' YEAR)
-- !query analysis
Project [(INTERVAL '1-1' YEAR TO MONTH div cast(INTERVAL '1' YEAR as interval year to month)) AS (INTERVAL '1-1' YEAR TO MONTH div INTERVAL '1' YEAR)#xL]
+- OneRowRelation


-- !query
SELECT div(INTERVAL '1-1' YEAR TO MONTH, INTERVAL '-1' MONTH)
-- !query analysis
Project [(INTERVAL '1-1' YEAR TO MONTH div cast(INTERVAL '-1' MONTH as interval year to month)) AS (INTERVAL '1-1' YEAR TO MONTH div INTERVAL '-1' MONTH)#xL]
+- OneRowRelation


-- !query
SELECT div(INTERVAL '1 06' DAY TO HOUR, INTERVAL '1' DAY)
-- !query analysis
Project [(INTERVAL '1 06' DAY TO HOUR div cast(INTERVAL '1' DAY as interval day to hour)) AS (INTERVAL '1 06' DAY TO HOUR div INTERVAL '1' DAY)#xL]
+- OneRowRelation


-- !query
SELECT div(INTERVAL '1 06' DAY TO HOUR, INTERVAL '-1' HOUR)
-- !query analysis
Project [(INTERVAL '1 06' DAY TO HOUR div cast(INTERVAL '-01' HOUR as interval day to hour)) AS (INTERVAL '1 06' DAY TO HOUR div INTERVAL '-01' HOUR)#xL]
+- OneRowRelation


-- !query
SELECT div(INTERVAL '1' MONTH, INTERVAL '-1' DAY)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "left" : "\"INTERVAL MONTH\"",
    "right" : "\"INTERVAL DAY\"",
    "sqlExpr" : "\"(INTERVAL '1' MONTH div INTERVAL '-1' DAY)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 49,
    "fragment" : "div(INTERVAL '1' MONTH, INTERVAL '-1' DAY)"
  } ]
}


-- !query
SELECT signum(INTERVAL '-10' YEAR)
-- !query analysis
Project [SIGNUM(INTERVAL '-10' YEAR) AS SIGNUM(INTERVAL '-10' YEAR)#x]
+- OneRowRelation


-- !query
SELECT signum(INTERVAL '10' MONTH)
-- !query analysis
Project [SIGNUM(INTERVAL '10' MONTH) AS SIGNUM(INTERVAL '10' MONTH)#x]
+- OneRowRelation


-- !query
SELECT signum(INTERVAL '0-0' YEAR TO MONTH)
-- !query analysis
Project [SIGNUM(INTERVAL '0-0' YEAR TO MONTH) AS SIGNUM(INTERVAL '0-0' YEAR TO MONTH)#x]
+- OneRowRelation


-- !query
SELECT signum(INTERVAL '-10' DAY)
-- !query analysis
Project [SIGNUM(INTERVAL '-10' DAY) AS SIGNUM(INTERVAL '-10' DAY)#x]
+- OneRowRelation


-- !query
SELECT signum(INTERVAL '10' HOUR)
-- !query analysis
Project [SIGNUM(INTERVAL '10' HOUR) AS SIGNUM(INTERVAL '10' HOUR)#x]
+- OneRowRelation


-- !query
SELECT signum(INTERVAL '0 0:0:0' DAY TO SECOND)
-- !query analysis
Project [SIGNUM(INTERVAL '0 00:00:00' DAY TO SECOND) AS SIGNUM(INTERVAL '0 00:00:00' DAY TO SECOND)#x]
+- OneRowRelation


-- !query
SELECT width_bucket(INTERVAL '0' YEAR, INTERVAL '0' YEAR, INTERVAL '10' YEAR, 10)
-- !query analysis
Project [width_bucket(INTERVAL '0' YEAR, INTERVAL '0' YEAR, INTERVAL '10' YEAR, cast(10 as bigint)) AS width_bucket(INTERVAL '0' YEAR, INTERVAL '0' YEAR, INTERVAL '10' YEAR, 10)#xL]
+- OneRowRelation


-- !query
SELECT width_bucket(INTERVAL '-1' YEAR, INTERVAL -'1-2' YEAR TO MONTH, INTERVAL '1-2' YEAR TO MONTH, 10)
-- !query analysis
Project [width_bucket(INTERVAL '-1' YEAR, INTERVAL '-1-2' YEAR TO MONTH, INTERVAL '1-2' YEAR TO MONTH, cast(10 as bigint)) AS width_bucket(INTERVAL '-1' YEAR, INTERVAL '-1-2' YEAR TO MONTH, INTERVAL '1-2' YEAR TO MONTH, 10)#xL]
+- OneRowRelation


-- !query
SELECT width_bucket(INTERVAL '0' DAY, INTERVAL '0' DAY, INTERVAL '10' DAY, 10)
-- !query analysis
Project [width_bucket(INTERVAL '0' DAY, INTERVAL '0' DAY, INTERVAL '10' DAY, cast(10 as bigint)) AS width_bucket(INTERVAL '0' DAY, INTERVAL '0' DAY, INTERVAL '10' DAY, 10)#xL]
+- OneRowRelation


-- !query
SELECT width_bucket(INTERVAL '-59' MINUTE, INTERVAL -'1 01' DAY TO HOUR, INTERVAL '1 2:3:4.001' DAY TO SECOND, 10)
-- !query analysis
Project [width_bucket(INTERVAL '-59' MINUTE, INTERVAL '-1 01' DAY TO HOUR, INTERVAL '1 02:03:04.001' DAY TO SECOND, cast(10 as bigint)) AS width_bucket(INTERVAL '-59' MINUTE, INTERVAL '-1 01' DAY TO HOUR, INTERVAL '1 02:03:04.001' DAY TO SECOND, 10)#xL]
+- OneRowRelation
