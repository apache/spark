-- Automatically generated by SQLQueryTestSuite
-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values('aaa', 'aaa')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values('AAA', 'AAA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values('bbb', 'bbb')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values('BBB', 'BBB')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
describe table t1
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`t1`, false, [col_name#x, data_type#x, comment#x]


-- !query
select count(*) from t1 group by utf8_binary
-- !query analysis
Aggregate [utf8_binary#x], [count(1) AS count(1)#xL]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select count(*) from t1 group by utf8_lcase
-- !query analysis
Aggregate [utf8_lcase#x], [count(1) AS count(1)#xL]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select * from t1 where utf8_binary = 'aaa'
-- !query analysis
Project [utf8_binary#x, utf8_lcase#x]
+- Filter (utf8_binary#x = aaa)
   +- SubqueryAlias spark_catalog.default.t1
      +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select * from t1 where utf8_lcase = 'aaa' collate utf8_lcase
-- !query analysis
Project [utf8_binary#x, utf8_lcase#x]
+- Filter (utf8_lcase#x = collate(aaa, utf8_lcase))
   +- SubqueryAlias spark_catalog.default.t1
      +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select * from t1 where utf8_binary < 'bbb'
-- !query analysis
Project [utf8_binary#x, utf8_lcase#x]
+- Filter (utf8_binary#x < bbb)
   +- SubqueryAlias spark_catalog.default.t1
      +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select * from t1 where utf8_lcase < 'bbb' collate utf8_lcase
-- !query analysis
Project [utf8_binary#x, utf8_lcase#x]
+- Filter (utf8_lcase#x < collate(bbb, utf8_lcase))
   +- SubqueryAlias spark_catalog.default.t1
      +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select l.utf8_binary, r.utf8_lcase from t1 l join t1 r on l.utf8_lcase = r.utf8_lcase
-- !query analysis
Project [utf8_binary#x, utf8_lcase#x]
+- Join Inner, (utf8_lcase#x = utf8_lcase#x)
   :- SubqueryAlias l
   :  +- SubqueryAlias spark_catalog.default.t1
   :     +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet
   +- SubqueryAlias r
      +- SubqueryAlias spark_catalog.default.t1
         +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
create table t2(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t2`, false


-- !query
insert into t2 values('aaa', 'aaa')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t2, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t2], Append, `spark_catalog`.`default`.`t2`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t2), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t2 values('bbb', 'bbb')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t2, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t2], Append, `spark_catalog`.`default`.`t2`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t2), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select * from t1 anti join t2 on t1.utf8_lcase = t2.utf8_lcase
-- !query analysis
Project [utf8_binary#x, utf8_lcase#x]
+- Join LeftAnti, (utf8_lcase#x = utf8_lcase#x)
   :- SubqueryAlias spark_catalog.default.t1
   :  +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet
   +- SubqueryAlias spark_catalog.default.t2
      +- Relation spark_catalog.default.t2[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t2
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t2


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
select col1 collate utf8_lcase from values ('aaa'), ('AAA'), ('bbb'), ('BBB'), ('zzz'), ('ZZZ') except select col1 collate utf8_lcase from values ('aaa'), ('bbb')
-- !query analysis
Except false
:- Project [collate(col1#x, utf8_lcase) AS collate(col1, utf8_lcase)#x]
:  +- LocalRelation [col1#x]
+- Project [collate(col1#x, utf8_lcase) AS collate(col1, utf8_lcase)#x]
   +- LocalRelation [col1#x]


-- !query
select col1 collate utf8_lcase from values ('aaa'), ('AAA'), ('bbb'), ('BBB'), ('zzz'), ('ZZZ') except all select col1 collate utf8_lcase from values ('aaa'), ('bbb')
-- !query analysis
Except All true
:- Project [collate(col1#x, utf8_lcase) AS collate(col1, utf8_lcase)#x]
:  +- LocalRelation [col1#x]
+- Project [collate(col1#x, utf8_lcase) AS collate(col1, utf8_lcase)#x]
   +- LocalRelation [col1#x]


-- !query
select col1 collate utf8_lcase from values ('aaa'), ('AAA'), ('bbb'), ('BBB'), ('zzz'), ('ZZZ') union select col1 collate utf8_lcase from values ('aaa'), ('bbb')
-- !query analysis
Distinct
+- Union false, false
   :- Project [collate(col1#x, utf8_lcase) AS collate(col1, utf8_lcase)#x]
   :  +- LocalRelation [col1#x]
   +- Project [collate(col1#x, utf8_lcase) AS collate(col1, utf8_lcase)#x]
      +- LocalRelation [col1#x]


-- !query
select col1 collate utf8_lcase from values ('aaa'), ('AAA'), ('bbb'), ('BBB'), ('zzz'), ('ZZZ') union all select col1 collate utf8_lcase from values ('aaa'), ('bbb')
-- !query analysis
Union false, false
:- Project [collate(col1#x, utf8_lcase) AS collate(col1, utf8_lcase)#x]
:  +- LocalRelation [col1#x]
+- Project [collate(col1#x, utf8_lcase) AS collate(col1, utf8_lcase)#x]
   +- LocalRelation [col1#x]


-- !query
select col1 collate utf8_lcase from values ('aaa'), ('bbb'), ('BBB'), ('zzz'), ('ZZZ') intersect select col1 collate utf8_lcase from values ('aaa'), ('bbb')
-- !query analysis
Intersect false
:- Project [collate(col1#x, utf8_lcase) AS collate(col1, utf8_lcase)#x]
:  +- LocalRelation [col1#x]
+- Project [collate(col1#x, utf8_lcase) AS collate(col1, utf8_lcase)#x]
   +- LocalRelation [col1#x]


-- !query
create table t1 (c1 struct<utf8_binary: string collate utf8_binary, utf8_lcase: string collate utf8_lcase>) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values (named_struct('utf8_binary', 'aaa', 'utf8_lcase', 'aaa'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [c1]
+- Project [named_struct(utf8_binary, col1#x.utf8_binary, utf8_lcase, cast(col1#x.utf8_lcase as string collate UTF8_LCASE)) AS c1#x]
   +- LocalRelation [col1#x]


-- !query
insert into t1 values (named_struct('utf8_binary', 'AAA', 'utf8_lcase', 'AAA'))
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [c1]
+- Project [named_struct(utf8_binary, col1#x.utf8_binary, utf8_lcase, cast(col1#x.utf8_lcase as string collate UTF8_LCASE)) AS c1#x]
   +- LocalRelation [col1#x]


-- !query
select count(*) from t1 group by c1.utf8_binary
-- !query analysis
Aggregate [c1#x.utf8_binary], [count(1) AS count(1)#xL]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[c1#x] parquet


-- !query
select count(*) from t1 group by c1.utf8_lcase
-- !query analysis
Aggregate [c1#x.utf8_lcase], [count(1) AS count(1)#xL]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[c1#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
select array_contains(ARRAY('aaa' collate utf8_lcase),'AAA' collate utf8_lcase)
-- !query analysis
Project [array_contains(array(collate(aaa, utf8_lcase)), collate(AAA, utf8_lcase)) AS array_contains(array(collate(aaa, utf8_lcase)), collate(AAA, utf8_lcase))#x]
+- OneRowRelation


-- !query
select array_position(ARRAY('aaa' collate utf8_lcase, 'bbb' collate utf8_lcase),'BBB' collate utf8_lcase)
-- !query analysis
Project [array_position(array(collate(aaa, utf8_lcase), collate(bbb, utf8_lcase)), collate(BBB, utf8_lcase)) AS array_position(array(collate(aaa, utf8_lcase), collate(bbb, utf8_lcase)), collate(BBB, utf8_lcase))#xL]
+- OneRowRelation


-- !query
select nullif('aaa' COLLATE utf8_lcase, 'AAA' COLLATE utf8_lcase)
-- !query analysis
Project [nullif(collate(aaa, utf8_lcase), collate(AAA, utf8_lcase)) AS nullif(collate(aaa, utf8_lcase), collate(AAA, utf8_lcase))#x]
+- OneRowRelation


-- !query
select least('aaa' COLLATE utf8_lcase, 'AAA' collate utf8_lcase, 'a' collate utf8_lcase)
-- !query analysis
Project [least(collate(aaa, utf8_lcase), collate(AAA, utf8_lcase), collate(a, utf8_lcase)) AS least(collate(aaa, utf8_lcase), collate(AAA, utf8_lcase), collate(a, utf8_lcase))#x]
+- OneRowRelation


-- !query
select arrays_overlap(array('aaa' collate utf8_lcase), array('AAA' collate utf8_lcase))
-- !query analysis
Project [arrays_overlap(array(collate(aaa, utf8_lcase)), array(collate(AAA, utf8_lcase))) AS arrays_overlap(array(collate(aaa, utf8_lcase)), array(collate(AAA, utf8_lcase)))#x]
+- OneRowRelation


-- !query
select array_distinct(array('aaa' collate utf8_lcase, 'AAA' collate utf8_lcase))
-- !query analysis
Project [array_distinct(array(collate(aaa, utf8_lcase), collate(AAA, utf8_lcase))) AS array_distinct(array(collate(aaa, utf8_lcase), collate(AAA, utf8_lcase)))#x]
+- OneRowRelation


-- !query
select array_union(array('aaa' collate utf8_lcase), array('AAA' collate utf8_lcase))
-- !query analysis
Project [array_union(array(collate(aaa, utf8_lcase)), array(collate(AAA, utf8_lcase))) AS array_union(array(collate(aaa, utf8_lcase)), array(collate(AAA, utf8_lcase)))#x]
+- OneRowRelation


-- !query
select array_intersect(array('aaa' collate utf8_lcase), array('AAA' collate utf8_lcase))
-- !query analysis
Project [array_intersect(array(collate(aaa, utf8_lcase)), array(collate(AAA, utf8_lcase))) AS array_intersect(array(collate(aaa, utf8_lcase)), array(collate(AAA, utf8_lcase)))#x]
+- OneRowRelation


-- !query
select array_except(array('aaa' collate utf8_lcase), array('AAA' collate utf8_lcase))
-- !query analysis
Project [array_except(array(collate(aaa, utf8_lcase)), array(collate(AAA, utf8_lcase))) AS array_except(array(collate(aaa, utf8_lcase)), array(collate(AAA, utf8_lcase)))#x]
+- OneRowRelation


-- !query
select 'a' collate unicode < 'A'
-- !query analysis
Project [(collate(a, unicode) < cast(A as string collate UNICODE)) AS (collate(a, unicode) < A)#x]
+- OneRowRelation


-- !query
select 'a' collate unicode_ci = 'A'
-- !query analysis
Project [(collate(a, unicode_ci) = cast(A as string collate UNICODE_CI)) AS (collate(a, unicode_ci) = A)#x]
+- OneRowRelation


-- !query
select 'a' collate unicode_ai = 'å'
-- !query analysis
Project [(collate(a, unicode_ai) = cast(å as string collate UNICODE_AI)) AS (collate(a, unicode_ai) = å)#x]
+- OneRowRelation


-- !query
select 'a' collate unicode_ci_ai = 'Å'
-- !query analysis
Project [(collate(a, unicode_ci_ai) = cast(Å as string collate UNICODE_CI_AI)) AS (collate(a, unicode_ci_ai) = Å)#x]
+- OneRowRelation


-- !query
select 'a' collate en < 'A'
-- !query analysis
Project [(collate(a, en) < cast(A as string collate en)) AS (collate(a, en) < A)#x]
+- OneRowRelation


-- !query
select 'a' collate en_ci = 'A'
-- !query analysis
Project [(collate(a, en_ci) = cast(A as string collate en_CI)) AS (collate(a, en_ci) = A)#x]
+- OneRowRelation


-- !query
select 'a' collate en_ai = 'å'
-- !query analysis
Project [(collate(a, en_ai) = cast(å as string collate en_AI)) AS (collate(a, en_ai) = å)#x]
+- OneRowRelation


-- !query
select 'a' collate en_ci_ai = 'Å'
-- !query analysis
Project [(collate(a, en_ci_ai) = cast(Å as string collate en_CI_AI)) AS (collate(a, en_ci_ai) = Å)#x]
+- OneRowRelation


-- !query
select 'Kypper' collate sv < 'Köpfe'
-- !query analysis
Project [(collate(Kypper, sv) < cast(Köpfe as string collate sv)) AS (collate(Kypper, sv) < Köpfe)#x]
+- OneRowRelation


-- !query
select 'Kypper' collate de > 'Köpfe'
-- !query analysis
Project [(collate(Kypper, de) > cast(Köpfe as string collate de)) AS (collate(Kypper, de) > Köpfe)#x]
+- OneRowRelation


-- !query
select 'I' collate tr_ci = 'ı'
-- !query analysis
Project [(collate(I, tr_ci) = cast(ı as string collate tr_CI)) AS (collate(I, tr_ci) = ı)#x]
+- OneRowRelation


-- !query
create table t4 (text string collate utf8_binary, pairDelim string collate utf8_lcase, keyValueDelim string collate utf8_binary) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t4`, false


-- !query
insert into t4 values('a:1,b:2,c:3', ',', ':')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t4, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t4], Append, `spark_catalog`.`default`.`t4`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t4), [text, pairDelim, keyValueDelim]
+- Project [cast(col1#x as string) AS text#x, cast(col2#x as string collate UTF8_LCASE) AS pairDelim#x, cast(col3#x as string) AS keyValueDelim#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
select str_to_map(text, pairDelim, keyValueDelim) from t4
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select str_to_map(text collate utf8_binary, pairDelim collate utf8_lcase, keyValueDelim collate utf8_binary) from t4
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.EXPLICIT",
  "sqlState" : "42P21",
  "messageParameters" : {
    "explicitTypes" : "`string`, `string collate UTF8_LCASE`"
  }
}


-- !query
select str_to_map(text collate utf8_binary, pairDelim collate utf8_binary, keyValueDelim collate utf8_binary) from t4
-- !query analysis
Project [str_to_map(collate(text#x, utf8_binary), collate(pairDelim#x, utf8_binary), collate(keyValueDelim#x, utf8_binary)) AS str_to_map(collate(text, utf8_binary), collate(pairDelim, utf8_binary), collate(keyValueDelim, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t4
   +- Relation spark_catalog.default.t4[text#x,pairDelim#x,keyValueDelim#x] parquet


-- !query
drop table t4
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t4


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('Spark', 'SQL')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select concat_ws(' ', utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select concat_ws(' ' collate utf8_binary, utf8_binary, 'SQL' collate utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.EXPLICIT",
  "sqlState" : "42P21",
  "messageParameters" : {
    "explicitTypes" : "`string`, `string collate UTF8_LCASE`"
  }
}


-- !query
select concat_ws(',', utf8_lcase, 'word'), concat_ws(',', utf8_binary, 'word') from t1
-- !query analysis
Project [concat_ws(cast(, as string collate UTF8_LCASE), utf8_lcase#x, cast(word as string collate UTF8_LCASE)) AS concat_ws(,, utf8_lcase, word)#x, concat_ws(,, utf8_binary#x, word) AS concat_ws(,, utf8_binary, word)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select concat_ws(',', utf8_lcase, 'word' collate utf8_binary), concat_ws(',', utf8_binary, 'word' collate utf8_lcase) from t1
-- !query analysis
Project [concat_ws(,, cast(utf8_lcase#x as string), collate(word, utf8_binary)) AS concat_ws(,, utf8_lcase, collate(word, utf8_binary))#x, concat_ws(cast(, as string collate UTF8_LCASE), cast(utf8_binary#x as string collate UTF8_LCASE), collate(word, utf8_lcase)) AS concat_ws(,, utf8_binary, collate(word, utf8_lcase))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('Spark', 'SQL')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select elt(2, utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select elt(1, utf8_binary collate utf8_lcase, utf8_lcase) from t1
-- !query analysis
Project [elt(1, collate(utf8_binary#x, utf8_lcase), utf8_lcase#x, false) AS elt(1, collate(utf8_binary, utf8_lcase), utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select elt(1, utf8_binary, 'word'), elt(1, utf8_lcase, 'word') from t1
-- !query analysis
Project [elt(1, utf8_binary#x, word, false) AS elt(1, utf8_binary, word)#x, elt(1, utf8_lcase#x, cast(word as string collate UTF8_LCASE), false) AS elt(1, utf8_lcase, word)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaAAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select split_part(utf8_binary, utf8_lcase, 3) from t1
-- !query analysis
Project [split_part(utf8_binary#x, utf8_lcase#x, 3) AS split_part(utf8_binary, utf8_lcase, 3)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select split_part(utf8_binary, 'a', 3), split_part(utf8_lcase, 'a', 3) from t1
-- !query analysis
Project [split_part(utf8_binary#x, a, 3) AS split_part(utf8_binary, a, 3)#x, split_part(utf8_lcase#x, a, 3) AS split_part(utf8_lcase, a, 3)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select split_part(utf8_binary, 'a' collate utf8_lcase, 3), split_part(utf8_lcase, 'a' collate utf8_binary, 3) from t1
-- !query analysis
Project [split_part(utf8_binary#x, collate(a, utf8_lcase), 3) AS split_part(utf8_binary, collate(a, utf8_lcase), 3)#x, split_part(utf8_lcase#x, collate(a, utf8_binary), 3) AS split_part(utf8_lcase, collate(a, utf8_binary), 3)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select contains(utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select contains(utf8_binary collate utf8_lcase, utf8_lcase), contains(utf8_binary, utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [Contains(collate(utf8_binary#x, utf8_lcase), utf8_lcase#x) AS contains(collate(utf8_binary, utf8_lcase), utf8_lcase)#x, Contains(utf8_binary#x, collate(utf8_lcase#x, utf8_binary)) AS contains(utf8_binary, collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select contains(utf8_binary, 'AAa'), contains(utf8_lcase, 'AaAA') from t1
-- !query analysis
Project [Contains(utf8_binary#x, AAa) AS contains(utf8_binary, AAa)#x, Contains(utf8_lcase#x, cast(AaAA as string collate UTF8_LCASE)) AS contains(utf8_lcase, AaAA)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaaAaAaaAaaAaAaaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select substring_index(utf8_binary, utf8_lcase, 1) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select substring_index(utf8_lcase, utf8_binary collate utf8_lcase, 3), substring_index(utf8_lcase collate utf8_binary, utf8_binary, -3) from t1
-- !query analysis
Project [substring_index(utf8_lcase#x, collate(utf8_binary#x, utf8_lcase), 3) AS substring_index(utf8_lcase, collate(utf8_binary, utf8_lcase), 3)#x, substring_index(collate(utf8_lcase#x, utf8_binary), utf8_binary#x, -3) AS substring_index(collate(utf8_lcase, utf8_binary), utf8_binary, -3)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select substring_index(utf8_binary, 'AAa', 1), substring_index(utf8_lcase, 'AaAA', 3) from t1
-- !query analysis
Project [substring_index(utf8_binary#x, AAa, 1) AS substring_index(utf8_binary, AAa, 1)#x, substring_index(utf8_lcase#x, cast(AaAA as string collate UTF8_LCASE), 3) AS substring_index(utf8_lcase, AaAA, 3)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaaAaAaaAaaAaAaaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select instr(utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select instr(utf8_lcase, utf8_binary collate utf8_lcase), instr(utf8_lcase collate utf8_binary, utf8_binary) from t1
-- !query analysis
Project [instr(utf8_lcase#x, collate(utf8_binary#x, utf8_lcase)) AS instr(utf8_lcase, collate(utf8_binary, utf8_lcase))#x, instr(collate(utf8_lcase#x, utf8_binary), utf8_binary#x) AS instr(collate(utf8_lcase, utf8_binary), utf8_binary)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select instr(utf8_binary, 'AAa'), instr(utf8_lcase, 'AaAA') from t1
-- !query analysis
Project [instr(utf8_binary#x, AAa) AS instr(utf8_binary, AAa)#x, instr(utf8_lcase#x, cast(AaAA as string collate UTF8_LCASE)) AS instr(utf8_lcase, AaAA)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('İo', 'İo')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select find_in_set(utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select find_in_set(utf8_binary, 'aaAaaAaA,i̇o'), find_in_set(utf8_lcase, 'aaAaaAaA,i̇o') from t1
-- !query analysis
Project [find_in_set(utf8_binary#x, aaAaaAaA,i̇o) AS find_in_set(utf8_binary, aaAaaAaA,i̇o)#x, find_in_set(utf8_lcase#x, cast(aaAaaAaA,i̇o as string collate UTF8_LCASE)) AS find_in_set(utf8_lcase, aaAaaAaA,i̇o)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select find_in_set(utf8_binary, 'aaAaaAaA,i̇o' collate utf8_lcase), find_in_set(utf8_lcase, 'aaAaaAaA,i̇o' collate utf8_binary) from t1
-- !query analysis
Project [find_in_set(cast(utf8_binary#x as string collate UTF8_LCASE), collate(aaAaaAaA,i̇o, utf8_lcase)) AS find_in_set(utf8_binary, collate(aaAaaAaA,i̇o, utf8_lcase))#x, find_in_set(cast(utf8_lcase#x as string), collate(aaAaaAaA,i̇o, utf8_binary)) AS find_in_set(utf8_lcase, collate(aaAaaAaA,i̇o, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('İo', 'İo')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select startswith(utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select startswith(utf8_binary, 'aaAaaAaA'), startswith(utf8_lcase, 'aaAaaAaA') from t1
-- !query analysis
Project [StartsWith(utf8_binary#x, aaAaaAaA) AS startswith(utf8_binary, aaAaaAaA)#x, StartsWith(utf8_lcase#x, cast(aaAaaAaA as string collate UTF8_LCASE)) AS startswith(utf8_lcase, aaAaaAaA)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select startswith(utf8_binary, 'aaAaaAaA' collate utf8_lcase), startswith(utf8_lcase, 'aaAaaAaA' collate utf8_binary) from t1
-- !query analysis
Project [StartsWith(cast(utf8_binary#x as string collate UTF8_LCASE), collate(aaAaaAaA, utf8_lcase)) AS startswith(utf8_binary, collate(aaAaaAaA, utf8_lcase))#x, StartsWith(cast(utf8_lcase#x as string), collate(aaAaaAaA, utf8_binary)) AS startswith(utf8_lcase, collate(aaAaaAaA, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('İo', 'İo')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select translate(utf8_binary, utf8_lcase collate utf8_lcase, 'abc' collate utf8_binary) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.EXPLICIT",
  "sqlState" : "42P21",
  "messageParameters" : {
    "explicitTypes" : "`string collate UTF8_LCASE`, `string`"
  }
}


-- !query
select translate(utf8_binary, 'aaAaaAaA', '12345'), translate(utf8_lcase, 'aaAaaAaA', '12345') from t1
-- !query analysis
Project [translate(utf8_binary#x, aaAaaAaA, 12345) AS translate(utf8_binary, aaAaaAaA, 12345)#x, translate(utf8_lcase#x, cast(aaAaaAaA as string collate UTF8_LCASE), cast(12345 as string collate UTF8_LCASE)) AS translate(utf8_lcase, aaAaaAaA, 12345)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select translate(utf8_binary, 'aaAaaAaA' collate utf8_lcase, '12345'), translate(utf8_lcase, 'aaAaaAaA' collate utf8_binary, '12345') from t1
-- !query analysis
Project [translate(cast(utf8_binary#x as string collate UTF8_LCASE), collate(aaAaaAaA, utf8_lcase), cast(12345 as string collate UTF8_LCASE)) AS translate(utf8_binary, collate(aaAaaAaA, utf8_lcase), 12345)#x, translate(cast(utf8_lcase#x as string), collate(aaAaaAaA, utf8_binary), 12345) AS translate(utf8_lcase, collate(aaAaaAaA, utf8_binary), 12345)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('İo', 'İo')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select replace(utf8_binary, utf8_lcase collate utf8_lcase, 'abc' collate utf8_binary) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.EXPLICIT",
  "sqlState" : "42P21",
  "messageParameters" : {
    "explicitTypes" : "`string collate UTF8_LCASE`, `string`"
  }
}


-- !query
select replace(utf8_binary, 'aaAaaAaA', '12345'), replace(utf8_lcase, 'aaAaaAaA', '12345') from t1
-- !query analysis
Project [replace(utf8_binary#x, aaAaaAaA, 12345) AS replace(utf8_binary, aaAaaAaA, 12345)#x, replace(utf8_lcase#x, cast(aaAaaAaA as string collate UTF8_LCASE), cast(12345 as string collate UTF8_LCASE)) AS replace(utf8_lcase, aaAaaAaA, 12345)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select replace(utf8_binary, 'aaAaaAaA' collate utf8_lcase, '12345'), replace(utf8_lcase, 'aaAaaAaA' collate utf8_binary, '12345') from t1
-- !query analysis
Project [replace(cast(utf8_binary#x as string collate UTF8_LCASE), collate(aaAaaAaA, utf8_lcase), cast(12345 as string collate UTF8_LCASE)) AS replace(utf8_binary, collate(aaAaaAaA, utf8_lcase), 12345)#x, replace(cast(utf8_lcase#x as string), collate(aaAaaAaA, utf8_binary), 12345) AS replace(utf8_lcase, collate(aaAaaAaA, utf8_binary), 12345)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('İo', 'i̇o')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select endswith(utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select endswith(utf8_binary, 'aaAaaAaA'), endswith(utf8_lcase, 'aaAaaAaA') from t1
-- !query analysis
Project [EndsWith(utf8_binary#x, aaAaaAaA) AS endswith(utf8_binary, aaAaaAaA)#x, EndsWith(utf8_lcase#x, cast(aaAaaAaA as string collate UTF8_LCASE)) AS endswith(utf8_lcase, aaAaaAaA)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select endswith(utf8_binary, utf8_lcase collate utf8_binary), endswith(utf8_lcase, utf8_binary collate utf8_lcase) from t1
-- !query analysis
Project [EndsWith(utf8_binary#x, collate(utf8_lcase#x, utf8_binary)) AS endswith(utf8_binary, collate(utf8_lcase, utf8_binary))#x, EndsWith(utf8_lcase#x, collate(utf8_binary#x, utf8_lcase)) AS endswith(utf8_lcase, collate(utf8_binary, utf8_lcase))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('İo', 'i̇o')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select repeat(utf8_binary, 3), repeat(utf8_lcase, 2) from t1
-- !query analysis
Project [repeat(utf8_binary#x, 3) AS repeat(utf8_binary, 3)#x, repeat(utf8_lcase#x, 2) AS repeat(utf8_lcase, 2)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select repeat(utf8_binary collate utf8_lcase, 3), repeat(utf8_lcase collate utf8_binary, 2) from t1
-- !query analysis
Project [repeat(collate(utf8_binary#x, utf8_lcase), 3) AS repeat(collate(utf8_binary, utf8_lcase), 3)#x, repeat(collate(utf8_lcase#x, utf8_binary), 2) AS repeat(collate(utf8_lcase, utf8_binary), 2)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('efd2', 'efd2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select ascii(utf8_binary), ascii(utf8_lcase) from t1
-- !query analysis
Project [ascii(utf8_binary#x) AS ascii(utf8_binary)#x, ascii(utf8_lcase#x) AS ascii(utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select ascii(utf8_binary collate utf8_lcase), ascii(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [ascii(collate(utf8_binary#x, utf8_lcase)) AS ascii(collate(utf8_binary, utf8_lcase))#x, ascii(collate(utf8_lcase#x, utf8_binary)) AS ascii(collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select unbase64(utf8_binary), unbase64(utf8_lcase) from t1
-- !query analysis
Project [unbase64(utf8_binary#x, false) AS unbase64(utf8_binary)#x, unbase64(utf8_lcase#x, false) AS unbase64(utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select unbase64(utf8_binary collate utf8_lcase), unbase64(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [unbase64(collate(utf8_binary#x, utf8_lcase), false) AS unbase64(collate(utf8_binary, utf8_lcase))#x, unbase64(collate(utf8_lcase#x, utf8_binary), false) AS unbase64(collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(ascii long) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values (97)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [ascii]
+- Project [cast(col1#x as bigint) AS ascii#xL]
   +- LocalRelation [col1#x]


-- !query
insert into t1 values (66)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [ascii]
+- Project [cast(col1#x as bigint) AS ascii#xL]
   +- LocalRelation [col1#x]


-- !query
select chr(ascii) from t1
-- !query analysis
Project [chr(ascii#xL) AS chr(ascii)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[ascii#xL] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('efd2', 'efd2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select base64(utf8_binary), base64(utf8_lcase) from t1
-- !query analysis
Project [base64(cast(utf8_binary#x as binary)) AS base64(utf8_binary)#x, base64(cast(utf8_lcase#x as binary)) AS base64(utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select base64(utf8_binary collate utf8_lcase), base64(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [base64(cast(collate(utf8_binary#x, utf8_lcase) as binary)) AS base64(collate(utf8_binary, utf8_lcase))#x, base64(cast(collate(utf8_lcase#x, utf8_binary) as binary)) AS base64(collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select decode(encode(utf8_binary, 'utf-8'), 'utf-8'), decode(encode(utf8_lcase, 'utf-8'), 'utf-8') from t1
-- !query analysis
Project [decode(encode(utf8_binary#x, utf-8), utf-8) AS decode(encode(utf8_binary, utf-8), utf-8)#x, decode(encode(utf8_lcase#x, utf-8), utf-8) AS decode(encode(utf8_lcase, utf-8), utf-8)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select decode(encode(utf8_binary collate utf8_lcase, 'utf-8'), 'utf-8'), decode(encode(utf8_lcase collate utf8_binary, 'utf-8'), 'utf-8') from t1
-- !query analysis
Project [decode(encode(collate(utf8_binary#x, utf8_lcase), utf-8), utf-8) AS decode(encode(collate(utf8_binary, utf8_lcase), utf-8), utf-8)#x, decode(encode(collate(utf8_lcase#x, utf8_binary), utf-8), utf-8) AS decode(encode(collate(utf8_lcase, utf8_binary), utf-8), utf-8)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(ascii double) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values (97.52143)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [ascii]
+- Project [cast(col1#x as double) AS ascii#x]
   +- LocalRelation [col1#x]


-- !query
insert into t1 values (66.421)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [ascii]
+- Project [cast(col1#x as double) AS ascii#x]
   +- LocalRelation [col1#x]


-- !query
select format_number(ascii, '###.###') from t1
-- !query analysis
Project [format_number(ascii#x, ###.###) AS format_number(ascii, ###.###)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[ascii#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('efd2', 'efd2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select encode(utf8_binary, 'utf-8'), encode(utf8_lcase, 'utf-8') from t1
-- !query analysis
Project [encode(utf8_binary#x, utf-8) AS encode(utf8_binary, utf-8)#x, encode(utf8_lcase#x, utf-8) AS encode(utf8_lcase, utf-8)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select encode(utf8_binary collate utf8_lcase, 'utf-8'), encode(utf8_lcase collate utf8_binary, 'utf-8') from t1
-- !query analysis
Project [encode(collate(utf8_binary#x, utf8_lcase), utf-8) AS encode(collate(utf8_binary, utf8_lcase), utf-8)#x, encode(collate(utf8_lcase#x, utf8_binary), utf-8) AS encode(collate(utf8_lcase, utf8_binary), utf-8)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select to_binary(utf8_binary, 'utf-8'), to_binary(utf8_lcase, 'utf-8') from t1
-- !query analysis
Project [to_binary(utf8_binary#x, Some(utf-8), false) AS to_binary(utf8_binary, utf-8)#x, to_binary(utf8_lcase#x, Some(utf-8), false) AS to_binary(utf8_lcase, utf-8)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select to_binary(utf8_binary collate utf8_lcase, 'utf-8'), to_binary(utf8_lcase collate utf8_binary, 'utf-8') from t1
-- !query analysis
Project [to_binary(collate(utf8_binary#x, utf8_lcase), Some(utf-8), false) AS to_binary(collate(utf8_binary, utf8_lcase), utf-8)#x, to_binary(collate(utf8_lcase#x, utf8_binary), Some(utf-8), false) AS to_binary(collate(utf8_lcase, utf8_binary), utf-8)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('Hello, world! Nice day.', 'Hello, world! Nice day.')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('Something else. Nothing here.', 'Something else. Nothing here.')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select sentences(utf8_binary), sentences(utf8_lcase) from t1
-- !query analysis
Project [sentences(utf8_binary#x, , ) AS sentences(utf8_binary, , )#x, sentences(utf8_lcase#x, , ) AS sentences(utf8_lcase, , )#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select sentences(utf8_binary collate utf8_lcase), sentences(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [sentences(collate(utf8_binary#x, utf8_lcase), , ) AS sentences(collate(utf8_binary, utf8_lcase), , )#x, sentences(collate(utf8_lcase#x, utf8_binary), , ) AS sentences(collate(utf8_lcase, utf8_binary), , )#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('Hello, world! Nice day.', 'Hello, world! Nice day.')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('Something else. Nothing here.', 'Something else. Nothing here.')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select upper(utf8_binary), upper(utf8_lcase) from t1
-- !query analysis
Project [upper(utf8_binary#x) AS upper(utf8_binary)#x, upper(utf8_lcase#x) AS upper(utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select upper(utf8_binary collate utf8_lcase), upper(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [upper(collate(utf8_binary#x, utf8_lcase)) AS upper(collate(utf8_binary, utf8_lcase))#x, upper(collate(utf8_lcase#x, utf8_binary)) AS upper(collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('Hello, world! Nice day.', 'Hello, world! Nice day.')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('Something else. Nothing here.', 'Something else. Nothing here.')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select lower(utf8_binary), lower(utf8_lcase) from t1
-- !query analysis
Project [lower(utf8_binary#x) AS lower(utf8_binary)#x, lower(utf8_lcase#x) AS lower(utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select lower(utf8_binary collate utf8_lcase), lower(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [lower(collate(utf8_binary#x, utf8_lcase)) AS lower(collate(utf8_binary, utf8_lcase))#x, lower(collate(utf8_lcase#x, utf8_binary)) AS lower(collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('Hello, world! Nice day.', 'Hello, world! Nice day.')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('Something else. Nothing here.', 'Something else. Nothing here.')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select initcap(utf8_binary), initcap(utf8_lcase) from t1
-- !query analysis
Project [initcap(utf8_binary#x) AS initcap(utf8_binary)#x, initcap(utf8_lcase#x) AS initcap(utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select initcap(utf8_binary collate utf8_lcase), initcap(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [initcap(collate(utf8_binary#x, utf8_lcase)) AS initcap(collate(utf8_binary, utf8_lcase))#x, initcap(collate(utf8_lcase#x, utf8_binary)) AS initcap(collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaaAaAaaAaaAaAaaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select overlay(utf8_binary, utf8_lcase, 3) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select overlay(utf8_lcase, utf8_binary collate utf8_lcase, 3), overlay(utf8_lcase collate utf8_binary, utf8_binary, 3) from t1
-- !query analysis
Project [overlay(utf8_lcase#x, collate(utf8_binary#x, utf8_lcase), 3, -1) AS overlay(utf8_lcase, collate(utf8_binary, utf8_lcase), 3, -1)#x, overlay(collate(utf8_lcase#x, utf8_binary), utf8_binary#x, 3, -1) AS overlay(collate(utf8_lcase, utf8_binary), utf8_binary, 3, -1)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select overlay(utf8_binary, 'AAa', 3), overlay(utf8_lcase, 'AaAA', 3) from t1
-- !query analysis
Project [overlay(utf8_binary#x, AAa, 3, -1) AS overlay(utf8_binary, AAa, 3, -1)#x, overlay(utf8_lcase#x, cast(AaAA as string collate UTF8_LCASE), 3, -1) AS overlay(utf8_lcase, AaAA, 3, -1)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(format string collate utf8_binary, utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('%s%s', 'abCdE', 'abCdE')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [format, utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS format#x, cast(col2#x as string) AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
select format_string(format, utf8_binary, utf8_lcase) from t1
-- !query analysis
Project [format_string(format#x, utf8_binary#x, utf8_lcase#x) AS format_string(format, utf8_binary, utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[format#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select format_string(format collate utf8_lcase, utf8_lcase, utf8_binary collate utf8_lcase, 3), format_string(format, utf8_lcase collate utf8_binary, utf8_binary) from t1
-- !query analysis
Project [format_string(collate(format#x, utf8_lcase), utf8_lcase#x, collate(utf8_binary#x, utf8_lcase), 3) AS format_string(collate(format, utf8_lcase), utf8_lcase, collate(utf8_binary, utf8_lcase), 3)#x, format_string(format#x, collate(utf8_lcase#x, utf8_binary), utf8_binary#x) AS format_string(format, collate(utf8_lcase, utf8_binary), utf8_binary)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[format#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select format_string(format, utf8_binary, utf8_lcase) from t1
-- !query analysis
Project [format_string(format#x, utf8_binary#x, utf8_lcase#x) AS format_string(format, utf8_binary, utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[format#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('efd2', 'efd2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select soundex(utf8_binary), soundex(utf8_lcase) from t1
-- !query analysis
Project [soundex(utf8_binary#x) AS soundex(utf8_binary)#x, soundex(utf8_lcase#x) AS soundex(utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select soundex(utf8_binary collate utf8_lcase), soundex(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [soundex(collate(utf8_binary#x, utf8_lcase)) AS soundex(collate(utf8_binary, utf8_lcase))#x, soundex(collate(utf8_lcase#x, utf8_binary)) AS soundex(collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('efd2', 'efd2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select length(utf8_binary), length(utf8_lcase) from t1
-- !query analysis
Project [length(utf8_binary#x) AS length(utf8_binary)#x, length(utf8_lcase#x) AS length(utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select length(utf8_binary collate utf8_lcase), length(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [length(collate(utf8_binary#x, utf8_lcase)) AS length(collate(utf8_binary, utf8_lcase))#x, length(collate(utf8_lcase#x, utf8_binary)) AS length(collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select bit_length(utf8_binary), bit_length(utf8_lcase) from t1
-- !query analysis
Project [bit_length(utf8_binary#x) AS bit_length(utf8_binary)#x, bit_length(utf8_lcase#x) AS bit_length(utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select bit_length(utf8_binary collate utf8_lcase), bit_length(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [bit_length(collate(utf8_binary#x, utf8_lcase)) AS bit_length(collate(utf8_binary, utf8_lcase))#x, bit_length(collate(utf8_lcase#x, utf8_binary)) AS bit_length(collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select octet_length(utf8_binary), octet_length(utf8_lcase) from t1
-- !query analysis
Project [octet_length(utf8_binary#x) AS octet_length(utf8_binary)#x, octet_length(utf8_lcase#x) AS octet_length(utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select octet_length(utf8_binary collate utf8_lcase), octet_length(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [octet_length(collate(utf8_binary#x, utf8_lcase)) AS octet_length(collate(utf8_binary, utf8_lcase))#x, octet_length(collate(utf8_lcase#x, utf8_binary)) AS octet_length(collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(num long) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values (97)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [num]
+- Project [cast(col1#x as bigint) AS num#xL]
   +- LocalRelation [col1#x]


-- !query
insert into t1 values (66)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [num]
+- Project [cast(col1#x as bigint) AS num#xL]
   +- LocalRelation [col1#x]


-- !query
select luhn_check(num) from t1
-- !query analysis
Project [luhn_check(cast(num#xL as string)) AS luhn_check(num)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[num#xL] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('kitten', 'sitTing')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select levenshtein(utf8_binary, utf8_lcase) from t1
-- !query analysis
Project [levenshtein(utf8_binary#x, utf8_lcase#x, None) AS levenshtein(utf8_binary, utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select levenshtein(utf8_binary, 'aaAaaAaA'), levenshtein(utf8_lcase, 'aaAaaAaA') from t1
-- !query analysis
Project [levenshtein(utf8_binary#x, aaAaaAaA, None) AS levenshtein(utf8_binary, aaAaaAaA)#x, levenshtein(utf8_lcase#x, aaAaaAaA, None) AS levenshtein(utf8_lcase, aaAaaAaA)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select levenshtein(utf8_binary, utf8_lcase collate utf8_binary), levenshtein(utf8_lcase, utf8_binary collate utf8_lcase) from t1
-- !query analysis
Project [levenshtein(utf8_binary#x, collate(utf8_lcase#x, utf8_binary), None) AS levenshtein(utf8_binary, collate(utf8_lcase, utf8_binary))#x, levenshtein(utf8_lcase#x, collate(utf8_binary#x, utf8_lcase), None) AS levenshtein(utf8_lcase, collate(utf8_binary, utf8_lcase))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('efd2', 'efd2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('abc', 'abc')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select is_valid_utf8(utf8_binary), is_valid_utf8(utf8_lcase) from t1
-- !query analysis
Project [is_valid_utf8(utf8_binary#x) AS is_valid_utf8(utf8_binary)#x, is_valid_utf8(utf8_lcase#x) AS is_valid_utf8(utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select is_valid_utf8(utf8_binary collate utf8_lcase), is_valid_utf8(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [is_valid_utf8(collate(utf8_binary#x, utf8_lcase)) AS is_valid_utf8(collate(utf8_binary, utf8_lcase))#x, is_valid_utf8(collate(utf8_lcase#x, utf8_binary)) AS is_valid_utf8(collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('efd2', 'efd2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('abc', 'abc')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select make_valid_utf8(utf8_binary), make_valid_utf8(utf8_lcase) from t1
-- !query analysis
Project [make_valid_utf8(utf8_binary#x) AS make_valid_utf8(utf8_binary)#x, make_valid_utf8(utf8_lcase#x) AS make_valid_utf8(utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select make_valid_utf8(utf8_binary collate utf8_lcase), make_valid_utf8(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [make_valid_utf8(collate(utf8_binary#x, utf8_lcase)) AS make_valid_utf8(collate(utf8_binary, utf8_lcase))#x, make_valid_utf8(collate(utf8_lcase#x, utf8_binary)) AS make_valid_utf8(collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('efd2', 'efd2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('abc', 'abc')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select validate_utf8(utf8_binary), validate_utf8(utf8_lcase) from t1
-- !query analysis
Project [validate_utf8(utf8_binary#x) AS validate_utf8(utf8_binary)#x, validate_utf8(utf8_lcase#x) AS validate_utf8(utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select validate_utf8(utf8_binary collate utf8_lcase), validate_utf8(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [validate_utf8(collate(utf8_binary#x, utf8_lcase)) AS validate_utf8(collate(utf8_binary, utf8_lcase))#x, validate_utf8(collate(utf8_lcase#x, utf8_binary)) AS validate_utf8(collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('efd2', 'efd2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('abc', 'abc')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select try_validate_utf8(utf8_binary), try_validate_utf8(utf8_lcase) from t1
-- !query analysis
Project [try_validate_utf8(utf8_binary#x) AS try_validate_utf8(utf8_binary)#x, try_validate_utf8(utf8_lcase#x) AS try_validate_utf8(utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select try_validate_utf8(utf8_binary collate utf8_lcase), try_validate_utf8(utf8_lcase collate utf8_binary) from t1
-- !query analysis
Project [try_validate_utf8(collate(utf8_binary#x, utf8_lcase)) AS try_validate_utf8(collate(utf8_binary, utf8_lcase))#x, try_validate_utf8(collate(utf8_lcase#x, utf8_binary)) AS try_validate_utf8(collate(utf8_lcase, utf8_binary))#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('efd2', 'efd2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('abc', 'abc')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select substr(utf8_binary, 2, 2), substr(utf8_lcase, 2, 2) from t1
-- !query analysis
Project [substr(utf8_binary#x, 2, 2) AS substr(utf8_binary, 2, 2)#x, substr(utf8_lcase#x, 2, 2) AS substr(utf8_lcase, 2, 2)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select substr(utf8_binary collate utf8_lcase, 2, 2), substr(utf8_lcase collate utf8_binary, 2, 2) from t1
-- !query analysis
Project [substr(collate(utf8_binary#x, utf8_lcase), 2, 2) AS substr(collate(utf8_binary, utf8_lcase), 2, 2)#x, substr(collate(utf8_lcase#x, utf8_binary), 2, 2) AS substr(collate(utf8_lcase, utf8_binary), 2, 2)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select right(utf8_binary, 2), right(utf8_lcase, 2) from t1
-- !query analysis
Project [right(utf8_binary#x, 2) AS right(utf8_binary, 2)#x, right(utf8_lcase#x, 2) AS right(utf8_lcase, 2)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select right(utf8_binary collate utf8_lcase, 2), right(utf8_lcase collate utf8_binary, 2) from t1
-- !query analysis
Project [right(collate(utf8_binary#x, utf8_lcase), 2) AS right(collate(utf8_binary, utf8_lcase), 2)#x, right(collate(utf8_lcase#x, utf8_binary), 2) AS right(collate(utf8_lcase, utf8_binary), 2)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select left(utf8_binary, '2' collate utf8_lcase), left(utf8_lcase, 2) from t1
-- !query analysis
Project [left(utf8_binary#x, cast(collate(2, utf8_lcase) as int)) AS left(utf8_binary, collate(2, utf8_lcase))#x, left(utf8_lcase#x, 2) AS left(utf8_lcase, 2)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select left(utf8_binary collate utf8_lcase, 2), left(utf8_lcase collate utf8_binary, 2) from t1
-- !query analysis
Project [left(collate(utf8_binary#x, utf8_lcase), 2) AS left(collate(utf8_binary, utf8_lcase), 2)#x, left(collate(utf8_lcase#x, utf8_binary), 2) AS left(collate(utf8_lcase, utf8_binary), 2)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('efd2', 'efd2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('abc', 'abc')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select rpad(utf8_binary, 8, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select rpad(utf8_lcase, 8, utf8_binary collate utf8_lcase), rpad(utf8_lcase collate utf8_binary, 8, utf8_binary) from t1
-- !query analysis
Project [rpad(utf8_lcase#x, 8, collate(utf8_binary#x, utf8_lcase)) AS rpad(utf8_lcase, 8, collate(utf8_binary, utf8_lcase))#x, rpad(collate(utf8_lcase#x, utf8_binary), 8, utf8_binary#x) AS rpad(collate(utf8_lcase, utf8_binary), 8, utf8_binary)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select rpad(utf8_binary, 8, 'AAa'), rpad(utf8_lcase, 8, 'AaAA') from t1
-- !query analysis
Project [rpad(utf8_binary#x, 8, AAa) AS rpad(utf8_binary, 8, AAa)#x, rpad(utf8_lcase#x, 8, cast(AaAA as string collate UTF8_LCASE)) AS rpad(utf8_lcase, 8, AaAA)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('efd2', 'efd2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('abc', 'abc')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select lpad(utf8_binary, 8, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select lpad(utf8_lcase, 8, utf8_binary collate utf8_lcase), lpad(utf8_lcase collate utf8_binary, 8, utf8_binary) from t1
-- !query analysis
Project [lpad(utf8_lcase#x, 8, collate(utf8_binary#x, utf8_lcase)) AS lpad(utf8_lcase, 8, collate(utf8_binary, utf8_lcase))#x, lpad(collate(utf8_lcase#x, utf8_binary), 8, utf8_binary#x) AS lpad(collate(utf8_lcase, utf8_binary), 8, utf8_binary)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select lpad(utf8_binary, 8, 'AAa'), lpad(utf8_lcase, 8, 'AaAA') from t1
-- !query analysis
Project [lpad(utf8_binary#x, 8, AAa) AS lpad(utf8_binary, 8, AAa)#x, lpad(utf8_lcase#x, 8, cast(AaAA as string collate UTF8_LCASE)) AS lpad(utf8_lcase, 8, AaAA)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('efd2', 'efD2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
insert into t1 values ('abc', 'aBc')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select locate(utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select locate(utf8_lcase, utf8_binary collate utf8_lcase), locate(utf8_lcase collate utf8_binary, utf8_binary) from t1
-- !query analysis
Project [locate(utf8_lcase#x, collate(utf8_binary#x, utf8_lcase), 1) AS locate(utf8_lcase, collate(utf8_binary, utf8_lcase), 1)#x, locate(collate(utf8_lcase#x, utf8_binary), utf8_binary#x, 1) AS locate(collate(utf8_lcase, utf8_binary), utf8_binary, 1)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select locate('B', utf8_binary), locate('B', utf8_lcase) from t1
-- !query analysis
Project [locate(B, utf8_binary#x, 1) AS locate(B, utf8_binary, 1)#x, locate(cast(B as string collate UTF8_LCASE), utf8_lcase#x, 1) AS locate(B, utf8_lcase, 1)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
create table t1(utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('abcdcba', 'aBcDCbA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [utf8_binary, utf8_lcase]
+- Project [cast(col1#x as string) AS utf8_binary#x, cast(col2#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
select TRIM(utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select TRIM(utf8_lcase, utf8_binary collate utf8_lcase), TRIM(utf8_lcase collate utf8_binary, utf8_binary) from t1
-- !query analysis
Project [trim(collate(utf8_binary#x, utf8_lcase), Some(utf8_lcase#x)) AS TRIM(BOTH utf8_lcase FROM collate(utf8_binary, utf8_lcase))#x, trim(utf8_binary#x, Some(collate(utf8_lcase#x, utf8_binary))) AS TRIM(BOTH collate(utf8_lcase, utf8_binary) FROM utf8_binary)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select TRIM('ABC', utf8_binary), TRIM('ABC', utf8_lcase) from t1
-- !query analysis
Project [trim(utf8_binary#x, Some(ABC)) AS TRIM(BOTH ABC FROM utf8_binary)#x, trim(utf8_lcase#x, Some(cast(ABC as string collate UTF8_LCASE))) AS TRIM(BOTH ABC FROM utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select BTRIM(utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select BTRIM(utf8_lcase, utf8_binary collate utf8_lcase), BTRIM(utf8_lcase collate utf8_binary, utf8_binary) from t1
-- !query analysis
Project [btrim(utf8_lcase#x, collate(utf8_binary#x, utf8_lcase)) AS btrim(utf8_lcase, collate(utf8_binary, utf8_lcase))#x, btrim(collate(utf8_lcase#x, utf8_binary), utf8_binary#x) AS btrim(collate(utf8_lcase, utf8_binary), utf8_binary)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select BTRIM('ABC', utf8_binary), BTRIM('ABC', utf8_lcase) from t1
-- !query analysis
Project [btrim(ABC, utf8_binary#x) AS btrim(ABC, utf8_binary)#x, btrim(ABC, utf8_lcase#x) AS btrim(ABC, utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select LTRIM(utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select LTRIM(utf8_lcase, utf8_binary collate utf8_lcase), LTRIM(utf8_lcase collate utf8_binary, utf8_binary) from t1
-- !query analysis
Project [ltrim(collate(utf8_binary#x, utf8_lcase), Some(utf8_lcase#x)) AS TRIM(LEADING utf8_lcase FROM collate(utf8_binary, utf8_lcase))#x, ltrim(utf8_binary#x, Some(collate(utf8_lcase#x, utf8_binary))) AS TRIM(LEADING collate(utf8_lcase, utf8_binary) FROM utf8_binary)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select LTRIM('ABC', utf8_binary), LTRIM('ABC', utf8_lcase) from t1
-- !query analysis
Project [ltrim(utf8_binary#x, Some(ABC)) AS TRIM(LEADING ABC FROM utf8_binary)#x, ltrim(utf8_lcase#x, Some(cast(ABC as string collate UTF8_LCASE))) AS TRIM(LEADING ABC FROM utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select RTRIM(utf8_binary, utf8_lcase) from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "COLLATION_MISMATCH.IMPLICIT",
  "sqlState" : "42P21"
}


-- !query
select RTRIM(utf8_lcase, utf8_binary collate utf8_lcase), RTRIM(utf8_lcase collate utf8_binary, utf8_binary) from t1
-- !query analysis
Project [rtrim(collate(utf8_binary#x, utf8_lcase), Some(utf8_lcase#x)) AS TRIM(TRAILING utf8_lcase FROM collate(utf8_binary, utf8_lcase))#x, rtrim(utf8_binary#x, Some(collate(utf8_lcase#x, utf8_binary))) AS TRIM(TRAILING collate(utf8_lcase, utf8_binary) FROM utf8_binary)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
select RTRIM('ABC', utf8_binary), RTRIM('ABC', utf8_lcase) from t1
-- !query analysis
Project [rtrim(utf8_binary#x, Some(ABC)) AS TRIM(TRAILING ABC FROM utf8_binary)#x, rtrim(utf8_lcase#x, Some(cast(ABC as string collate UTF8_LCASE))) AS TRIM(TRAILING ABC FROM utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1
