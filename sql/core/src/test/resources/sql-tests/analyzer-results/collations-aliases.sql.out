-- Automatically generated by SQLQueryTestSuite
-- !query
create table t1(s string, utf8_binary string collate utf8_binary, utf8_lcase string collate utf8_lcase) using parquet
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t1`, false


-- !query
insert into t1 values ('Spark', 'Spark', 'SQL')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaAAaA', 'aaAaAAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaAAaA', 'aaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('aaAaAAaA', 'aaAaAAaA', 'aaAaaAaAaaAaaAaAaaAaaAaA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('bbAbaAbA', 'bbAbAAbA', 'a')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('İo', 'İo', 'İo')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('İo', 'İo', 'İo ')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('İo', 'İo ', 'İo')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('İo', 'İo', 'i̇o')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('efd2', 'efd2', 'efd2')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('Hello, world! Nice day.', 'Hello, world! Nice day.', 'Hello, world! Nice day.')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('Something else. Nothing here.', 'Something else. Nothing here.', 'Something else. Nothing here.')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('kitten', 'kitten', 'sitTing')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('abc', 'abc', 'abc')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
insert into t1 values ('abcdcba', 'abcdcba', 'aBcDCbA')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t1, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t1], Append, `spark_catalog`.`default`.`t1`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t1), [s, utf8_binary, utf8_lcase]
+- Project [col1#x AS s#x, col2#x AS utf8_binary#x, cast(col3#x as string collate UTF8_LCASE) AS utf8_lcase#x]
   +- LocalRelation [col1#x, col2#x, col3#x]


-- !query
select concat_ws(' ', utf8_lcase, utf8_lcase) from t1
-- !query analysis
Project [concat_ws( , utf8_lcase#x, utf8_lcase#x) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select `concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)` from (
  select concat_ws(' ', utf8_lcase, utf8_lcase) from t1
)
-- !query analysis
Project [concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
+- SubqueryAlias __auto_generated_subquery_name
   +- Project [concat_ws( , utf8_lcase#x, utf8_lcase#x) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
      +- SubqueryAlias spark_catalog.default.t1
         +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select * from (
  select concat_ws(' ', utf8_lcase, utf8_lcase) from t1
)
-- !query analysis
Project [concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
+- SubqueryAlias __auto_generated_subquery_name
   +- Project [concat_ws( , utf8_lcase#x, utf8_lcase#x) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
      +- SubqueryAlias spark_catalog.default.t1
         +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select subq1.* from (
  select concat_ws(' ', utf8_lcase, utf8_lcase) from t1
) AS subq1
-- !query analysis
Project [concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
+- SubqueryAlias subq1
   +- Project [concat_ws( , utf8_lcase#x, utf8_lcase#x) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
      +- SubqueryAlias spark_catalog.default.t1
         +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
with cte as (
  select concat_ws(' ', utf8_lcase, utf8_lcase) from t1
)
select * from cte
-- !query analysis
WithCTE
:- CTERelationDef xxxx, false
:  +- SubqueryAlias cte
:     +- Project [concat_ws( , utf8_lcase#x, utf8_lcase#x) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
:        +- SubqueryAlias spark_catalog.default.t1
:           +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet
+- Project [concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
   +- SubqueryAlias cte
      +- CTERelationRef xxxx, true, [concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x], false, false


-- !query
select * from values (1) where exists (
  select concat_ws(' ', utf8_lcase, utf8_lcase) from t1
)
-- !query analysis
Project [col1#x]
+- Filter exists#x []
   :  +- Project [concat_ws( , utf8_lcase#x, utf8_lcase#x) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
   :     +- SubqueryAlias spark_catalog.default.t1
   :        +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet
   +- LocalRelation [col1#x]


-- !query
select (
  select concat_ws(' ', utf8_lcase, utf8_lcase) from t1 limit 1
)
-- !query analysis
Project [scalar-subquery#x [] AS scalarsubquery()#x]
:  +- GlobalLimit 1
:     +- LocalLimit 1
:        +- Project [concat_ws( , utf8_lcase#x, utf8_lcase#x) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
:           +- SubqueryAlias spark_catalog.default.t1
:              +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet
+- OneRowRelation


-- !query
select (
  with cte as (
    select concat_ws(' ', utf8_lcase, utf8_lcase) from t1
  )
  select * from cte limit 1
)
-- !query analysis
Project [scalar-subquery#x [] AS scalarsubquery()#x]
:  +- WithCTE
:     :- CTERelationDef xxxx, false
:     :  +- SubqueryAlias cte
:     :     +- Project [concat_ws( , utf8_lcase#x, utf8_lcase#x) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
:     :        +- SubqueryAlias spark_catalog.default.t1
:     :           +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet
:     +- GlobalLimit 1
:        +- LocalLimit 1
:           +- Project [concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
:              +- SubqueryAlias cte
:                 +- CTERelationRef xxxx, true, [concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x], false, false
+- OneRowRelation


-- !query
select * from (
  select concat_ws(' ', utf8_lcase, utf8_lcase) from t1 limit 1
)
where (
  `concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)` == 'aaa'
)
-- !query analysis
Project [concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
+- Filter (concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x = aaa)
   +- SubqueryAlias __auto_generated_subquery_name
      +- GlobalLimit 1
         +- LocalLimit 1
            +- Project [concat_ws( , utf8_lcase#x, utf8_lcase#x) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
               +- SubqueryAlias spark_catalog.default.t1
                  +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select lower(`concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)`) from (
  select concat_ws(' ', utf8_lcase, utf8_lcase) from t1
  group by 1
  order by 1
)
-- !query analysis
Project [lower(concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x) AS lower(concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase))#x]
+- SubqueryAlias __auto_generated_subquery_name
   +- Sort [concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x ASC NULLS FIRST], true
      +- Aggregate [concat_ws( , utf8_lcase#x, utf8_lcase#x)], [concat_ws( , utf8_lcase#x, utf8_lcase#x) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
         +- SubqueryAlias spark_catalog.default.t1
            +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select lower(`concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)`) from (
  select concat_ws(' ', utf8_lcase, utf8_lcase) from t1
  group by 1
  order by max(concat_ws(' ', utf8_lcase, utf8_lcase))
)
-- !query analysis
Project [lower(concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x) AS lower(concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase))#x]
+- SubqueryAlias __auto_generated_subquery_name
   +- Project [concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
      +- Sort [max(concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase))#x ASC NULLS FIRST], true
         +- Aggregate [concat_ws( , utf8_lcase#x, utf8_lcase#x)], [concat_ws( , utf8_lcase#x, utf8_lcase#x) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x, max(concat_ws( , utf8_lcase#x, utf8_lcase#x)) AS max(concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase))#x]
            +- SubqueryAlias spark_catalog.default.t1
               +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
create temporary view v1 as (
  select concat_ws(' ', utf8_lcase, utf8_lcase) from t1
)
-- !query analysis
CreateViewCommand `v1`, (
  select concat_ws(' ', utf8_lcase, utf8_lcase) from t1
), false, false, LocalTempView, UNSUPPORTED, true
   +- Project [concat_ws( , utf8_lcase#x, utf8_lcase#x) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
      +- SubqueryAlias spark_catalog.default.t1
         +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select * from v1
-- !query analysis
Project [concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
+- SubqueryAlias v1
   +- View (`v1`, [concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x])
      +- Project [cast(concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x as string collate UTF8_LCASE) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
         +- Project [concat_ws( , utf8_lcase#x, utf8_lcase#x) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
            +- SubqueryAlias spark_catalog.default.t1
               +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
select `concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)` from v1
-- !query analysis
Project [concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
+- SubqueryAlias v1
   +- View (`v1`, [concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x])
      +- Project [cast(concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x as string collate UTF8_LCASE) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
         +- Project [concat_ws( , utf8_lcase#x, utf8_lcase#x) AS concat_ws(' ' collate UTF8_LCASE, utf8_lcase, utf8_lcase)#x]
            +- SubqueryAlias spark_catalog.default.t1
               +- Relation spark_catalog.default.t1[s#x,utf8_binary#x,utf8_lcase#x] parquet


-- !query
drop view v1
-- !query analysis
DropTempViewCommand v1


-- !query
drop table t1
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1
