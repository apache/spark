-- Automatically generated by SQLQueryTestSuite
-- !query
SELECT * FROM testdata LIMIT 2
-- !query analysis
GlobalLimit 2
+- LocalLimit 2
   +- Project [key#x, value#x]
      +- SubqueryAlias spark_catalog.default.testdata
         +- Relation spark_catalog.default.testdata[key#x,value#x] parquet


-- !query
SELECT * FROM arraydata LIMIT 2
-- !query analysis
GlobalLimit 2
+- LocalLimit 2
   +- Project [arraycol#x, nestedarraycol#x]
      +- SubqueryAlias spark_catalog.default.arraydata
         +- Relation spark_catalog.default.arraydata[arraycol#x,nestedarraycol#x] parquet


-- !query
SELECT * FROM mapdata LIMIT 2
-- !query analysis
GlobalLimit 2
+- LocalLimit 2
   +- Project [mapcol#x]
      +- SubqueryAlias spark_catalog.default.mapdata
         +- Relation spark_catalog.default.mapdata[mapcol#x] parquet


-- !query
SELECT * FROM testdata LIMIT 2 + 1
-- !query analysis
GlobalLimit (2 + 1)
+- LocalLimit (2 + 1)
   +- Project [key#x, value#x]
      +- SubqueryAlias spark_catalog.default.testdata
         +- Relation spark_catalog.default.testdata[key#x,value#x] parquet


-- !query
SELECT * FROM testdata LIMIT CAST(1 AS int)
-- !query analysis
GlobalLimit cast(1 as int)
+- LocalLimit cast(1 as int)
   +- Project [key#x, value#x]
      +- SubqueryAlias spark_catalog.default.testdata
         +- Relation spark_catalog.default.testdata[key#x,value#x] parquet


-- !query
SELECT * FROM testdata LIMIT -1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_2403",
  "messageParameters" : {
    "name" : "limit",
    "v" : "-1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 30,
    "stopIndex" : 31,
    "fragment" : "-1"
  } ]
}


-- !query
SELECT * FROM testData TABLESAMPLE (-1 ROWS)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_2403",
  "messageParameters" : {
    "name" : "limit",
    "v" : "-1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 37,
    "stopIndex" : 38,
    "fragment" : "-1"
  } ]
}


-- !query
SELECT * FROM testdata LIMIT CAST(1 AS INT)
-- !query analysis
GlobalLimit cast(1 as int)
+- LocalLimit cast(1 as int)
   +- Project [key#x, value#x]
      +- SubqueryAlias spark_catalog.default.testdata
         +- Relation spark_catalog.default.testdata[key#x,value#x] parquet


-- !query
SELECT * FROM testdata LIMIT CAST(NULL AS INT)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_2402",
  "messageParameters" : {
    "limitExpr" : "CAST(NULL AS INT)",
    "name" : "limit"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 30,
    "stopIndex" : 46,
    "fragment" : "CAST(NULL AS INT)"
  } ]
}


-- !query
SELECT * FROM testdata LIMIT key > 3
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_2400",
  "messageParameters" : {
    "limitExpr" : "(spark_catalog.default.testdata.key > 3)",
    "name" : "limit"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 30,
    "stopIndex" : 36,
    "fragment" : "key > 3"
  } ]
}


-- !query
SELECT * FROM testdata LIMIT true
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_2401",
  "messageParameters" : {
    "dataType" : "boolean",
    "name" : "limit"
  }
}


-- !query
SELECT * FROM testdata LIMIT 'a'
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_2401",
  "messageParameters" : {
    "dataType" : "string",
    "name" : "limit"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 30,
    "stopIndex" : 32,
    "fragment" : "'a'"
  } ]
}


-- !query
SELECT * FROM (SELECT * FROM range(10) LIMIT 5) WHERE id > 3
-- !query analysis
Project [id#xL]
+- Filter (id#xL > cast(3 as bigint))
   +- SubqueryAlias __auto_generated_subquery_name
      +- GlobalLimit 5
         +- LocalLimit 5
            +- Project [id#xL]
               +- Range (0, 10, step=1, splits=None)


-- !query
SELECT * FROM testdata WHERE key < 3 LIMIT ALL
-- !query analysis
Project [key#x, value#x]
+- Filter (key#x < 3)
   +- SubqueryAlias spark_catalog.default.testdata
      +- Relation spark_catalog.default.testdata[key#x,value#x] parquet
