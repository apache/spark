-- Automatically generated by SQLQueryTestSuite
-- !query
SET spark.sql.ansi.enabled = true
-- !query analysis
SetCommand (spark.sql.ansi.enabled,Some(true))


-- !query
DECLARE title STRING
-- !query analysis
CreateVariable defaultvalueexpression(null, null), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.title


-- !query
SET VARIABLE title = '-- Basic sanity --'
-- !query analysis
SetVariable [variablereference(system.session.title=CAST(NULL AS STRING))]
+- Project [-- Basic sanity -- AS title#x]
   +- OneRowRelation


-- !query
DECLARE var1 INT = 5
-- !query analysis
CreateVariable defaultvalueexpression(cast(5 as int), 5), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT var1
-- !query analysis
Project [variablereference(system.session.var1=5) AS var1#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = 6
-- !query analysis
SetVariable [variablereference(system.session.var1=5)]
+- Project [6 AS var1#x]
   +- OneRowRelation


-- !query
SELECT var1
-- !query analysis
Project [variablereference(system.session.var1=6) AS var1#x]
+- OneRowRelation


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SET VARIABLE title = 'Create Variable - Success Cases'
-- !query analysis
SetVariable [variablereference(system.session.title='-- Basic sanity --')]
+- Project [Create Variable - Success Cases AS title#x]
   +- OneRowRelation


-- !query
DECLARE VARIABLE var1 INT
-- !query analysis
CreateVariable defaultvalueexpression(null, null), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT 'Expect: INT, NULL', typeof(var1), var1
-- !query analysis
Project [Expect: INT, NULL AS Expect: INT, NULL#x, typeof(variablereference(system.session.var1=CAST(NULL AS INT))) AS typeof(variablereference(system.session.var1=CAST(NULL AS INT)))#x, variablereference(system.session.var1=CAST(NULL AS INT)) AS var1#x]
+- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 DOUBLE
-- !query analysis
CreateVariable defaultvalueexpression(null, null), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT 'Expect: DOUBLE, NULL', typeof(var1), var1
-- !query analysis
Project [Expect: DOUBLE, NULL AS Expect: DOUBLE, NULL#x, typeof(variablereference(system.session.var1=CAST(NULL AS DOUBLE))) AS typeof(variablereference(system.session.var1=CAST(NULL AS DOUBLE)))#x, variablereference(system.session.var1=CAST(NULL AS DOUBLE)) AS var1#x]
+- OneRowRelation


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DECLARE OR REPLACE VARIABLE var1 TIMESTAMP
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT 'Expect: TIMESTAMP, NULL', typeof(var1), var1
-- !query analysis
Project [Expect: TIMESTAMP, NULL AS Expect: TIMESTAMP, NULL#x, typeof(variablereference(system.session.var1=CAST(NULL AS TIMESTAMP))) AS typeof(variablereference(system.session.var1=CAST(NULL AS TIMESTAMP)))#x, variablereference(system.session.var1=CAST(NULL AS TIMESTAMP)) AS var1#x]
+- OneRowRelation


-- !query
SET VARIABLE title = 'Create Variable - Failure Cases'
-- !query analysis
SetVariable [variablereference(system.session.title='Create Variable - Success Cases')]
+- Project [Create Variable - Failure Cases AS title#x]
   +- OneRowRelation


-- !query
DECLARE VARIABLE IF NOT EXISTS var1 INT
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'EXISTS'",
    "hint" : ""
  }
}


-- !query
DROP TEMPORARY VARIABLE IF EXISTS var1
-- !query analysis
DropVariable true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SET VARIABLE title = 'Drop Variable'
-- !query analysis
SetVariable [variablereference(system.session.title='Create Variable - Failure Cases')]
+- Project [Drop Variable AS title#x]
   +- OneRowRelation


-- !query
DECLARE VAR var1 INT
-- !query analysis
CreateVariable defaultvalueexpression(null, null), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT var1
-- !query analysis
Project [variablereference(system.session.var1=CAST(NULL AS INT)) AS var1#x]
+- OneRowRelation


-- !query
DROP TEMPORARY VAR var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT var1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNRESOLVED_COLUMN.WITHOUT_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`var1`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 11,
    "fragment" : "var1"
  } ]
}


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "VARIABLE_NOT_FOUND",
  "sqlState" : "42883",
  "messageParameters" : {
    "variableName" : "`system`.`session`.`var1`"
  }
}


-- !query
DROP TEMPORARY VARIABLE IF EXISTS var1
-- !query analysis
DropVariable true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DECLARE VARIABLE var1 INT
-- !query analysis
CreateVariable defaultvalueexpression(null, null), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DROP VARIABLE var1
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'VARIABLE'",
    "hint" : ""
  }
}


-- !query
DROP VARIABLE system.session.var1
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'VARIABLE'",
    "hint" : ""
  }
}


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SET VARIABLE title = 'Test qualifiers - success'
-- !query analysis
SetVariable [variablereference(system.session.title='Drop Variable')]
+- Project [Test qualifiers - success AS title#x]
   +- OneRowRelation


-- !query
DECLARE VARIABLE var1 INT DEFAULT 1
-- !query analysis
CreateVariable defaultvalueexpression(cast(1 as int), 1), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT 1 as Expected, var1 as Unqualified, session.var1 AS SchemaQualified, system.session.var1 AS fullyQualified
-- !query analysis
Project [1 AS Expected#x, variablereference(system.session.var1=1) AS Unqualified#x, variablereference(system.session.var1=1) AS SchemaQualified#x, variablereference(system.session.var1=1) AS fullyQualified#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = 2
-- !query analysis
SetVariable [variablereference(system.session.var1=1)]
+- Project [2 AS var1#x]
   +- OneRowRelation


-- !query
SELECT 2 as Expected, var1 as Unqualified, session.var1 AS SchemaQualified, system.session.var1 AS fullyQualified
-- !query analysis
Project [2 AS Expected#x, variablereference(system.session.var1=2) AS Unqualified#x, variablereference(system.session.var1=2) AS SchemaQualified#x, variablereference(system.session.var1=2) AS fullyQualified#x]
+- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE session.var1 INT DEFAULT 1
-- !query analysis
CreateVariable defaultvalueexpression(cast(1 as int), 1), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT 1 as Expected, var1 as Unqualified, session.var1 AS SchemaQualified, system.session.var1 AS fullyQualified
-- !query analysis
Project [1 AS Expected#x, variablereference(system.session.var1=1) AS Unqualified#x, variablereference(system.session.var1=1) AS SchemaQualified#x, variablereference(system.session.var1=1) AS fullyQualified#x]
+- OneRowRelation


-- !query
SET VARIABLE session.var1 = 2
-- !query analysis
SetVariable [variablereference(system.session.var1=1)]
+- Project [2 AS var1#x]
   +- OneRowRelation


-- !query
SELECT 2 as Expected, var1 as Unqualified, session.var1 AS SchemaQualified, system.session.var1 AS fullyQualified
-- !query analysis
Project [2 AS Expected#x, variablereference(system.session.var1=2) AS Unqualified#x, variablereference(system.session.var1=2) AS SchemaQualified#x, variablereference(system.session.var1=2) AS fullyQualified#x]
+- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE system.session.var1 INT DEFAULT 1
-- !query analysis
CreateVariable defaultvalueexpression(cast(1 as int), 1), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT 1 as Expected, var1 as Unqualified, session.var1 AS SchemaQualified, system.session.var1 AS fullyQualified
-- !query analysis
Project [1 AS Expected#x, variablereference(system.session.var1=1) AS Unqualified#x, variablereference(system.session.var1=1) AS SchemaQualified#x, variablereference(system.session.var1=1) AS fullyQualified#x]
+- OneRowRelation


-- !query
SET VARIABLE system.session.var1 = 2
-- !query analysis
SetVariable [variablereference(system.session.var1=1)]
+- Project [2 AS var1#x]
   +- OneRowRelation


-- !query
SELECT 2 as Expected, var1 as Unqualified, session.var1 AS SchemaQualified, system.session.var1 AS fullyQualified
-- !query analysis
Project [2 AS Expected#x, variablereference(system.session.var1=2) AS Unqualified#x, variablereference(system.session.var1=2) AS SchemaQualified#x, variablereference(system.session.var1=2) AS fullyQualified#x]
+- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE sySteM.sEssIon.vAr1 INT DEFAULT 1
-- !query analysis
CreateVariable defaultvalueexpression(cast(1 as int), 1), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.vAr1


-- !query
SELECT 1 as Expected, var1 as Unqualified, sessIon.Var1 AS SchemaQualified, System.sessiOn.var1 AS fullyQualified
-- !query analysis
Project [1 AS Expected#x, variablereference(system.session.var1=1) AS Unqualified#x, variablereference(system.session.var1=1) AS SchemaQualified#x, variablereference(system.session.var1=1) AS fullyQualified#x]
+- OneRowRelation


-- !query
SET VARIABLE sYstem.sesSiOn.vaR1 = 2
-- !query analysis
SetVariable [variablereference(system.session.var1=1)]
+- Project [2 AS vaR1#x]
   +- OneRowRelation


-- !query
SELECT 2 as Expected, VAR1 as Unqualified, SESSION.VAR1 AS SchemaQualified, SYSTEM.SESSION.VAR1 AS fullyQualified
-- !query analysis
Project [2 AS Expected#x, variablereference(system.session.var1=2) AS Unqualified#x, variablereference(system.session.var1=2) AS SchemaQualified#x, variablereference(system.session.var1=2) AS fullyQualified#x]
+- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 INT
-- !query analysis
CreateVariable defaultvalueexpression(null, null), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "VARIABLE_NOT_FOUND",
  "sqlState" : "42883",
  "messageParameters" : {
    "variableName" : "`system`.`session`.`var1`"
  }
}


-- !query
DECLARE OR REPLACE VARIABLE var1 INT
-- !query analysis
CreateVariable defaultvalueexpression(null, null), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DROP TEMPORARY VARIABLE session.var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "VARIABLE_NOT_FOUND",
  "sqlState" : "42883",
  "messageParameters" : {
    "variableName" : "`system`.`session`.`var1`"
  }
}


-- !query
DECLARE OR REPLACE VARIABLE var1 INT
-- !query analysis
CreateVariable defaultvalueexpression(null, null), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DROP TEMPORARY VARIABLE system.session.var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "VARIABLE_NOT_FOUND",
  "sqlState" : "42883",
  "messageParameters" : {
    "variableName" : "`system`.`session`.`var1`"
  }
}


-- !query
DECLARE OR REPLACE VARIABLE var1 INT
-- !query analysis
CreateVariable defaultvalueexpression(null, null), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DROP TEMPORARY VARIABLE sysTem.sesSion.vAr1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.vAr1


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "VARIABLE_NOT_FOUND",
  "sqlState" : "42883",
  "messageParameters" : {
    "variableName" : "`system`.`session`.`var1`"
  }
}


-- !query
SET VARIABLE title = 'Test variable in aggregate'
-- !query analysis
SetVariable [variablereference(system.session.title='Test qualifiers - success')]
+- Project [Test variable in aggregate AS title#x]
   +- OneRowRelation


-- !query
SELECT (SELECT MAX(id) FROM RANGE(10) WHERE id < title) FROM VALUES 1, 2 AS t(title)
-- !query analysis
Project [scalar-subquery#x [title#x] AS scalarsubquery(title)#xL]
:  +- Aggregate [max(id#xL) AS max(id)#xL]
:     +- Filter (id#xL < cast(outer(title#x) as bigint))
:        +- Range (0, 10, step=1)
+- SubqueryAlias t
   +- LocalRelation [title#x]


-- !query
SET VARIABLE title = 'Test qualifiers - fail'
-- !query analysis
SetVariable [variablereference(system.session.title='Test variable in aggregate')]
+- Project [Test qualifiers - fail AS title#x]
   +- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE builtin.var1 INT
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_VARIABLE",
  "sqlState" : "42883",
  "messageParameters" : {
    "searchPath" : "`system`.`session`",
    "variableName" : "`builtin`.`var1`"
  }
}


-- !query
DECLARE OR REPLACE VARIABLE system.sesion.var1 INT
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_VARIABLE",
  "sqlState" : "42883",
  "messageParameters" : {
    "searchPath" : "`system`.`session`",
    "variableName" : "`system`.`sesion`.`var1`"
  }
}


-- !query
DECLARE OR REPLACE VARIABLE sys.session.var1 INT
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_VARIABLE",
  "sqlState" : "42883",
  "messageParameters" : {
    "searchPath" : "`system`.`session`",
    "variableName" : "`sys`.`session`.`var1`"
  }
}


-- !query
DECLARE OR REPLACE VARIABLE var1 INT
-- !query analysis
CreateVariable defaultvalueexpression(null, null), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT var
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNRESOLVED_COLUMN.WITHOUT_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`var`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 10,
    "fragment" : "var"
  } ]
}


-- !query
SELECT ses.var1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNRESOLVED_COLUMN.WITHOUT_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`ses`.`var1`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 15,
    "fragment" : "ses.var1"
  } ]
}


-- !query
SELECT b.sesson.var1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNRESOLVED_COLUMN.WITHOUT_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`b`.`sesson`.`var1`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 20,
    "fragment" : "b.sesson.var1"
  } ]
}


-- !query
SELECT builtn.session.var1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNRESOLVED_COLUMN.WITHOUT_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`builtn`.`session`.`var1`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 26,
    "fragment" : "builtn.session.var1"
  } ]
}


-- !query
SET VARIABLE ses.var1 = 1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_VARIABLE",
  "sqlState" : "42883",
  "messageParameters" : {
    "searchPath" : "`SYSTEM`.`SESSION`",
    "variableName" : "`ses`.`var1`"
  }
}


-- !query
SET VARIABLE builtn.session.var1 = 1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_VARIABLE",
  "sqlState" : "42883",
  "messageParameters" : {
    "searchPath" : "`SYSTEM`.`SESSION`",
    "variableName" : "`builtn`.`session`.`var1`"
  }
}


-- !query
SET VARIABLE title = 'Test DEFAULT on create - success'
-- !query analysis
SetVariable [variablereference(system.session.title='Test qualifiers - fail')]
+- Project [Test DEFAULT on create - success AS title#x]
   +- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 INT DEFAULT 1
-- !query analysis
CreateVariable defaultvalueexpression(cast(1 as int), 1), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT 1 AS Expected, var1 AS result
-- !query analysis
Project [1 AS Expected#x, variablereference(system.session.var1=1) AS result#x]
+- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 DOUBLE DEFAULT 1 + RAND(5)
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
SELECT true AS Expected, var1 >= 1 AS result
-- !query analysis
Project [true AS Expected#x, (variablereference(system.session.var1=1.023906964275029D) >= cast(1 as double)) AS result#x]
+- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 = 'Hello'
-- !query analysis
CreateVariable defaultvalueexpression(Hello, 'Hello'), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT 'STRING, Hello' AS Expected, typeof(var1) AS type, var1 AS result
-- !query analysis
Project [STRING, Hello AS Expected#x, typeof(variablereference(system.session.var1='Hello')) AS type#x, variablereference(system.session.var1='Hello') AS result#x]
+- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 DEFAULT NULL
-- !query analysis
CreateVariable defaultvalueexpression(null, NULL), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT 'VOID, NULL' AS Expected, typeof(var1) AS type, var1 AS result
-- !query analysis
Project [VOID, NULL AS Expected#x, typeof(variablereference(system.session.var1=NULL)) AS type#x, variablereference(system.session.var1=NULL) AS result#x]
+- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE INT DEFAULT 5.0
-- !query analysis
CreateVariable defaultvalueexpression(5.0, 5.0), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.INT


-- !query
SELECT 'INT, 5' AS Expected, typeof(var1) AS type, var1 AS result
-- !query analysis
Project [INT, 5 AS Expected#x, typeof(variablereference(system.session.var1=NULL)) AS type#x, variablereference(system.session.var1=NULL) AS result#x]
+- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 MAP<string, double> DEFAULT MAP('Hello', 5.1, 'World', -7.1E10)
-- !query analysis
CreateVariable defaultvalueexpression(cast(map(Hello, cast(5.1 as double), World, -7.1E10) as map<string,double>), MAP('Hello', 5.1, 'World', -7.1E10)), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT 'MAP<string, double>, [Hello -> 5.1, World -> -7E10]' AS Expected, typeof(var1) AS type, var1 AS result
-- !query analysis
Project [MAP<string, double>, [Hello -> 5.1, World -> -7E10] AS Expected#x, typeof(variablereference(system.session.var1=MAP('Hello', 5.1D, 'World', -7.1E10D))) AS type#x, variablereference(system.session.var1=MAP('Hello', 5.1D, 'World', -7.1E10D)) AS result#x]
+- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 INT DEFAULT NULL
-- !query analysis
CreateVariable defaultvalueexpression(cast(null as int), NULL), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT 'NULL' AS Expected, var1 AS result
-- !query analysis
Project [NULL AS Expected#x, variablereference(system.session.var1=CAST(NULL AS INT)) AS result#x]
+- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 STRING DEFAULT CURRENT_DATABASE()
-- !query analysis
CreateVariable defaultvalueexpression(cast(current_schema() as string), CURRENT_DATABASE()), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT 'true' AS Expected, length(var1) > 0 AS result
-- !query analysis
Project [true AS Expected#x, (length(variablereference(system.session.var1='default')) > 0) AS result#x]
+- OneRowRelation


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DECLARE var1
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_SQL_SYNTAX.VARIABLE_TYPE_OR_DEFAULT_REQUIRED",
  "sqlState" : "42000",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 12,
    "fragment" : "DECLARE var1"
  } ]
}


-- !query
SET VARIABLE title = 'Test DEFAULT on create - failures'
-- !query analysis
SetVariable [variablereference(system.session.title='Test DEFAULT on create - success')]
+- Project [Test DEFAULT on create - failures AS title#x]
   +- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 INT DEFAULT (SELECT c1 FROM VALUES(1) AS T(c1))
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_DEFAULT_VALUE.SUBQUERY_EXPRESSION",
  "sqlState" : "42623",
  "messageParameters" : {
    "colName" : "`system`.`session`.`var1`",
    "defaultValue" : "(SELECT c1 FROM VALUES(1) AS T(c1))",
    "statement" : "DECLARE VARIABLE"
  }
}


-- !query
DECLARE OR REPLACE VARIABLE var1 INT DEFAULT 'hello'
-- !query analysis
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'hello'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 52,
    "fragment" : "DECLARE OR REPLACE VARIABLE var1 INT DEFAULT 'hello'"
  } ]
}


-- !query
DECLARE OR REPLACE VARIABLE var1 INT DEFAULT 1 / 0
-- !query analysis
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "DIVIDE_BY_ZERO",
  "sqlState" : "22012",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 46,
    "stopIndex" : 50,
    "fragment" : "1 / 0"
  } ]
}


-- !query
DECLARE OR REPLACE VARIABLE var1 SMALLINT DEFAULT 100000
-- !query analysis
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "CAST_OVERFLOW",
  "sqlState" : "22003",
  "messageParameters" : {
    "sourceType" : "\"INT\"",
    "targetType" : "\"SMALLINT\"",
    "value" : "100000"
  }
}


-- !query
SET VARIABLE title = 'SET VARIABLE - single target'
-- !query analysis
SetVariable [variablereference(system.session.title='Test DEFAULT on create - failures')]
+- Project [SET VARIABLE - single target AS title#x]
   +- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 INT DEFAULT 5
-- !query analysis
CreateVariable defaultvalueexpression(cast(5 as int), 5), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SET VARIABLE var1 = 7
-- !query analysis
SetVariable [variablereference(system.session.var1=5)]
+- Project [7 AS var1#x]
   +- OneRowRelation


-- !query
SELECT var1
-- !query analysis
Project [variablereference(system.session.var1=7) AS var1#x]
+- OneRowRelation


-- !query
SET VAR var1 = 8
-- !query analysis
SetVariable [variablereference(system.session.var1=7)]
+- Project [8 AS var1#x]
   +- OneRowRelation


-- !query
SELECT var1
-- !query analysis
Project [variablereference(system.session.var1=8) AS var1#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = (SELECT c1 FROM VALUES(1) AS T(c1))
-- !query analysis
SetVariable [variablereference(system.session.var1=8)]
+- Project [scalar-subquery#x [] AS var1#x]
   :  +- Project [c1#x]
   :     +- SubqueryAlias T
   :        +- LocalRelation [c1#x]
   +- OneRowRelation


-- !query
SELECT var1
-- !query analysis
Project [variablereference(system.session.var1=1) AS var1#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = (SELECT c1 FROM VALUES(1) AS T(c1) WHERE 1=0)
-- !query analysis
SetVariable [variablereference(system.session.var1=1)]
+- Project [scalar-subquery#x [] AS var1#x]
   :  +- Project [c1#x]
   :     +- Filter (1 = 0)
   :        +- SubqueryAlias T
   :           +- LocalRelation [c1#x]
   +- OneRowRelation


-- !query
SELECT var1 AS `null`
-- !query analysis
Project [variablereference(system.session.var1=CAST(NULL AS INT)) AS null#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = (SELECT c1 FROM VALUES(1.0) AS T(c1))
-- !query analysis
SetVariable [variablereference(system.session.var1=CAST(NULL AS INT))]
+- Project [cast(var1#x as int) AS var1#x]
   +- Project [scalar-subquery#x [] AS var1#x]
      :  +- Project [c1#x]
      :     +- SubqueryAlias T
      :        +- LocalRelation [c1#x]
      +- OneRowRelation


-- !query
SELECT var1
-- !query analysis
Project [variablereference(system.session.var1=1) AS var1#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = (SELECT c1 FROM VALUES(1.0E10) AS T(c1))
-- !query analysis
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "CAST_OVERFLOW",
  "sqlState" : "22003",
  "messageParameters" : {
    "sourceType" : "\"DOUBLE\"",
    "targetType" : "\"INT\"",
    "value" : "1.0E10D"
  }
}


-- !query
SELECT var1
-- !query analysis
Project [variablereference(system.session.var1=1) AS var1#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = (SELECT c1 FROM VALUES(1), (2) AS T(c1))
-- !query analysis
org.apache.spark.SparkException
{
  "errorClass" : "SCALAR_SUBQUERY_TOO_MANY_ROWS",
  "sqlState" : "21000",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 21,
    "stopIndex" : 60,
    "fragment" : "(SELECT c1 FROM VALUES(1), (2) AS T(c1))"
  } ]
}


-- !query
SET VARIABLE var1 = (SELECT c1, c1 FROM VALUES(1), (2) AS T(c1))
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_SUBQUERY_EXPRESSION.SCALAR_SUBQUERY_RETURN_MORE_THAN_ONE_OUTPUT_COLUMN",
  "sqlState" : "42823",
  "messageParameters" : {
    "number" : "2"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 21,
    "stopIndex" : 64,
    "fragment" : "(SELECT c1, c1 FROM VALUES(1), (2) AS T(c1))"
  } ]
}


-- !query
SET VARIABLE var1 = (SELECT c1 FROM VALUES('hello') AS T(c1))
-- !query analysis
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'hello'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 61,
    "fragment" : "SET VARIABLE var1 = (SELECT c1 FROM VALUES('hello') AS T(c1))"
  } ]
}


-- !query
DECLARE OR REPLACE VARIABLE var1 INT DEFAULT 5
-- !query analysis
CreateVariable defaultvalueexpression(cast(5 as int), 5), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SET VARIABLE var1 = var1 + 1
-- !query analysis
SetVariable [variablereference(system.session.var1=5)]
+- Project [(variablereference(system.session.var1=5) + 1) AS var1#x]
   +- OneRowRelation


-- !query
SELECT var1
-- !query analysis
Project [variablereference(system.session.var1=6) AS var1#x]
+- OneRowRelation


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SET VARIABLE title = 'SET VARIABLE - comma separated target'
-- !query analysis
SetVariable [variablereference(system.session.title='SET VARIABLE - single target')]
+- Project [SET VARIABLE - comma separated target AS title#x]
   +- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 INT DEFAULT 5
-- !query analysis
CreateVariable defaultvalueexpression(cast(5 as int), 5), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DECLARE OR REPLACE VARIABLE var2 STRING DEFAULT 'hello'
-- !query analysis
CreateVariable defaultvalueexpression(cast(hello as string), 'hello'), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var2


-- !query
DECLARE OR REPLACE VARIABLE var3 DOUBLE DEFAULT 2
-- !query analysis
CreateVariable defaultvalueexpression(cast(2 as double), 2), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var3


-- !query
SET VARIABLE var1 = 6, var2 = 'world', var3 = pi()
-- !query analysis
SetVariable [variablereference(system.session.var1=5), variablereference(system.session.var2='hello'), variablereference(system.session.var3=2.0D)]
+- Project [6 AS var1#x, world AS var2#x, PI() AS var3#x]
   +- OneRowRelation


-- !query
SELECT var1 AS `6`, var2 AS `world` , var3 as `3.14...`
-- !query analysis
Project [variablereference(system.session.var1=6) AS 6#x, variablereference(system.session.var2='world') AS world#x, variablereference(system.session.var3=3.141592653589793D) AS 3.14...#x]
+- OneRowRelation


-- !query
SET VAR var1 = 7, var2 = 'universe', var3 = -1
-- !query analysis
SetVariable [variablereference(system.session.var1=6), variablereference(system.session.var2='world'), variablereference(system.session.var3=3.141592653589793D)]
+- Project [var1#x, var2#x, cast(var3#x as double) AS var3#x]
   +- Project [7 AS var1#x, universe AS var2#x, -1 AS var3#x]
      +- OneRowRelation


-- !query
SELECT var1 AS `7`, var2 AS `universe` , var3 as `-1`
-- !query analysis
Project [variablereference(system.session.var1=7) AS 7#x, variablereference(system.session.var2='universe') AS universe#x, variablereference(system.session.var3=-1.0D) AS -1#x]
+- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 INT DEFAULT 5
-- !query analysis
CreateVariable defaultvalueexpression(cast(5 as int), 5), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DECLARE OR REPLACE VARIABLE var2 STRING DEFAULT 'hello'
-- !query analysis
CreateVariable defaultvalueexpression(cast(hello as string), 'hello'), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var2


-- !query
DECLARE OR REPLACE VARIABLE var3 DOUBLE DEFAULT 2
-- !query analysis
CreateVariable defaultvalueexpression(cast(2 as double), 2), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var3


-- !query
SET VARIABLE var1 = var3, var2 = ascii(var1), var3 = var1
-- !query analysis
SetVariable [variablereference(system.session.var1=5), variablereference(system.session.var2='hello'), variablereference(system.session.var3=2.0D)]
+- Project [cast(var3#x as int) AS var1#x, cast(var2#x as string) AS var2#x, cast(var1#x as double) AS var3#x]
   +- Project [variablereference(system.session.var3=2.0D) AS var3#x, ascii(cast(variablereference(system.session.var1=5) as string)) AS var2#x, variablereference(system.session.var1=5) AS var1#x]
      +- OneRowRelation


-- !query
SELECT var1 AS `2`, var2 AS `104`, var3 AS `5`
-- !query analysis
Project [variablereference(system.session.var1=2) AS 2#x, variablereference(system.session.var2='53') AS 104#x, variablereference(system.session.var3=5.0D) AS 5#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = var3, var2 = INTERVAL'5' HOUR, var3 = var1
-- !query analysis
SetVariable [variablereference(system.session.var1=2), variablereference(system.session.var2='53'), variablereference(system.session.var3=5.0D)]
+- Project [cast(var3#x as int) AS var1#x, cast(var2#x as string) AS var2#x, cast(var1#x as double) AS var3#x]
   +- Project [variablereference(system.session.var3=5.0D) AS var3#x, INTERVAL '05' HOUR AS var2#x, variablereference(system.session.var1=2) AS var1#x]
      +- OneRowRelation


-- !query
SET VARIABLE var1 = 1, var2 = 0, vAr1 = 1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DUPLICATE_ASSIGNMENTS",
  "sqlState" : "42701",
  "messageParameters" : {
    "nameList" : "`var1`"
  }
}


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DROP TEMPORARY VARIABLE var2
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var2


-- !query
DROP TEMPORARY VARIABLE var3
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var3


-- !query
SET VARIABLE title = 'SET VARIABLE - row assignment'
-- !query analysis
SetVariable [variablereference(system.session.title='SET VARIABLE - comma separated target')]
+- Project [SET VARIABLE - row assignment AS title#x]
   +- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 INT DEFAULT 5
-- !query analysis
CreateVariable defaultvalueexpression(cast(5 as int), 5), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DECLARE OR REPLACE VARIABLE var2 STRING DEFAULT 'hello'
-- !query analysis
CreateVariable defaultvalueexpression(cast(hello as string), 'hello'), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var2


-- !query
DECLARE OR REPLACE VARIABLE var3 DOUBLE DEFAULT 2
-- !query analysis
CreateVariable defaultvalueexpression(cast(2 as double), 2), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var3


-- !query
SET VARIABLE (var1) = (SELECT c1 FROM VALUES(1) AS T(c1))
-- !query analysis
SetVariable [variablereference(system.session.var1=5)]
+- Project [c1#x]
   +- SubqueryAlias T
      +- LocalRelation [c1#x]


-- !query
SELECT var1
-- !query analysis
Project [variablereference(system.session.var1=1) AS var1#x]
+- OneRowRelation


-- !query
SET VAR (var1) = (SELECT c1 FROM VALUES(2) AS T(c1))
-- !query analysis
SetVariable [variablereference(system.session.var1=1)]
+- Project [c1#x]
   +- SubqueryAlias T
      +- LocalRelation [c1#x]


-- !query
SELECT var1
-- !query analysis
Project [variablereference(system.session.var1=2) AS var1#x]
+- OneRowRelation


-- !query
SET VARIABLE (var1, var2) = (SELECT c1, c2 FROM VALUES(10, 11) AS T(c1, c2))
-- !query analysis
SetVariable [variablereference(system.session.var1=2), variablereference(system.session.var2='hello')]
+- Project [c1#x, cast(c2#x as string) AS var2#x]
   +- Project [c1#x, c2#x]
      +- SubqueryAlias T
         +- LocalRelation [c1#x, c2#x]


-- !query
SELECT var1 AS `10`, var2 AS `11`
-- !query analysis
Project [variablereference(system.session.var1=10) AS 10#x, variablereference(system.session.var2='11') AS 11#x]
+- OneRowRelation


-- !query
SET VARIABLE (var1, var2, var3) = (SELECT c1, c2, c3 FROM VALUES(100, 110, 120) AS T(c1, c2, c3))
-- !query analysis
SetVariable [variablereference(system.session.var1=10), variablereference(system.session.var2='11'), variablereference(system.session.var3=2.0D)]
+- Project [c1#x, cast(c2#x as string) AS var2#x, cast(c3#x as double) AS var3#x]
   +- Project [c1#x, c2#x, c3#x]
      +- SubqueryAlias T
         +- LocalRelation [c1#x, c2#x, c3#x]


-- !query
SELECT var1 AS `100`, var2 AS `110`, var3 AS `120`
-- !query analysis
Project [variablereference(system.session.var1=100) AS 100#x, variablereference(system.session.var2='110') AS 110#x, variablereference(system.session.var3=120.0D) AS 120#x]
+- OneRowRelation


-- !query
SET VARIABLE (var1, var2, var3) = (SELECT c1, c2, c3 FROM VALUES(100, 110, 120) AS T(c1, c2, c3) WHERE 1 = 0)
-- !query analysis
SetVariable [variablereference(system.session.var1=100), variablereference(system.session.var2='110'), variablereference(system.session.var3=120.0D)]
+- Project [c1#x, cast(c2#x as string) AS var2#x, cast(c3#x as double) AS var3#x]
   +- Project [c1#x, c2#x, c3#x]
      +- Filter (1 = 0)
         +- SubqueryAlias T
            +- LocalRelation [c1#x, c2#x, c3#x]


-- !query
SELECT var1 AS `NULL`, var2 AS `NULL`, var3 AS `NULL`
-- !query analysis
Project [variablereference(system.session.var1=CAST(NULL AS INT)) AS NULL#x, variablereference(system.session.var2=CAST(NULL AS STRING)) AS NULL#x, variablereference(system.session.var3=CAST(NULL AS DOUBLE)) AS NULL#x]
+- OneRowRelation


-- !query
SET VARIABLE () = (SELECT 1)
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_SET_SYNTAX",
  "sqlState" : "42000",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 28,
    "fragment" : "SET VARIABLE () = (SELECT 1)"
  } ]
}


-- !query
SET VARIABLE (var1, var2, var3) = (SELECT c1, c2, c3 FROM VALUES(100, 110, 120), (-100, -110, -120) AS T(c1, c2, c3))
-- !query analysis
org.apache.spark.SparkException
{
  "errorClass" : "ROW_SUBQUERY_TOO_MANY_ROWS",
  "sqlState" : "21000"
}


-- !query
SET VARIABLE (var1, var2, var3) = (SELECT c1, c2 FROM VALUES(100, 110, 120) AS T(c1, c2, c3))
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ASSIGNMENT_ARITY_MISMATCH",
  "sqlState" : "42802",
  "messageParameters" : {
    "numExpr" : "2",
    "numTarget" : "3"
  }
}


-- !query
SET VARIABLE (var1, var2, var3) = (SELECT c1, c2, c3, c1 FROM VALUES(100, 110, 120) AS T(c1, c2, c3))
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ASSIGNMENT_ARITY_MISMATCH",
  "sqlState" : "42802",
  "messageParameters" : {
    "numExpr" : "4",
    "numTarget" : "3"
  }
}


-- !query
SET VARIABLE (var1, var2, var1) = (SELECT c1, c2, c3, c1 FROM VALUES(100, 110, 120) AS T(c1, c2, c3))
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DUPLICATE_ASSIGNMENTS",
  "sqlState" : "42701",
  "messageParameters" : {
    "nameList" : "`var1`"
  }
}


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DROP TEMPORARY VARIABLE var2
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var2


-- !query
DROP TEMPORARY VARIABLE var3
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var3


-- !query
SET VARIABLE title = 'DEFAULT expression usage'
-- !query analysis
SetVariable [variablereference(system.session.title='SET VARIABLE - row assignment')]
+- Project [DEFAULT expression usage AS title#x]
   +- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 STRING DEFAULT 'default1'
-- !query analysis
CreateVariable defaultvalueexpression(cast(default1 as string), 'default1'), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DECLARE OR REPLACE VARIABLE var2 STRING DEFAULT 'default2'
-- !query analysis
CreateVariable defaultvalueexpression(cast(default2 as string), 'default2'), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var2


-- !query
DECLARE OR REPLACE VARIABLE var3 STRING DEFAULT 'default3'
-- !query analysis
CreateVariable defaultvalueexpression(cast(default3 as string), 'default3'), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var3


-- !query
SET VARIABLE var1 = 'hello'
-- !query analysis
SetVariable [variablereference(system.session.var1='default1')]
+- Project [hello AS var1#x]
   +- OneRowRelation


-- !query
SET VARIABLE var1 = DEFAULT
-- !query analysis
SetVariable [variablereference(system.session.var1='hello')]
+- Project [default1 AS DEFAULT#x]
   +- OneRowRelation


-- !query
SELECT var1 AS `default`
-- !query analysis
Project [variablereference(system.session.var1='default1') AS default#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = 'hello1'
-- !query analysis
SetVariable [variablereference(system.session.var1='default1')]
+- Project [hello1 AS var1#x]
   +- OneRowRelation


-- !query
SET VARIABLE var1 = 'hello2'
-- !query analysis
SetVariable [variablereference(system.session.var1='hello1')]
+- Project [hello2 AS var1#x]
   +- OneRowRelation


-- !query
SET VARIABLE var1 = 'hello3'
-- !query analysis
SetVariable [variablereference(system.session.var1='hello2')]
+- Project [hello3 AS var1#x]
   +- OneRowRelation


-- !query
SET VARIABLE var1 = DEFAULT, var2 = DEFAULT, var3 = DEFAULT
-- !query analysis
SetVariable [variablereference(system.session.var1='hello3'), variablereference(system.session.var2='default2'), variablereference(system.session.var3='default3')]
+- Project [default1 AS DEFAULT#x, default2 AS DEFAULT#x, default3 AS DEFAULT#x]
   +- OneRowRelation


-- !query
SELECT var1 AS `default1`, var2 AS `default2`, var3 AS `default3`
-- !query analysis
Project [variablereference(system.session.var1='default1') AS default1#x, variablereference(system.session.var2='default2') AS default2#x, variablereference(system.session.var3='default3') AS default3#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = 'hello'
-- !query analysis
SetVariable [variablereference(system.session.var1='default1')]
+- Project [hello AS var1#x]
   +- OneRowRelation


-- !query
SET VARIABLE (var1) = (SELECT DEFAULT FROM VALUES(1) AS T(c1))
-- !query analysis
SetVariable [variablereference(system.session.var1='hello')]
+- Project [default1 AS DEFAULT#x]
   +- SubqueryAlias T
      +- LocalRelation [c1#x]


-- !query
SELECT var1 AS `default`
-- !query analysis
Project [variablereference(system.session.var1='default1') AS default#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = 'hello'
-- !query analysis
SetVariable [variablereference(system.session.var1='default1')]
+- Project [hello AS var1#x]
   +- OneRowRelation


-- !query
SET VARIABLE (var1) = (SELECT DEFAULT FROM VALUES('world') AS T(default))
-- !query analysis
SetVariable [variablereference(system.session.var1='hello')]
+- Project [DEFAULT#x]
   +- SubqueryAlias T
      +- LocalRelation [default#x]


-- !query
SELECT var1 AS `world`
-- !query analysis
Project [variablereference(system.session.var1='world') AS world#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = 'hello'
-- !query analysis
SetVariable [variablereference(system.session.var1='world')]
+- Project [hello AS var1#x]
   +- OneRowRelation


-- !query
SET VARIABLE (var1) = (SELECT DEFAULT FROM VALUES(1) AS T(c1) LIMIT 1)
-- !query analysis
SetVariable [variablereference(system.session.var1='hello')]
+- GlobalLimit 1
   +- LocalLimit 1
      +- Project [default1 AS DEFAULT#x]
         +- SubqueryAlias T
            +- LocalRelation [c1#x]


-- !query
SELECT var1 AS `default`
-- !query analysis
Project [variablereference(system.session.var1='default1') AS default#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = 'hello'
-- !query analysis
SetVariable [variablereference(system.session.var1='default1')]
+- Project [hello AS var1#x]
   +- OneRowRelation


-- !query
SET VARIABLE (var1) = (SELECT DEFAULT FROM VALUES(1),(2),(3) AS T(c1) LIMIT 1 OFFSET 1)
-- !query analysis
SetVariable [variablereference(system.session.var1='hello')]
+- GlobalLimit 1
   +- LocalLimit 1
      +- Offset 1
         +- Project [default1 AS DEFAULT#x]
            +- SubqueryAlias T
               +- LocalRelation [c1#x]


-- !query
SELECT var1 AS `default`
-- !query analysis
Project [variablereference(system.session.var1='default1') AS default#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = 'hello'
-- !query analysis
SetVariable [variablereference(system.session.var1='default1')]
+- Project [hello AS var1#x]
   +- OneRowRelation


-- !query
SET VARIABLE (var1) = (SELECT DEFAULT FROM VALUES(1),(2),(3) AS T(c1) OFFSET 1)
-- !query analysis
org.apache.spark.SparkException
{
  "errorClass" : "ROW_SUBQUERY_TOO_MANY_ROWS",
  "sqlState" : "21000"
}


-- !query
SELECT var1 AS `default`
-- !query analysis
Project [variablereference(system.session.var1='hello') AS default#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = 'hello'
-- !query analysis
SetVariable [variablereference(system.session.var1='hello')]
+- Project [hello AS var1#x]
   +- OneRowRelation


-- !query
SET VARIABLE (var1) = (WITH v1(c1) AS (VALUES(1) AS T(c1)) SELECT DEFAULT FROM VALUES(1),(2),(3) AS T(c1))
-- !query analysis
org.apache.spark.SparkException
{
  "errorClass" : "ROW_SUBQUERY_TOO_MANY_ROWS",
  "sqlState" : "21000"
}


-- !query
SELECT var1 AS `default`
-- !query analysis
Project [variablereference(system.session.var1='hello') AS default#x]
+- OneRowRelation


-- !query
SET VARIABLE var1 = 'Hello' || DEFAULT
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DEFAULT_PLACEMENT_INVALID",
  "sqlState" : "42608"
}


-- !query
SET VARIABLE (var1) = (VALUES(DEFAULT))
-- !query analysis
SetVariable [variablereference(system.session.var1='hello')]
+- LocalRelation [col1#x]


-- !query
SET VARIABLE (var1) = (WITH v1(c1) AS (VALUES(1) AS T(c1)) SELECT DEFAULT + 1 FROM VALUES(1),(2),(3) AS T(c1))
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DEFAULT_PLACEMENT_INVALID",
  "sqlState" : "42608"
}


-- !query
SET VARIABLE var1 = session.default
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNRESOLVED_COLUMN.WITHOUT_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`session`.`default`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 21,
    "stopIndex" : 35,
    "fragment" : "session.default"
  } ]
}


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DROP TEMPORARY VARIABLE var2
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var2


-- !query
DROP TEMPORARY VARIABLE var3
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var3


-- !query
SET VARIABLE title = 'SET command'
-- !query analysis
SetVariable [variablereference(system.session.title='DEFAULT expression usage')]
+- Project [SET command AS title#x]
   +- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 INT DEFAULT 1
-- !query analysis
CreateVariable defaultvalueexpression(cast(1 as int), 1), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SET x.var1 = 5
-- !query analysis
SetCommand (x.var1,Some(5))


-- !query
SET x = 5
-- !query analysis
SetCommand (x,Some(5))


-- !query
SET system.x.var = 5
-- !query analysis
SetCommand (system.x.var,Some(5))


-- !query
SET x.session.var1 = 5
-- !query analysis
SetCommand (x.session.var1,Some(5))


-- !query
SET var1 = 5
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_FEATURE.SET_VARIABLE_USING_SET",
  "sqlState" : "0A000",
  "messageParameters" : {
    "variableName" : "`var1`"
  }
}


-- !query
SET session.var1 = 5
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_FEATURE.SET_VARIABLE_USING_SET",
  "sqlState" : "0A000",
  "messageParameters" : {
    "variableName" : "`session`.`var1`"
  }
}


-- !query
SET system.session.var1 = 5
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_FEATURE.SET_VARIABLE_USING_SET",
  "sqlState" : "0A000",
  "messageParameters" : {
    "variableName" : "`system`.`session`.`var1`"
  }
}


-- !query
SET vAr1 = 5
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_FEATURE.SET_VARIABLE_USING_SET",
  "sqlState" : "0A000",
  "messageParameters" : {
    "variableName" : "`vAr1`"
  }
}


-- !query
SET seSSion.var1 = 5
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_FEATURE.SET_VARIABLE_USING_SET",
  "sqlState" : "0A000",
  "messageParameters" : {
    "variableName" : "`seSSion`.`var1`"
  }
}


-- !query
SET sYStem.session.var1 = 5
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_FEATURE.SET_VARIABLE_USING_SET",
  "sqlState" : "0A000",
  "messageParameters" : {
    "variableName" : "`sYStem`.`session`.`var1`"
  }
}


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
DECLARE OR REPLACE VARIABLE var1 INT DEFAULT 1
-- !query analysis
CreateVariable defaultvalueexpression(cast(1 as int), 1), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT var1 AS `2` FROM VALUES(2) AS T(var1)
-- !query analysis
Project [var1#x AS 2#x]
+- SubqueryAlias T
   +- LocalRelation [var1#x]


-- !query
SELECT c1 AS `2` FROM VALUES(2) AS T(var1), LATERAL(SELECT var1) AS TT(c1)
-- !query analysis
Project [c1#x AS 2#x]
+- LateralJoin lateral-subquery#x [var1#x], Inner
   :  +- SubqueryAlias TT
   :     +- Project [var1#x AS c1#x]
   :        +- Project [outer(var1#x)]
   :           +- OneRowRelation
   +- SubqueryAlias T
      +- LocalRelation [var1#x]


-- !query
SELECT session.var1 AS `1` FROM VALUES(2) AS T(var1)
-- !query analysis
Project [variablereference(system.session.var1=1) AS 1#x]
+- SubqueryAlias T
   +- LocalRelation [var1#x]


-- !query
SELECT c1 AS `1` FROM VALUES(2) AS T(var1), LATERAL(SELECT session.var1) AS TT(c1)
-- !query analysis
Project [c1#x AS 1#x]
+- LateralJoin lateral-subquery#x [], Inner
   :  +- SubqueryAlias TT
   :     +- Project [var1#x AS c1#x]
   :        +- Project [variablereference(system.session.var1=1) AS var1#x]
   :           +- OneRowRelation
   +- SubqueryAlias T
      +- LocalRelation [var1#x]


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SET VARIABLE title = 'variable references -- visibility'
-- !query analysis
SetVariable [variablereference(system.session.title='SET command')]
+- Project [variable references -- visibility AS title#x]
   +- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 INT DEFAULT 1
-- !query analysis
CreateVariable defaultvalueexpression(cast(1 as int), 1), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
VALUES (var1)
-- !query analysis
LocalRelation [col1#x]


-- !query
SELECT var1
-- !query analysis
Project [variablereference(system.session.var1=1) AS var1#x]
+- OneRowRelation


-- !query
SELECT sum(var1) FROM VALUES(1)
-- !query analysis
Aggregate [sum(variablereference(system.session.var1=1)) AS sum(variablereference(system.session.var1=1))#xL]
+- LocalRelation [col1#x]


-- !query
SELECT var1 + SUM(0) FROM VALUES(1)
-- !query analysis
Aggregate [(cast(variablereference(system.session.var1=1) as bigint) + sum(0)) AS (variablereference(system.session.var1=1) + sum(0))#xL]
+- LocalRelation [col1#x]


-- !query
SELECT substr('12345', var1, 1)
-- !query analysis
Project [substr(12345, variablereference(system.session.var1=1), 1) AS substr(12345, variablereference(system.session.var1=1), 1)#x]
+- OneRowRelation


-- !query
SELECT 1 FROM VALUES(1, 2) AS T(c1, c2) GROUP BY c1 + var1
-- !query analysis
Aggregate [(c1#x + variablereference(system.session.var1=1))], [1 AS 1#x]
+- SubqueryAlias T
   +- LocalRelation [c1#x, c2#x]


-- !query
SELECT c1, sum(c2) FROM VALUES(1, 2) AS T(c1, c2) GROUP BY c1 HAVING sum(c1) != var1
-- !query analysis
Project [c1#x, sum(c2)#xL]
+- Filter NOT (sum(c1#x)#xL = cast(variablereference(system.session.var1=1) as bigint))
   +- Aggregate [c1#x], [c1#x, sum(c2#x) AS sum(c2)#xL, sum(c1#x) AS sum(c1#x)#xL]
      +- SubqueryAlias T
         +- LocalRelation [c1#x, c2#x]


-- !query
SELECT 1 FROM VALUES(1) AS T(c1) WHERE c1 IN (var1)
-- !query analysis
Project [1 AS 1#x]
+- Filter c1#x IN (variablereference(system.session.var1=1))
   +- SubqueryAlias T
      +- LocalRelation [c1#x]


-- !query
SELECT sum(c1) FILTER (c1 != var1) FROM VALUES(1, 2), (2, 3) AS T(c1, c2)
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT array(1, 2, 4)[var1]
-- !query analysis
Project [array(1, 2, 4)[variablereference(system.session.var1=1)] AS array(1, 2, 4)[variablereference(system.session.var1=1)]#x]
+- OneRowRelation


-- !query
SELECT 1 FROM VALUES(1) AS T(c1) WHERE c1 = var1
-- !query analysis
Project [1 AS 1#x]
+- Filter (c1#x = variablereference(system.session.var1=1))
   +- SubqueryAlias T
      +- LocalRelation [c1#x]


-- !query
WITH v1 AS (SELECT var1 AS c1) SELECT c1 AS `1` FROM v1
-- !query analysis
WithCTE
:- CTERelationDef xxxx, false
:  +- SubqueryAlias v1
:     +- Project [variablereference(system.session.var1=1) AS c1#x]
:        +- OneRowRelation
+- Project [c1#x AS 1#x]
   +- SubqueryAlias v1
      +- CTERelationRef xxxx, true, [c1#x], false


-- !query
CREATE OR REPLACE TEMPORARY VIEW v AS SELECT var1 AS c1
-- !query analysis
CreateViewCommand `v`, SELECT var1 AS c1, false, true, LocalTempView, UNSUPPORTED, true
   +- Project [variablereference(system.session.var1=1) AS c1#x]
      +- OneRowRelation


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x]
+- SubqueryAlias v
   +- View (`v`, [c1#x])
      +- Project [cast(c1#x as int) AS c1#x]
         +- Project [variablereference(system.session.var1=1) AS c1#x]
            +- OneRowRelation


-- !query
DROP VIEW v
-- !query analysis
DropTempViewCommand v


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SET VARIABLE title = 'variable references -- prohibited'
-- !query analysis
SetVariable [variablereference(system.session.title='variable references -- visibility')]
+- Project [variable references -- prohibited AS title#x]
   +- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 INT DEFAULT 1
-- !query analysis
CreateVariable defaultvalueexpression(cast(1 as int), 1), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
CREATE OR REPLACE VIEW v AS SELECT var1 AS c1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_TEMP_OBJ_REFERENCE",
  "sqlState" : "42K0F",
  "messageParameters" : {
    "obj" : "VIEW",
    "objName" : "`spark_catalog`.`default`.`v`",
    "tempObj" : "VARIABLE",
    "tempObjName" : "`var1`"
  }
}


-- !query
DROP VIEW IF EXISTS V
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`V`, true, true, false


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SET VARIABLE title = 'variable references -- test constant folding'
-- !query analysis
SetVariable [variablereference(system.session.title='variable references -- prohibited')]
+- Project [variable references -- test constant folding AS title#x]
   +- OneRowRelation


-- !query
DECLARE OR REPLACE VARIABLE var1 STRING DEFAULT 'a INT'
-- !query analysis
CreateVariable defaultvalueexpression(cast(a INT as string), 'a INT'), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1


-- !query
SELECT from_json('{"a": 1}', var1)
-- !query analysis
Project [from_json(StructField(a,IntegerType,true), {"a": 1}, Some(America/Los_Angeles), false) AS from_json({"a": 1})#x]
+- OneRowRelation


-- !query
DROP TEMPORARY VARIABLE var1
-- !query analysis
DropVariable false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.var1
