-- Automatically generated by SQLQueryTestSuite
-- !query
SELECT CEIL(2.5, 0)
-- !query analysis
Project [ceil(2.5, 0) AS ceil(2.5, 0)#x]
+- OneRowRelation


-- !query
SELECT CEIL(3.5, 0)
-- !query analysis
Project [ceil(3.5, 0) AS ceil(3.5, 0)#x]
+- OneRowRelation


-- !query
SELECT CEIL(-2.5, 0)
-- !query analysis
Project [ceil(-2.5, 0) AS ceil(-2.5, 0)#x]
+- OneRowRelation


-- !query
SELECT CEIL(-3.5, 0)
-- !query analysis
Project [ceil(-3.5, 0) AS ceil(-3.5, 0)#x]
+- OneRowRelation


-- !query
SELECT CEIL(-0.35, 1)
-- !query analysis
Project [ceil(-0.35, 1) AS ceil(-0.35, 1)#x]
+- OneRowRelation


-- !query
SELECT CEIL(-35, -1)
-- !query analysis
Project [ceil(cast(-35 as decimal(10,0)), -1) AS ceil(-35, -1)#x]
+- OneRowRelation


-- !query
SELECT CEIL(-0.1, 0)
-- !query analysis
Project [ceil(-0.1, 0) AS ceil(-0.1, 0)#x]
+- OneRowRelation


-- !query
SELECT CEIL(5, 0)
-- !query analysis
Project [ceil(cast(5 as decimal(10,0)), 0) AS ceil(5, 0)#x]
+- OneRowRelation


-- !query
SELECT CEIL(3.14115, -3)
-- !query analysis
Project [ceil(3.14115, -3) AS ceil(3.14115, -3)#x]
+- OneRowRelation


-- !query
SELECT CEIL(9.9, 0)
-- !query analysis
Project [ceil(9.9, 0) AS ceil(9.9, 0)#x]
+- OneRowRelation


-- !query
SELECT CEIL(CAST(99 AS DECIMAL(2, 0)), -1)
-- !query analysis
Project [ceil(cast(99 as decimal(2,0)), -1) AS ceil(CAST(99 AS DECIMAL(2,0)), -1)#x]
+- OneRowRelation


-- !query
SELECT CEIL(2.5, null)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NON_FOLDABLE_ARGUMENT",
  "sqlState" : "42K08",
  "messageParameters" : {
    "funcName" : "`ceil`",
    "paramName" : "`scale`",
    "paramType" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "CEIL(2.5, null)"
  } ]
}


-- !query
SELECT CEIL(2.5, 'a')
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NON_FOLDABLE_ARGUMENT",
  "sqlState" : "42K08",
  "messageParameters" : {
    "funcName" : "`ceil`",
    "paramName" : "`scale`",
    "paramType" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 21,
    "fragment" : "CEIL(2.5, 'a')"
  } ]
}


-- !query
SELECT CEIL(2.5, 0, 0)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITHOUT_SUGGESTION",
  "sqlState" : "42605",
  "messageParameters" : {
    "actualNum" : "3",
    "docroot" : "https://spark.apache.org/docs/latest",
    "expectedNum" : "2",
    "functionName" : "`ceil`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "CEIL(2.5, 0, 0)"
  } ]
}


-- !query
SELECT FLOOR(2.5, 0)
-- !query analysis
Project [floor(2.5, 0) AS floor(2.5, 0)#x]
+- OneRowRelation


-- !query
SELECT FLOOR(3.5, 0)
-- !query analysis
Project [floor(3.5, 0) AS floor(3.5, 0)#x]
+- OneRowRelation


-- !query
SELECT FLOOR(-2.5, 0)
-- !query analysis
Project [floor(-2.5, 0) AS floor(-2.5, 0)#x]
+- OneRowRelation


-- !query
SELECT FLOOR(-3.5, 0)
-- !query analysis
Project [floor(-3.5, 0) AS floor(-3.5, 0)#x]
+- OneRowRelation


-- !query
SELECT FLOOR(-0.35, 1)
-- !query analysis
Project [floor(-0.35, 1) AS floor(-0.35, 1)#x]
+- OneRowRelation


-- !query
SELECT FLOOR(-35, -1)
-- !query analysis
Project [floor(cast(-35 as decimal(10,0)), -1) AS floor(-35, -1)#x]
+- OneRowRelation


-- !query
SELECT FLOOR(-0.1, 0)
-- !query analysis
Project [floor(-0.1, 0) AS floor(-0.1, 0)#x]
+- OneRowRelation


-- !query
SELECT FLOOR(5, 0)
-- !query analysis
Project [floor(cast(5 as decimal(10,0)), 0) AS floor(5, 0)#x]
+- OneRowRelation


-- !query
SELECT FLOOR(3.14115, -3)
-- !query analysis
Project [floor(3.14115, -3) AS floor(3.14115, -3)#x]
+- OneRowRelation


-- !query
SELECT FLOOR(-9.9, 0)
-- !query analysis
Project [floor(-9.9, 0) AS floor(-9.9, 0)#x]
+- OneRowRelation


-- !query
SELECT FLOOR(CAST(-99 AS DECIMAL(2, 0)), -1)
-- !query analysis
Project [floor(cast(-99 as decimal(2,0)), -1) AS floor(CAST(-99 AS DECIMAL(2,0)), -1)#x]
+- OneRowRelation


-- !query
SELECT FLOOR(2.5, null)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NON_FOLDABLE_ARGUMENT",
  "sqlState" : "42K08",
  "messageParameters" : {
    "funcName" : "`floor`",
    "paramName" : "`scale`",
    "paramType" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 23,
    "fragment" : "FLOOR(2.5, null)"
  } ]
}


-- !query
SELECT FLOOR(2.5, 'a')
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NON_FOLDABLE_ARGUMENT",
  "sqlState" : "42K08",
  "messageParameters" : {
    "funcName" : "`floor`",
    "paramName" : "`scale`",
    "paramType" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "FLOOR(2.5, 'a')"
  } ]
}


-- !query
SELECT FLOOR(2.5, 0, 0)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITHOUT_SUGGESTION",
  "sqlState" : "42605",
  "messageParameters" : {
    "actualNum" : "3",
    "docroot" : "https://spark.apache.org/docs/latest",
    "expectedNum" : "2",
    "functionName" : "`floor`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 23,
    "fragment" : "FLOOR(2.5, 0, 0)"
  } ]
}
