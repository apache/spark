-- Automatically generated by SQLQueryTestSuite
-- !query
SELECT avg(udf(four)) AS avg_1 FROM onek
-- !query analysis
Aggregate [avg(cast(udf(cast(four#x as string)) as int)) AS avg_1#x]
+- SubqueryAlias spark_catalog.default.onek
   +- Relation spark_catalog.default.onek[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT udf(avg(a)) AS avg_32 FROM aggtest WHERE a < 100
-- !query analysis
Aggregate [cast(udf(cast(avg(a#x) as string)) as double) AS avg_32#x]
+- Filter (a#x < 100)
   +- SubqueryAlias spark_catalog.default.aggtest
      +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
select CAST(avg(udf(b)) AS Decimal(10,3)) AS avg_107_943 FROM aggtest
-- !query analysis
Aggregate [cast(avg(cast(udf(cast(b#x as string)) as float)) as decimal(10,3)) AS avg_107_943#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT sum(udf(four)) AS sum_1500 FROM onek
-- !query analysis
Aggregate [sum(cast(udf(cast(four#x as string)) as int)) AS sum_1500#xL]
+- SubqueryAlias spark_catalog.default.onek
   +- Relation spark_catalog.default.onek[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT udf(sum(a)) AS sum_198 FROM aggtest
-- !query analysis
Aggregate [cast(udf(cast(sum(a#x) as string)) as bigint) AS sum_198#xL]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT udf(udf(sum(b))) AS avg_431_773 FROM aggtest
-- !query analysis
Aggregate [cast(udf(cast(cast(udf(cast(sum(b#x) as string)) as double) as string)) as double) AS avg_431_773#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT udf(max(four)) AS max_3 FROM onek
-- !query analysis
Aggregate [cast(udf(cast(max(four#x) as string)) as int) AS max_3#x]
+- SubqueryAlias spark_catalog.default.onek
   +- Relation spark_catalog.default.onek[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT max(udf(a)) AS max_100 FROM aggtest
-- !query analysis
Aggregate [max(cast(udf(cast(a#x as string)) as int)) AS max_100#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT udf(udf(max(aggtest.b))) AS max_324_78 FROM aggtest
-- !query analysis
Aggregate [cast(udf(cast(cast(udf(cast(max(b#x) as string)) as float) as string)) as float) AS max_324_78#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT stddev_pop(udf(b)) FROM aggtest
-- !query analysis
Aggregate [stddev_pop(cast(cast(udf(cast(b#x as string)) as float) as double)) AS stddev_pop(udf(b))#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT udf(stddev_samp(b)) FROM aggtest
-- !query analysis
Aggregate [cast(udf(cast(stddev_samp(cast(b#x as double)) as string)) as double) AS udf(stddev_samp(b))#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT var_pop(udf(b)) FROM aggtest
-- !query analysis
Aggregate [var_pop(cast(cast(udf(cast(b#x as string)) as float) as double)) AS var_pop(udf(b))#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT udf(var_samp(b)) FROM aggtest
-- !query analysis
Aggregate [cast(udf(cast(var_samp(cast(b#x as double)) as string)) as double) AS udf(var_samp(b))#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT udf(stddev_pop(CAST(b AS Decimal(38,0)))) FROM aggtest
-- !query analysis
Aggregate [cast(udf(cast(stddev_pop(cast(cast(b#x as decimal(38,0)) as double)) as string)) as double) AS udf(stddev_pop(CAST(b AS DECIMAL(38,0))))#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT stddev_samp(CAST(udf(b) AS Decimal(38,0))) FROM aggtest
-- !query analysis
Aggregate [stddev_samp(cast(cast(cast(udf(cast(b#x as string)) as float) as decimal(38,0)) as double)) AS stddev_samp(CAST(udf(b) AS DECIMAL(38,0)))#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT udf(var_pop(CAST(b AS Decimal(38,0)))) FROM aggtest
-- !query analysis
Aggregate [cast(udf(cast(var_pop(cast(cast(b#x as decimal(38,0)) as double)) as string)) as double) AS udf(var_pop(CAST(b AS DECIMAL(38,0))))#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT var_samp(udf(CAST(b AS Decimal(38,0)))) FROM aggtest
-- !query analysis
Aggregate [var_samp(cast(cast(udf(cast(cast(b#x as decimal(38,0)) as string)) as decimal(38,0)) as double)) AS var_samp(udf(CAST(b AS DECIMAL(38,0))))#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT udf(var_pop(1.0)), var_samp(udf(2.0))
-- !query analysis
Aggregate [cast(udf(cast(var_pop(cast(1.0 as double)) as string)) as double) AS udf(var_pop(1.0))#x, var_samp(cast(cast(udf(cast(2.0 as string)) as decimal(2,1)) as double)) AS var_samp(udf(2.0))#x]
+- OneRowRelation


-- !query
SELECT stddev_pop(udf(CAST(3.0 AS Decimal(38,0)))), stddev_samp(CAST(udf(4.0) AS Decimal(38,0)))
-- !query analysis
Aggregate [stddev_pop(cast(cast(udf(cast(cast(3.0 as decimal(38,0)) as string)) as decimal(38,0)) as double)) AS stddev_pop(udf(CAST(3.0 AS DECIMAL(38,0))))#x, stddev_samp(cast(cast(cast(udf(cast(4.0 as string)) as decimal(2,1)) as decimal(38,0)) as double)) AS stddev_samp(CAST(udf(4.0) AS DECIMAL(38,0)))#x]
+- OneRowRelation


-- !query
select sum(udf(CAST(null AS int))) from range(1,4)
-- !query analysis
Aggregate [sum(cast(udf(cast(cast(null as int) as string)) as int)) AS sum(udf(CAST(NULL AS INT)))#xL]
+- Range (1, 4, step=1)


-- !query
select sum(udf(CAST(null AS long))) from range(1,4)
-- !query analysis
Aggregate [sum(cast(udf(cast(cast(null as bigint) as string)) as bigint)) AS sum(udf(CAST(NULL AS BIGINT)))#xL]
+- Range (1, 4, step=1)


-- !query
select sum(udf(CAST(null AS Decimal(38,0)))) from range(1,4)
-- !query analysis
Aggregate [sum(cast(udf(cast(cast(null as decimal(38,0)) as string)) as decimal(38,0))) AS sum(udf(CAST(NULL AS DECIMAL(38,0))))#x]
+- Range (1, 4, step=1)


-- !query
select sum(udf(CAST(null AS DOUBLE))) from range(1,4)
-- !query analysis
Aggregate [sum(cast(udf(cast(cast(null as double) as string)) as double)) AS sum(udf(CAST(NULL AS DOUBLE)))#x]
+- Range (1, 4, step=1)


-- !query
select avg(udf(CAST(null AS int))) from range(1,4)
-- !query analysis
Aggregate [avg(cast(udf(cast(cast(null as int) as string)) as int)) AS avg(udf(CAST(NULL AS INT)))#x]
+- Range (1, 4, step=1)


-- !query
select avg(udf(CAST(null AS long))) from range(1,4)
-- !query analysis
Aggregate [avg(cast(udf(cast(cast(null as bigint) as string)) as bigint)) AS avg(udf(CAST(NULL AS BIGINT)))#x]
+- Range (1, 4, step=1)


-- !query
select avg(udf(CAST(null AS Decimal(38,0)))) from range(1,4)
-- !query analysis
Aggregate [avg(cast(udf(cast(cast(null as decimal(38,0)) as string)) as decimal(38,0))) AS avg(udf(CAST(NULL AS DECIMAL(38,0))))#x]
+- Range (1, 4, step=1)


-- !query
select avg(udf(CAST(null AS DOUBLE))) from range(1,4)
-- !query analysis
Aggregate [avg(cast(udf(cast(cast(null as double) as string)) as double)) AS avg(udf(CAST(NULL AS DOUBLE)))#x]
+- Range (1, 4, step=1)


-- !query
select sum(CAST(udf('NaN') AS DOUBLE)) from range(1,4)
-- !query analysis
Aggregate [sum(cast(cast(udf(cast(NaN as string)) as string) as double)) AS sum(CAST(udf(NaN) AS DOUBLE))#x]
+- Range (1, 4, step=1)


-- !query
select avg(CAST(udf('NaN') AS DOUBLE)) from range(1,4)
-- !query analysis
Aggregate [avg(cast(cast(udf(cast(NaN as string)) as string) as double)) AS avg(CAST(udf(NaN) AS DOUBLE))#x]
+- Range (1, 4, step=1)


-- !query
SELECT avg(CAST(udf(x) AS DOUBLE)), var_pop(CAST(udf(x) AS DOUBLE))
FROM (VALUES ('Infinity'), ('1')) v(x)
-- !query analysis
Aggregate [avg(cast(cast(udf(cast(x#x as string)) as string) as double)) AS avg(CAST(udf(x) AS DOUBLE))#x, var_pop(cast(cast(udf(cast(x#x as string)) as string) as double)) AS var_pop(CAST(udf(x) AS DOUBLE))#x]
+- SubqueryAlias v
   +- Project [col1#x AS x#x]
      +- LocalRelation [col1#x]


-- !query
SELECT avg(CAST(udf(x) AS DOUBLE)), var_pop(CAST(udf(x) AS DOUBLE))
FROM (VALUES ('Infinity'), ('Infinity')) v(x)
-- !query analysis
Aggregate [avg(cast(cast(udf(cast(x#x as string)) as string) as double)) AS avg(CAST(udf(x) AS DOUBLE))#x, var_pop(cast(cast(udf(cast(x#x as string)) as string) as double)) AS var_pop(CAST(udf(x) AS DOUBLE))#x]
+- SubqueryAlias v
   +- Project [col1#x AS x#x]
      +- LocalRelation [col1#x]


-- !query
SELECT avg(CAST(udf(x) AS DOUBLE)), var_pop(CAST(udf(x) AS DOUBLE))
FROM (VALUES ('-Infinity'), ('Infinity')) v(x)
-- !query analysis
Aggregate [avg(cast(cast(udf(cast(x#x as string)) as string) as double)) AS avg(CAST(udf(x) AS DOUBLE))#x, var_pop(cast(cast(udf(cast(x#x as string)) as string) as double)) AS var_pop(CAST(udf(x) AS DOUBLE))#x]
+- SubqueryAlias v
   +- Project [col1#x AS x#x]
      +- LocalRelation [col1#x]


-- !query
SELECT avg(udf(CAST(x AS DOUBLE))), udf(var_pop(CAST(x AS DOUBLE)))
FROM (VALUES (100000003), (100000004), (100000006), (100000007)) v(x)
-- !query analysis
Aggregate [avg(cast(udf(cast(cast(x#x as double) as string)) as double)) AS avg(udf(CAST(x AS DOUBLE)))#x, cast(udf(cast(var_pop(cast(x#x as double)) as string)) as double) AS udf(var_pop(CAST(x AS DOUBLE)))#x]
+- SubqueryAlias v
   +- Project [col1#x AS x#x]
      +- LocalRelation [col1#x]


-- !query
SELECT avg(udf(CAST(x AS DOUBLE))), udf(var_pop(CAST(x AS DOUBLE)))
FROM (VALUES (7000000000005), (7000000000007)) v(x)
-- !query analysis
Aggregate [avg(cast(udf(cast(cast(x#xL as double) as string)) as double)) AS avg(udf(CAST(x AS DOUBLE)))#x, cast(udf(cast(var_pop(cast(x#xL as double)) as string)) as double) AS udf(var_pop(CAST(x AS DOUBLE)))#x]
+- SubqueryAlias v
   +- Project [col1#xL AS x#xL]
      +- LocalRelation [col1#xL]


-- !query
SELECT regr_count(b, a) FROM aggtest
-- !query analysis
Aggregate [regr_count(b#x, a#x) AS regr_count(b, a)#xL]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT regr_sxx(b, a) FROM aggtest
-- !query analysis
Aggregate [regr_sxx(cast(b#x as double), cast(a#x as double)) AS regr_sxx(b, a)#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT regr_syy(b, a) FROM aggtest
-- !query analysis
Aggregate [regr_syy(cast(b#x as double), cast(a#x as double)) AS regr_syy(b, a)#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT regr_sxy(b, a) FROM aggtest
-- !query analysis
Aggregate [regr_sxy(cast(b#x as double), cast(a#x as double)) AS regr_sxy(b, a)#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT regr_avgx(b, a), regr_avgy(b, a) FROM aggtest
-- !query analysis
Aggregate [regr_avgx(b#x, a#x) AS regr_avgx(b, a)#x, regr_avgy(b#x, a#x) AS regr_avgy(b, a)#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT regr_r2(b, a) FROM aggtest
-- !query analysis
Aggregate [regr_r2(cast(b#x as double), cast(a#x as double)) AS regr_r2(b, a)#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT regr_slope(b, a), regr_intercept(b, a) FROM aggtest
-- !query analysis
Aggregate [regr_slope(cast(b#x as double), cast(a#x as double)) AS regr_slope(b, a)#x, regr_intercept(cast(b#x as double), cast(a#x as double)) AS regr_intercept(b, a)#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT udf(covar_pop(b, udf(a))), covar_samp(udf(b), a) FROM aggtest
-- !query analysis
Aggregate [cast(udf(cast(covar_pop(cast(b#x as double), cast(cast(udf(cast(a#x as string)) as int) as double)) as string)) as double) AS udf(covar_pop(b, udf(a)))#x, covar_samp(cast(cast(udf(cast(b#x as string)) as float) as double), cast(a#x as double)) AS covar_samp(udf(b), a)#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
SELECT corr(b, udf(a)) FROM aggtest
-- !query analysis
Aggregate [corr(cast(b#x as double), cast(cast(udf(cast(a#x as string)) as int) as double)) AS corr(b, udf(a))#x]
+- SubqueryAlias spark_catalog.default.aggtest
   +- Relation spark_catalog.default.aggtest[a#x,b#x] parquet


-- !query
CREATE TEMPORARY VIEW regr_test AS SELECT * FROM VALUES (10,150),(20,250),(30,350),(80,540),(100,200) AS regr_test (x, y)
-- !query analysis
CreateViewCommand `regr_test`, SELECT * FROM VALUES (10,150),(20,250),(30,350),(80,540),(100,200) AS regr_test (x, y), false, false, LocalTempView, UNSUPPORTED, true
   +- Project [x#x, y#x]
      +- SubqueryAlias regr_test
         +- LocalRelation [x#x, y#x]


-- !query
SELECT count(*), sum(x), regr_sxx(y,x), sum(y),regr_syy(y,x), regr_sxy(y,x)
FROM regr_test WHERE x IN (10,20,30,80)
-- !query analysis
Aggregate [count(1) AS count(1)#xL, sum(x#x) AS sum(x)#xL, regr_sxx(cast(y#x as double), cast(x#x as double)) AS regr_sxx(y, x)#x, sum(y#x) AS sum(y)#xL, regr_syy(cast(y#x as double), cast(x#x as double)) AS regr_syy(y, x)#x, regr_sxy(cast(y#x as double), cast(x#x as double)) AS regr_sxy(y, x)#x]
+- Filter x#x IN (10,20,30,80)
   +- SubqueryAlias regr_test
      +- View (`regr_test`, [x#x, y#x])
         +- Project [cast(x#x as int) AS x#x, cast(y#x as int) AS y#x]
            +- Project [x#x, y#x]
               +- SubqueryAlias regr_test
                  +- LocalRelation [x#x, y#x]


-- !query
SELECT count(*), sum(x), regr_sxx(y,x), sum(y),regr_syy(y,x), regr_sxy(y,x)
FROM regr_test
-- !query analysis
Aggregate [count(1) AS count(1)#xL, sum(x#x) AS sum(x)#xL, regr_sxx(cast(y#x as double), cast(x#x as double)) AS regr_sxx(y, x)#x, sum(y#x) AS sum(y)#xL, regr_syy(cast(y#x as double), cast(x#x as double)) AS regr_syy(y, x)#x, regr_sxy(cast(y#x as double), cast(x#x as double)) AS regr_sxy(y, x)#x]
+- SubqueryAlias regr_test
   +- View (`regr_test`, [x#x, y#x])
      +- Project [cast(x#x as int) AS x#x, cast(y#x as int) AS y#x]
         +- Project [x#x, y#x]
            +- SubqueryAlias regr_test
               +- LocalRelation [x#x, y#x]


-- !query
SELECT count(*), sum(x), regr_sxx(y,x), sum(y),regr_syy(y,x), regr_sxy(y,x)
FROM regr_test WHERE x IN (10,20,30)
-- !query analysis
Aggregate [count(1) AS count(1)#xL, sum(x#x) AS sum(x)#xL, regr_sxx(cast(y#x as double), cast(x#x as double)) AS regr_sxx(y, x)#x, sum(y#x) AS sum(y)#xL, regr_syy(cast(y#x as double), cast(x#x as double)) AS regr_syy(y, x)#x, regr_sxy(cast(y#x as double), cast(x#x as double)) AS regr_sxy(y, x)#x]
+- Filter x#x IN (10,20,30)
   +- SubqueryAlias regr_test
      +- View (`regr_test`, [x#x, y#x])
         +- Project [cast(x#x as int) AS x#x, cast(y#x as int) AS y#x]
            +- Project [x#x, y#x]
               +- SubqueryAlias regr_test
                  +- LocalRelation [x#x, y#x]


-- !query
SELECT count(*), sum(x), regr_sxx(y,x), sum(y),regr_syy(y,x), regr_sxy(y,x)
FROM regr_test WHERE x IN (80,100)
-- !query analysis
Aggregate [count(1) AS count(1)#xL, sum(x#x) AS sum(x)#xL, regr_sxx(cast(y#x as double), cast(x#x as double)) AS regr_sxx(y, x)#x, sum(y#x) AS sum(y)#xL, regr_syy(cast(y#x as double), cast(x#x as double)) AS regr_syy(y, x)#x, regr_sxy(cast(y#x as double), cast(x#x as double)) AS regr_sxy(y, x)#x]
+- Filter x#x IN (80,100)
   +- SubqueryAlias regr_test
      +- View (`regr_test`, [x#x, y#x])
         +- Project [cast(x#x as int) AS x#x, cast(y#x as int) AS y#x]
            +- Project [x#x, y#x]
               +- SubqueryAlias regr_test
                  +- LocalRelation [x#x, y#x]


-- !query
DROP VIEW regr_test
-- !query analysis
DropTempViewCommand regr_test


-- !query
SELECT count(udf(four)) AS cnt_1000 FROM onek
-- !query analysis
Aggregate [count(cast(udf(cast(four#x as string)) as int)) AS cnt_1000#xL]
+- SubqueryAlias spark_catalog.default.onek
   +- Relation spark_catalog.default.onek[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
SELECT udf(count(DISTINCT four)) AS cnt_4 FROM onek
-- !query analysis
Aggregate [cast(udf(cast(count(distinct four#x) as string)) as bigint) AS cnt_4#xL]
+- SubqueryAlias spark_catalog.default.onek
   +- Relation spark_catalog.default.onek[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
select ten, udf(count(*)), sum(udf(four)) from onek
group by ten order by ten
-- !query analysis
Sort [ten#x ASC NULLS FIRST], true
+- Aggregate [ten#x], [ten#x, cast(udf(cast(count(1) as string)) as bigint) AS udf(count(1))#xL, sum(cast(udf(cast(four#x as string)) as int)) AS sum(udf(four))#xL]
   +- SubqueryAlias spark_catalog.default.onek
      +- Relation spark_catalog.default.onek[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
select ten, count(udf(four)), udf(sum(DISTINCT four)) from onek
group by ten order by ten
-- !query analysis
Sort [ten#x ASC NULLS FIRST], true
+- Aggregate [ten#x], [ten#x, count(cast(udf(cast(four#x as string)) as int)) AS count(udf(four))#xL, cast(udf(cast(sum(distinct four#x) as string)) as bigint) AS udf(sum(DISTINCT four))#xL]
   +- SubqueryAlias spark_catalog.default.onek
      +- Relation spark_catalog.default.onek[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
select ten, udf(sum(distinct four)) from onek a
group by ten
having exists (select 1 from onek b where udf(sum(distinct a.four)) = b.four)
-- !query analysis
Project [ten#x, udf(sum(DISTINCT four))#xL]
+- Filter exists#x [sum(distinct four#x)#xL]
   :  +- Project [1 AS 1#x]
   :     +- Filter (outer(udf(sum(DISTINCT four))#xL) = cast(four#x as bigint))
   :        +- SubqueryAlias b
   :           +- SubqueryAlias spark_catalog.default.onek
   :              +- Relation spark_catalog.default.onek[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet
   +- Aggregate [ten#x], [ten#x, cast(udf(cast(sum(distinct four#x) as string)) as bigint) AS udf(sum(DISTINCT four))#xL, sum(distinct four#x) AS sum(distinct four#x)#xL]
      +- SubqueryAlias a
         +- SubqueryAlias spark_catalog.default.onek
            +- Relation spark_catalog.default.onek[unique1#x,unique2#x,two#x,four#x,ten#x,twenty#x,hundred#x,thousand#x,twothousand#x,fivethous#x,tenthous#x,odd#x,even#x,stringu1#x,stringu2#x,string4#x] parquet


-- !query
select ten, sum(distinct four) from onek a
group by ten
having exists (select 1 from onek b
               where sum(distinct a.four + b.four) = udf(b.four))
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.AGGREGATE_FUNCTION_MIXED_OUTER_LOCAL_REFERENCES",
  "sqlState" : "0A000",
  "messageParameters" : {
    "function" : "sum(DISTINCT (outer(a.four) + b.four))"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 114,
    "stopIndex" : 142,
    "fragment" : "sum(distinct a.four + b.four)"
  } ]
}


-- !query
select
  (select udf(max((select i.unique2 from tenk1 i where i.unique1 = o.unique1))))
from tenk1 o
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "UNRESOLVED_COLUMN.WITH_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`o`.`unique1`",
    "proposal" : "`i`.`unique1`, `i`.`unique2`, `i`.`even`, `i`.`four`, `i`.`odd`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 75,
    "stopIndex" : 83,
    "fragment" : "o.unique1"
  } ]
}
