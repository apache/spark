-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE OR REPLACE TEMPORARY VIEW t1 AS SELECT * FROM VALUES
(1), (2), (3), (4)
as t1(int_col1)
-- !query analysis
CreateViewCommand `t1`, SELECT * FROM VALUES
(1), (2), (3), (4)
as t1(int_col1), false, true, LocalTempView, UNSUPPORTED, true
   +- Project [int_col1#x]
      +- SubqueryAlias t1
         +- LocalRelation [int_col1#x]


-- !query
CREATE FUNCTION myDoubleAvg AS 'test.org.apache.spark.sql.MyDoubleAvg'
-- !query analysis
CreateFunctionCommand spark_catalog.default.myDoubleAvg, test.org.apache.spark.sql.MyDoubleAvg, false, false, false


-- !query
SELECT default.myDoubleAvg(udf(int_col1)) as my_avg, udf(default.myDoubleAvg(udf(int_col1))) as my_avg2, udf(default.myDoubleAvg(int_col1)) as my_avg3 from t1
-- !query analysis
Aggregate [spark_catalog.default.mydoubleavg(cast(cast(udf(cast(int_col1#x as string)) as int) as double), test.org.apache.spark.sql.MyDoubleAvg@xxxxxxxx, 0, 0, Some(spark_catalog.default.mydoubleavg)) AS my_avg#x, cast(udf(cast(spark_catalog.default.mydoubleavg(cast(cast(udf(cast(int_col1#x as string)) as int) as double), test.org.apache.spark.sql.MyDoubleAvg@xxxxxxxx, 0, 0, Some(spark_catalog.default.mydoubleavg)) as string)) as double) AS my_avg2#x, cast(udf(cast(spark_catalog.default.mydoubleavg(cast(int_col1#x as double), test.org.apache.spark.sql.MyDoubleAvg@xxxxxxxx, 0, 0, Some(spark_catalog.default.mydoubleavg)) as string)) as double) AS my_avg3#x]
+- SubqueryAlias t1
   +- View (`t1`, [int_col1#x])
      +- Project [cast(int_col1#x as int) AS int_col1#x]
         +- Project [int_col1#x]
            +- SubqueryAlias t1
               +- LocalRelation [int_col1#x]


-- !query
SELECT default.myDoubleAvg(udf(int_col1), udf(3)) as my_avg from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "WRONG_NUM_ARGS.WITHOUT_SUGGESTION",
  "sqlState" : "42605",
  "messageParameters" : {
    "actualNum" : "2",
    "docroot" : "https://spark.apache.org/docs/latest",
    "expectedNum" : "1",
    "functionName" : "`spark_catalog`.`default`.`mydoubleavg`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 49,
    "fragment" : "default.myDoubleAvg(udf(int_col1), udf(3))"
  } ]
}


-- !query
CREATE FUNCTION udaf1 AS 'test.non.existent.udaf'
-- !query analysis
CreateFunctionCommand spark_catalog.default.udaf1, test.non.existent.udaf, false, false, false


-- !query
SELECT default.udaf1(udf(int_col1)) as udaf1, udf(default.udaf1(udf(int_col1))) as udaf2, udf(default.udaf1(int_col1)) as udaf3 from t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "condition" : "CANNOT_LOAD_FUNCTION_CLASS",
  "sqlState" : "46103",
  "messageParameters" : {
    "className" : "test.non.existent.udaf",
    "functionName" : "`spark_catalog`.`default`.`udaf1`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 35,
    "fragment" : "default.udaf1(udf(int_col1))"
  } ]
}


-- !query
DROP FUNCTION myDoubleAvg
-- !query analysis
DropFunctionCommand spark_catalog.default.mydoubleavg, false, false


-- !query
DROP FUNCTION udaf1
-- !query analysis
DropFunctionCommand spark_catalog.default.udaf1, false, false
