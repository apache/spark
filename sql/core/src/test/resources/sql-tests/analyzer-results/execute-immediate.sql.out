-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TEMPORARY VIEW tbl_view AS SELECT * FROM VALUES
  (10, 'name1', named_struct('f1', 1, 's2', named_struct('f2', 101, 'f3', 'a'))),
  (20, 'name2', named_struct('f1', 2, 's2', named_struct('f2', 202, 'f3', 'b'))),
  (30, 'name3', named_struct('f1', 3, 's2', named_struct('f2', 303, 'f3', 'c'))),
  (40, 'name4', named_struct('f1', 4, 's2', named_struct('f2', 404, 'f3', 'd'))),
  (50, 'name5', named_struct('f1', 5, 's2', named_struct('f2', 505, 'f3', 'e'))),
  (60, 'name6', named_struct('f1', 6, 's2', named_struct('f2', 606, 'f3', 'f'))),
  (70, 'name7', named_struct('f1', 7, 's2', named_struct('f2', 707, 'f3', 'g')))
AS tbl_view(id, name, data)
-- !query analysis
CreateViewCommand `tbl_view`, SELECT * FROM VALUES
  (10, 'name1', named_struct('f1', 1, 's2', named_struct('f2', 101, 'f3', 'a'))),
  (20, 'name2', named_struct('f1', 2, 's2', named_struct('f2', 202, 'f3', 'b'))),
  (30, 'name3', named_struct('f1', 3, 's2', named_struct('f2', 303, 'f3', 'c'))),
  (40, 'name4', named_struct('f1', 4, 's2', named_struct('f2', 404, 'f3', 'd'))),
  (50, 'name5', named_struct('f1', 5, 's2', named_struct('f2', 505, 'f3', 'e'))),
  (60, 'name6', named_struct('f1', 6, 's2', named_struct('f2', 606, 'f3', 'f'))),
  (70, 'name7', named_struct('f1', 7, 's2', named_struct('f2', 707, 'f3', 'g')))
AS tbl_view(id, name, data), false, false, LocalTempView, UNSUPPORTED, true
   +- Project [id#x, name#x, data#x]
      +- SubqueryAlias tbl_view
         +- LocalRelation [id#x, name#x, data#x]


-- !query
CREATE TABLE x (id INT) USING csv
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`x`, false


-- !query
DECLARE sql_string STRING
-- !query analysis
CreateVariable defaultvalueexpression(null, null), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.sql_string


-- !query
SET VAR sql_string = 'SELECT * from tbl_view where name = \'name1\''
-- !query analysis
SetVariable [variablereference(system.session.sql_string=CAST(NULL AS STRING))]
+- Project [SELECT * from tbl_view where name = 'name1' AS sql_string#x]
   +- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SET spark.sql.ansi.enabled=true'
-- !query analysis
CommandResult [key#x, value#x], Execute SetCommand, [[spark.sql.ansi.enabled,true]]
   +- SetCommand (spark.sql.ansi.enabled,Some(true))


-- !query
EXECUTE IMMEDIATE 'CREATE TEMPORARY VIEW IDENTIFIER(:tblName) AS SELECT id, name FROM tbl_view' USING 'tbl_view_tmp' as tblName
-- !query analysis
CommandResult Execute CreateViewCommand
   +- CreateViewCommand `tbl_view_tmp`, SELECT id, name FROM tbl_view, false, false, LocalTempView, UNSUPPORTED, true
         +- Project [id#x, name#x]
            +- SubqueryAlias tbl_view
               +- View (`tbl_view`, [id#x, name#x, data#x])
                  +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
                     +- Project [id#x, name#x, data#x]
                        +- SubqueryAlias tbl_view
                           +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * FROM tbl_view_tmp'
-- !query analysis
Project [id#x, name#x]
+- SubqueryAlias tbl_view_tmp
   +- View (`tbl_view_tmp`, [id#x, name#x])
      +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x]
         +- Project [id#x, name#x]
            +- SubqueryAlias tbl_view
               +- View (`tbl_view`, [id#x, name#x, data#x])
                  +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
                     +- Project [id#x, name#x, data#x]
                        +- SubqueryAlias tbl_view
                           +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'REFRESH TABLE IDENTIFIER(:tblName)' USING 'x' as tblName
-- !query analysis
CommandResult Execute RefreshTableCommand
   +- RefreshTableCommand `spark_catalog`.`default`.`x`


-- !query
EXECUTE IMMEDIATE sql_string
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter (name#x = name1)
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = \'name1\''
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter (name#x = name1)
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
SET VAR sql_string = 'SELECT * from tbl_view where name = ? or name = ?'
-- !query analysis
SetVariable [variablereference(system.session.sql_string='SELECT * from tbl_view where name = \'name1\'')]
+- Project [SELECT * from tbl_view where name = ? or name = ? AS sql_string#x]
   +- OneRowRelation


-- !query
DECLARE a STRING
-- !query analysis
CreateVariable defaultvalueexpression(null, null), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.a


-- !query
SET VAR a = 'name1'
-- !query analysis
SetVariable [variablereference(system.session.a=CAST(NULL AS STRING))]
+- Project [name1 AS a#x]
   +- OneRowRelation


-- !query
EXECUTE IMMEDIATE sql_string USING 'name1', 'name3'
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name1) OR (name#x = name3))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE sql_string USING a, 'name2'
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name1) OR (name#x = name2))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = ? or name = ?' USING 'name1', 'name3'
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name1) OR (name#x = name3))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = ? or name = ?' USING a, 'name2'
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name1) OR (name#x = name2))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = ? or name = ?' USING (a, 'name2')
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name1) OR (name#x = name2))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'INSERT INTO x VALUES(?)' USING 1
-- !query analysis
CommandResult Execute InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/x, false, CSV, [path=file:[not included in comparison]/{warehouse_dir}/x], Append, `spark_catalog`.`default`.`x`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/x), [id]
   +- InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/x, false, CSV, [path=file:[not included in comparison]/{warehouse_dir}/x], Append, `spark_catalog`.`default`.`x`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/x), [id]
      +- Project [col1#x AS id#x]
         +- LocalRelation [col1#x]


-- !query
SELECT * from x
-- !query analysis
Project [id#x]
+- SubqueryAlias spark_catalog.default.x
   +- Relation spark_catalog.default.x[id#x] csv


-- !query
SET VAR sql_string = 'SELECT * from tbl_view where name = :first or id = :second'
-- !query analysis
SetVariable [variablereference(system.session.sql_string='SELECT * from tbl_view where name = ? or name = ?')]
+- Project [SELECT * from tbl_view where name = :first or id = :second AS sql_string#x]
   +- OneRowRelation


-- !query
DECLARE b INT
-- !query analysis
CreateVariable defaultvalueexpression(null, null), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.b


-- !query
SET VAR b = 40
-- !query analysis
SetVariable [variablereference(system.session.b=CAST(NULL AS INT))]
+- Project [40 AS b#x]
   +- OneRowRelation


-- !query
EXECUTE IMMEDIATE sql_string USING 40 as second, 'name7' as first
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name7) OR (id#x = 40))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE sql_string USING b as second, 'name7' as first
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name7) OR (id#x = 40))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = :first or id = :second' USING 40 as second, 'name7' as first
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name7) OR (id#x = 40))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = :first or id = :second' USING 'name7' as first, b as second
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name7) OR (id#x = 40))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT tbl_view.*, :first as p FROM tbl_view WHERE name = :first' USING 'name7' as first
-- !query analysis
Project [id#x, name#x, data#x, name7 AS p#x]
+- Filter (name#x = name7)
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SET VAR sql_string = ?' USING 'SELECT id from tbl_view where name = :first'
-- !query analysis
CommandResult SetVariable [variablereference(system.session.sql_string='SELECT * from tbl_view where name = :first or id = :second')]
   +- SetVariable [variablereference(system.session.sql_string='SELECT * from tbl_view where name = :first or id = :second')]
      +- Project [SELECT id from tbl_view where name = :first AS sql_string#x]
         +- OneRowRelation


-- !query
SELECT sql_string
-- !query analysis
Project [variablereference(system.session.sql_string='SELECT id from tbl_view where name = :first') AS sql_string#x]
+- OneRowRelation


-- !query
DECLARE res_id INT
-- !query analysis
CreateVariable defaultvalueexpression(null, null), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.res_id


-- !query
EXECUTE IMMEDIATE sql_string INTO res_id USING 'name7' as first
-- !query analysis
SetVariable [variablereference(system.session.res_id=CAST(NULL AS INT))]
+- GlobalLimit 2
   +- LocalLimit 2
      +- Project [id#x]
         +- Filter (name#x = name7)
            +- SubqueryAlias tbl_view
               +- View (`tbl_view`, [id#x, name#x, data#x])
                  +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
                     +- Project [id#x, name#x, data#x]
                        +- SubqueryAlias tbl_view
                           +- LocalRelation [id#x, name#x, data#x]


-- !query
SELECT res_id
-- !query analysis
Project [variablereference(system.session.res_id=70) AS res_id#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE sql_string INTO res_id USING a as first
-- !query analysis
SetVariable [variablereference(system.session.res_id=70)]
+- GlobalLimit 2
   +- LocalLimit 2
      +- Project [id#x]
         +- Filter (name#x = name1)
            +- SubqueryAlias tbl_view
               +- View (`tbl_view`, [id#x, name#x, data#x])
                  +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
                     +- Project [id#x, name#x, data#x]
                        +- SubqueryAlias tbl_view
                           +- LocalRelation [id#x, name#x, data#x]


-- !query
SELECT res_id
-- !query analysis
Project [variablereference(system.session.res_id=10) AS res_id#x]
+- OneRowRelation


-- !query
SET VAR sql_string = 'SELECT * from tbl_view where name = :first or id = :second'
-- !query analysis
SetVariable [variablereference(system.session.sql_string='SELECT id from tbl_view where name = :first')]
+- Project [SELECT * from tbl_view where name = :first or id = :second AS sql_string#x]
   +- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT 42' INTO res_id
-- !query analysis
SetVariable [variablereference(system.session.res_id=10)]
+- Project [42 AS 42#x]
   +- OneRowRelation


-- !query
SELECT res_id
-- !query analysis
Project [variablereference(system.session.res_id=42) AS res_id#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT id, name FROM tbl_view WHERE id = ?' INTO b, a USING 10
-- !query analysis
SetVariable [variablereference(system.session.b=40), variablereference(system.session.a='name1')]
+- GlobalLimit 2
   +- LocalLimit 2
      +- Project [id#x, name#x]
         +- Filter (id#x = 10)
            +- SubqueryAlias tbl_view
               +- View (`tbl_view`, [id#x, name#x, data#x])
                  +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
                     +- Project [id#x, name#x, data#x]
                        +- SubqueryAlias tbl_view
                           +- LocalRelation [id#x, name#x, data#x]


-- !query
SELECT b, a
-- !query analysis
Project [variablereference(system.session.b=10) AS b#x, variablereference(system.session.a='name1') AS a#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT * FROM tbl_view where id = ? AND name = ?' USING b as first, a
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((id#x = 10) AND (name#x = name1))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT 42 WHERE 2 = 1' INTO res_id
-- !query analysis
SetVariable [variablereference(system.session.res_id=42)]
+- Project [42 AS 42#x]
   +- Filter (2 = 1)
      +- OneRowRelation


-- !query
SELECT res_id
-- !query analysis
Project [variablereference(system.session.res_id=CAST(NULL AS INT)) AS res_id#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT \'1707\'' INTO res_id
-- !query analysis
SetVariable [variablereference(system.session.res_id=CAST(NULL AS INT))]
+- Project [cast(1707#x as int) AS res_id#x]
   +- Project [1707 AS 1707#x]
      +- OneRowRelation


-- !query
SELECT res_id
-- !query analysis
Project [variablereference(system.session.res_id=1707) AS res_id#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT \'invalid_cast_error_expected\'' INTO res_id
-- !query analysis
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "expression" : "'invalid_cast_error_expected'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 70,
    "fragment" : "EXECUTE IMMEDIATE 'SELECT \\'invalid_cast_error_expected\\'' INTO res_id"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'INSERT INTO x VALUES (?)' INTO res_id USING 1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_STATEMENT_FOR_EXECUTE_INTO",
  "sqlState" : "07501",
  "messageParameters" : {
    "sqlString" : "INSERT INTO X VALUES (?)"
  }
}


-- !query
DECLARE OR REPLACE testvarA INT
-- !query analysis
CreateVariable defaultvalueexpression(null, null), true
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.testvarA


-- !query
EXECUTE IMMEDIATE 'SET VAR testVarA = 1' INTO testVarA
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_STATEMENT_FOR_EXECUTE_INTO",
  "sqlState" : "07501",
  "messageParameters" : {
    "sqlString" : "SET VAR TESTVARA = 1"
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT * FROM tbl_view WHERE ? = id' USING id
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNRESOLVED_COLUMN.WITHOUT_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`id`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 63,
    "stopIndex" : 64,
    "fragment" : "id"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELECT * FROM tbl_view where ? = id and :first = name' USING 1 as x, 'name2' as first
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_QUERY_MIXED_QUERY_PARAMETERS",
  "sqlState" : "42613"
}


-- !query
EXECUTE IMMEDIATE 'SELECT * FROM tbl_view where :x = id and :first = name' USING 1, 'name2' as first
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ALL_PARAMETERS_MUST_BE_NAMED",
  "sqlState" : "07001",
  "messageParameters" : {
    "exprs" : "\"1\""
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT * FROM tbl_view where :first = name' USING 1, 'name2' as first
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ALL_PARAMETERS_MUST_BE_NAMED",
  "sqlState" : "07001",
  "messageParameters" : {
    "exprs" : "\"1\""
  }
}


-- !query
EXECUTE IMMEDIATE 'SELCT Fa'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'SELCT'",
    "hint" : ""
  },
  "queryContext" : [ {
    "objectType" : "EXECUTE IMMEDIATE",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 8,
    "fragment" : "SELCT Fa"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELCT Fa' INTO res_id
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'SELCT'",
    "hint" : ""
  },
  "queryContext" : [ {
    "objectType" : "EXECUTE IMMEDIATE",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 8,
    "fragment" : "SELCT Fa"
  } ]
}


-- !query
EXECUTE IMMEDIATE b
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_EXPR_TYPE_FOR_QUERY_EXECUTE_IMMEDIATE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "exprType" : "\"INT\""
  }
}


-- !query
SET VAR sql_string = 'SELECT * from tbl_view where name = :first or id = :second'
-- !query analysis
SetVariable [variablereference(system.session.sql_string='SELECT * from tbl_view where name = :first or id = :second')]
+- Project [SELECT * from tbl_view where name = :first or id = :second AS sql_string#x]
   +- OneRowRelation


-- !query
SET VAR a = 'na'
-- !query analysis
SetVariable [variablereference(system.session.a='name1')]
+- Project [na AS a#x]
   +- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = :first' USING CONCAT(a , "me1") as first
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter (name#x = name1)
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = :first' USING (SELECT 42) as first, 'name2' as second
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_EXPR_FOR_PARAMETER",
  "sqlState" : "42K0E",
  "messageParameters" : {
    "invalidExprSql" : "\"scalarsubquery()\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 70,
    "stopIndex" : 80,
    "fragment" : "(SELECT 42)"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELECT id, name FROM tbl_view WHERE id = ?' INTO a, b USING 10
-- !query analysis
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "expression" : "'name1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 81,
    "fragment" : "EXECUTE IMMEDIATE 'SELECT id, name FROM tbl_view WHERE id = ?' INTO a, b USING 10"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELECT id, name FROM tbl_view WHERE id = ?' INTO (a, b) USING 10
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT id FROM tbl_view' INTO res_id
-- !query analysis
org.apache.spark.SparkException
{
  "errorClass" : "ROW_SUBQUERY_TOO_MANY_ROWS",
  "sqlState" : "21000"
}


-- !query
EXECUTE IMMEDIATE 'SELECT id, data.f1 FROM tbl_view' INTO res_id
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ASSIGNMENT_ARITY_MISMATCH",
  "sqlState" : "42802",
  "messageParameters" : {
    "numExpr" : "2",
    "numTarget" : "1"
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT id FROM tbl_view' INTO res_id, b
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ASSIGNMENT_ARITY_MISMATCH",
  "sqlState" : "42802",
  "messageParameters" : {
    "numExpr" : "1",
    "numTarget" : "2"
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT id FROM tbl_view WHERE id = :first' USING 10 as first, 20 as first
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "EXEC_IMMEDIATE_DUPLICATE_ARGUMENT_ALIASES",
  "sqlState" : "42701",
  "messageParameters" : {
    "aliases" : "`first`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 63,
    "stopIndex" : 92,
    "fragment" : "USING 10 as first, 20 as first"
  } ]
}


-- !query
DECLARE p = 10
-- !query analysis
CreateVariable defaultvalueexpression(10, 10), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.p


-- !query
EXECUTE IMMEDIATE 'SELECT id FROM tbl_view WHERE id = :p' USING p
-- !query analysis
Project [id#x]
+- Filter (id#x = 10)
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT id FROM tbl_view WHERE id = :p' USING p, 'p'
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ALL_PARAMETERS_MUST_BE_NAMED",
  "sqlState" : "07001",
  "messageParameters" : {
    "exprs" : "\"p\""
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT id, data.f1 FROM tbl_view WHERE id = 10' INTO res_id, res_id
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DUPLICATE_ASSIGNMENTS",
  "sqlState" : "42701",
  "messageParameters" : {
    "nameList" : "`res_id`"
  }
}


-- !query
EXECUTE IMMEDIATE 'EXECUTE IMMEDIATE \'SELECT id FROM tbl_view WHERE id = ?\' USING 10'
-- !query analysis
Project [id#x]
+- Filter (id#x = 10)
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
SET VAR sql_string = null
-- !query analysis
SetVariable [variablereference(system.session.sql_string='SELECT * from tbl_view where name = :first or id = :second')]
+- Project [cast(sql_string#x as string) AS sql_string#x]
   +- Project [null AS sql_string#x]
      +- OneRowRelation


-- !query
EXECUTE IMMEDIATE sql_string
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NULL_QUERY_STRING_EXECUTE_IMMEDIATE",
  "sqlState" : "22004",
  "messageParameters" : {
    "varName" : "`sql_string`"
  }
}


-- !query
SET VAR sql_string = 5
-- !query analysis
SetVariable [variablereference(system.session.sql_string=CAST(NULL AS STRING))]
+- Project [cast(sql_string#x as string) AS sql_string#x]
   +- Project [5 AS sql_string#x]
      +- OneRowRelation


-- !query
EXECUTE IMMEDIATE sql_string
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'5'",
    "hint" : ""
  },
  "queryContext" : [ {
    "objectType" : "EXECUTE IMMEDIATE",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 1,
    "fragment" : "5"
  } ]
}


-- !query
SET VAR sql_string = 'hello'
-- !query analysis
SetVariable [variablereference(system.session.sql_string='5')]
+- Project [hello AS sql_string#x]
   +- OneRowRelation


-- !query
EXECUTE IMMEDIATE length(sql_string)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_EXPR_TYPE_FOR_QUERY_EXECUTE_IMMEDIATE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "exprType" : "\"INT\""
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT 42 where ? = :first' USING 1, 2 as first
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_QUERY_MIXED_QUERY_PARAMETERS",
  "sqlState" : "42613"
}


-- !query
DECLARE int_var INT
-- !query analysis
CreateVariable defaultvalueexpression(null, null), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.int_var


-- !query
SET VAR int_var = 42
-- !query analysis
SetVariable [variablereference(system.session.int_var=CAST(NULL AS INT))]
+- Project [42 AS int_var#x]
   +- OneRowRelation


-- !query
EXECUTE IMMEDIATE int_var
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_EXPR_TYPE_FOR_QUERY_EXECUTE_IMMEDIATE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "exprType" : "\"INT\""
  }
}


-- !query
DECLARE null_var STRING
-- !query analysis
CreateVariable defaultvalueexpression(null, null), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.null_var


-- !query
SET VAR null_var = null
-- !query analysis
SetVariable [variablereference(system.session.null_var=CAST(NULL AS STRING))]
+- Project [cast(null_var#x as string) AS null_var#x]
   +- Project [null AS null_var#x]
      +- OneRowRelation


-- !query
EXECUTE IMMEDIATE null_var
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NULL_QUERY_STRING_EXECUTE_IMMEDIATE",
  "sqlState" : "22004",
  "messageParameters" : {
    "varName" : "`null_var`"
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT ?' USING (SELECT 1)
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_EXPR_FOR_PARAMETER",
  "sqlState" : "42K0E",
  "messageParameters" : {
    "invalidExprSql" : "\"scalarsubquery()\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 36,
    "stopIndex" : 45,
    "fragment" : "(SELECT 1)"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELECT :first' USING 2, 3
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ALL_PARAMETERS_MUST_BE_NAMED",
  "sqlState" : "07001",
  "messageParameters" : {
    "exprs" : "\"2\", \"3\""
  }
}


-- !query
EXECUTE IMMEDIATE (SELECT c FROM (VALUES(1)) AS T(c))
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_EXPR_TYPE_FOR_QUERY_EXECUTE_IMMEDIATE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "exprType" : "\"INT\""
  }
}


-- !query
DROP TABLE x
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.x


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING 5 AS p
-- !query analysis
Project [typeof(5) AS type#x, 5 AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING 5L AS p
-- !query analysis
Project [typeof(5) AS type#x, 5 AS val#xL]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING 5S AS p
-- !query analysis
Project [typeof(5) AS type#x, 5 AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING 5Y AS p
-- !query analysis
Project [typeof(5) AS type#x, 5 AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING 3.14F AS p
-- !query analysis
Project [typeof(cast(3.14 as float)) AS type#x, cast(3.14 as float) AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING 3.14159D AS p
-- !query analysis
Project [typeof(3.14159) AS type#x, 3.14159 AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING 123.45BD AS p
-- !query analysis
Project [typeof(123.45) AS type#x, 123.45 AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING true AS p
-- !query analysis
Project [typeof(true) AS type#x, true AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING false AS p
-- !query analysis
Project [typeof(false) AS type#x, false AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING 'hello world' AS p
-- !query analysis
Project [typeof(hello world) AS type#x, hello world AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING 'it''s a test' AS p
-- !query analysis
Project [typeof(it's a test) AS type#x, it's a test AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING DATE '2023-12-25' AS p
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING TIMESTAMP '2023-12-25 10:30:45' AS p
-- !query analysis
[Analyzer test output redacted due to nondeterminism]


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING TIMESTAMP_NTZ '2023-12-25 10:30:45' AS p
-- !query analysis
Project [typeof(2023-12-25 10:30:45) AS type#x, 2023-12-25 10:30:45 AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING CAST(NULL AS INT) AS p
-- !query analysis
Project [typeof(cast(null as int)) AS type#x, cast(null as int) AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING CAST(NULL AS STRING) AS p
-- !query analysis
Project [typeof(cast(null as string)) AS type#x, cast(null as string) AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, hex(:p) as val' USING X'010203FF' AS p
-- !query analysis
Project [typeof(0x010203FF) AS type#x, hex(0x010203FF) AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING INTERVAL '3' DAY AS p
-- !query analysis
Project [typeof(INTERVAL '3' DAY) AS type#x, INTERVAL '3' DAY AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING INTERVAL '2' YEAR AS p
-- !query analysis
Project [typeof(INTERVAL '2' YEAR) AS type#x, INTERVAL '2' YEAR AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING INTERVAL '1-2' YEAR TO MONTH AS p
-- !query analysis
Project [typeof(INTERVAL '1-2' YEAR TO MONTH) AS type#x, INTERVAL '1-2' YEAR TO MONTH AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING INTERVAL '3 4:5:6' DAY TO SECOND AS p
-- !query analysis
Project [typeof(INTERVAL '3 04:05:06' DAY TO SECOND) AS type#x, INTERVAL '3 04:05:06' DAY TO SECOND AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING 999.999BD AS p
-- !query analysis
Project [typeof(999.999) AS type#x, 999.999 AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p1) as type1, :p1 as val1, typeof(:p2) as type2, :p2 as val2' 
  USING 42 as p1, 'test string' as p2
-- !query analysis
Project [typeof(42) AS type1#x, 42 AS val1#x, typeof(test string) AS type2#x, test string AS val2#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING ARRAY(1, 2, 3) AS p
-- !query analysis
Project [typeof(array(1, 2, 3)) AS type#x, array(1, 2, 3) AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING ARRAY('a', 'b', 'c') AS p
-- !query analysis
Project [typeof(array(a, b, c)) AS type#x, array(a, b, c) AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING ARRAY(ARRAY(1, 2), ARRAY(3, 4)) AS p
-- !query analysis
Project [typeof(array(array(1, 2), array(3, 4))) AS type#x, array(array(1, 2), array(3, 4)) AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING MAP('key1', 'value1', 'key2', 'value2') AS p
-- !query analysis
Project [typeof(map(key1, value1, key2, value2)) AS type#x, map(key1, value1, key2, value2) AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT typeof(:p) as type, :p as val' USING MAP(1, 'one', 2, 'two') AS p
-- !query analysis
Project [typeof(map(1, one, 2, two)) AS type#x, map(1, one, 2, two) AS val#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT :param'
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNBOUND_SQL_PARAMETER",
  "sqlState" : "42P02",
  "messageParameters" : {
    "name" : "param"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 13,
    "fragment" : ":param"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELECT ?'
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNBOUND_SQL_PARAMETER",
  "sqlState" : "42P02",
  "messageParameters" : {
    "name" : "_7"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 8,
    "fragment" : "?"
  } ]
}
