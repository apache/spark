-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TEMPORARY VIEW tbl_view AS SELECT * FROM VALUES
  (10, 'name1', named_struct('f1', 1, 's2', named_struct('f2', 101, 'f3', 'a'))),
  (20, 'name2', named_struct('f1', 2, 's2', named_struct('f2', 202, 'f3', 'b'))),
  (30, 'name3', named_struct('f1', 3, 's2', named_struct('f2', 303, 'f3', 'c'))),
  (40, 'name4', named_struct('f1', 4, 's2', named_struct('f2', 404, 'f3', 'd'))),
  (50, 'name5', named_struct('f1', 5, 's2', named_struct('f2', 505, 'f3', 'e'))),
  (60, 'name6', named_struct('f1', 6, 's2', named_struct('f2', 606, 'f3', 'f'))),
  (70, 'name7', named_struct('f1', 7, 's2', named_struct('f2', 707, 'f3', 'g')))
AS tbl_view(id, name, data)
-- !query analysis
CreateViewCommand `tbl_view`, SELECT * FROM VALUES
  (10, 'name1', named_struct('f1', 1, 's2', named_struct('f2', 101, 'f3', 'a'))),
  (20, 'name2', named_struct('f1', 2, 's2', named_struct('f2', 202, 'f3', 'b'))),
  (30, 'name3', named_struct('f1', 3, 's2', named_struct('f2', 303, 'f3', 'c'))),
  (40, 'name4', named_struct('f1', 4, 's2', named_struct('f2', 404, 'f3', 'd'))),
  (50, 'name5', named_struct('f1', 5, 's2', named_struct('f2', 505, 'f3', 'e'))),
  (60, 'name6', named_struct('f1', 6, 's2', named_struct('f2', 606, 'f3', 'f'))),
  (70, 'name7', named_struct('f1', 7, 's2', named_struct('f2', 707, 'f3', 'g')))
AS tbl_view(id, name, data), false, false, LocalTempView, UNSUPPORTED, true
   +- Project [id#x, name#x, data#x]
      +- SubqueryAlias tbl_view
         +- LocalRelation [id#x, name#x, data#x]


-- !query
CREATE TABLE x (id INT) USING csv
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`x`, false


-- !query
DECLARE sql_string STRING
-- !query analysis
CreateVariable defaultvalueexpression(null, null), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.sql_string


-- !query
SET VAR sql_string = 'SELECT * from tbl_view where name = \'name1\''
-- !query analysis
SetVariable [variablereference(system.session.sql_string=CAST(NULL AS STRING))]
+- Project [SELECT * from tbl_view where name = 'name1' AS sql_string#x]
   +- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SET spark.sql.ansi.enabled=true'
-- !query analysis
SetCommand (spark.sql.ansi.enabled,Some(true))


-- !query
EXECUTE IMMEDIATE 'CREATE TEMPORARY VIEW IDENTIFIER(:tblName) AS SELECT id, name FROM tbl_view' USING 'tbl_view_tmp' as tblName
-- !query analysis
CreateViewCommand `tbl_view_tmp`, SELECT id, name FROM tbl_view, false, false, LocalTempView, UNSUPPORTED, true
   +- Project [id#x, name#x]
      +- SubqueryAlias tbl_view
         +- View (`tbl_view`, [id#x, name#x, data#x])
            +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
               +- Project [id#x, name#x, data#x]
                  +- SubqueryAlias tbl_view
                     +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * FROM tbl_view_tmp'
-- !query analysis
Project [id#x, name#x]
+- SubqueryAlias tbl_view_tmp
   +- View (`tbl_view_tmp`, [id#x, name#x])
      +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x]
         +- Project [id#x, name#x]
            +- SubqueryAlias tbl_view
               +- View (`tbl_view`, [id#x, name#x, data#x])
                  +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
                     +- Project [id#x, name#x, data#x]
                        +- SubqueryAlias tbl_view
                           +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'REFRESH TABLE IDENTIFIER(:tblName)' USING 'x' as tblName
-- !query analysis
RefreshTableCommand `spark_catalog`.`default`.`x`


-- !query
EXECUTE IMMEDIATE sql_string
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter (name#x = name1)
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = \'name1\''
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter (name#x = name1)
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
SET VAR sql_string = 'SELECT * from tbl_view where name = ? or name = ?'
-- !query analysis
SetVariable [variablereference(system.session.sql_string='SELECT * from tbl_view where name = \'name1\'')]
+- Project [SELECT * from tbl_view where name = ? or name = ? AS sql_string#x]
   +- OneRowRelation


-- !query
DECLARE a STRING
-- !query analysis
CreateVariable defaultvalueexpression(null, null), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.a


-- !query
SET VAR a = 'name1'
-- !query analysis
SetVariable [variablereference(system.session.a=CAST(NULL AS STRING))]
+- Project [name1 AS a#x]
   +- OneRowRelation


-- !query
EXECUTE IMMEDIATE sql_string USING 'name1', 'name3'
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name1) OR (name#x = name3))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE sql_string USING a, 'name2'
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = variablereference(system.session.a='name1')) OR (name#x = name2))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = ? or name = ?' USING 'name1', 'name3'
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name1) OR (name#x = name3))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = ? or name = ?' USING a, 'name2'
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = variablereference(system.session.a='name1')) OR (name#x = name2))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = ? or name = ?' USING (a, 'name2')
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = variablereference(system.session.a='name1')) OR (name#x = name2))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'INSERT INTO x VALUES(?)' USING 1
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/x, false, CSV, [path=file:[not included in comparison]/{warehouse_dir}/x], Append, `spark_catalog`.`default`.`x`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/x), [id]
+- Project [cast(col1#x as int) AS id#x]
   +- LocalRelation [col1#x]


-- !query
SELECT * from x
-- !query analysis
Project [id#x]
+- SubqueryAlias spark_catalog.default.x
   +- Relation spark_catalog.default.x[id#x] csv


-- !query
SET VAR sql_string = 'SELECT * from tbl_view where name = :first or id = :second'
-- !query analysis
SetVariable [variablereference(system.session.sql_string='SELECT * from tbl_view where name = ? or name = ?')]
+- Project [SELECT * from tbl_view where name = :first or id = :second AS sql_string#x]
   +- OneRowRelation


-- !query
DECLARE b INT
-- !query analysis
CreateVariable defaultvalueexpression(null, null), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.b


-- !query
SET VAR b = 40
-- !query analysis
SetVariable [variablereference(system.session.b=CAST(NULL AS INT))]
+- Project [40 AS b#x]
   +- OneRowRelation


-- !query
EXECUTE IMMEDIATE sql_string USING 40 as second, 'name7' as first
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name7) OR (id#x = 40))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE sql_string USING b as second, 'name7' as first
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name7) OR (id#x = variablereference(system.session.b=40)))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = :first or id = :second' USING 40 as second, 'name7' as first
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name7) OR (id#x = 40))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = :first or id = :second' USING 'name7' as first, b as second
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((name#x = name7) OR (id#x = variablereference(system.session.b=40)))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT tbl_view.*, :first as p FROM tbl_view WHERE name = :first' USING 'name7' as first
-- !query analysis
Project [id#x, name#x, data#x, name7 AS p#x]
+- Filter (name#x = name7)
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SET VAR sql_string = ?' USING 'SELECT id from tbl_view where name = :first'
-- !query analysis
SetVariable [variablereference(system.session.sql_string='SELECT * from tbl_view where name = :first or id = :second')]
+- Project [SELECT id from tbl_view where name = :first AS sql_string#x]
   +- OneRowRelation


-- !query
SELECT sql_string
-- !query analysis
Project [variablereference(system.session.sql_string='SELECT id from tbl_view where name = :first') AS sql_string#x]
+- OneRowRelation


-- !query
DECLARE res_id INT
-- !query analysis
CreateVariable defaultvalueexpression(null, null), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.res_id


-- !query
EXECUTE IMMEDIATE sql_string INTO res_id USING 'name7' as first
-- !query analysis
SetVariable [variablereference(system.session.res_id=CAST(NULL AS INT))]
+- GlobalLimit 2
   +- LocalLimit 2
      +- Project [id#x]
         +- Filter (name#x = name7)
            +- SubqueryAlias tbl_view
               +- View (`tbl_view`, [id#x, name#x, data#x])
                  +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
                     +- Project [id#x, name#x, data#x]
                        +- SubqueryAlias tbl_view
                           +- LocalRelation [id#x, name#x, data#x]


-- !query
SELECT res_id
-- !query analysis
Project [variablereference(system.session.res_id=70) AS res_id#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE sql_string INTO res_id USING a as first
-- !query analysis
SetVariable [variablereference(system.session.res_id=70)]
+- GlobalLimit 2
   +- LocalLimit 2
      +- Project [id#x]
         +- Filter (name#x = variablereference(system.session.a='name1'))
            +- SubqueryAlias tbl_view
               +- View (`tbl_view`, [id#x, name#x, data#x])
                  +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
                     +- Project [id#x, name#x, data#x]
                        +- SubqueryAlias tbl_view
                           +- LocalRelation [id#x, name#x, data#x]


-- !query
SELECT res_id
-- !query analysis
Project [variablereference(system.session.res_id=10) AS res_id#x]
+- OneRowRelation


-- !query
SET VAR sql_string = 'SELECT * from tbl_view where name = :first or id = :second'
-- !query analysis
SetVariable [variablereference(system.session.sql_string='SELECT id from tbl_view where name = :first')]
+- Project [SELECT * from tbl_view where name = :first or id = :second AS sql_string#x]
   +- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT 42' INTO res_id
-- !query analysis
SetVariable [variablereference(system.session.res_id=10)]
+- Project [42 AS 42#x]
   +- OneRowRelation


-- !query
SELECT res_id
-- !query analysis
Project [variablereference(system.session.res_id=42) AS res_id#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT id, name FROM tbl_view WHERE id = ?' INTO b, a USING 10
-- !query analysis
SetVariable [variablereference(system.session.b=40), variablereference(system.session.a='name1')]
+- GlobalLimit 2
   +- LocalLimit 2
      +- Project [id#x, name#x]
         +- Filter (id#x = 10)
            +- SubqueryAlias tbl_view
               +- View (`tbl_view`, [id#x, name#x, data#x])
                  +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
                     +- Project [id#x, name#x, data#x]
                        +- SubqueryAlias tbl_view
                           +- LocalRelation [id#x, name#x, data#x]


-- !query
SELECT b, a
-- !query analysis
Project [variablereference(system.session.b=10) AS b#x, variablereference(system.session.a='name1') AS a#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT * FROM tbl_view where id = ? AND name = ?' USING b as first, a
-- !query analysis
Project [id#x, name#x, data#x]
+- Filter ((id#x = variablereference(system.session.b=10)) AND (name#x = variablereference(system.session.a='name1')))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT 42 WHERE 2 = 1' INTO res_id
-- !query analysis
SetVariable [variablereference(system.session.res_id=42)]
+- Project [42 AS 42#x]
   +- Filter (2 = 1)
      +- OneRowRelation


-- !query
SELECT res_id
-- !query analysis
Project [variablereference(system.session.res_id=CAST(NULL AS INT)) AS res_id#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT \'1707\'' INTO res_id
-- !query analysis
SetVariable [variablereference(system.session.res_id=CAST(NULL AS INT))]
+- Project [cast(1707#x as int) AS res_id#x]
   +- Project [1707 AS 1707#x]
      +- OneRowRelation


-- !query
SELECT res_id
-- !query analysis
Project [variablereference(system.session.res_id=1707) AS res_id#x]
+- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT \'invalid_cast_error_expected\'' INTO res_id
-- !query analysis
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "expression" : "'invalid_cast_error_expected'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 70,
    "fragment" : "EXECUTE IMMEDIATE 'SELECT \\'invalid_cast_error_expected\\'' INTO res_id"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'INSERT INTO x VALUES (?)' INTO res_id USING 1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_STATEMENT_FOR_EXECUTE_INTO",
  "sqlState" : "07501",
  "messageParameters" : {
    "sqlString" : "INSERT INTO X VALUES (?)"
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT * FROM tbl_view WHERE ? = id' USING id
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_VARIABLE",
  "sqlState" : "42883",
  "messageParameters" : {
    "searchPath" : "`system`.`session`",
    "variableName" : "`id`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 63,
    "stopIndex" : 64,
    "fragment" : "id"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELECT * FROM tbl_view where ? = id and :first = name' USING 1, 'name2' as first
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_QUERY_MIXED_QUERY_PARAMETERS",
  "sqlState" : "42613"
}


-- !query
EXECUTE IMMEDIATE 'SELECT * FROM tbl_view where :first = name' USING 1, 'name2' as first
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ALL_PARAMETERS_MUST_BE_NAMED",
  "sqlState" : "07001",
  "messageParameters" : {
    "exprs" : "\"1\""
  }
}


-- !query
EXECUTE IMMEDIATE 'SELCT Fa'
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'SELCT'",
    "hint" : ""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 28,
    "fragment" : "EXECUTE IMMEDIATE 'SELCT Fa'"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELCT Fa' INTO res_id
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'SELCT'",
    "hint" : ""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 40,
    "fragment" : "EXECUTE IMMEDIATE 'SELCT Fa' INTO res_id"
  } ]
}


-- !query
EXECUTE IMMEDIATE b
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_VARIABLE_TYPE_FOR_QUERY_EXECUTE_IMMEDIATE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "varType" : "\"INT\""
  }
}


-- !query
SET VAR sql_string = 'SELECT * from tbl_view where name = :first or id = :second'
-- !query analysis
SetVariable [variablereference(system.session.sql_string='SELECT * from tbl_view where name = :first or id = :second')]
+- Project [SELECT * from tbl_view where name = :first or id = :second AS sql_string#x]
   +- OneRowRelation


-- !query
SET VAR a = 'na'
-- !query analysis
SetVariable [variablereference(system.session.a='name1')]
+- Project [na AS a#x]
   +- OneRowRelation


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = :first' USING CONCAT(a , "me1") as first
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_EXPR_FOR_PARAMETER",
  "sqlState" : "42K0E",
  "messageParameters" : {
    "invalidExprSql" : "\"CONCAT(a, me1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 70,
    "stopIndex" : 86,
    "fragment" : "CONCAT(a , \"me1\")"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELECT * from tbl_view where name = :first' USING (SELECT 42) as first, 'name2' as second
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_EXPR_FOR_PARAMETER",
  "sqlState" : "42K0E",
  "messageParameters" : {
    "invalidExprSql" : "\"scalarsubquery()\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 70,
    "stopIndex" : 80,
    "fragment" : "(SELECT 42)"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELECT id, name FROM tbl_view WHERE id = ?' INTO a, b USING 10
-- !query analysis
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "expression" : "'name1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 81,
    "fragment" : "EXECUTE IMMEDIATE 'SELECT id, name FROM tbl_view WHERE id = ?' INTO a, b USING 10"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELECT id, name FROM tbl_view WHERE id = ?' INTO (a, b) USING 10
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT id FROM tbl_view' INTO res_id
-- !query analysis
org.apache.spark.SparkException
{
  "errorClass" : "ROW_SUBQUERY_TOO_MANY_ROWS",
  "sqlState" : "21000"
}


-- !query
EXECUTE IMMEDIATE 'SELECT id, data.f1 FROM tbl_view' INTO res_id
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ASSIGNMENT_ARITY_MISMATCH",
  "sqlState" : "42802",
  "messageParameters" : {
    "numExpr" : "2",
    "numTarget" : "1"
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT id FROM tbl_view' INTO res_id, b
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ASSIGNMENT_ARITY_MISMATCH",
  "sqlState" : "42802",
  "messageParameters" : {
    "numExpr" : "1",
    "numTarget" : "2"
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT id FROM tbl_view WHERE id = :first' USING 10 as first, 20 as first
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "EXEC_IMMEDIATE_DUPLICATE_ARGUMENT_ALIASES",
  "sqlState" : "42701",
  "messageParameters" : {
    "aliases" : "`first`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 63,
    "stopIndex" : 92,
    "fragment" : "USING 10 as first, 20 as first"
  } ]
}


-- !query
DECLARE p = 10
-- !query analysis
CreateVariable defaultvalueexpression(10, 10), false
+- ResolvedIdentifier org.apache.spark.sql.catalyst.analysis.FakeSystemCatalog$@xxxxxxxx, session.p


-- !query
EXECUTE IMMEDIATE 'SELECT id FROM tbl_view WHERE id = :p' USING p
-- !query analysis
Project [id#x]
+- Filter (id#x = variablereference(system.session.p=10))
   +- SubqueryAlias tbl_view
      +- View (`tbl_view`, [id#x, name#x, data#x])
         +- Project [cast(id#x as int) AS id#x, cast(name#x as string) AS name#x, cast(data#x as struct<f1:int,s2:struct<f2:int,f3:string>>) AS data#x]
            +- Project [id#x, name#x, data#x]
               +- SubqueryAlias tbl_view
                  +- LocalRelation [id#x, name#x, data#x]


-- !query
EXECUTE IMMEDIATE 'SELECT id FROM tbl_view WHERE id = :p' USING p, 'p'
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ALL_PARAMETERS_MUST_BE_NAMED",
  "sqlState" : "07001",
  "messageParameters" : {
    "exprs" : "\"p\""
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT id, data.f1 FROM tbl_view WHERE id = 10' INTO res_id, res_id
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DUPLICATE_ASSIGNMENTS",
  "sqlState" : "42701",
  "messageParameters" : {
    "nameList" : "`res_id`"
  }
}


-- !query
EXECUTE IMMEDIATE 'EXECUTE IMMEDIATE \'SELECT id FROM tbl_view WHERE id = ? USING 10\''
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NESTED_EXECUTE_IMMEDIATE",
  "sqlState" : "07501",
  "messageParameters" : {
    "sqlString" : "EXECUTE IMMEDIATE 'SELECT ID FROM TBL_VIEW WHERE ID = ? USING 10'"
  }
}


-- !query
SET VAR sql_string = null
-- !query analysis
SetVariable [variablereference(system.session.sql_string='SELECT * from tbl_view where name = :first or id = :second')]
+- Project [cast(sql_string#x as string) AS sql_string#x]
   +- Project [null AS sql_string#x]
      +- OneRowRelation


-- !query
EXECUTE IMMEDIATE sql_string
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NULL_QUERY_STRING_EXECUTE_IMMEDIATE",
  "sqlState" : "22004",
  "messageParameters" : {
    "varName" : "`sql_string`"
  }
}


-- !query
DROP TABLE x
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.x
