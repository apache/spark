-- Automatically generated by SQLQueryTestSuite
-- !query
DROP TABLE IF EXISTS t1
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
DROP TABLE IF EXISTS hll_binary_test
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.hll_binary_test


-- !query
DROP TABLE IF EXISTS hll_string_test
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.hll_string_test


-- !query
CREATE TABLE t1 USING JSON AS VALUES (0), (1), (2), (2), (2), (3), (4) as tab(col)
-- !query analysis
CreateDataSourceTableAsSelectCommand `spark_catalog`.`default`.`t1`, ErrorIfExists, [col]
   +- SubqueryAlias tab
      +- LocalRelation [col#x]


-- !query
CREATE TABLE hll_binary_test (bytes BINARY) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`hll_binary_test`, false


-- !query
CREATE TABLE hll_string_test (s STRING) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`hll_string_test`, false


-- !query
INSERT INTO hll_binary_test VALUES (X''), (CAST('  ' AS BINARY)), (X'e280'), (X'c1'), (X'c120')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/hll_binary_test, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/hll_binary_test], Append, `spark_catalog`.`default`.`hll_binary_test`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/hll_binary_test), [bytes]
+- Project [col1#x AS bytes#x]
   +- LocalRelation [col1#x]


-- !query
INSERT INTO hll_string_test VALUES (''), ('  '), (CAST(X'C1' AS STRING)), (CAST(X'80' AS STRING)), ('\uFFFD'), ('Å'), ('å'), ('a\u030A'), ('Å '), ('å  '), ('a\u030A   ')
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/hll_string_test, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/hll_string_test], Append, `spark_catalog`.`default`.`hll_string_test`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/hll_string_test), [s]
+- Project [col1#x AS s#x]
   +- LocalRelation [col1#x]


-- !query
SELECT hll_sketch_estimate(hll_sketch_agg(col)) AS result FROM t1
-- !query analysis
Aggregate [hll_sketch_estimate(hll_sketch_agg(col#x, 12, 0, 0)) AS result#xL]
+- SubqueryAlias spark_catalog.default.t1
   +- Relation spark_catalog.default.t1[col#x] json


-- !query
SELECT hll_sketch_estimate(hll_sketch_agg(bytes)) FROM hll_binary_test
-- !query analysis
Aggregate [hll_sketch_estimate(hll_sketch_agg(bytes#x, 12, 0, 0)) AS hll_sketch_estimate(hll_sketch_agg(bytes, 12))#xL]
+- SubqueryAlias spark_catalog.default.hll_binary_test
   +- Relation spark_catalog.default.hll_binary_test[bytes#x] parquet


-- !query
SELECT hll_sketch_estimate(hll_sketch_agg(s)) utf8_b FROM hll_string_test
-- !query analysis
Aggregate [hll_sketch_estimate(hll_sketch_agg(s#x, 12, 0, 0)) AS utf8_b#xL]
+- SubqueryAlias spark_catalog.default.hll_string_test
   +- Relation spark_catalog.default.hll_string_test[s#x] parquet


-- !query
SELECT hll_sketch_estimate(hll_sketch_agg(s COLLATE UTF8_LCASE)) utf8_lc FROM hll_string_test
-- !query analysis
Aggregate [hll_sketch_estimate(hll_sketch_agg(collate(s#x, UTF8_LCASE), 12, 0, 0)) AS utf8_lc#xL]
+- SubqueryAlias spark_catalog.default.hll_string_test
   +- Relation spark_catalog.default.hll_string_test[s#x] parquet


-- !query
SELECT hll_sketch_estimate(hll_sketch_agg(s COLLATE UNICODE)) unicode FROM hll_string_test
-- !query analysis
Aggregate [hll_sketch_estimate(hll_sketch_agg(collate(s#x, UNICODE), 12, 0, 0)) AS unicode#xL]
+- SubqueryAlias spark_catalog.default.hll_string_test
   +- Relation spark_catalog.default.hll_string_test[s#x] parquet


-- !query
SELECT hll_sketch_estimate(hll_sketch_agg(s COLLATE UNICODE_CI)) unicode_ci FROM hll_string_test
-- !query analysis
Aggregate [hll_sketch_estimate(hll_sketch_agg(collate(s#x, UNICODE_CI), 12, 0, 0)) AS unicode_ci#xL]
+- SubqueryAlias spark_catalog.default.hll_string_test
   +- Relation spark_catalog.default.hll_string_test[s#x] parquet


-- !query
SELECT hll_sketch_estimate(hll_sketch_agg(s COLLATE UTF8_BINARY_RTRIM)) utf8_b_rt FROM hll_string_test
-- !query analysis
Aggregate [hll_sketch_estimate(hll_sketch_agg(collate(s#x, UTF8_BINARY_RTRIM), 12, 0, 0)) AS utf8_b_rt#xL]
+- SubqueryAlias spark_catalog.default.hll_string_test
   +- Relation spark_catalog.default.hll_string_test[s#x] parquet


-- !query
SELECT hll_sketch_estimate(hll_sketch_agg(s COLLATE UTF8_LCASE_RTRIM)) utf8_lc_rt FROM hll_string_test
-- !query analysis
Aggregate [hll_sketch_estimate(hll_sketch_agg(collate(s#x, UTF8_LCASE_RTRIM), 12, 0, 0)) AS utf8_lc_rt#xL]
+- SubqueryAlias spark_catalog.default.hll_string_test
   +- Relation spark_catalog.default.hll_string_test[s#x] parquet


-- !query
SELECT hll_sketch_estimate(hll_sketch_agg(s COLLATE UNICODE_RTRIM)) unicode_rt FROM hll_string_test
-- !query analysis
Aggregate [hll_sketch_estimate(hll_sketch_agg(collate(s#x, UNICODE_RTRIM), 12, 0, 0)) AS unicode_rt#xL]
+- SubqueryAlias spark_catalog.default.hll_string_test
   +- Relation spark_catalog.default.hll_string_test[s#x] parquet


-- !query
SELECT hll_sketch_estimate(hll_sketch_agg(s COLLATE UNICODE_CI_RTRIM)) unicode_ci_rt FROM hll_string_test
-- !query analysis
Aggregate [hll_sketch_estimate(hll_sketch_agg(collate(s#x, UNICODE_CI_RTRIM), 12, 0, 0)) AS unicode_ci_rt#xL]
+- SubqueryAlias spark_catalog.default.hll_string_test
   +- Relation spark_catalog.default.hll_string_test[s#x] parquet


-- !query
SELECT hll_sketch_estimate(hll_sketch_agg(col, 12))
FROM VALUES (50), (60), (60), (60), (75), (100) tab(col)
-- !query analysis
Aggregate [hll_sketch_estimate(hll_sketch_agg(col#x, 12, 0, 0)) AS hll_sketch_estimate(hll_sketch_agg(col, 12))#xL]
+- SubqueryAlias tab
   +- LocalRelation [col#x]


-- !query
SELECT hll_sketch_estimate(hll_sketch_agg(col))
FROM VALUES ('abc'), ('def'), ('abc'), ('ghi'), ('abc') tab(col)
-- !query analysis
Aggregate [hll_sketch_estimate(hll_sketch_agg(col#x, 12, 0, 0)) AS hll_sketch_estimate(hll_sketch_agg(col, 12))#xL]
+- SubqueryAlias tab
   +- LocalRelation [col#x]


-- !query
SELECT hll_sketch_estimate(
  hll_union(
    hll_sketch_agg(col1),
    hll_sketch_agg(col2)))
  FROM VALUES
    (1, 4),
    (1, 4),
    (2, 5),
    (2, 5),
    (3, 6) AS tab(col1, col2)
-- !query analysis
Aggregate [hll_sketch_estimate(hll_union(hll_sketch_agg(col1#x, 12, 0, 0), hll_sketch_agg(col2#x, 12, 0, 0), false)) AS hll_sketch_estimate(hll_union(hll_sketch_agg(col1, 12), hll_sketch_agg(col2, 12), false))#xL]
+- SubqueryAlias tab
   +- LocalRelation [col1#x, col2#x]


-- !query
SELECT hll_sketch_estimate(hll_union_agg(sketch, true))
    FROM (SELECT hll_sketch_agg(col) as sketch
            FROM VALUES (1) AS tab(col)
          UNION ALL
          SELECT hll_sketch_agg(col, 20) as sketch
            FROM VALUES (1) AS tab(col))
-- !query analysis
Aggregate [hll_sketch_estimate(hll_union_agg(sketch#x, true, 0, 0)) AS hll_sketch_estimate(hll_union_agg(sketch, true))#xL]
+- SubqueryAlias __auto_generated_subquery_name
   +- Union false, false
      :- Aggregate [hll_sketch_agg(col#x, 12, 0, 0) AS sketch#x]
      :  +- SubqueryAlias tab
      :     +- LocalRelation [col#x]
      +- Aggregate [hll_sketch_agg(col#x, 20, 0, 0) AS sketch#x]
         +- SubqueryAlias tab
            +- LocalRelation [col#x]


-- !query
SELECT hll_sketch_agg(col)
FROM VALUES (ARRAY(1, 2)), (ARRAY(3, 4)) tab(col)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"col\"",
    "inputType" : "\"ARRAY<INT>\"",
    "paramIndex" : "first",
    "requiredType" : "(\"INT\" or \"BIGINT\" or \"STRING\" or \"BINARY\")",
    "sqlExpr" : "\"hll_sketch_agg(col, 12)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 26,
    "fragment" : "hll_sketch_agg(col)"
  } ]
}


-- !query
SELECT hll_sketch_agg(col, 2)
FROM VALUES (50), (60), (60) tab(col)
-- !query analysis
Aggregate [hll_sketch_agg(col#x, 2, 0, 0) AS hll_sketch_agg(col, 2)#x]
+- SubqueryAlias tab
   +- LocalRelation [col#x]


-- !query
SELECT hll_sketch_agg(col, 40)
FROM VALUES (50), (60), (60) tab(col)
-- !query analysis
Aggregate [hll_sketch_agg(col#x, 40, 0, 0) AS hll_sketch_agg(col, 40)#x]
+- SubqueryAlias tab
   +- LocalRelation [col#x]


-- !query
SELECT hll_sketch_agg(col, CAST(NULL AS INT)) AS k_is_null
FROM VALUES (15), (16), (17) tab(col)
-- !query analysis
Aggregate [hll_sketch_agg(col#x, cast(null as int), 0, 0) AS k_is_null#x]
+- SubqueryAlias tab
   +- LocalRelation [col#x]


-- !query
SELECT hll_sketch_agg(col, CAST(col AS INT)) AS k_non_constant
FROM VALUES (15), (16), (17) tab(col)
-- !query analysis
Aggregate [hll_sketch_agg(col#x, cast(col#x as int), 0, 0) AS k_non_constant#x]
+- SubqueryAlias tab
   +- LocalRelation [col#x]


-- !query
SELECT hll_sketch_agg(col, '15')
FROM VALUES (50), (60), (60) tab(col)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"15\"",
    "inputType" : "\"STRING\"",
    "paramIndex" : "second",
    "requiredType" : "\"INT\"",
    "sqlExpr" : "\"hll_sketch_agg(col, 15)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 32,
    "fragment" : "hll_sketch_agg(col, '15')"
  } ]
}


-- !query
SELECT hll_union(
    hll_sketch_agg(col1, 12),
    hll_sketch_agg(col2, 13))
  FROM VALUES
    (1, 4),
    (1, 4),
    (2, 5),
    (2, 5),
    (3, 6) AS tab(col1, col2)
-- !query analysis
Aggregate [hll_union(hll_sketch_agg(col1#x, 12, 0, 0), hll_sketch_agg(col2#x, 13, 0, 0), false) AS hll_union(hll_sketch_agg(col1, 12), hll_sketch_agg(col2, 13), false)#x]
+- SubqueryAlias tab
   +- LocalRelation [col1#x, col2#x]


-- !query
SELECT hll_union_agg(sketch, false)
FROM (SELECT hll_sketch_agg(col, 12) as sketch
        FROM VALUES (1) AS tab(col)
      UNION ALL
      SELECT hll_sketch_agg(col, 20) as sketch
        FROM VALUES (1) AS tab(col))
-- !query analysis
Aggregate [hll_union_agg(sketch#x, false, 0, 0) AS hll_union_agg(sketch, false)#x]
+- SubqueryAlias __auto_generated_subquery_name
   +- Union false, false
      :- Aggregate [hll_sketch_agg(col#x, 12, 0, 0) AS sketch#x]
      :  +- SubqueryAlias tab
      :     +- LocalRelation [col#x]
      +- Aggregate [hll_sketch_agg(col#x, 20, 0, 0) AS sketch#x]
         +- SubqueryAlias tab
            +- LocalRelation [col#x]


-- !query
SELECT hll_union(1, 2)
  FROM VALUES
    (1, 4),
    (1, 4),
    (2, 5),
    (2, 5),
    (3, 6) AS tab(col1, col2)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"1\"",
    "inputType" : "\"INT\"",
    "paramIndex" : "first",
    "requiredType" : "\"BINARY\"",
    "sqlExpr" : "\"hll_union(1, 2, false)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "hll_union(1, 2)"
  } ]
}


-- !query
SELECT hll_sketch_estimate(CAST ('abc' AS BINARY))
-- !query analysis
Project [hll_sketch_estimate(cast(abc as binary)) AS hll_sketch_estimate(CAST(abc AS BINARY))#xL]
+- OneRowRelation


-- !query
SELECT hll_union(CAST ('abc' AS BINARY), CAST ('def' AS BINARY))
-- !query analysis
Project [hll_union(cast(abc as binary), cast(def as binary), false) AS hll_union(CAST(abc AS BINARY), CAST(def AS BINARY), false)#x]
+- OneRowRelation


-- !query
SELECT hll_union_agg(buffer, false)
FROM (SELECT CAST('abc' AS BINARY) AS buffer)
-- !query analysis
Aggregate [hll_union_agg(buffer#x, false, 0, 0) AS hll_union_agg(buffer, false)#x]
+- SubqueryAlias __auto_generated_subquery_name
   +- Project [cast(abc as binary) AS buffer#x]
      +- OneRowRelation


-- !query
DROP TABLE IF EXISTS t1
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t1


-- !query
DROP TABLE IF EXISTS hll_binary_test
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.hll_binary_test


-- !query
DROP TABLE IF EXISTS hll_string_test
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.hll_string_test
