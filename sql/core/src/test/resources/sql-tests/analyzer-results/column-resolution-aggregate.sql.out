-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TEMPORARY VIEW v1 AS VALUES (1, 1, 1), (2, 2, 1) AS t(a, b, k)
-- !query analysis
CreateViewCommand `v1`, VALUES (1, 1, 1), (2, 2, 1) AS t(a, b, k), false, false, LocalTempView, UNSUPPORTED, true
   +- SubqueryAlias t
      +- LocalRelation [a#x, b#x, k#x]


-- !query
CREATE TEMPORARY VIEW v2 AS VALUES (1, 1, 1), (2, 2, 1) AS t(x, y, all)
-- !query analysis
CreateViewCommand `v2`, VALUES (1, 1, 1), (2, 2, 1) AS t(x, y, all), false, false, LocalTempView, UNSUPPORTED, true
   +- SubqueryAlias t
      +- LocalRelation [x#x, y#x, all#x]


-- !query
SELECT max(a) AS b, b FROM v1 GROUP BY k
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "MISSING_AGGREGATION",
  "sqlState" : "42803",
  "messageParameters" : {
    "expression" : "\"b\"",
    "expressionAnyValue" : "\"any_value(b)\""
  }
}


-- !query
SELECT a FROM v1 WHERE (12, 13) IN (SELECT max(x + 10) AS a, a + 1 FROM v2)
-- !query analysis
Project [a#x]
+- Filter named_struct(_0, 12, _1, 13) IN (list#x [])
   :  +- Project [a#x, (a#x + 1) AS (lateralAliasReference(a) + 1)#x]
   :     +- Project [max((x + 10))#x, max((x + 10))#x AS a#x]
   :        +- Aggregate [max((x#x + 10)) AS max((x + 10))#x]
   :           +- SubqueryAlias v2
   :              +- View (`v2`, [x#x, y#x, all#x])
   :                 +- Project [cast(x#x as int) AS x#x, cast(y#x as int) AS y#x, cast(all#x as int) AS all#x]
   :                    +- SubqueryAlias t
   :                       +- LocalRelation [x#x, y#x, all#x]
   +- SubqueryAlias v1
      +- View (`v1`, [a#x, b#x, k#x])
         +- Project [cast(a#x as int) AS a#x, cast(b#x as int) AS b#x, cast(k#x as int) AS k#x]
            +- SubqueryAlias t
               +- LocalRelation [a#x, b#x, k#x]


-- !query
SELECT a AS k FROM v1 GROUP BY k
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "MISSING_AGGREGATION",
  "sqlState" : "42803",
  "messageParameters" : {
    "expression" : "\"a\"",
    "expressionAnyValue" : "\"any_value(a)\""
  }
}


-- !query
SELECT x FROM v2 GROUP BY all
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "MISSING_AGGREGATION",
  "sqlState" : "42803",
  "messageParameters" : {
    "expression" : "\"x\"",
    "expressionAnyValue" : "\"any_value(x)\""
  }
}


-- !query
SELECT a AS all, b FROM v1 GROUP BY all
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "MISSING_AGGREGATION",
  "sqlState" : "42803",
  "messageParameters" : {
    "expression" : "\"b\"",
    "expressionAnyValue" : "\"any_value(b)\""
  }
}


-- !query
SELECT k AS lca, lca + 1 AS col FROM v1 GROUP BY k, col
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_FEATURE.LATERAL_COLUMN_ALIAS_IN_GROUP_BY",
  "sqlState" : "0A000"
}


-- !query
SELECT k AS lca, lca + 1 AS col FROM v1 GROUP BY all
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_FEATURE.LATERAL_COLUMN_ALIAS_IN_GROUP_BY",
  "sqlState" : "0A000"
}


-- !query
SELECT k AS lca, lca + 1 AS col FROM v1 GROUP BY lca
-- !query analysis
Project [lca#x, (lca#x + 1) AS col#x]
+- Project [k#x, k#x AS lca#x]
   +- Aggregate [k#x], [k#x]
      +- SubqueryAlias v1
         +- View (`v1`, [a#x, b#x, k#x])
            +- Project [cast(a#x as int) AS a#x, cast(b#x as int) AS b#x, cast(k#x as int) AS k#x]
               +- SubqueryAlias t
                  +- LocalRelation [a#x, b#x, k#x]


-- !query
SELECT * FROM v2 WHERE EXISTS (SELECT a, b FROM v1 GROUP BY all)
-- !query analysis
Project [x#x, y#x, all#x]
+- Filter exists#x []
   :  +- Aggregate [a#x, b#x], [a#x, b#x]
   :     +- SubqueryAlias v1
   :        +- View (`v1`, [a#x, b#x, k#x])
   :           +- Project [cast(a#x as int) AS a#x, cast(b#x as int) AS b#x, cast(k#x as int) AS k#x]
   :              +- SubqueryAlias t
   :                 +- LocalRelation [a#x, b#x, k#x]
   +- SubqueryAlias v2
      +- View (`v2`, [x#x, y#x, all#x])
         +- Project [cast(x#x as int) AS x#x, cast(y#x as int) AS y#x, cast(all#x as int) AS all#x]
            +- SubqueryAlias t
               +- LocalRelation [x#x, y#x, all#x]


-- !query
CREATE TEMPORARY VIEW vcol(col2 STRING) AS VALUES ('{"str": "test"}')
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'AS'",
    "hint" : ": missing 'USING'"
  }
}


-- !query
SELECT timestamp(col2:str) FROM vcol GROUP BY timestamp(col2:str)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`vcol`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 33,
    "stopIndex" : 36,
    "fragment" : "vcol"
  } ]
}


-- !query
CREATE TEMPORARY VIEW vcol2(col1 STRUCT<a: STRING>, a STRING) AS VALUES (named_struct('a', 'nested'), 'outer')
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'AS'",
    "hint" : ": missing 'USING'"
  }
}


-- !query
SELECT col1.a, a FROM vcol2 ORDER BY a
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`vcol2`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 23,
    "stopIndex" : 27,
    "fragment" : "vcol2"
  } ]
}


-- !query
SELECT col1.a, a FROM vcol2 ORDER BY col1.a
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`vcol2`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 23,
    "stopIndex" : 27,
    "fragment" : "vcol2"
  } ]
}


-- !query
SELECT DISTINCT(col1.a:b.c AS out1, col1.a:b.d AS out2) FROM vcol2
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`vcol2`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 62,
    "stopIndex" : 66,
    "fragment" : "vcol2"
  } ]
}


-- !query
CREATE TEMPORARY VIEW vcol3(col1 INT, col2 INT) AS VALUES (1, 2), (3, 4)
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'AS'",
    "hint" : ": missing 'USING'"
  }
}


-- !query
SELECT col1 FROM vcol3 GROUP BY col1 HAVING MAX(col2) == (SELECT 1 WHERE MAX(col2) = 1)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`vcol3`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 18,
    "stopIndex" : 22,
    "fragment" : "vcol3"
  } ]
}


-- !query
SELECT col1 FROM vcol3 GROUP BY col1 HAVING (SELECT 1 WHERE MAX(col2) = 1) == MAX(col2)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`vcol3`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 18,
    "stopIndex" : 22,
    "fragment" : "vcol3"
  } ]
}


-- !query
SELECT col1 FROM vcol3 GROUP BY col1 HAVING (SELECT 1 WHERE MAX(col2) = 1) == (SELECT 1 WHERE MAX(col2) = 1)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`vcol3`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 18,
    "stopIndex" : 22,
    "fragment" : "vcol3"
  } ]
}


-- !query
SELECT col1 FROM vcol3 GROUP BY col1 HAVING bool_or(col2 = 1) AND bool_or(col2 = 1)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`vcol3`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 18,
    "stopIndex" : 22,
    "fragment" : "vcol3"
  } ]
}


-- !query
SELECT 1 GROUP BY COALESCE(1, 1) HAVING COALESCE(1, 1) = 1  OR COALESCE(1, 1) IS NOT NULL
-- !query analysis
Project [1#x]
+- Filter ((coalesce(1, 1)#x = 1#x) OR isnotnull(coalesce(1, 1)#x))
   +- Aggregate [coalesce(1, 1)], [1 AS 1#x, coalesce(1, 1) AS coalesce(1, 1)#x]
      +- OneRowRelation


-- !query
SELECT col1 FROM vcol3 t1 GROUP BY col1 HAVING (
    SELECT MAX(t2.col1) FROM vcol3 t2 WHERE t2.col1 == MAX(t1.col1) GROUP BY t2.col1 HAVING (
        SELECT t3.col1 FROM vcol3 t3 WHERE t3.col1 == MAX(t2.col1)
    )
)
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`vcol3`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 18,
    "stopIndex" : 22,
    "fragment" : "vcol3"
  } ]
}


-- !query
DROP VIEW vcol
-- !query analysis
org.apache.spark.sql.catalyst.analysis.NoSuchTableException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`vcol`"
  }
}


-- !query
DROP VIEW vcol2
-- !query analysis
org.apache.spark.sql.catalyst.analysis.NoSuchTableException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`vcol2`"
  }
}


-- !query
DROP VIEW vcol3
-- !query analysis
org.apache.spark.sql.catalyst.analysis.NoSuchTableException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`default`.`vcol3`"
  }
}
