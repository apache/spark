-- Automatically generated by SQLQueryTestSuite
-- !query
SET spark.sql.legacy.viewSchemaBindingMode
-- !query analysis
SetCommand (spark.sql.legacy.viewSchemaBindingMode,None)


-- !query
SET spark.sql.legacy.viewSchemaBindingMode = false
-- !query analysis
SetCommand (spark.sql.legacy.viewSchemaBindingMode,Some(false))


-- !query
CREATE OR REPLACE VIEW v WITH SCHEMA BINDING AS SELECT 1
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "FEATURE_NOT_ENABLED",
  "sqlState" : "56038",
  "messageParameters" : {
    "configKey" : "spark.sql.legacy.viewSchemaBindingMode",
    "configValue" : "true",
    "featureName" : "VIEW ... WITH SCHEMA ..."
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 26,
    "stopIndex" : 44,
    "fragment" : "WITH SCHEMA BINDING"
  } ]
}


-- !query
CREATE OR REPLACE VIEW v WITH SCHEMA COMPENSATION AS SELECT 1
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "FEATURE_NOT_ENABLED",
  "sqlState" : "56038",
  "messageParameters" : {
    "configKey" : "spark.sql.legacy.viewSchemaBindingMode",
    "configValue" : "true",
    "featureName" : "VIEW ... WITH SCHEMA ..."
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 26,
    "stopIndex" : 49,
    "fragment" : "WITH SCHEMA COMPENSATION"
  } ]
}


-- !query
CREATE OR REPLACE VIEW v WITH SCHEMA TYPE EVOLUTION AS SELECT 1
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "FEATURE_NOT_ENABLED",
  "sqlState" : "56038",
  "messageParameters" : {
    "configKey" : "spark.sql.legacy.viewSchemaBindingMode",
    "configValue" : "true",
    "featureName" : "VIEW ... WITH SCHEMA ..."
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 26,
    "stopIndex" : 51,
    "fragment" : "WITH SCHEMA TYPE EVOLUTION"
  } ]
}


-- !query
CREATE OR REPLACE VIEW v WITH SCHEMA EVOLUTION AS SELECT 1
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "FEATURE_NOT_ENABLED",
  "sqlState" : "56038",
  "messageParameters" : {
    "configKey" : "spark.sql.legacy.viewSchemaBindingMode",
    "configValue" : "true",
    "featureName" : "VIEW ... WITH SCHEMA ..."
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 26,
    "stopIndex" : 46,
    "fragment" : "WITH SCHEMA EVOLUTION"
  } ]
}


-- !query
CREATE OR REPLACE VIEW v AS SELECT 1
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT 1, false, true, PersistedView, UNSUPPORTED, true
   +- Project [1 AS 1#x]
      +- OneRowRelation


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
SHOW TABLE EXTENDED LIKE 'v'
-- !query analysis
ShowTablesCommand default, v, [namespace#x, tableName#x, isTemporary#x, information#x], true


-- !query
SHOW CREATE TABLE v
-- !query analysis
ShowCreateTableCommand `spark_catalog`.`default`.`v`, [createtab_stmt#x]


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, true, true, false


-- !query
CREATE OR REPLACE TEMPORARY VIEW v AS SELECT 1
-- !query analysis
CreateViewCommand `v`, SELECT 1, false, true, LocalTempView, UNSUPPORTED, true
   +- Project [1 AS 1#x]
      +- OneRowRelation


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `v`, true, [col_name#x, data_type#x, comment#x]


-- !query
SHOW TABLE EXTENDED LIKE 'v'
-- !query analysis
ShowTablesCommand default, v, [namespace#x, tableName#x, isTemporary#x, information#x], true


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTempViewCommand v


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT NOT NULL) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
CREATE OR REPLACE VIEW v AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, true, PersistedView, UNSUPPORTED, true
   +- Project [c1#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x])
      +- Project [cast(c1#x as int) AS c1#x]
         +- Project [c1#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
SHOW CREATE TABLE v
-- !query analysis
ShowCreateTableCommand `spark_catalog`.`default`.`v`, [createtab_stmt#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 BIGINT NOT NULL) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x])
      +- Project [cast(c1#xL as int) AS c1#x]
         +- Project [c1#xL]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#xL] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
SET spark.sql.legacy.viewSchemaBindingMode = true
-- !query analysis
SetCommand (spark.sql.legacy.viewSchemaBindingMode,Some(true))


-- !query
SET spark.sql.legacy.viewSchemaCompensation = false
-- !query analysis
SetCommand (spark.sql.legacy.viewSchemaCompensation,Some(false))


-- !query
SET spark.sql.ansi.enabled = false
-- !query analysis
SetCommand (spark.sql.ansi.enabled,Some(false))


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT NOT NULL) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
CREATE OR REPLACE VIEW v AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, true, PersistedView, BINDING, true
   +- Project [c1#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x])
      +- Project [cast(c1#x as int) AS c1#x]
         +- Project [c1#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
SHOW CREATE TABLE v
-- !query analysis
ShowCreateTableCommand `spark_catalog`.`default`.`v`, [createtab_stmt#x]


-- !query
DROP TABLE t
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 BIGINT NOT NULL) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES (1)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1]
+- Project [cast(col1#x as bigint) AS c1#xL]
   +- LocalRelation [col1#x]


-- !query
SELECT * FROM v
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "CANNOT_UP_CAST_DATATYPE",
  "sqlState" : "42846",
  "messageParameters" : {
    "details" : "The type path of the target object is:\n\nYou can either add an explicit cast to the input data or choose a higher precision type of the field in the target object",
    "expression" : "spark_catalog.default.t.c1",
    "sourceType" : "\"BIGINT\"",
    "targetType" : "\"INT\""
  }
}


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
SHOW CREATE TABLE v
-- !query analysis
ShowCreateTableCommand `spark_catalog`.`default`.`v`, [createtab_stmt#x]


-- !query
SET spark.sql.legacy.viewSchemaCompensation = true
-- !query analysis
SetCommand (spark.sql.legacy.viewSchemaCompensation,Some(true))


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT NOT NULL) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
CREATE OR REPLACE VIEW v AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, true, PersistedView, COMPENSATION, true
   +- Project [c1#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x])
      +- Project [cast(c1#x as int) AS c1#x]
         +- Project [c1#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
SHOW CREATE TABLE v
-- !query analysis
ShowCreateTableCommand `spark_catalog`.`default`.`v`, [createtab_stmt#x]


-- !query
DROP TABLE t
-- !query analysis
DropTable false, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 BIGINT NOT NULL) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES (1)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1]
+- Project [cast(col1#x as bigint) AS c1#xL]
   +- LocalRelation [col1#x]


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x])
      +- Project [cast(c1#xL as int) AS c1#x]
         +- Project [c1#xL]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#xL] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
SHOW CREATE TABLE v
-- !query analysis
ShowCreateTableCommand `spark_catalog`.`default`.`v`, [createtab_stmt#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 STRING NOT NULL, c2 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES ('1', 2)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2]
+- Project [cast(col1#x as string) AS c1#x, cast(col2#x as int) AS c2#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x])
      +- Project [cast(c1#x as int) AS c1#x]
         +- Project [c1#x, c2#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
INSERT INTO t VALUES ('a', 2)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2]
+- Project [cast(col1#x as string) AS c1#x, cast(col2#x as int) AS c2#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x])
      +- Project [cast(c1#x as int) AS c1#x]
         +- Project [c1#x, c2#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 MAP<STRING, STRING>, c2 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.CAST_WITHOUT_SUGGESTION",
  "sqlState" : "42K09",
  "messageParameters" : {
    "sqlExpr" : "\"c1\"",
    "srcType" : "\"MAP<STRING, STRING>\"",
    "targetType" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 15,
    "fragment" : "v"
  } ]
}


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT, c2 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
INSERT INTO t VALUES (1, 2)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/t], Append, `spark_catalog`.`default`.`t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/t), [c1, c2]
+- Project [cast(col1#x as int) AS c1#x, cast(col2#x as int) AS c2#x]
   +- LocalRelation [col1#x, col2#x]


-- !query
CREATE OR REPLACE VIEW v AS SELECT * FROM t
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT * FROM t, false, true, PersistedView, COMPENSATION, true
   +- Project [c1#x, c2#x]
      +- SubqueryAlias spark_catalog.default.t
         +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
SELECT * FROM v
-- !query analysis
Project [c1#x, c2#x]
+- SubqueryAlias spark_catalog.default.v
   +- View (`spark_catalog`.`default`.`v`, [c1#x, c2#x])
      +- Project [cast(c1#x as int) AS c1#x, cast(c2#x as int) AS c2#x]
         +- Project [c1#x, c2#x]
            +- SubqueryAlias spark_catalog.default.t
               +- Relation spark_catalog.default.t[c1#x,c2#x] parquet


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c1 INT NOT NULL) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INCOMPATIBLE_VIEW_SCHEMA_CHANGE",
  "sqlState" : "51024",
  "messageParameters" : {
    "actualCols" : "[]",
    "colName" : "c2",
    "expectedNum" : "1",
    "suggestion" : "CREATE OR REPLACE VIEW spark_catalog.default.v AS SELECT * FROM t",
    "viewName" : "`spark_catalog`.`default`.`v`"
  }
}


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(c3 INT NOT NULL, c2 INT) USING PARQUET
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT * FROM v
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INCOMPATIBLE_VIEW_SCHEMA_CHANGE",
  "sqlState" : "51024",
  "messageParameters" : {
    "actualCols" : "[]",
    "colName" : "c1",
    "expectedNum" : "1",
    "suggestion" : "CREATE OR REPLACE VIEW spark_catalog.default.v AS SELECT * FROM t",
    "viewName" : "`spark_catalog`.`default`.`v`"
  }
}


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
SET spark.sql.legacy.viewSchemaBindingMode = false
-- !query analysis
SetCommand (spark.sql.legacy.viewSchemaBindingMode,Some(false))


-- !query
SET spark.sql.legacy.viewSchemaCompensation = false
-- !query analysis
SetCommand (spark.sql.legacy.viewSchemaCompensation,Some(false))


-- !query
CREATE OR REPLACE VIEW v AS SELECT 1
-- !query analysis
CreateViewCommand `spark_catalog`.`default`.`v`, SELECT 1, false, true, PersistedView, UNSUPPORTED, true
   +- Project [1 AS 1#x]
      +- OneRowRelation


-- !query
SET spark.sql.legacy.viewSchemaBindingMode = true
-- !query analysis
SetCommand (spark.sql.legacy.viewSchemaBindingMode,Some(true))


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
SHOW TABLE EXTENDED LIKE 'v'
-- !query analysis
ShowTablesCommand default, v, [namespace#x, tableName#x, isTemporary#x, information#x], true


-- !query
SHOW CREATE TABLE v
-- !query analysis
ShowCreateTableCommand `spark_catalog`.`default`.`v`, [createtab_stmt#x]


-- !query
SET spark.sql.legacy.viewSchemaCompensation = true
-- !query analysis
SetCommand (spark.sql.legacy.viewSchemaCompensation,Some(true))


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `spark_catalog`.`default`.`v`, true, [col_name#x, data_type#x, comment#x]


-- !query
SHOW TABLE EXTENDED LIKE 'v'
-- !query analysis
ShowTablesCommand default, v, [namespace#x, tableName#x, isTemporary#x, information#x], true


-- !query
SHOW CREATE TABLE v
-- !query analysis
ShowCreateTableCommand `spark_catalog`.`default`.`v`, [createtab_stmt#x]


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, true, true, false


-- !query
SET spark.sql.legacy.viewSchemaBindingMode = false
-- !query analysis
SetCommand (spark.sql.legacy.viewSchemaBindingMode,Some(false))


-- !query
SET spark.sql.legacy.viewSchemaCompensation = false
-- !query analysis
SetCommand (spark.sql.legacy.viewSchemaCompensation,Some(false))


-- !query
CREATE OR REPLACE TEMPORARY VIEW v AS SELECT 1
-- !query analysis
CreateViewCommand `v`, SELECT 1, false, true, LocalTempView, UNSUPPORTED, true
   +- Project [1 AS 1#x]
      +- OneRowRelation


-- !query
SET spark.sql.legacy.viewSchemaBindingMode = true
-- !query analysis
SetCommand (spark.sql.legacy.viewSchemaBindingMode,Some(true))


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `v`, true, [col_name#x, data_type#x, comment#x]


-- !query
SHOW TABLE EXTENDED LIKE 'v'
-- !query analysis
ShowTablesCommand default, v, [namespace#x, tableName#x, isTemporary#x, information#x], true


-- !query
SET spark.sql.legacy.viewSchemaCompensation = true
-- !query analysis
SetCommand (spark.sql.legacy.viewSchemaCompensation,Some(true))


-- !query
DESCRIBE EXTENDED v
-- !query analysis
DescribeTableCommand `v`, true, [col_name#x, data_type#x, comment#x]


-- !query
SHOW TABLE EXTENDED LIKE 'v'
-- !query analysis
ShowTablesCommand default, v, [namespace#x, tableName#x, isTemporary#x, information#x], true


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTempViewCommand v


-- !query
DROP VIEW IF EXISTS v
-- !query analysis
DropTableCommand `spark_catalog`.`default`.`v`, true, true, false


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t
