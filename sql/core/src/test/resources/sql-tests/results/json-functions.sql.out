-- Automatically generated by SQLQueryTestSuite
-- !query
select to_json(named_struct('a', 1, 'b', 2))
-- !query schema
struct<to_json(named_struct(a, 1, b, 2)):string>
-- !query output
{"a":1,"b":2}


-- !query
select to_json(named_struct('time', to_timestamp('2015-08-26', 'yyyy-MM-dd')), map('timestampFormat', 'dd/MM/yyyy'))
-- !query schema
struct<to_json(named_struct(time, to_timestamp(2015-08-26, yyyy-MM-dd))):string>
-- !query output
{"time":"26/08/2015"}


-- !query
select to_json(array(named_struct('a', 1, 'b', 2)))
-- !query schema
struct<to_json(array(named_struct(a, 1, b, 2))):string>
-- !query output
[{"a":1,"b":2}]


-- !query
select to_json(map(named_struct('a', 1, 'b', 2), named_struct('a', 1, 'b', 2)))
-- !query schema
struct<to_json(map(named_struct(a, 1, b, 2), named_struct(a, 1, b, 2))):string>
-- !query output
{"[1,2]":{"a":1,"b":2}}


-- !query
select to_json(map('a', named_struct('a', 1, 'b', 2)))
-- !query schema
struct<to_json(map(a, named_struct(a, 1, b, 2))):string>
-- !query output
{"a":{"a":1,"b":2}}


-- !query
select to_json(map('a', 1))
-- !query schema
struct<to_json(map(a, 1)):string>
-- !query output
{"a":1}


-- !query
select to_json(array(map('a',1)))
-- !query schema
struct<to_json(array(map(a, 1))):string>
-- !query output
[{"a":1}]


-- !query
select to_json(array(map('a',1), map('b',2)))
-- !query schema
struct<to_json(array(map(a, 1), map(b, 2))):string>
-- !query output
[{"a":1},{"b":2}]


-- !query
select to_json(named_struct('a', 1, 'b', 2), named_struct('mode', 'PERMISSIVE'))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_OPTIONS.NON_MAP_FUNCTION",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 80,
    "fragment" : "to_json(named_struct('a', 1, 'b', 2), named_struct('mode', 'PERMISSIVE'))"
  } ]
}


-- !query
select to_json(named_struct('a', 1, 'b', 2), map('mode', 1))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_OPTIONS.NON_STRING_TYPE",
  "messageParameters" : {
    "mapType" : "\"MAP<STRING, INT>\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 60,
    "fragment" : "to_json(named_struct('a', 1, 'b', 2), map('mode', 1))"
  } ]
}


-- !query
select to_json()
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITH_SUGGESTION",
  "messageParameters" : {
    "actualNum" : "0",
    "expectedNum" : "[1, 2]",
    "functionName" : "`to_json`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 16,
    "fragment" : "to_json()"
  } ]
}


-- !query
select from_json('{"a":1}', 'a INT')
-- !query schema
struct<from_json({"a":1}):struct<a:int>>
-- !query output
{"a":1}


-- !query
select from_json('{"time":"26/08/2015"}', 'time Timestamp', map('timestampFormat', 'dd/MM/yyyy'))
-- !query schema
struct<from_json({"time":"26/08/2015"}):struct<time:timestamp>>
-- !query output
{"time":2015-08-26 00:00:00}


-- !query
select from_json('{"a":1}', 1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_SCHEMA.NON_STRING_LITERAL",
  "messageParameters" : {
    "inputSchema" : "\"1\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "from_json('{\"a\":1}', 1)"
  } ]
}


-- !query
select from_json('{"a":1}', 'a InvalidType')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42000",
  "messageParameters" : {
    "error" : "'InvalidType'",
    "hint" : ": extra input 'InvalidType'"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 44,
    "fragment" : "from_json('{\"a\":1}', 'a InvalidType')"
  } ]
}


-- !query
select from_json('{"a":1}', 'a INT', named_struct('mode', 'PERMISSIVE'))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_OPTIONS.NON_MAP_FUNCTION",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 72,
    "fragment" : "from_json('{\"a\":1}', 'a INT', named_struct('mode', 'PERMISSIVE'))"
  } ]
}


-- !query
select from_json('{"a":1}', 'a INT', map('mode', 1))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_OPTIONS.NON_STRING_TYPE",
  "messageParameters" : {
    "mapType" : "\"MAP<STRING, INT>\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 52,
    "fragment" : "from_json('{\"a\":1}', 'a INT', map('mode', 1))"
  } ]
}


-- !query
select from_json()
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITH_SUGGESTION",
  "messageParameters" : {
    "actualNum" : "0",
    "expectedNum" : "[2, 3]",
    "functionName" : "`from_json`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 18,
    "fragment" : "from_json()"
  } ]
}


-- !query
SELECT json_tuple('{"a" : 1, "b" : 2}', CAST(NULL AS STRING), 'b', CAST(NULL AS STRING), 'a')
-- !query schema
struct<c0:string,c1:string,c2:string,c3:string>
-- !query output
NULL	2	NULL	1


-- !query
CREATE TEMPORARY VIEW jsonTable(jsonField, a) AS SELECT * FROM VALUES ('{"a": 1, "b": 2}', 'a')
-- !query schema
struct<>
-- !query output



-- !query
SELECT json_tuple(jsonField, 'b', CAST(NULL AS STRING), a) FROM jsonTable
-- !query schema
struct<c0:string,c1:string,c2:string>
-- !query output
2	NULL	1


-- !query
SELECT json_tuple('{"a":"1"}', if(c1 < 1, null, 'a')) FROM ( SELECT rand() AS c1 )
-- !query schema
struct<c0:string>
-- !query output
NULL


-- !query
SELECT json_tuple('{"a":"1"}', if(c1 < 1, null, 'a'), if(c2 < 1, null, 'a')) FROM ( SELECT 0 AS c1, rand() AS c2 )
-- !query schema
struct<c0:string,c1:string>
-- !query output
NULL	NULL


-- !query
DROP VIEW IF EXISTS jsonTable
-- !query schema
struct<>
-- !query output



-- !query
select from_json('{"a":1, "b":2}', 'map<string, int>')
-- !query schema
struct<entries:map<string,int>>
-- !query output
{"a":1,"b":2}


-- !query
select from_json('{"a":1, "b":"2"}', 'struct<a:int,b:string>')
-- !query schema
struct<from_json({"a":1, "b":"2"}):struct<a:int,b:string>>
-- !query output
{"a":1,"b":"2"}


-- !query
select schema_of_json('{"c1":0, "c2":[1]}')
-- !query schema
struct<schema_of_json({"c1":0, "c2":[1]}):string>
-- !query output
STRUCT<c1: BIGINT, c2: ARRAY<BIGINT>>


-- !query
select from_json('{"c1":[1, 2, 3]}', schema_of_json('{"c1":[0]}'))
-- !query schema
struct<from_json({"c1":[1, 2, 3]}):struct<c1:array<bigint>>>
-- !query output
{"c1":[1,2,3]}


-- !query
select from_json('[1, 2, 3]', 'array<int>')
-- !query schema
struct<from_json([1, 2, 3]):array<int>>
-- !query output
[1,2,3]


-- !query
select from_json('[1, "2", 3]', 'array<int>')
-- !query schema
struct<from_json([1, "2", 3]):array<int>>
-- !query output
NULL


-- !query
select from_json('[1, 2, null]', 'array<int>')
-- !query schema
struct<from_json([1, 2, null]):array<int>>
-- !query output
[1,2,null]


-- !query
select from_json('[{"a": 1}, {"a":2}]', 'array<struct<a:int>>')
-- !query schema
struct<from_json([{"a": 1}, {"a":2}]):array<struct<a:int>>>
-- !query output
[{"a":1},{"a":2}]


-- !query
select from_json('{"a": 1}', 'array<struct<a:int>>')
-- !query schema
struct<from_json({"a": 1}):array<struct<a:int>>>
-- !query output
[{"a":1}]


-- !query
select from_json('[null, {"a":2}]', 'array<struct<a:int>>')
-- !query schema
struct<from_json([null, {"a":2}]):array<struct<a:int>>>
-- !query output
[null,{"a":2}]


-- !query
select from_json('[{"a": 1}, {"b":2}]', 'array<map<string,int>>')
-- !query schema
struct<from_json([{"a": 1}, {"b":2}]):array<map<string,int>>>
-- !query output
[{"a":1},{"b":2}]


-- !query
select from_json('[{"a": 1}, 2]', 'array<map<string,int>>')
-- !query schema
struct<from_json([{"a": 1}, 2]):array<map<string,int>>>
-- !query output
NULL


-- !query
select from_json('{"d": "2012-12-15", "t": "2012-12-15 15:15:15"}', 'd date, t timestamp')
-- !query schema
struct<from_json({"d": "2012-12-15", "t": "2012-12-15 15:15:15"}):struct<d:date,t:timestamp>>
-- !query output
{"d":2012-12-15,"t":2012-12-15 15:15:15}


-- !query
select from_json(
  '{"d": "12/15 2012", "t": "12/15 2012 15:15:15"}',
  'd date, t timestamp',
  map('dateFormat', 'MM/dd yyyy', 'timestampFormat', 'MM/dd yyyy HH:mm:ss'))
-- !query schema
struct<from_json({"d": "12/15 2012", "t": "12/15 2012 15:15:15"}):struct<d:date,t:timestamp>>
-- !query output
{"d":2012-12-15,"t":2012-12-15 15:15:15}


-- !query
select from_json(
  '{"d": "02-29"}',
  'd date',
  map('dateFormat', 'MM-dd'))
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUpgradeException
{
  "errorClass" : "INCONSISTENT_BEHAVIOR_CROSS_VERSION.PARSE_DATETIME_BY_NEW_PARSER",
  "messageParameters" : {
    "config" : "\"spark.sql.legacy.timeParserPolicy\"",
    "datetime" : "'02-29'"
  }
}


-- !query
select from_json(
  '{"t": "02-29"}',
  't timestamp',
  map('timestampFormat', 'MM-dd'))
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUpgradeException
{
  "errorClass" : "INCONSISTENT_BEHAVIOR_CROSS_VERSION.PARSE_DATETIME_BY_NEW_PARSER",
  "messageParameters" : {
    "config" : "\"spark.sql.legacy.timeParserPolicy\"",
    "datetime" : "'02-29'"
  }
}


-- !query
select to_json(array('1', '2', '3'))
-- !query schema
struct<to_json(array(1, 2, 3)):string>
-- !query output
["1","2","3"]


-- !query
select to_json(array(array(1, 2, 3), array(4)))
-- !query schema
struct<to_json(array(array(1, 2, 3), array(4))):string>
-- !query output
[[1,2,3],[4]]


-- !query
select schema_of_json('{"c1":1}', map('primitivesAsString', 'true'))
-- !query schema
struct<schema_of_json({"c1":1}):string>
-- !query output
STRUCT<c1: STRING>


-- !query
select schema_of_json('{"c1":01, "c2":0.1}', map('allowNumericLeadingZeros', 'true', 'prefersDecimal', 'true'))
-- !query schema
struct<schema_of_json({"c1":01, "c2":0.1}):string>
-- !query output
STRUCT<c1: BIGINT, c2: DECIMAL(1,1)>


-- !query
select schema_of_json(null)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_NULL",
  "messageParameters" : {
    "exprName" : "json",
    "sqlExpr" : "\"schema_of_json(NULL)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 27,
    "fragment" : "schema_of_json(null)"
  } ]
}


-- !query
CREATE TEMPORARY VIEW jsonTable(jsonField, a) AS SELECT * FROM VALUES ('{"a": 1, "b": 2}', 'a')
-- !query schema
struct<>
-- !query output



-- !query
SELECT schema_of_json(jsonField) FROM jsonTable
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.NON_FOLDABLE_INPUT",
  "messageParameters" : {
    "inputExpr" : "\"jsonField\"",
    "inputName" : "json",
    "inputType" : "\"STRING\"",
    "sqlExpr" : "\"schema_of_json(jsonField)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 32,
    "fragment" : "schema_of_json(jsonField)"
  } ]
}


-- !query
select json_array_length(null)
-- !query schema
struct<json_array_length(NULL):int>
-- !query output
NULL


-- !query
select json_array_length(2)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "messageParameters" : {
    "inputSql" : "\"2\"",
    "inputType" : "\"INT\"",
    "paramIndex" : "1",
    "requiredType" : "\"STRING\"",
    "sqlExpr" : "\"json_array_length(2)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 27,
    "fragment" : "json_array_length(2)"
  } ]
}


-- !query
select json_array_length()
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITH_SUGGESTION",
  "messageParameters" : {
    "actualNum" : "0",
    "expectedNum" : "1",
    "functionName" : "`json_array_length`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 26,
    "fragment" : "json_array_length()"
  } ]
}


-- !query
select json_array_length('')
-- !query schema
struct<json_array_length():int>
-- !query output
NULL


-- !query
select json_array_length('[]')
-- !query schema
struct<json_array_length([]):int>
-- !query output
0


-- !query
select json_array_length('[1,2,3]')
-- !query schema
struct<json_array_length([1,2,3]):int>
-- !query output
3


-- !query
select json_array_length('[[1,2],[5,6,7]]')
-- !query schema
struct<json_array_length([[1,2],[5,6,7]]):int>
-- !query output
2


-- !query
select json_array_length('[{"a":123},{"b":"hello"}]')
-- !query schema
struct<json_array_length([{"a":123},{"b":"hello"}]):int>
-- !query output
2


-- !query
select json_array_length('[1,2,3,[33,44],{"key":[2,3,4]}]')
-- !query schema
struct<json_array_length([1,2,3,[33,44],{"key":[2,3,4]}]):int>
-- !query output
5


-- !query
select json_array_length('{"key":"not a json array"}')
-- !query schema
struct<json_array_length({"key":"not a json array"}):int>
-- !query output
NULL


-- !query
select json_array_length('[1,2,3,4,5')
-- !query schema
struct<json_array_length([1,2,3,4,5):int>
-- !query output
NULL


-- !query
select json_object_keys()
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITH_SUGGESTION",
  "messageParameters" : {
    "actualNum" : "0",
    "expectedNum" : "1",
    "functionName" : "`json_object_keys`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "json_object_keys()"
  } ]
}


-- !query
select json_object_keys(null)
-- !query schema
struct<json_object_keys(NULL):array<string>>
-- !query output
NULL


-- !query
select json_object_keys(200)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "messageParameters" : {
    "inputSql" : "\"200\"",
    "inputType" : "\"INT\"",
    "paramIndex" : "1",
    "requiredType" : "\"STRING\"",
    "sqlExpr" : "\"json_object_keys(200)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 28,
    "fragment" : "json_object_keys(200)"
  } ]
}


-- !query
select json_object_keys('')
-- !query schema
struct<json_object_keys():array<string>>
-- !query output
NULL


-- !query
select json_object_keys('{}')
-- !query schema
struct<json_object_keys({}):array<string>>
-- !query output
[]


-- !query
select json_object_keys('{"key": 1}')
-- !query schema
struct<json_object_keys({"key": 1}):array<string>>
-- !query output
["key"]


-- !query
select json_object_keys('{"key": "value", "key2": 2}')
-- !query schema
struct<json_object_keys({"key": "value", "key2": 2}):array<string>>
-- !query output
["key","key2"]


-- !query
select json_object_keys('{"arrayKey": [1, 2, 3]}')
-- !query schema
struct<json_object_keys({"arrayKey": [1, 2, 3]}):array<string>>
-- !query output
["arrayKey"]


-- !query
select json_object_keys('{"key":[1,2,3,{"key":"value"},[1,2,3]]}')
-- !query schema
struct<json_object_keys({"key":[1,2,3,{"key":"value"},[1,2,3]]}):array<string>>
-- !query output
["key"]


-- !query
select json_object_keys('{"f1":"abc","f2":{"f3":"a", "f4":"b"}}')
-- !query schema
struct<json_object_keys({"f1":"abc","f2":{"f3":"a", "f4":"b"}}):array<string>>
-- !query output
["f1","f2"]


-- !query
select json_object_keys('{"k1": [1, 2, {"key": 5}], "k2": {"key2": [1, 2]}}')
-- !query schema
struct<json_object_keys({"k1": [1, 2, {"key": 5}], "k2": {"key2": [1, 2]}}):array<string>>
-- !query output
["k1","k2"]


-- !query
select json_object_keys('{[1,2]}')
-- !query schema
struct<json_object_keys({[1,2]}):array<string>>
-- !query output
NULL


-- !query
select json_object_keys('{"key": 45, "random_string"}')
-- !query schema
struct<json_object_keys({"key": 45, "random_string"}):array<string>>
-- !query output
NULL


-- !query
select json_object_keys('[1, 2, 3]')
-- !query schema
struct<json_object_keys([1, 2, 3]):array<string>>
-- !query output
NULL


-- !query
DROP VIEW IF EXISTS jsonTable
-- !query schema
struct<>
-- !query output

