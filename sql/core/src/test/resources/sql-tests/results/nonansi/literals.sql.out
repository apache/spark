-- Automatically generated by SQLQueryTestSuite
-- !query
select null, Null, nUll
-- !query schema
struct<NULL:void,NULL:void,NULL:void>
-- !query output
NULL	NULL	NULL


-- !query
select true, tRue, false, fALse
-- !query schema
struct<true:boolean,true:boolean,false:boolean,false:boolean>
-- !query output
true	true	false	false


-- !query
select 1Y
-- !query schema
struct<1:tinyint>
-- !query output
1


-- !query
select 127Y, -128Y
-- !query schema
struct<127:tinyint,-128:tinyint>
-- !query output
127	-128


-- !query
select 128Y
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_NUMERIC_LITERAL_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxValue" : "127",
    "minValue" : "-128",
    "rawStrippedQualifier" : "128",
    "typeName" : "tinyint"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 11,
    "fragment" : "128Y"
  } ]
}


-- !query
select 1S
-- !query schema
struct<1:smallint>
-- !query output
1


-- !query
select 32767S, -32768S
-- !query schema
struct<32767:smallint,-32768:smallint>
-- !query output
32767	-32768


-- !query
select 32768S
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_NUMERIC_LITERAL_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxValue" : "32767",
    "minValue" : "-32768",
    "rawStrippedQualifier" : "32768",
    "typeName" : "smallint"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 13,
    "fragment" : "32768S"
  } ]
}


-- !query
select 1L, 2147483648L
-- !query schema
struct<1:bigint,2147483648:bigint>
-- !query output
1	2147483648


-- !query
select 9223372036854775807L, -9223372036854775808L
-- !query schema
struct<9223372036854775807:bigint,-9223372036854775808:bigint>
-- !query output
9223372036854775807	-9223372036854775808


-- !query
select 9223372036854775808L
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_NUMERIC_LITERAL_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxValue" : "9223372036854775807",
    "minValue" : "-9223372036854775808",
    "rawStrippedQualifier" : "9223372036854775808",
    "typeName" : "bigint"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 27,
    "fragment" : "9223372036854775808L"
  } ]
}


-- !query
select 1, -1
-- !query schema
struct<1:int,-1:int>
-- !query output
1	-1


-- !query
select 2147483647, -2147483648
-- !query schema
struct<2147483647:int,-2147483648:int>
-- !query output
2147483647	-2147483648


-- !query
select 9223372036854775807, -9223372036854775808
-- !query schema
struct<9223372036854775807:bigint,-9223372036854775808:bigint>
-- !query output
9223372036854775807	-9223372036854775808


-- !query
select 9223372036854775808, -9223372036854775809
-- !query schema
struct<9223372036854775808:decimal(19,0),-9223372036854775809:decimal(19,0)>
-- !query output
9223372036854775808	-9223372036854775809


-- !query
select 1234567890123456789012345678901234567890
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "DECIMAL_PRECISION_EXCEEDS_MAX_PRECISION",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxPrecision" : "38",
    "precision" : "40"
  }
}


-- !query
select 1234567890123456789012345678901234567890.0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "DECIMAL_PRECISION_EXCEEDS_MAX_PRECISION",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxPrecision" : "38",
    "precision" : "41"
  }
}


-- !query
select 1F, 1.2F, .10f, 0.10f
-- !query schema
struct<1.0:float,1.2:float,0.1:float,0.1:float>
-- !query output
1.0	1.2	0.1	0.1


-- !query
select -1F, -1.2F, -.10F, -0.10F
-- !query schema
struct<-1.0:float,-1.2:float,-0.1:float,-0.1:float>
-- !query output
-1.0	-1.2	-0.1	-0.1


-- !query
select -3.4028235E39f
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_NUMERIC_LITERAL_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxValue" : "3.4028234663852886E+38",
    "minValue" : "-3.4028234663852886E+38",
    "rawStrippedQualifier" : "-3.4028235E39",
    "typeName" : "float"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 21,
    "fragment" : "-3.4028235E39f"
  } ]
}


-- !query
select 1D, 1.2D, 1e10, 1.5e5, .10D, 0.10D, .1e5, .9e+2, 0.9e+2, 900e-1, 9.e+1
-- !query schema
struct<1.0:double,1.2:double,1.0E10:double,150000.0:double,0.1:double,0.1:double,10000.0:double,90.0:double,90.0:double,90.0:double,90.0:double>
-- !query output
1.0	1.2	1.0E10	150000.0	0.1	0.1	10000.0	90.0	90.0	90.0	90.0


-- !query
select -1D, -1.2D, -1e10, -1.5e5, -.10D, -0.10D, -.1e5
-- !query schema
struct<-1.0:double,-1.2:double,-1.0E10:double,-150000.0:double,-0.1:double,-0.1:double,-10000.0:double>
-- !query output
-1.0	-1.2	-1.0E10	-150000.0	-0.1	-0.1	-10000.0


-- !query
select .e3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'.'",
    "hint" : ""
  }
}


-- !query
select 1E309, -1E309
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_NUMERIC_LITERAL_RANGE",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxValue" : "1.7976931348623157E+308",
    "minValue" : "-1.7976931348623157E+308",
    "rawStrippedQualifier" : "1E309",
    "typeName" : "double"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 12,
    "fragment" : "1E309"
  } ]
}


-- !query
select 0.3, -0.8, .5, -.18, 0.1111, .1111
-- !query schema
struct<0.3:decimal(1,1),-0.8:decimal(1,1),0.5:decimal(1,1),-0.18:decimal(2,2),0.1111:decimal(4,4),0.1111:decimal(4,4)>
-- !query output
0.3	-0.8	0.5	-0.18	0.1111	0.1111


-- !query
select 0.3 F, 0.4 D, 0.5 BD
-- !query schema
struct<F:decimal(1,1),D:decimal(1,1),BD:decimal(1,1)>
-- !query output
0.3	0.4	0.5


-- !query
select 123456789012345678901234567890123456789e10d, 123456789012345678901234567890123456789.1e10d
-- !query schema
struct<1.2345678901234568E48:double,1.2345678901234568E48:double>
-- !query output
1.2345678901234568E48	1.2345678901234568E48


-- !query
select "Hello Peter!", 'hello lee!'
-- !query schema
struct<Hello Peter!:string,hello lee!:string>
-- !query output
Hello Peter!	hello lee!


-- !query
select 'hello' 'world', 'hello' " " 'lee'
-- !query schema
struct<helloworld:string,hello lee:string>
-- !query output
helloworld	hello lee


-- !query
select "hello 'peter'"
-- !query schema
struct<hello 'peter':string>
-- !query output
hello 'peter'


-- !query
select 'pattern%', 'no-pattern\%', 'pattern\\%', 'pattern\\\%'
-- !query schema
struct<pattern%:string,no-pattern\%:string,pattern\%:string,pattern\\%:string>
-- !query output
pattern%	no-pattern\%	pattern\%	pattern\\%


-- !query
select '\'', '"', '\n', '\r', '\t', 'Z'
-- !query schema
struct<':string,":string,
:string,:string,	:string,Z:string>
-- !query output
'	"	
				Z


-- !query
select '\110\145\154\154\157\041'
-- !query schema
struct<Hello!:string>
-- !query output
Hello!


-- !query
select '\u0057\u006F\u0072\u006C\u0064\u0020\u003A\u0029'
-- !query schema
struct<World :):string>
-- !query output
World :)


-- !query
select dAte '2016-03-12'
-- !query schema
struct<DATE '2016-03-12':date>
-- !query output
2016-03-12


-- !query
select date 'mar 11 2016'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'mar 11 2016'",
    "valueType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "date 'mar 11 2016'"
  } ]
}


-- !query
select tImEstAmp '2016-03-11 20:54:00.000'
-- !query schema
struct<TIMESTAMP '2016-03-11 20:54:00':timestamp>
-- !query output
2016-03-11 20:54:00


-- !query
select timestamp '2016-33-11 20:54:00.000'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'2016-33-11 20:54:00.000'",
    "valueType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 42,
    "fragment" : "timestamp '2016-33-11 20:54:00.000'"
  } ]
}


-- !query
select GEO '(10,-6)'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "UNSUPPORTED_TYPED_LITERAL",
  "sqlState" : "0A000",
  "messageParameters" : {
    "supportedTypes" : "\"DATE\", \"TIMESTAMP_NTZ\", \"TIMESTAMP_LTZ\", \"TIMESTAMP\", \"INTERVAL\", \"X\"",
    "unsupportedType" : "\"GEO\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 20,
    "fragment" : "GEO '(10,-6)'"
  } ]
}


-- !query
select 90912830918230182310293801923652346786BD, 123.0E-28BD, 123.08BD
-- !query schema
struct<90912830918230182310293801923652346786:decimal(38,0),1.230E-26:decimal(29,29),123.08:decimal(5,2)>
-- !query output
90912830918230182310293801923652346786	0.00000000000000000000000001230	123.08


-- !query
select 1.20E-38BD
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "DECIMAL_PRECISION_EXCEEDS_MAX_PRECISION",
  "sqlState" : "22003",
  "messageParameters" : {
    "maxPrecision" : "38",
    "precision" : "40"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 17,
    "fragment" : "1.20E-38BD"
  } ]
}


-- !query
select x'2379ACFe'
-- !query schema
struct<X'2379ACFE':binary>
-- !query output
#y��


-- !query
select X'XuZ'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'XuZ'",
    "valueType" : "\"X\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 13,
    "fragment" : "X'XuZ'"
  } ]
}


-- !query
SELECT 3.14, -3.14, 3.14e8, 3.14e-8, -3.14e8, -3.14e-8, 3.14e+8, 3.14E8, 3.14E-8
-- !query schema
struct<3.14:decimal(3,2),-3.14:decimal(3,2),3.14E8:double,3.14E-8:double,-3.14E8:double,-3.14E-8:double,3.14E8:double,3.14E8:double,3.14E-8:double>
-- !query output
3.14	-3.14	3.14E8	3.14E-8	-3.14E8	-3.14E-8	3.14E8	3.14E8	3.14E-8


-- !query
select +date '1999-01-01'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"DATE '1999-01-01'\"",
    "inputType" : "\"DATE\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ DATE '1999-01-01')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "+date '1999-01-01'"
  } ]
}


-- !query
select +timestamp '1999-01-01'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"TIMESTAMP '1999-01-01 00:00:00'\"",
    "inputType" : "\"TIMESTAMP\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ TIMESTAMP '1999-01-01 00:00:00')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "+timestamp '1999-01-01'"
  } ]
}


-- !query
select +interval '1 day'
-- !query schema
struct<(+ INTERVAL '1' DAY):interval day>
-- !query output
1 00:00:00.000000000


-- !query
select +map(1, 2)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"map(1, 2)\"",
    "inputType" : "\"MAP<INT, INT>\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ map(1, 2))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 17,
    "fragment" : "+map(1, 2)"
  } ]
}


-- !query
select +array(1,2)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"array(1, 2)\"",
    "inputType" : "\"ARRAY<INT>\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ array(1, 2))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 18,
    "fragment" : "+array(1,2)"
  } ]
}


-- !query
select +named_struct('a', 1, 'b', 'spark')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"named_struct(a, 1, b, spark)\"",
    "inputType" : "\"STRUCT<a: INT NOT NULL, b: STRING NOT NULL>\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ named_struct(a, 1, b, spark))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 42,
    "fragment" : "+named_struct('a', 1, 'b', 'spark')"
  } ]
}


-- !query
select +X'1'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"X'01'\"",
    "inputType" : "\"BINARY\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ X'01')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 12,
    "fragment" : "+X'1'"
  } ]
}


-- !query
select -date '1999-01-01'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"DATE '1999-01-01'\"",
    "inputType" : "\"DATE\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(- DATE '1999-01-01')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "-date '1999-01-01'"
  } ]
}


-- !query
select -timestamp '1999-01-01'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"TIMESTAMP '1999-01-01 00:00:00'\"",
    "inputType" : "\"TIMESTAMP\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(- TIMESTAMP '1999-01-01 00:00:00')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "-timestamp '1999-01-01'"
  } ]
}


-- !query
select -x'2379ACFe'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"X'2379ACFE'\"",
    "inputType" : "\"BINARY\"",
    "paramIndex" : "first",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(- X'2379ACFE')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 19,
    "fragment" : "-x'2379ACFe'"
  } ]
}


-- !query
select -0, -0.0
-- !query schema
struct<0:int,0.0:decimal(1,1)>
-- !query output
0	0.0
