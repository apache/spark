-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TEMPORARY VIEW t AS SELECT 1.0 as a, 0.0 as b
-- !query schema
struct<>
-- !query output



-- !query
select a / b from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "DIVIDE_BY_ZERO",
  "sqlState" : "22012",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 12,
    "fragment" : "a / b"
  } ]
}


-- !query
select a % b from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "DIVIDE_BY_ZERO",
  "sqlState" : "22012",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 12,
    "fragment" : "a % b"
  } ]
}


-- !query
select pmod(a, b) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "DIVIDE_BY_ZERO",
  "sqlState" : "22012",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 17,
    "fragment" : "pmod(a, b)"
  } ]
}


-- !query
create table decimals_test(id int, a decimal(38,18), b decimal(38,18)) using parquet
-- !query schema
struct<>
-- !query output



-- !query
insert into decimals_test values(1, 100.0, 999.0), (2, 12345.123, 12345.123),
  (3, 0.1234567891011, 1234.1), (4, 123456789123456789.0, 1.123456789123456789)
-- !query schema
struct<>
-- !query output



-- !query
select id, a+b, a-b, a*b, a/b from decimals_test order by id
-- !query schema
struct<id:int,(a + b):decimal(38,17),(a - b):decimal(38,17),(a * b):decimal(38,6),(a / b):decimal(38,6)>
-- !query output
1	1099.00000000000000000	-899.00000000000000000	99900.000000	0.100100
2	24690.24600000000000000	0.00000000000000000	152402061.885129	1.000000
3	1234.22345678910110000	-1233.97654321089890000	152.358023	0.000100
4	123456789123456790.12345678912345679	123456789123456787.87654321087654321	138698367904130467.515623	109890109097814272.043109


-- !query
select id, a*10, b/10 from decimals_test order by id
-- !query schema
struct<id:int,(a * 10):decimal(38,15),(b / 10):decimal(38,18)>
-- !query output
1	1000.000000000000000	99.900000000000000000
2	123451.230000000000000	1234.512300000000000000
3	1.234567891011000	123.410000000000000000
4	1234567891234567890.000000000000000	0.112345678912345679


-- !query
select 10.3 * 3.0
-- !query schema
struct<(10.3 * 3.0):decimal(6,2)>
-- !query output
30.90


-- !query
select 10.3000 * 3.0
-- !query schema
struct<(10.3000 * 3.0):decimal(9,5)>
-- !query output
30.90000


-- !query
select 10.30000 * 30.0
-- !query schema
struct<(10.30000 * 30.0):decimal(11,6)>
-- !query output
309.000000


-- !query
select 10.300000000000000000 * 3.000000000000000000
-- !query schema
struct<(10.300000000000000000 * 3.000000000000000000):decimal(38,34)>
-- !query output
30.9000000000000000000000000000000000


-- !query
select 10.300000000000000000 * 3.0000000000000000000
-- !query schema
struct<(10.300000000000000000 * 3.0000000000000000000):decimal(38,34)>
-- !query output
30.9000000000000000000000000000000000


-- !query
select 2.35E10 * 1.0
-- !query schema
struct<(2.35E10 * 1.0):double>
-- !query output
2.35E10


-- !query
select (5e36BD + 0.1) + 5e36BD
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "1",
    "value" : "10000000000000000000000000000000000000.1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "(5e36BD + 0.1) + 5e36BD"
  } ]
}


-- !query
select (-4e36BD - 0.1) - 7e36BD
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "1",
    "value" : "-11000000000000000000000000000000000000.1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "(-4e36BD - 0.1) - 7e36BD"
  } ]
}


-- !query
select 12345678901234567890.0 * 12345678901234567890.0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "2",
    "value" : "152415787532388367501905199875019052100"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 54,
    "fragment" : "12345678901234567890.0 * 12345678901234567890.0"
  } ]
}


-- !query
select 1e35BD / 0.1
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "6",
    "value" : "1000000000000000000000000000000000000.000000000000000000000000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 19,
    "fragment" : "1e35BD / 0.1"
  } ]
}


-- !query
select 1.2345678901234567890E30BD * 1.2345678901234567890E25BD
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "0",
    "value" : "15241578753238836750190519987501905210000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 62,
    "fragment" : "1.2345678901234567890E30BD * 1.2345678901234567890E25BD"
  } ]
}


-- !query
select 12345678912345678912345678912.1234567 + 9999999999999999999999999999999.12345
-- !query schema
struct<(12345678912345678912345678912.1234567 + 9999999999999999999999999999999.12345):decimal(38,6)>
-- !query output
10012345678912345678912345678911.246907


-- !query
select 123456789123456789.1234567890 * 1.123456789123456789
-- !query schema
struct<(123456789123456789.1234567890 * 1.123456789123456789):decimal(38,18)>
-- !query output
138698367904130467.654320988515622621


-- !query
select 12345678912345.123456789123 / 0.000000012345678
-- !query schema
struct<(12345678912345.123456789123 / 1.2345678E-8):decimal(38,9)>
-- !query output
1000000073899961059796.725866332


-- !query
SELECT CAST(20 AS DECIMAL(4, 1))
UNION ALL
SELECT CAST(10 AS DECIMAL(3, 1)) + CAST(90 AS DECIMAL(3, 1))
-- !query schema
struct<CAST(20 AS DECIMAL(4,1)):decimal(4,1)>
-- !query output
100.0
20.0


-- !query
SELECT CAST(20 AS DECIMAL(4, 1))
UNION ALL
SELECT CAST(10 AS DECIMAL(3, 1)) - CAST(-90 AS DECIMAL(3, 1))
-- !query schema
struct<CAST(20 AS DECIMAL(4,1)):decimal(4,1)>
-- !query output
100.0
20.0


-- !query
SELECT CAST(20 AS DECIMAL(4, 1))
UNION ALL
SELECT CAST(10 AS DECIMAL(3, 1)) * CAST(10 AS DECIMAL(3, 1))
-- !query schema
struct<CAST(20 AS DECIMAL(4,1)):decimal(7,2)>
-- !query output
100.00
20.00


-- !query
SELECT CAST(20 AS DECIMAL(4, 1))
UNION ALL
SELECT CAST(10 AS DECIMAL(3, 1)) / CAST(10 AS DECIMAL(3, 1))
-- !query schema
struct<CAST(20 AS DECIMAL(4,1)):decimal(9,6)>
-- !query output
1.000000
20.000000


-- !query
SELECT CAST(20 AS DECIMAL(4, 1))
UNION ALL
SELECT CAST(10 AS DECIMAL(10, 2)) % CAST(3 AS DECIMAL(5, 1))
-- !query schema
struct<CAST(20 AS DECIMAL(4,1)):decimal(6,2)>
-- !query output
1.00
20.00


-- !query
SELECT CAST(20 AS DECIMAL(4, 1))
UNION ALL
SELECT pmod(CAST(10 AS DECIMAL(10, 2)), CAST(3 AS DECIMAL(5, 1)))
-- !query schema
struct<CAST(20 AS DECIMAL(4,1)):decimal(6,2)>
-- !query output
1.00
20.00


-- !query
SELECT CAST(20 AS DECIMAL(4, 1))
UNION ALL
SELECT CAST(10 AS DECIMAL(10, 2)) div CAST(3 AS DECIMAL(5, 1))
-- !query schema
struct<CAST(20 AS DECIMAL(4,1)):decimal(21,1)>
-- !query output
20.0
3.0


-- !query
set spark.sql.decimalOperations.allowPrecisionLoss=false
-- !query schema
struct<key:string,value:string>
-- !query output
spark.sql.decimalOperations.allowPrecisionLoss	false


-- !query
select /*+ COALESCE(1) */ id, a+b, a-b, a*b, a/b from decimals_test order by id
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "36",
    "value" : "152.358023429667510000000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 41,
    "stopIndex" : 43,
    "fragment" : "a*b"
  } ]
}


-- !query
select id, a*10, b/10 from decimals_test order by id
-- !query schema
struct<id:int,(a * 10):decimal(38,18),(b / 10):decimal(38,19)>
-- !query output
1	1000.000000000000000000	99.9000000000000000000
2	123451.230000000000000000	1234.5123000000000000000
3	1.234567891011000000	123.4100000000000000000
4	1234567891234567890.000000000000000000	0.1123456789123456789


-- !query
select 10.3 * 3.0
-- !query schema
struct<(10.3 * 3.0):decimal(6,2)>
-- !query output
30.90


-- !query
select 10.3000 * 3.0
-- !query schema
struct<(10.3000 * 3.0):decimal(9,5)>
-- !query output
30.90000


-- !query
select 10.30000 * 30.0
-- !query schema
struct<(10.30000 * 30.0):decimal(11,6)>
-- !query output
309.000000


-- !query
select 10.300000000000000000 * 3.000000000000000000
-- !query schema
struct<(10.300000000000000000 * 3.000000000000000000):decimal(38,36)>
-- !query output
30.900000000000000000000000000000000000


-- !query
select 10.300000000000000000 * 3.0000000000000000000
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "37",
    "value" : "30.9000000000000000000000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 52,
    "fragment" : "10.300000000000000000 * 3.0000000000000000000"
  } ]
}


-- !query
select 2.35E10 * 1.0
-- !query schema
struct<(2.35E10 * 1.0):double>
-- !query output
2.35E10


-- !query
select (5e36BD + 0.1) + 5e36BD
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "1",
    "value" : "10000000000000000000000000000000000000.1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "(5e36BD + 0.1) + 5e36BD"
  } ]
}


-- !query
select (-4e36BD - 0.1) - 7e36BD
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "1",
    "value" : "-11000000000000000000000000000000000000.1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "(-4e36BD - 0.1) - 7e36BD"
  } ]
}


-- !query
select 12345678901234567890.0 * 12345678901234567890.0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "2",
    "value" : "152415787532388367501905199875019052100"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 54,
    "fragment" : "12345678901234567890.0 * 12345678901234567890.0"
  } ]
}


-- !query
select 1e35BD / 0.1
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "3",
    "value" : "1000000000000000000000000000000000000.000000000000000000000000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 19,
    "fragment" : "1e35BD / 0.1"
  } ]
}


-- !query
select 1.2345678901234567890E30BD * 1.2345678901234567890E25BD
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "0",
    "value" : "15241578753238836750190519987501905210000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 62,
    "fragment" : "1.2345678901234567890E30BD * 1.2345678901234567890E25BD"
  } ]
}


-- !query
select 12345678912345678912345678912.1234567 + 9999999999999999999999999999999.12345
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "7",
    "value" : "10012345678912345678912345678911.2469067"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 84,
    "fragment" : "12345678912345678912345678912.1234567 + 9999999999999999999999999999999.12345"
  } ]
}


-- !query
select 123456789123456789.1234567890 * 1.123456789123456789
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "28",
    "value" : "138698367904130467.654320988515622620750"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 59,
    "fragment" : "123456789123456789.1234567890 * 1.123456789123456789"
  } ]
}


-- !query
select 12345678912345.123456789123 / 0.000000012345678
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "18",
    "value" : "1000000073899961059796.725866331521039184725213147467478092333"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 54,
    "fragment" : "12345678912345.123456789123 / 0.000000012345678"
  } ]
}


-- !query
select 1.0123456789012345678901234567890123456e36BD / 0.1
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "2",
    "value" : "10123456789012345678901234567890123456.000000000000000000000000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 57,
    "fragment" : "1.0123456789012345678901234567890123456e36BD / 0.1"
  } ]
}


-- !query
select 1.0123456789012345678901234567890123456e35BD / 1.0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "3",
    "value" : "101234567890123456789012345678901234.560000000000000000000000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 57,
    "fragment" : "1.0123456789012345678901234567890123456e35BD / 1.0"
  } ]
}


-- !query
select 1.0123456789012345678901234567890123456e34BD / 1.0
-- !query schema
struct<(10123456789012345678901234567890123.456 / 1.0):decimal(38,3)>
-- !query output
10123456789012345678901234567890123.456


-- !query
select 1.0123456789012345678901234567890123456e33BD / 1.0
-- !query schema
struct<(1012345678901234567890123456789012.3456 / 1.0):decimal(38,4)>
-- !query output
1012345678901234567890123456789012.3456


-- !query
select 1.0123456789012345678901234567890123456e32BD / 1.0
-- !query schema
struct<(101234567890123456789012345678901.23456 / 1.0):decimal(38,5)>
-- !query output
101234567890123456789012345678901.23456


-- !query
select 1.0123456789012345678901234567890123456e31BD / 1.0
-- !query schema
struct<(10123456789012345678901234567890.123456 / 1.0):decimal(38,6)>
-- !query output
10123456789012345678901234567890.123456


-- !query
select 1.0123456789012345678901234567890123456e31BD / 0.1
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE.WITH_SUGGESTION",
  "sqlState" : "22003",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "38",
    "scale" : "6",
    "value" : "101234567890123456789012345678901.234560000000000000000000000000000000000"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 57,
    "fragment" : "1.0123456789012345678901234567890123456e31BD / 0.1"
  } ]
}


-- !query
select 1.0123456789012345678901234567890123456e31BD / 10.0
-- !query schema
struct<(10123456789012345678901234567890.123456 / 10.0):decimal(38,7)>
-- !query output
1012345678901234567890123456789.0123456


-- !query
drop table decimals_test
-- !query schema
struct<>
-- !query output

