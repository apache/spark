-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE OR REPLACE TEMPORARY VIEW testData AS SELECT * FROM VALUES
(null, 1L, 1.0D, date("2017-08-01"), timestamp_seconds(1501545600), "a"),
(1, 1L, 1.0D, date("2017-08-01"), timestamp_seconds(1501545600), "a"),
(1, 2L, 2.5D, date("2017-08-02"), timestamp_seconds(1502000000), "a"),
(2, 2147483650L, 100.001D, date("2020-12-31"), timestamp_seconds(1609372800), "a"),
(1, null, 1.0D, date("2017-08-01"), timestamp_seconds(1501545600), "b"),
(2, 3L, 3.3D, date("2017-08-03"), timestamp_seconds(1503000000), "b"),
(3, 2147483650L, 100.001D, date("2020-12-31"), timestamp_seconds(1609372800), "b"),
(null, null, null, null, null, null),
(3, 1L, 1.0D, date("2017-08-01"), timestamp_seconds(1501545600), null)
AS testData(val, val_long, val_double, val_date, val_timestamp, cate)
-- !query schema
struct<>
-- !query output



-- !query
SELECT udf(val), cate, count(val) OVER(PARTITION BY cate ORDER BY udf(val) ROWS CURRENT ROW) FROM testData
ORDER BY cate, udf(val)
-- !query schema
struct<udf(val):int,cate:string,count(val) OVER (PARTITION BY cate ORDER BY udf(val) ASC NULLS FIRST ROWS BETWEEN CURRENT ROW AND CURRENT ROW):bigint>
-- !query output
NULL	NULL	0
3	NULL	1
NULL	a	0
1	a	1
1	a	1
2	a	1
1	b	1
2	b	1
3	b	1


-- !query
SELECT udf(val), cate, sum(val) OVER(PARTITION BY cate ORDER BY udf(val)
ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING) FROM testData ORDER BY cate, udf(val)
-- !query schema
struct<udf(val):int,cate:string,sum(val) OVER (PARTITION BY cate ORDER BY udf(val) ASC NULLS FIRST ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING):bigint>
-- !query output
NULL	NULL	3
3	NULL	3
NULL	a	1
1	a	2
1	a	4
2	a	4
1	b	3
2	b	6
3	b	6


-- !query
SELECT val_long, udf(cate), sum(val_long) OVER(PARTITION BY cate ORDER BY udf(val_long)
ROWS BETWEEN CURRENT ROW AND 2147483648 FOLLOWING) FROM testData ORDER BY udf(cate), val_long
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.SPECIFIED_WINDOW_FRAME_UNACCEPTED_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "expectedType" : "\"INT\"",
    "exprType" : "\"BIGINT\"",
    "location" : "upper",
    "sqlExpr" : "\"ROWS BETWEEN CURRENT ROW AND 2147483648 FOLLOWING\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 47,
    "stopIndex" : 138,
    "fragment" : "(PARTITION BY cate ORDER BY udf(val_long)\nROWS BETWEEN CURRENT ROW AND 2147483648 FOLLOWING)"
  } ]
}


-- !query
SELECT udf(val), cate, count(val) OVER(PARTITION BY udf(cate) ORDER BY val RANGE 1 PRECEDING) FROM testData
ORDER BY cate, udf(val)
-- !query schema
struct<udf(val):int,cate:string,count(val) OVER (PARTITION BY udf(cate) ORDER BY val ASC NULLS FIRST RANGE BETWEEN 1 PRECEDING AND CURRENT ROW):bigint>
-- !query output
NULL	NULL	0
3	NULL	1
NULL	a	0
1	a	2
1	a	2
2	a	3
1	b	1
2	b	2
3	b	2


-- !query
SELECT val, udf(cate), sum(val) OVER(PARTITION BY udf(cate) ORDER BY val
RANGE BETWEEN CURRENT ROW AND 1 FOLLOWING) FROM testData ORDER BY udf(cate), val
-- !query schema
struct<val:int,udf(cate):string,sum(val) OVER (PARTITION BY udf(cate) ORDER BY val ASC NULLS FIRST RANGE BETWEEN CURRENT ROW AND 1 FOLLOWING):bigint>
-- !query output
NULL	NULL	NULL
3	NULL	3
NULL	a	NULL
1	a	4
1	a	4
2	a	2
1	b	3
2	b	5
3	b	3


-- !query
SELECT val_long, udf(cate), sum(val_long) OVER(PARTITION BY udf(cate) ORDER BY val_long
RANGE BETWEEN CURRENT ROW AND 2147483648 FOLLOWING) FROM testData ORDER BY udf(cate), val_long
-- !query schema
struct<val_long:bigint,udf(cate):string,sum(val_long) OVER (PARTITION BY udf(cate) ORDER BY val_long ASC NULLS FIRST RANGE BETWEEN CURRENT ROW AND 2147483648 FOLLOWING):bigint>
-- !query output
NULL	NULL	NULL
1	NULL	1
1	a	4
1	a	4
2	a	2147483652
2147483650	a	2147483650
NULL	b	NULL
3	b	2147483653
2147483650	b	2147483650


-- !query
SELECT val_double, udf(cate), sum(val_double) OVER(PARTITION BY udf(cate) ORDER BY val_double
RANGE BETWEEN CURRENT ROW AND 2.5 FOLLOWING) FROM testData ORDER BY udf(cate), val_double
-- !query schema
struct<val_double:double,udf(cate):string,sum(val_double) OVER (PARTITION BY udf(cate) ORDER BY val_double ASC NULLS FIRST RANGE BETWEEN CURRENT ROW AND 2.5 FOLLOWING):double>
-- !query output
NULL	NULL	NULL
1.0	NULL	1.0
1.0	a	4.5
1.0	a	4.5
2.5	a	2.5
100.001	a	100.001
1.0	b	4.3
3.3	b	3.3
100.001	b	100.001


-- !query
SELECT val_date, udf(cate), max(val_date) OVER(PARTITION BY udf(cate) ORDER BY val_date
RANGE BETWEEN CURRENT ROW AND 2 FOLLOWING) FROM testData ORDER BY udf(cate), val_date
-- !query schema
struct<val_date:date,udf(cate):string,max(val_date) OVER (PARTITION BY udf(cate) ORDER BY val_date ASC NULLS FIRST RANGE BETWEEN CURRENT ROW AND 2 FOLLOWING):date>
-- !query output
NULL	NULL	NULL
2017-08-01	NULL	2017-08-01
2017-08-01	a	2017-08-02
2017-08-01	a	2017-08-02
2017-08-02	a	2017-08-02
2020-12-31	a	2020-12-31
2017-08-01	b	2017-08-03
2017-08-03	b	2017-08-03
2020-12-31	b	2020-12-31


-- !query
SELECT val_timestamp, udf(cate), avg(val_timestamp) OVER(PARTITION BY udf(cate) ORDER BY val_timestamp
RANGE BETWEEN CURRENT ROW AND interval 23 days 4 hours FOLLOWING) FROM testData
ORDER BY udf(cate), val_timestamp
-- !query schema
struct<val_timestamp:timestamp,udf(cate):string,avg(val_timestamp) OVER (PARTITION BY udf(cate) ORDER BY val_timestamp ASC NULLS FIRST RANGE BETWEEN CURRENT ROW AND INTERVAL '23 04' DAY TO HOUR FOLLOWING):double>
-- !query output
NULL	NULL	NULL
2017-07-31 17:00:00	NULL	1.5015456E9
2017-07-31 17:00:00	a	1.5016970666666667E9
2017-07-31 17:00:00	a	1.5016970666666667E9
2017-08-05 23:13:20	a	1.502E9
2020-12-30 16:00:00	a	1.6093728E9
2017-07-31 17:00:00	b	1.5022728E9
2017-08-17 13:00:00	b	1.503E9
2020-12-30 16:00:00	b	1.6093728E9


-- !query
SELECT val, udf(cate), sum(val) OVER(PARTITION BY cate ORDER BY val DESC
RANGE BETWEEN CURRENT ROW AND 1 FOLLOWING) FROM testData ORDER BY cate, val
-- !query schema
struct<val:int,udf(cate):string,sum(val) OVER (PARTITION BY cate ORDER BY val DESC NULLS LAST RANGE BETWEEN CURRENT ROW AND 1 FOLLOWING):bigint>
-- !query output
NULL	NULL	NULL
3	NULL	3
NULL	a	NULL
1	a	2
1	a	2
2	a	4
1	b	1
2	b	3
3	b	5


-- !query
SELECT udf(val), cate, count(val) OVER(PARTITION BY udf(cate)
ROWS BETWEEN UNBOUNDED FOLLOWING AND 1 FOLLOWING) FROM testData ORDER BY cate, udf(val)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.SPECIFIED_WINDOW_FRAME_INVALID_BOUND",
  "sqlState" : "42K09",
  "messageParameters" : {
    "lower" : "\"UNBOUNDED FOLLOWING\"",
    "sqlExpr" : "\"ROWS BETWEEN UNBOUNDED FOLLOWING AND 1 FOLLOWING\"",
    "upper" : "\"1\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 39,
    "stopIndex" : 111,
    "fragment" : "(PARTITION BY udf(cate)\nROWS BETWEEN UNBOUNDED FOLLOWING AND 1 FOLLOWING)"
  } ]
}


-- !query
SELECT udf(val), cate, count(val) OVER(PARTITION BY udf(cate)
RANGE BETWEEN CURRENT ROW AND 1 FOLLOWING) FROM testData ORDER BY cate, udf(val)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.RANGE_FRAME_WITHOUT_ORDER",
  "sqlState" : "42K09",
  "messageParameters" : {
    "sqlExpr" : "\"(PARTITION BY udf(cate) RANGE BETWEEN CURRENT ROW AND 1 FOLLOWING)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 39,
    "stopIndex" : 104,
    "fragment" : "(PARTITION BY udf(cate)\nRANGE BETWEEN CURRENT ROW AND 1 FOLLOWING)"
  } ]
}


-- !query
SELECT udf(val), cate, count(val) OVER(PARTITION BY udf(cate) ORDER BY udf(val), cate
RANGE BETWEEN CURRENT ROW AND 1 FOLLOWING) FROM testData ORDER BY cate, udf(val)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.RANGE_FRAME_MULTI_ORDER",
  "sqlState" : "42K09",
  "messageParameters" : {
    "orderSpec" : "cast(udf(cast(val#x as string)) as int) ASC NULLS FIRST,cate#x ASC NULLS FIRST",
    "sqlExpr" : "\"(PARTITION BY udf(cate) ORDER BY udf(val) ASC NULLS FIRST, cate ASC NULLS FIRST RANGE BETWEEN CURRENT ROW AND 1 FOLLOWING)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 39,
    "stopIndex" : 128,
    "fragment" : "(PARTITION BY udf(cate) ORDER BY udf(val), cate\nRANGE BETWEEN CURRENT ROW AND 1 FOLLOWING)"
  } ]
}


-- !query
SELECT udf(val), cate, count(val) OVER(PARTITION BY udf(cate) ORDER BY current_timestamp
RANGE BETWEEN CURRENT ROW AND 1 FOLLOWING) FROM testData ORDER BY cate, udf(val)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.RANGE_FRAME_INVALID_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "orderSpecType" : "\"TIMESTAMP\"",
    "sqlExpr" : "\"(PARTITION BY udf(cate) ORDER BY current_timestamp() ASC NULLS FIRST RANGE BETWEEN CURRENT ROW AND 1 FOLLOWING)\"",
    "valueBoundaryType" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 39,
    "stopIndex" : 131,
    "fragment" : "(PARTITION BY udf(cate) ORDER BY current_timestamp\nRANGE BETWEEN CURRENT ROW AND 1 FOLLOWING)"
  } ]
}


-- !query
SELECT udf(val), cate, count(val) OVER(PARTITION BY udf(cate) ORDER BY val
RANGE BETWEEN 1 FOLLOWING AND 1 PRECEDING) FROM testData ORDER BY udf(cate), val
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.SPECIFIED_WINDOW_FRAME_WRONG_COMPARISON",
  "sqlState" : "42K09",
  "messageParameters" : {
    "comparison" : "less than or equal",
    "sqlExpr" : "\"RANGE BETWEEN 1 FOLLOWING AND 1 PRECEDING\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 39,
    "stopIndex" : 117,
    "fragment" : "(PARTITION BY udf(cate) ORDER BY val\nRANGE BETWEEN 1 FOLLOWING AND 1 PRECEDING)"
  } ]
}


-- !query
SELECT udf(val), cate, count(val) OVER(PARTITION BY udf(cate) ORDER BY udf(val)
RANGE BETWEEN CURRENT ROW AND current_date PRECEDING) FROM testData ORDER BY cate, val(val)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0064",
  "messageParameters" : {
    "msg" : "Frame bound value must be a literal."
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 111,
    "stopIndex" : 132,
    "fragment" : "current_date PRECEDING"
  } ]
}


-- !query
SELECT udf(val), cate,
max(udf(val)) OVER w AS max,
min(udf(val)) OVER w AS min,
min(udf(val)) OVER w AS min,
count(udf(val)) OVER w AS count,
sum(udf(val)) OVER w AS sum,
avg(udf(val)) OVER w AS avg,
stddev(udf(val)) OVER w AS stddev,
first_value(udf(val)) OVER w AS first_value,
first_value(udf(val), true) OVER w AS first_value_ignore_null,
first_value(udf(val), false) OVER w AS first_value_contain_null,
any_value(udf(val)) OVER w AS any_value,
any_value(udf(val), true) OVER w AS any_value_ignore_null,
any_value(udf(val), false) OVER w AS any_value_contain_null,
last_value(udf(val)) OVER w AS last_value,
last_value(udf(val), true) OVER w AS last_value_ignore_null,
last_value(udf(val), false) OVER w AS last_value_contain_null,
rank() OVER w AS rank,
dense_rank() OVER w AS dense_rank,
cume_dist() OVER w AS cume_dist,
percent_rank() OVER w AS percent_rank,
ntile(2) OVER w AS ntile,
row_number() OVER w AS row_number,
var_pop(udf(val)) OVER w AS var_pop,
var_samp(udf(val)) OVER w AS var_samp,
approx_count_distinct(udf(val)) OVER w AS approx_count_distinct,
covar_pop(udf(val), udf(val_long)) OVER w AS covar_pop,
corr(udf(val), udf(val_long)) OVER w AS corr,
stddev_samp(udf(val)) OVER w AS stddev_samp,
stddev_pop(udf(val)) OVER w AS stddev_pop,
collect_list(udf(val)) OVER w AS collect_list,
collect_set(udf(val)) OVER w AS collect_set,
skewness(udf(val_double)) OVER w AS skewness,
kurtosis(udf(val_double)) OVER w AS kurtosis
FROM testData
WINDOW w AS (PARTITION BY udf(cate) ORDER BY udf(val))
ORDER BY cate, udf(val)
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "DIVIDE_BY_ZERO",
  "sqlState" : "22012",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1126,
    "stopIndex" : 1161,
    "fragment" : "corr(udf(val), udf(val_long)) OVER w"
  } ]
}


-- !query
SELECT udf(val), cate, avg(null) OVER(PARTITION BY cate ORDER BY val) FROM testData ORDER BY cate, val
-- !query schema
struct<udf(val):int,cate:string,avg(NULL) OVER (PARTITION BY cate ORDER BY val ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW):double>
-- !query output
NULL	NULL	NULL
3	NULL	NULL
NULL	a	NULL
1	a	NULL
1	a	NULL
2	a	NULL
1	b	NULL
2	b	NULL
3	b	NULL


-- !query
SELECT udf(val), cate, row_number() OVER(PARTITION BY cate) FROM testData ORDER BY cate, udf(val)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1037",
  "messageParameters" : {
    "wf" : "row_number()"
  }
}


-- !query
SELECT udf(val), cate, sum(val) OVER(), avg(val) OVER() FROM testData ORDER BY cate, val
-- !query schema
struct<udf(val):int,cate:string,sum(val) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):bigint,avg(val) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):double>
-- !query output
NULL	NULL	13	1.8571428571428572
3	NULL	13	1.8571428571428572
NULL	a	13	1.8571428571428572
1	a	13	1.8571428571428572
1	a	13	1.8571428571428572
2	a	13	1.8571428571428572
1	b	13	1.8571428571428572
2	b	13	1.8571428571428572
3	b	13	1.8571428571428572


-- !query
SELECT udf(val), cate,
first_value(false) OVER w AS first_value,
first_value(true, true) OVER w AS first_value_ignore_null,
first_value(false, false) OVER w AS first_value_contain_null,
any_value(false) OVER w AS any_value,
any_value(true, true) OVER w AS any_value_ignore_null,
any_value(false, false) OVER w AS any_value_contain_null,
last_value(false) OVER w AS last_value,
last_value(true, true) OVER w AS last_value_ignore_null,
last_value(false, false) OVER w AS last_value_contain_null
FROM testData
WINDOW w AS ()
ORDER BY cate, val
-- !query schema
struct<udf(val):int,cate:string,first_value:boolean,first_value_ignore_null:boolean,first_value_contain_null:boolean,any_value:boolean,any_value_ignore_null:boolean,any_value_contain_null:boolean,last_value:boolean,last_value_ignore_null:boolean,last_value_contain_null:boolean>
-- !query output
NULL	NULL	false	true	false	false	true	false	false	true	false
3	NULL	false	true	false	false	true	false	false	true	false
NULL	a	false	true	false	false	true	false	false	true	false
1	a	false	true	false	false	true	false	false	true	false
1	a	false	true	false	false	true	false	false	true	false
2	a	false	true	false	false	true	false	false	true	false
1	b	false	true	false	false	true	false	false	true	false
2	b	false	true	false	false	true	false	false	true	false
3	b	false	true	false	false	true	false	false	true	false


-- !query
SELECT udf(cate), sum(val) OVER (w)
FROM testData
WHERE val is not null
WINDOW w AS (PARTITION BY cate ORDER BY val)
-- !query schema
struct<udf(cate):string,sum(val) OVER (PARTITION BY cate ORDER BY val ASC NULLS FIRST RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW):bigint>
-- !query output
NULL	3
a	2
a	2
a	4
b	1
b	3
b	6
