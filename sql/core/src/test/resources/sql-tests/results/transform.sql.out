-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE OR REPLACE TEMPORARY VIEW t AS SELECT * FROM VALUES
('1', true, unhex('537061726B2053514C'), tinyint(1), 1, smallint(100), bigint(1), float(1.0), 1.0, Decimal(1.0), timestamp('1997-01-02'), date('2000-04-01')),
('2', false, unhex('537061726B2053514C'), tinyint(2), 2,  smallint(200), bigint(2), float(2.0), 2.0, Decimal(2.0), timestamp('1997-01-02 03:04:05'), date('2000-04-02')),
('3', true, unhex('537061726B2053514C'), tinyint(3), 3, smallint(300), bigint(3), float(3.0), 3.0, Decimal(3.0), timestamp('1997-02-10 17:32:01-08'), date('2000-04-03'))
AS t(a, b, c, d, e, f, g, h, i, j, k, l)
-- !query schema
struct<>
-- !query output



-- !query
CREATE OR REPLACE TEMPORARY VIEW script_trans AS SELECT * FROM VALUES
(1, 2, 3),
(4, 5, 6),
(7, 8, 9)
AS script_trans(a, b, c)
-- !query schema
struct<>
-- !query output



-- !query
CREATE OR REPLACE TEMPORARY VIEW complex_trans AS SELECT * FROM VALUES
(1, 1),
(1, 1),
(2, 2),
(2, 2),
(3, 3),
(2, 2),
(3, 3),
(1, 1),
(3, 3)
as complex_trans(a, b)
-- !query schema
struct<>
-- !query output



-- !query
SELECT TRANSFORM(a)
USING 'cat' AS (a)
FROM t
-- !query schema
struct<a:string>
-- !query output
1
2
3


-- !query
SELECT a, b, decode(c, 'UTF-8'), d, e, f, g, h, i, j, k, l FROM (
  SELECT TRANSFORM(a, b, c, d, e, f, g, h, i, j, k, l)
  USING 'cat' AS (
    a string,
    b boolean,
    c binary,
    d tinyint,
    e int,
    f smallint,
    g long,
    h float,
    i double,
    j decimal(38, 18),
    k timestamp,
    l date)
  FROM t
) tmp
-- !query schema
struct<a:string,b:boolean,decode(c, UTF-8):string,d:tinyint,e:int,f:smallint,g:bigint,h:float,i:double,j:decimal(38,18),k:timestamp,l:date>
-- !query output
1	true	Spark SQL	1	1	100	1	1.0	1.0	1.000000000000000000	1997-01-02 00:00:00	2000-04-01
2	false	Spark SQL	2	2	200	2	2.0	2.0	2.000000000000000000	1997-01-02 03:04:05	2000-04-02
3	true	Spark SQL	3	3	300	3	3.0	3.0	3.000000000000000000	1997-02-10 17:32:01	2000-04-03


-- !query
SELECT a, b, decode(c, 'UTF-8'), d, e, f, g, h, i, j, k, l FROM (
  SELECT TRANSFORM(a, b, c, d, e, f, g, h, i, j, k, l)
  USING 'cat' AS (
    a string,
    b string,
    c string,
    d string,
    e string,
    f string,
    g string,
    h string,
    i string,
    j string,
    k string,
    l string)
  FROM t
) tmp
-- !query schema
struct<a:string,b:string,decode(c, UTF-8):string,d:string,e:string,f:string,g:string,h:string,i:string,j:string,k:string,l:string>
-- !query output
1	true	Spark SQL	1	1	100	1	1.0	1.0	1	1997-01-02 00:00:00	2000-04-01
2	false	Spark SQL	2	2	200	2	2.0	2.0	2	1997-01-02 03:04:05	2000-04-02
3	true	Spark SQL	3	3	300	3	3.0	3.0	3	1997-02-10 17:32:01	2000-04-03


-- !query
SELECT TRANSFORM(a)
USING 'cat'
FROM t
-- !query schema
struct<key:string,value:string>
-- !query output
1	NULL
2	NULL
3	NULL


-- !query
SELECT TRANSFORM(a, b)
USING 'cat'
FROM t
-- !query schema
struct<key:string,value:string>
-- !query output
1	true
2	false
3	true


-- !query
SELECT TRANSFORM(a, b, c)
USING 'cat'
FROM t
-- !query schema
struct<key:string,value:string>
-- !query output
1	true
2	false
3	true


-- !query
SELECT TRANSFORM(a, b, c, d, e, f, g, h, i)
USING 'cat' AS (a int, b short, c long, d byte, e float, f double, g decimal(38, 18), h date, i timestamp)
FROM VALUES
('a','','1231a','a','213.21a','213.21a','0a.21d','2000-04-01123','1997-0102 00:00:') tmp(a, b, c, d, e, f, g, h, i)
-- !query schema
struct<a:int,b:smallint,c:bigint,d:tinyint,e:float,f:double,g:decimal(38,18),h:date,i:timestamp>
-- !query output
NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL


-- !query
SELECT TRANSFORM(b, max(a), sum(f))
USING 'cat' AS (a, b)
FROM t
GROUP BY b
-- !query schema
struct<a:string,b:string>
-- !query output
false	2
true	3


-- !query
MAP a, b USING 'cat' AS (a, b) FROM t
-- !query schema
struct<a:string,b:string>
-- !query output
1	true
2	false
3	true


-- !query
REDUCE a, b USING 'cat' AS (a, b) FROM t
-- !query schema
struct<a:string,b:string>
-- !query output
1	true
2	false
3	true


-- !query
SELECT TRANSFORM(a, b, c, null)
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '@'
  LINES TERMINATED BY '\n'
  NULL DEFINED AS 'NULL'
USING 'cat' AS (a, b, c, d)
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '@'
  LINES TERMINATED BY '\n'
  NULL DEFINED AS 'NULL'
FROM t
-- !query schema
struct<a:string,b:string,c:string,d:string>
-- !query output
1	true	Spark SQL	NULL
2	false	Spark SQL	NULL
3	true	Spark SQL	NULL


-- !query
SELECT TRANSFORM(a, b, c, null)
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '@'
  LINES TERMINATED BY '\n'
  NULL DEFINED AS 'NULL'
USING 'cat' AS (d)
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '@'
  LINES TERMINATED BY '\n'
  NULL DEFINED AS 'NULL'
FROM t
-- !query schema
struct<d:string>
-- !query output
1
2
3


-- !query
SELECT TRANSFORM(a, b, c, null)
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '@'
  LINES TERMINATED BY '\n'
USING 'cat' AS (a, b, c, d)
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '@'
  LINES TERMINATED BY '\n'
  NULL DEFINED AS 'NULL'
FROM t
-- !query schema
struct<a:string,b:string,c:string,d:string>
-- !query output
1	true	Spark SQL	\N
2	false	Spark SQL	\N
3	true	Spark SQL	\N


-- !query
SELECT TRANSFORM(a, b, c, null)
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '@'
  LINES TERMINATED BY '\n'
USING 'cat' AS (a, b, c, d)
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '@'
  LINES TERMINATED BY '\n'
FROM t
-- !query schema
struct<a:string,b:string,c:string,d:string>
-- !query output
1	true	Spark SQL	NULL
2	false	Spark SQL	NULL
3	true	Spark SQL	NULL


-- !query
SELECT TRANSFORM(a, b, c, null)
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '@'
  LINES TERMINATED BY '\n'
  NULL DEFINED AS 'XXXX'
USING 'cat' AS (a, b, c, d)
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '@'
  LINES TERMINATED BY '\n'
FROM t
-- !query schema
struct<a:string,b:string,c:string,d:string>
-- !query output
1	true	Spark SQL	XXXX
2	false	Spark SQL	XXXX
3	true	Spark SQL	XXXX


-- !query
SELECT TRANSFORM(a, b, c, null)
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '@'
  LINES TERMINATED BY '\n'
  NULL DEFINED AS '\n'
USING 'cat' AS (a, b, c, d)
  ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '@'
  LINES TERMINATED BY '\n'
FROM t
-- !query schema
struct<a:string,b:string,c:string,d:string>
-- !query output
	NULL	NULL	NULL
	NULL	NULL	NULL
	NULL	NULL	NULL
1	true	Spark SQL	
2	false	Spark SQL	
3	true	Spark SQL


-- !query
SELECT a, b, decode(c, 'UTF-8'), d, e, f, g, h, i, j, k, l FROM (
  SELECT TRANSFORM(a, b, c, d, e, f, g, h, i, j, k, l)
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ','
    LINES TERMINATED BY '\n'
    NULL DEFINED AS 'NULL'
    USING 'cat' AS (
      a string,
      b boolean,
      c binary,
      d tinyint,
      e int,
      f smallint,
      g long,
      h float,
      i double,
      j decimal(38, 18),
      k timestamp,
      l date)
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ','
    LINES TERMINATED BY '\n'
    NULL DEFINED AS 'NULL'
  FROM t
) tmp
-- !query schema
struct<a:string,b:boolean,decode(c, UTF-8):string,d:tinyint,e:int,f:smallint,g:bigint,h:float,i:double,j:decimal(38,18),k:timestamp,l:date>
-- !query output
1	true	Spark SQL	1	1	100	1	1.0	1.0	1.000000000000000000	1997-01-02 00:00:00	2000-04-01
2	false	Spark SQL	2	2	200	2	2.0	2.0	2.000000000000000000	1997-01-02 03:04:05	2000-04-02
3	true	Spark SQL	3	3	300	3	3.0	3.0	3.000000000000000000	1997-02-10 17:32:01	2000-04-03


-- !query
SELECT a, b, decode(c, 'UTF-8'), d, e, f, g, h, i, j, k, l FROM (
  SELECT TRANSFORM(a, b, c, d, e, f, g, h, i, j, k, l)
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ','
    LINES TERMINATED BY '\n'
    NULL DEFINED AS 'NULL'
    USING 'cat' AS (
      a string,
      b long,
      c binary,
      d tinyint,
      e int,
      f smallint,
      g long,
      h float,
      i double,
      j decimal(38, 18),
      k int,
      l long)
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ','
    LINES TERMINATED BY '\n'
    NULL DEFINED AS 'NULL'
  FROM t
) tmp
-- !query schema
struct<a:string,b:bigint,decode(c, UTF-8):string,d:tinyint,e:int,f:smallint,g:bigint,h:float,i:double,j:decimal(38,18),k:int,l:bigint>
-- !query output
1	NULL	Spark SQL	1	1	100	1	1.0	1.0	1.000000000000000000	NULL	NULL
2	NULL	Spark SQL	2	2	200	2	2.0	2.0	2.000000000000000000	NULL	NULL
3	NULL	Spark SQL	3	3	300	3	3.0	3.0	3.000000000000000000	NULL	NULL


-- !query
SELECT a, b, decode(c, 'UTF-8'), d, e, f, g, h, i, j, k, l FROM (
  SELECT TRANSFORM(a, b, c, d, e, f, g, h, i, j, k, l)
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ','
    LINES TERMINATED BY '@'
    NULL DEFINED AS 'NULL'
    USING 'cat' AS (
      a string,
      b string,
      c string,
      d string,
      e string,
      f string,
      g string,
      h string,
      i string,
      j string,
      k string,
      l string)
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY ','
    LINES TERMINATED BY '@'
    NULL DEFINED AS 'NULL'
  FROM t
) tmp
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0064",
  "messageParameters" : {
    "msg" : "LINES TERMINATED BY only supports newline '\\n' right now: @"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 69,
    "stopIndex" : 560,
    "fragment" : "SELECT TRANSFORM(a, b, c, d, e, f, g, h, i, j, k, l)\n    ROW FORMAT DELIMITED\n    FIELDS TERMINATED BY ','\n    LINES TERMINATED BY '@'\n    NULL DEFINED AS 'NULL'\n    USING 'cat' AS (\n      a string,\n      b string,\n      c string,\n      d string,\n      e string,\n      f string,\n      g string,\n      h string,\n      i string,\n      j string,\n      k string,\n      l string)\n    ROW FORMAT DELIMITED\n    FIELDS TERMINATED BY ','\n    LINES TERMINATED BY '@'\n    NULL DEFINED AS 'NULL'\n  FROM t"
  } ]
}


-- !query
SELECT TRANSFORM(b, a, CAST(c AS STRING))
  USING 'cat' AS (a, b, c)
FROM script_trans
WHERE a <= 4
-- !query schema
struct<a:string,b:string,c:string>
-- !query output
2	1	3
5	4	6


-- !query
SELECT TRANSFORM(1, 2, 3)
  USING 'cat' AS (a, b, c)
FROM script_trans
WHERE a <= 4
-- !query schema
struct<a:string,b:string,c:string>
-- !query output
1	2	3
1	2	3


-- !query
SELECT TRANSFORM(1, 2)
  USING 'cat' AS (a INT, b INT)
FROM script_trans
LIMIT 1
-- !query schema
struct<a:int,b:int>
-- !query output
1	2


-- !query
SELECT TRANSFORM(
  b, a,
  CASE
    WHEN c > 100 THEN 1
    WHEN c < 100 THEN 2
  ELSE 3 END)
  USING 'cat' AS (a, b,  c)
FROM script_trans
WHERE a <= 4
-- !query schema
struct<a:string,b:string,c:string>
-- !query output
2	1	2
5	4	2


-- !query
SELECT TRANSFORM(b, a, c + 1)
  USING 'cat' AS (a, b, c)
FROM script_trans
WHERE a <= 4
-- !query schema
struct<a:string,b:string,c:string>
-- !query output
2	1	4
5	4	7


-- !query
SELECT TRANSFORM(*)
  USING 'cat' AS (a, b, c)
FROM script_trans
WHERE a <= 4
-- !query schema
struct<a:string,b:string,c:string>
-- !query output
1	2	3
4	5	6


-- !query
SELECT TRANSFORM(b, MAX(a), CAST(SUM(c) AS STRING))
  USING 'cat' AS (a, b, c)
FROM script_trans
WHERE a <= 4
GROUP BY b
-- !query schema
struct<a:string,b:string,c:string>
-- !query output
2	1	3
5	4	6


-- !query
SELECT TRANSFORM(b, MAX(a) FILTER (WHERE a > 3), CAST(SUM(c) AS STRING))
  USING 'cat' AS (a,b,c)
FROM script_trans
WHERE a <= 4
GROUP BY b
-- !query schema
struct<a:string,b:string,c:string>
-- !query output
2	NULL	3
5	4	6


-- !query
SELECT TRANSFORM(b, MAX(a), CAST(sum(c) AS STRING))
  USING 'cat' AS (a, b, c)
FROM script_trans
WHERE a <= 2
GROUP BY b
-- !query schema
struct<a:string,b:string,c:string>
-- !query output
2	1	3


-- !query
SELECT TRANSFORM(b, MAX(a), CAST(SUM(c) AS STRING))
  USING 'cat' AS (a, b, c)
FROM script_trans
WHERE a <= 4
GROUP BY b
HAVING MAX(a) > 0
-- !query schema
struct<a:string,b:string,c:string>
-- !query output
2	1	3
5	4	6


-- !query
SELECT TRANSFORM(b, MAX(a), CAST(SUM(c) AS STRING))
  USING 'cat' AS (a, b, c)
FROM script_trans
WHERE a <= 4
GROUP BY b
HAVING MAX(a) > 1
-- !query schema
struct<a:string,b:string,c:string>
-- !query output
5	4	6


-- !query
SELECT TRANSFORM(b, MAX(a) OVER w, CAST(SUM(c) OVER w AS STRING))
  USING 'cat' AS (a, b, c)
FROM script_trans
WHERE a <= 4
WINDOW w AS (PARTITION BY b ORDER BY a)
-- !query schema
struct<a:string,b:string,c:string>
-- !query output
2	1	3
5	4	6


-- !query
SELECT TRANSFORM(b, MAX(a), CAST(SUM(c) AS STRING), myCol, myCol2)
  USING 'cat' AS (a STRING, b STRING, c STRING, d ARRAY<INT>, e STRING)
FROM script_trans
LATERAL VIEW explode(array(array(1,2,3))) myTable AS myCol
LATERAL VIEW explode(myTable.myCol) myTable2 AS myCol2
WHERE a <= 4
GROUP BY b, myCol, myCol2
HAVING max(a) > 1
-- !query schema
struct<a:string,b:string,c:string,d:array<int>,e:string>
-- !query output
5	4	6	[1,2,3]	1
5	4	6	[1,2,3]	2
5	4	6	[1,2,3]	3


-- !query
FROM(
  FROM script_trans
  SELECT TRANSFORM(a, b)
    USING 'cat' AS (`a` INT, b STRING)
) t
SELECT a + 1
-- !query schema
struct<(a + 1):int>
-- !query output
2
5
8


-- !query
FROM(
  SELECT TRANSFORM(a, SUM(b))
    USING 'cat' AS (`a` INT, b STRING)
  FROM script_trans
  GROUP BY a
) t
SELECT (b + 1) AS result
ORDER BY result
-- !query schema
struct<result:bigint>
-- !query output
3
6
9


-- !query
MAP k / 10 USING 'cat' AS (one) FROM (SELECT 10 AS k)
-- !query schema
struct<one:string>
-- !query output
1.0


-- !query
FROM (SELECT 1 AS key, 100 AS value) src
MAP src.*, src.key, CAST(src.key / 10 AS INT), CAST(src.key % 10 AS INT), src.value
  USING 'cat' AS (k, v, tkey, ten, one, tvalue)
-- !query schema
struct<k:string,v:string,tkey:string,ten:string,one:string,tvalue:string>
-- !query output
1	100	1	0	1	100


-- !query
SELECT TRANSFORM(1)
  USING 'cat' AS (a)
FROM script_trans
HAVING true
-- !query schema
struct<a:string>
-- !query output
1


-- !query
SET spark.sql.legacy.parser.havingWithoutGroupByAsWhere=true
-- !query schema
struct<key:string,value:string>
-- !query output
spark.sql.legacy.parser.havingWithoutGroupByAsWhere	true


-- !query
SELECT TRANSFORM(1)
  USING 'cat' AS (a)
FROM script_trans
HAVING true
-- !query schema
struct<a:string>
-- !query output
1
1
1


-- !query
SET spark.sql.legacy.parser.havingWithoutGroupByAsWhere=false
-- !query schema
struct<key:string,value:string>
-- !query output
spark.sql.legacy.parser.havingWithoutGroupByAsWhere	false


-- !query
WITH temp AS (
  SELECT TRANSFORM(a) USING 'cat' AS (b string) FROM t
)
SELECT t1.b FROM temp t1 JOIN temp t2 ON t1.b = t2.b
-- !query schema
struct<b:string>
-- !query output
1
2
3


-- !query
SELECT TRANSFORM(DISTINCT b, a, c)
  USING 'cat' AS (a, b, c)
FROM script_trans
WHERE a <= 4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "UNSUPPORTED_FEATURE.TRANSFORM_DISTINCT_ALL",
  "sqlState" : "0A000",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 92,
    "fragment" : "SELECT TRANSFORM(DISTINCT b, a, c)\n  USING 'cat' AS (a, b, c)\nFROM script_trans\nWHERE a <= 4"
  } ]
}


-- !query
SELECT TRANSFORM(ALL b, a, c)
  USING 'cat' AS (a, b, c)
FROM script_trans
WHERE a <= 4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "UNSUPPORTED_FEATURE.TRANSFORM_DISTINCT_ALL",
  "sqlState" : "0A000",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 87,
    "fragment" : "SELECT TRANSFORM(ALL b, a, c)\n  USING 'cat' AS (a, b, c)\nFROM script_trans\nWHERE a <= 4"
  } ]
}


-- !query
SELECT TRANSFORM(b AS b_1, MAX(a), CAST(sum(c) AS STRING))
  USING 'cat' AS (a, b, c)
FROM script_trans
WHERE a <= 2
GROUP BY b
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'AS'",
    "hint" : ""
  }
}


-- !query
SELECT TRANSFORM(b b_1, MAX(a), CAST(sum(c) AS STRING))
  USING 'cat' AS (a, b, c)
FROM script_trans
WHERE a <= 2
GROUP BY b
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'b_1'",
    "hint" : ""
  }
}


-- !query
SELECT TRANSFORM(b, MAX(a) AS max_a, CAST(sum(c) AS STRING))
  USING 'cat' AS (a, b, c)
FROM script_trans
WHERE a <= 2
GROUP BY b
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'AS'",
    "hint" : ""
  }
}


-- !query
FROM (
  SELECT TRANSFORM(a, b)
    USING 'cat' AS (a, b)
  FROM complex_trans
  CLUSTER BY a
) map_output
SELECT TRANSFORM(a, b)
  USING 'cat' AS (a, b)
-- !query schema
struct<a:string,b:string>
-- !query output
1	1
1	1
1	1
2	2
2	2
2	2
3	3
3	3
3	3


-- !query
FROM (
  SELECT TRANSFORM(a, b)
    USING 'cat' AS (a, b)
  FROM complex_trans
  ORDER BY a
) map_output
SELECT TRANSFORM(a, b)
  USING 'cat' AS (a, b)
-- !query schema
struct<a:string,b:string>
-- !query output
1	1
1	1
1	1
2	2
2	2
2	2
3	3
3	3
3	3


-- !query
SELECT TRANSFORM (a, b)
  USING 'cat' AS (a CHAR(10), b VARCHAR(10))
FROM VALUES('apache', 'spark') t(a, b)
-- !query schema
struct<a:string,b:string>
-- !query output
apache	spark
