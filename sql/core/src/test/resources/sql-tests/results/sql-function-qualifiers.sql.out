-- Automatically generated by SQLQueryTestSuite
-- !query
SET spark.sql.ansi.enabled = true
-- !query schema
struct<key:string,value:string>
-- !query output
spark.sql.ansi.enabled	true


-- !query
SELECT 'Test 1: Builtin function qualification' AS test_name
-- !query schema
struct<test_name:string>
-- !query output
Test 1: Builtin function qualification


-- !query
SELECT abs(-5) AS unqualified
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`abs`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 14,
    "fragment" : "abs(-5)"
  } ]
}


-- !query
SELECT builtin.abs(-5) AS schema_qualified
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`builtin`.`abs`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "builtin.abs(-5)"
  } ]
}


-- !query
SELECT system.builtin.abs(-5) AS fully_qualified
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "REQUIRES_SINGLE_PART_NAMESPACE",
  "sqlState" : "42K05",
  "messageParameters" : {
    "namespace" : "`system`.`builtin`",
    "sessionCatalog" : "spark_catalog"
  }
}


-- !query
SELECT BUILTIN.ABS(-5) AS uppercase
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`BUILTIN`.`ABS`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "BUILTIN.ABS(-5)"
  } ]
}


-- !query
SELECT System.Builtin.Abs(-5) AS mixed_case
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "REQUIRES_SINGLE_PART_NAMESPACE",
  "sqlState" : "42K05",
  "messageParameters" : {
    "namespace" : "`System`.`Builtin`",
    "sessionCatalog" : "spark_catalog"
  }
}


-- !query
SELECT 'Test 2: Temporary function without shadowing' AS test_name
-- !query schema
struct<test_name:string>
-- !query output
Test 2: Temporary function without shadowing


-- !query
CREATE TEMPORARY FUNCTION my_temp_upper() RETURNS STRING RETURN 'UPPERCASE'
-- !query schema
struct<>
-- !query output



-- !query
SELECT my_temp_upper() AS unqualified
-- !query schema
struct<unqualified:string>
-- !query output
UPPERCASE


-- !query
SELECT session.my_temp_upper() AS schema_qualified
-- !query schema
struct<schema_qualified:string>
-- !query output
UPPERCASE


-- !query
SELECT system.session.my_temp_upper() AS fully_qualified
-- !query schema
struct<fully_qualified:string>
-- !query output
UPPERCASE


-- !query
SELECT SESSION.my_temp_upper() AS uppercase
-- !query schema
struct<uppercase:string>
-- !query output
UPPERCASE


-- !query
SELECT System.Session.my_temp_upper() AS mixed_case
-- !query schema
struct<mixed_case:string>
-- !query output
UPPERCASE


-- !query
DROP TEMPORARY FUNCTION my_temp_upper
-- !query schema
struct<>
-- !query output



-- !query
SELECT 'Test 3: Temporary function shadows builtin' AS test_name
-- !query schema
struct<test_name:string>
-- !query output
Test 3: Temporary function shadows builtin


-- !query
SELECT abs(-10) AS builtin_before
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`abs`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 15,
    "fragment" : "abs(-10)"
  } ]
}


-- !query
CREATE TEMPORARY FUNCTION my_abs(x INT) RETURNS INT RETURN x * 100
-- !query schema
struct<>
-- !query output



-- !query
SELECT my_abs(-10) AS unqualified_shadowed
-- !query schema
struct<unqualified_shadowed:int>
-- !query output
-1000


-- !query
SELECT builtin.abs(-10) AS builtin_still_works
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`builtin`.`abs`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 23,
    "fragment" : "builtin.abs(-10)"
  } ]
}


-- !query
SELECT system.builtin.abs(-10) AS builtin_fully_qualified
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "REQUIRES_SINGLE_PART_NAMESPACE",
  "sqlState" : "42K05",
  "messageParameters" : {
    "namespace" : "`system`.`builtin`",
    "sessionCatalog" : "spark_catalog"
  }
}


-- !query
DROP TEMPORARY FUNCTION my_abs
-- !query schema
struct<>
-- !query output



-- !query
SELECT abs(-10) AS builtin_after
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`abs`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 15,
    "fragment" : "abs(-10)"
  } ]
}


-- !query
SELECT 'Test 4: Multiple builtin functions' AS test_name
-- !query schema
struct<test_name:string>
-- !query output
Test 4: Multiple builtin functions


-- !query
SELECT
  builtin.abs(-5) AS abs_result,
  builtin.upper('hello') AS upper_result,
  builtin.length('test') AS length_result,
  builtin.round(3.14159, 2) AS round_result
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`builtin`.`abs`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 24,
    "fragment" : "builtin.abs(-5)"
  } ]
}


-- !query
SELECT 'Test 5: Temp and builtin registries are separate' AS test_name
-- !query schema
struct<test_name:string>
-- !query output
Test 5: Temp and builtin registries are separate


-- !query
CREATE TEMPORARY FUNCTION my_custom(s STRING) RETURNS STRING RETURN CONCAT('CUSTOM: ', s)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.NoSuchFunctionException
{
  "errorClass" : "ROUTINE_NOT_FOUND",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`default`.`CONCAT`"
  }
}


-- !query
SELECT
  my_custom('test') AS temp_func,
  builtin.abs(-20) AS builtin_func,
  session.my_custom('test') AS temp_qualified
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`my_custom`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 26,
    "fragment" : "my_custom('test')"
  } ]
}


-- !query
DROP TEMPORARY FUNCTION my_custom
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.NoSuchTempFunctionException
{
  "errorClass" : "ROUTINE_NOT_FOUND",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`my_custom`"
  }
}


-- !query
SET spark.sql.ansi.enabled = false
-- !query schema
struct<key:string,value:string>
-- !query output
spark.sql.ansi.enabled	false
