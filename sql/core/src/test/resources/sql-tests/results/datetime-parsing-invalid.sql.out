-- Automatically generated by SQLQueryTestSuite
-- !query
select to_timestamp('294248', 'y')
-- !query schema
struct<>
-- !query output
java.lang.ArithmeticException
long overflow


-- !query
select to_timestamp('1', 'yy')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '1' could not be parsed at index 0"
  }
}


-- !query
select to_timestamp('-12', 'yy')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '-12' could not be parsed at index 0"
  }
}


-- !query
select to_timestamp('123', 'yy')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '123' could not be parsed, unparsed text found at index 2"
  }
}


-- !query
select to_timestamp('1', 'yyy')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '1' could not be parsed at index 0"
  }
}


-- !query
select to_timestamp('1234567', 'yyyyyyy')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUpgradeException
{
  "errorClass" : "INCONSISTENT_BEHAVIOR_CROSS_VERSION.DATETIME_PATTERN_RECOGNITION",
  "sqlState" : "42K0B",
  "messageParameters" : {
    "config" : "\"spark.sql.legacy.timeParserPolicy\"",
    "docroot" : "https://spark.apache.org/docs/latest",
    "pattern" : "'yyyyyyy'"
  }
}


-- !query
select to_timestamp('366', 'D')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Invalid date 'DayOfYear 366' as '1970' is not a leap year"
  }
}


-- !query
select to_timestamp('9', 'DD')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '9' could not be parsed at index 0"
  }
}


-- !query
select to_timestamp('366', 'DD')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Invalid date 'DayOfYear 366' as '1970' is not a leap year"
  }
}


-- !query
select to_timestamp('9', 'DDD')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '9' could not be parsed at index 0"
  }
}


-- !query
select to_timestamp('99', 'DDD')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '99' could not be parsed at index 0"
  }
}


-- !query
select to_timestamp('30-365', 'dd-DDD')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Conflict found: Field DayOfMonth 30 differs from DayOfMonth 31 derived from 1970-12-31."
  }
}


-- !query
select to_timestamp('11-365', 'MM-DDD')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Conflict found: Field MonthOfYear 11 differs from MonthOfYear 12 derived from 1970-12-31."
  }
}


-- !query
select to_timestamp('2019-366', 'yyyy-DDD')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '2019-366' could not be parsed: Invalid date 'DayOfYear 366' as '2019' is not a leap year"
  }
}


-- !query
select to_timestamp('12-30-365', 'MM-dd-DDD')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Conflict found: Field DayOfMonth 30 differs from DayOfMonth 31 derived from 1970-12-31."
  }
}


-- !query
select to_timestamp('2020-01-365', 'yyyy-dd-DDD')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '2020-01-365' could not be parsed: Conflict found: Field DayOfMonth 30 differs from DayOfMonth 1 derived from 2020-12-30"
  }
}


-- !query
select to_timestamp('2020-10-350', 'yyyy-MM-DDD')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '2020-10-350' could not be parsed: Conflict found: Field MonthOfYear 12 differs from MonthOfYear 10 derived from 2020-12-15"
  }
}


-- !query
select to_timestamp('2020-11-31-366', 'yyyy-MM-dd-DDD')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '2020-11-31-366' could not be parsed: Invalid date 'NOVEMBER 31'"
  }
}


-- !query
select from_csv('2018-366', 'date Date', map('dateFormat', 'yyyy-DDD'))
-- !query schema
struct<from_csv(2018-366):struct<date:date>>
-- !query output
{"date":null}


-- !query
select to_date("2020-01-27T20:06:11.847", "yyyy-MM-dd HH:mm:ss.SSS")
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '2020-01-27T20:06:11.847' could not be parsed at index 10"
  }
}


-- !query
select to_date("Unparseable", "yyyy-MM-dd HH:mm:ss.SSS")
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text 'Unparseable' could not be parsed at index 0"
  }
}


-- !query
select to_timestamp("2020-01-27T20:06:11.847", "yyyy-MM-dd HH:mm:ss.SSS")
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '2020-01-27T20:06:11.847' could not be parsed at index 10"
  }
}


-- !query
select to_timestamp("Unparseable", "yyyy-MM-dd HH:mm:ss.SSS")
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text 'Unparseable' could not be parsed at index 0"
  }
}


-- !query
select unix_timestamp("2020-01-27T20:06:11.847", "yyyy-MM-dd HH:mm:ss.SSS")
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '2020-01-27T20:06:11.847' could not be parsed at index 10"
  }
}


-- !query
select unix_timestamp("Unparseable", "yyyy-MM-dd HH:mm:ss.SSS")
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text 'Unparseable' could not be parsed at index 0"
  }
}


-- !query
select to_unix_timestamp("2020-01-27T20:06:11.847", "yyyy-MM-dd HH:mm:ss.SSS")
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text '2020-01-27T20:06:11.847' could not be parsed at index 10"
  }
}


-- !query
select to_unix_timestamp("Unparseable", "yyyy-MM-dd HH:mm:ss.SSS")
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "message" : "Text 'Unparseable' could not be parsed at index 0"
  }
}


-- !query
select cast("Unparseable" as timestamp)
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'Unparseable'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 39,
    "fragment" : "cast(\"Unparseable\" as timestamp)"
  } ]
}


-- !query
select cast("Unparseable" as date)
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'Unparseable'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 34,
    "fragment" : "cast(\"Unparseable\" as date)"
  } ]
}
