-- Automatically generated by SQLQueryTestSuite
-- !query
SELECT CEIL(2.5, 0)
-- !query schema
struct<ceil(2.5, 0):decimal(2,0)>
-- !query output
3


-- !query
SELECT CEIL(3.5, 0)
-- !query schema
struct<ceil(3.5, 0):decimal(2,0)>
-- !query output
4


-- !query
SELECT CEIL(-2.5, 0)
-- !query schema
struct<ceil(-2.5, 0):decimal(2,0)>
-- !query output
-2


-- !query
SELECT CEIL(-3.5, 0)
-- !query schema
struct<ceil(-3.5, 0):decimal(2,0)>
-- !query output
-3


-- !query
SELECT CEIL(-0.35, 1)
-- !query schema
struct<ceil(-0.35, 1):decimal(2,1)>
-- !query output
-0.3


-- !query
SELECT CEIL(-35, -1)
-- !query schema
struct<ceil(-35, -1):decimal(11,0)>
-- !query output
-30


-- !query
SELECT CEIL(-0.1, 0)
-- !query schema
struct<ceil(-0.1, 0):decimal(1,0)>
-- !query output
0


-- !query
SELECT CEIL(5, 0)
-- !query schema
struct<ceil(5, 0):decimal(11,0)>
-- !query output
5


-- !query
SELECT CEIL(3.14115, -3)
-- !query schema
struct<ceil(3.14115, -3):decimal(4,0)>
-- !query output
1000


-- !query
SELECT CEIL(9.9, 0)
-- !query schema
struct<ceil(9.9, 0):decimal(2,0)>
-- !query output
10


-- !query
SELECT CEIL(CAST(99 AS DECIMAL(2, 0)), -1)
-- !query schema
struct<ceil(CAST(99 AS DECIMAL(2,0)), -1):decimal(3,0)>
-- !query output
100


-- !query
SELECT CEIL(2.5, null)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1100",
  "messageParameters" : {
    "argName" : "scale",
    "funcName" : "ceil",
    "requiredType" : "int"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "CEIL(2.5, null)"
  } ]
}


-- !query
SELECT CEIL(2.5, 'a')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1100",
  "messageParameters" : {
    "argName" : "scale",
    "funcName" : "ceil",
    "requiredType" : "int"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 21,
    "fragment" : "CEIL(2.5, 'a')"
  } ]
}


-- !query
SELECT CEIL(2.5, 0, 0)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS",
  "messageParameters" : {
    "actualNum" : "3",
    "expectedNum" : "2",
    "functionName" : "`ceil`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "CEIL(2.5, 0, 0)"
  } ]
}


-- !query
SELECT FLOOR(2.5, 0)
-- !query schema
struct<floor(2.5, 0):decimal(2,0)>
-- !query output
2


-- !query
SELECT FLOOR(3.5, 0)
-- !query schema
struct<floor(3.5, 0):decimal(2,0)>
-- !query output
3


-- !query
SELECT FLOOR(-2.5, 0)
-- !query schema
struct<floor(-2.5, 0):decimal(2,0)>
-- !query output
-3


-- !query
SELECT FLOOR(-3.5, 0)
-- !query schema
struct<floor(-3.5, 0):decimal(2,0)>
-- !query output
-4


-- !query
SELECT FLOOR(-0.35, 1)
-- !query schema
struct<floor(-0.35, 1):decimal(2,1)>
-- !query output
-0.4


-- !query
SELECT FLOOR(-35, -1)
-- !query schema
struct<floor(-35, -1):decimal(11,0)>
-- !query output
-40


-- !query
SELECT FLOOR(-0.1, 0)
-- !query schema
struct<floor(-0.1, 0):decimal(1,0)>
-- !query output
-1


-- !query
SELECT FLOOR(5, 0)
-- !query schema
struct<floor(5, 0):decimal(11,0)>
-- !query output
5


-- !query
SELECT FLOOR(3.14115, -3)
-- !query schema
struct<floor(3.14115, -3):decimal(4,0)>
-- !query output
0


-- !query
SELECT FLOOR(-9.9, 0)
-- !query schema
struct<floor(-9.9, 0):decimal(2,0)>
-- !query output
-10


-- !query
SELECT FLOOR(CAST(-99 AS DECIMAL(2, 0)), -1)
-- !query schema
struct<floor(CAST(-99 AS DECIMAL(2,0)), -1):decimal(3,0)>
-- !query output
-100


-- !query
SELECT FLOOR(2.5, null)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1100",
  "messageParameters" : {
    "argName" : "scale",
    "funcName" : "floor",
    "requiredType" : "int"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 23,
    "fragment" : "FLOOR(2.5, null)"
  } ]
}


-- !query
SELECT FLOOR(2.5, 'a')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1100",
  "messageParameters" : {
    "argName" : "scale",
    "funcName" : "floor",
    "requiredType" : "int"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "FLOOR(2.5, 'a')"
  } ]
}


-- !query
SELECT FLOOR(2.5, 0, 0)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS",
  "messageParameters" : {
    "actualNum" : "3",
    "expectedNum" : "2",
    "functionName" : "`floor`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 23,
    "fragment" : "FLOOR(2.5, 0, 0)"
  } ]
}
