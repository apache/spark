-- Automatically generated by SQLQueryTestSuite
-- !query
SET hivevar:colname = 'c'
-- !query schema
struct<key:string,value:string>
-- !query output
hivevar:colname	'c'


-- !query
SELECT IDENTIFIER(${colname} || '_1') FROM VALUES(1) AS T(c_1)
-- !query schema
struct<c_1:int>
-- !query output
1


-- !query
SELECT IDENTIFIER('c1') FROM VALUES(1) AS T(c1)
-- !query schema
struct<c1:int>
-- !query output
1


-- !query
SELECT IDENTIFIER('t.c1') FROM VALUES(1) AS T(c1)
-- !query schema
struct<c1:int>
-- !query output
1


-- !query
SELECT IDENTIFIER('`t`.c1') FROM VALUES(1) AS T(c1)
-- !query schema
struct<c1:int>
-- !query output
1


-- !query
SELECT IDENTIFIER('`c 1`') FROM VALUES(1) AS T(`c 1`)
-- !query schema
struct<c 1:int>
-- !query output
1


-- !query
SELECT IDENTIFIER('``') FROM VALUES(1) AS T(``)
-- !query schema
struct<:int>
-- !query output
1


-- !query
SELECT IDENTIFIER('c' || '1') FROM VALUES(1) AS T(c1)
-- !query schema
struct<c1:int>
-- !query output
1


-- !query
CREATE SCHEMA IF NOT EXISTS s
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE s.tab(c1 INT) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
USE SCHEMA s
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO IDENTIFIER('ta' || 'b') VALUES(1)
-- !query schema
struct<>
-- !query output



-- !query
DELETE FROM IDENTIFIER('ta' || 'b') WHERE 1=0
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_FEATURE.TABLE_OPERATION",
  "sqlState" : "0A000",
  "messageParameters" : {
    "operation" : "DELETE",
    "tableName" : "`spark_catalog`.`s`.`tab`"
  }
}


-- !query
UPDATE IDENTIFIER('ta' || 'b') SET c1 = 2
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUnsupportedOperationException
{
  "errorClass" : "UNSUPPORTED_FEATURE.TABLE_OPERATION",
  "sqlState" : "0A000",
  "messageParameters" : {
    "operation" : "UPDATE TABLE",
    "tableName" : "`spark_catalog`.`s`.`tab`"
  }
}


-- !query
MERGE INTO IDENTIFIER('ta' || 'b') AS t USING IDENTIFIER('ta' || 'b') AS s ON s.c1 = t.c1
  WHEN MATCHED THEN UPDATE SET c1 = 3
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUnsupportedOperationException
{
  "errorClass" : "UNSUPPORTED_FEATURE.TABLE_OPERATION",
  "sqlState" : "0A000",
  "messageParameters" : {
    "operation" : "MERGE INTO TABLE",
    "tableName" : "`spark_catalog`.`s`.`tab`"
  }
}


-- !query
SELECT * FROM IDENTIFIER('tab')
-- !query schema
struct<c1:int>
-- !query output
1


-- !query
SELECT * FROM IDENTIFIER('s.tab')
-- !query schema
struct<c1:int>
-- !query output
1


-- !query
SELECT * FROM IDENTIFIER('`s`.`tab`')
-- !query schema
struct<c1:int>
-- !query output
1


-- !query
SELECT * FROM IDENTIFIER('t' || 'a' || 'b')
-- !query schema
struct<c1:int>
-- !query output
1


-- !query
USE SCHEMA default
-- !query schema
struct<>
-- !query output



-- !query
DROP TABLE s.tab
-- !query schema
struct<>
-- !query output



-- !query
DROP SCHEMA s
-- !query schema
struct<>
-- !query output



-- !query
SELECT IDENTIFIER('COAL' || 'ESCE')(NULL, 1)
-- !query schema
struct<coalesce(NULL, 1):int>
-- !query output
1


-- !query
SELECT IDENTIFIER('abs')(c1) FROM VALUES(-1) AS T(c1)
-- !query schema
struct<abs(c1):int>
-- !query output
1


-- !query
SELECT * FROM IDENTIFIER('ra' || 'nge')(0, 1)
-- !query schema
struct<id:bigint>
-- !query output
0


-- !query
CREATE TABLE IDENTIFIER('tab')(c1 INT) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
DROP TABLE IF EXISTS IDENTIFIER('ta' || 'b')
-- !query schema
struct<>
-- !query output



-- !query
CREATE SCHEMA identifier_clauses
-- !query schema
struct<>
-- !query output



-- !query
USE identifier_clauses
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE IDENTIFIER('ta' || 'b')(c1 INT) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
DROP TABLE IF EXISTS IDENTIFIER('identifier_clauses.' || 'tab')
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE IDENTIFIER('identifier_clauses.' || 'tab')(c1 INT) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
REPLACE TABLE IDENTIFIER('identifier_clauses.' || 'tab')(c1 INT) USING CSV
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_FEATURE.TABLE_OPERATION",
  "sqlState" : "0A000",
  "messageParameters" : {
    "operation" : "REPLACE TABLE",
    "tableName" : "`spark_catalog`.`identifier_clauses`.`tab`"
  }
}


-- !query
CACHE TABLE IDENTIFIER('ta' || 'b')
-- !query schema
struct<>
-- !query output



-- !query
UNCACHE TABLE IDENTIFIER('ta' || 'b')
-- !query schema
struct<>
-- !query output



-- !query
DROP TABLE IF EXISTS IDENTIFIER('ta' || 'b')
-- !query schema
struct<>
-- !query output



-- !query
USE default
-- !query schema
struct<>
-- !query output



-- !query
DROP SCHEMA identifier_clauses
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE tab(c1 INT) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO tab VALUES (1)
-- !query schema
struct<>
-- !query output



-- !query
SELECT c1 FROM tab
-- !query schema
struct<c1:int>
-- !query output
1


-- !query
DESCRIBE IDENTIFIER('ta' || 'b')
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
c1                  	int


-- !query
ANALYZE TABLE IDENTIFIER('ta' || 'b') COMPUTE STATISTICS
-- !query schema
struct<>
-- !query output



-- !query
ALTER TABLE IDENTIFIER('ta' || 'b') ADD COLUMN c2 INT
-- !query schema
struct<>
-- !query output



-- !query
SHOW TBLPROPERTIES IDENTIFIER('ta' || 'b')
-- !query schema
struct<key:string,value:string>
-- !query output



-- !query
SHOW COLUMNS FROM IDENTIFIER('ta' || 'b')
-- !query schema
struct<col_name:string>
-- !query output
c1
c2


-- !query
COMMENT ON TABLE IDENTIFIER('ta' || 'b') IS 'hello'
-- !query schema
struct<>
-- !query output



-- !query
REFRESH TABLE IDENTIFIER('ta' || 'b')
-- !query schema
struct<>
-- !query output



-- !query
REPAIR TABLE IDENTIFIER('ta' || 'b')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NOT_A_PARTITIONED_TABLE",
  "sqlState" : "42809",
  "messageParameters" : {
    "operation" : "MSCK REPAIR TABLE",
    "tableIdentWithDB" : "`spark_catalog`.`default`.`tab`"
  }
}


-- !query
TRUNCATE TABLE IDENTIFIER('ta' || 'b')
-- !query schema
struct<>
-- !query output



-- !query
DROP TABLE IF EXISTS tab
-- !query schema
struct<>
-- !query output



-- !query
CREATE OR REPLACE VIEW IDENTIFIER('v')(c1) AS VALUES(1)
-- !query schema
struct<>
-- !query output



-- !query
SELECT * FROM v
-- !query schema
struct<c1:int>
-- !query output
1


-- !query
ALTER VIEW IDENTIFIER('v') AS VALUES(2)
-- !query schema
struct<>
-- !query output



-- !query
DROP VIEW IDENTIFIER('v')
-- !query schema
struct<>
-- !query output



-- !query
CREATE TEMPORARY VIEW IDENTIFIER('v')(c1) AS VALUES(1)
-- !query schema
struct<>
-- !query output



-- !query
DROP VIEW IDENTIFIER('v')
-- !query schema
struct<>
-- !query output



-- !query
CREATE SCHEMA IDENTIFIER('id' || 'ent')
-- !query schema
struct<>
-- !query output



-- !query
ALTER SCHEMA IDENTIFIER('id' || 'ent') SET PROPERTIES (somekey = 'somevalue')
-- !query schema
struct<>
-- !query output



-- !query
ALTER SCHEMA IDENTIFIER('id' || 'ent') SET LOCATION 'someloc'
-- !query schema
struct<>
-- !query output



-- !query
COMMENT ON SCHEMA IDENTIFIER('id' || 'ent') IS 'some comment'
-- !query schema
struct<>
-- !query output



-- !query
DESCRIBE SCHEMA IDENTIFIER('id' || 'ent')
-- !query schema
struct<info_name:string,info_value:string>
-- !query output
Catalog Name	spark_catalog
Comment	some comment
Location [not included in comparison]/{warehouse_dir}/someloc
Namespace Name	ident
Owner	[not included in comparison]


-- !query
SHOW TABLES IN IDENTIFIER('id' || 'ent')
-- !query schema
struct<namespace:string,tableName:string,isTemporary:boolean>
-- !query output



-- !query
SHOW TABLE EXTENDED IN IDENTIFIER('id' || 'ent') LIKE 'hello'
-- !query schema
struct<namespace:string,tableName:string,isTemporary:boolean,information:string>
-- !query output



-- !query
USE IDENTIFIER('id' || 'ent')
-- !query schema
struct<>
-- !query output



-- !query
SHOW CURRENT SCHEMA
-- !query schema
struct<catalog:string,namespace:string>
-- !query output
spark_catalog	ident


-- !query
USE SCHEMA IDENTIFIER('id' || 'ent')
-- !query schema
struct<>
-- !query output



-- !query
USE SCHEMA default
-- !query schema
struct<>
-- !query output



-- !query
DROP SCHEMA IDENTIFIER('id' || 'ent')
-- !query schema
struct<>
-- !query output



-- !query
CREATE SCHEMA ident
-- !query schema
struct<>
-- !query output



-- !query
CREATE FUNCTION IDENTIFIER('ident.' || 'myDoubleAvg') AS 'test.org.apache.spark.sql.MyDoubleAvg'
-- !query schema
struct<>
-- !query output



-- !query
DESCRIBE FUNCTION IDENTIFIER('ident.' || 'myDoubleAvg')
-- !query schema
struct<function_desc:string>
-- !query output
Class: test.org.apache.spark.sql.MyDoubleAvg
Function: spark_catalog.ident.mydoubleavg
Usage: N/A.


-- !query
REFRESH FUNCTION IDENTIFIER('ident.' || 'myDoubleAvg')
-- !query schema
struct<>
-- !query output



-- !query
DROP FUNCTION IDENTIFIER('ident.' || 'myDoubleAvg')
-- !query schema
struct<>
-- !query output



-- !query
DROP SCHEMA ident
-- !query schema
struct<>
-- !query output



-- !query
CREATE TEMPORARY FUNCTION IDENTIFIER('my' || 'DoubleAvg') AS 'test.org.apache.spark.sql.MyDoubleAvg'
-- !query schema
struct<>
-- !query output



-- !query
DROP TEMPORARY FUNCTION IDENTIFIER('my' || 'DoubleAvg')
-- !query schema
struct<>
-- !query output



-- !query
DECLARE var = 'sometable'
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE IDENTIFIER(var)(c1 INT) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
SET VAR var = 'c1'
-- !query schema
struct<>
-- !query output



-- !query
SELECT IDENTIFIER(var) FROM VALUES(1) AS T(c1)
-- !query schema
struct<c1:int>
-- !query output
1


-- !query
SET VAR var = 'some'
-- !query schema
struct<>
-- !query output



-- !query
DROP TABLE IDENTIFIER(var || 'table')
-- !query schema
struct<>
-- !query output



-- !query
SELECT IDENTIFIER('c 1') FROM VALUES(1) AS T(`c 1`)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'1'",
    "hint" : ": extra input '1'"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 24,
    "fragment" : "IDENTIFIER('c 1')"
  } ]
}


-- !query
SELECT IDENTIFIER('') FROM VALUES(1) AS T(``)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_EMPTY_STATEMENT",
  "sqlState" : "42617",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 21,
    "fragment" : "IDENTIFIER('')"
  } ]
}


-- !query
VALUES(IDENTIFIER(CAST(NULL AS STRING)))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NOT_A_CONSTANT_STRING.NULL",
  "sqlState" : "42601",
  "messageParameters" : {
    "expr" : "CAST(NULL AS STRING)",
    "name" : "IDENTIFIER"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 19,
    "stopIndex" : 38,
    "fragment" : "CAST(NULL AS STRING)"
  } ]
}


-- !query
VALUES(IDENTIFIER(1))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NOT_A_CONSTANT_STRING.WRONG_TYPE",
  "sqlState" : "42601",
  "messageParameters" : {
    "dataType" : "int",
    "expr" : "1",
    "name" : "IDENTIFIER"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 19,
    "stopIndex" : 19,
    "fragment" : "1"
  } ]
}


-- !query
VALUES(IDENTIFIER(SUBSTR('HELLO', 1, RAND() + 1)))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NOT_A_CONSTANT_STRING.NOT_CONSTANT",
  "sqlState" : "42601",
  "messageParameters" : {
    "expr" : "substr('HELLO', 1, CAST((rand() + CAST(1 AS DOUBLE)) AS INT))",
    "name" : "IDENTIFIER"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 19,
    "stopIndex" : 48,
    "fragment" : "SUBSTR('HELLO', 1, RAND() + 1)"
  } ]
}


-- !query
SELECT `IDENTIFIER`('abs')(c1) FROM VALUES(-1) AS T(c1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`IDENTIFIER`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 26,
    "fragment" : "`IDENTIFIER`('abs')"
  } ]
}


-- !query
CREATE TABLE t(col1 INT)
-- !query schema
struct<>
-- !query output



-- !query
SELECT * FROM IDENTIFIER((SELECT 't'))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "NOT_A_CONSTANT_STRING.NOT_CONSTANT",
  "sqlState" : "42601",
  "messageParameters" : {
    "expr" : "scalarsubquery()",
    "name" : "IDENTIFIER"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 26,
    "stopIndex" : 37,
    "fragment" : "(SELECT 't')"
  } ]
}


-- !query
SELECT * FROM (SELECT IDENTIFIER((SELECT 'col1')) FROM IDENTIFIER((SELECT 't')))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "NOT_A_CONSTANT_STRING.NOT_CONSTANT",
  "sqlState" : "42601",
  "messageParameters" : {
    "expr" : "scalarsubquery()",
    "name" : "IDENTIFIER"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 67,
    "stopIndex" : 78,
    "fragment" : "(SELECT 't')"
  } ]
}


-- !query
SELECT IDENTIFIER((SELECT 'col1')) FROM VALUES(1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NOT_A_CONSTANT_STRING.NOT_CONSTANT",
  "sqlState" : "42601",
  "messageParameters" : {
    "expr" : "scalarsubquery()",
    "name" : "IDENTIFIER"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 19,
    "stopIndex" : 33,
    "fragment" : "(SELECT 'col1')"
  } ]
}


-- !query
SELECT col1, IDENTIFIER((SELECT col1)) FROM VALUES(1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NOT_A_CONSTANT_STRING.NOT_CONSTANT",
  "sqlState" : "42601",
  "messageParameters" : {
    "expr" : "scalarsubquery(col1)",
    "name" : "IDENTIFIER"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 25,
    "stopIndex" : 37,
    "fragment" : "(SELECT col1)"
  } ]
}


-- !query
SELECT IDENTIFIER((SELECT 'col1', 'col2')) FROM VALUES(1,2)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "UNSUPPORTED_TYPED_LITERAL",
  "sqlState" : "0A000",
  "messageParameters" : {
    "supportedTypes" : "\"DATE\", \"TIMESTAMP_NTZ\", \"TIMESTAMP_LTZ\", \"TIMESTAMP\", \"INTERVAL\", \"X\", \"TIME\"",
    "unsupportedType" : "\"SELECT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 20,
    "stopIndex" : 32,
    "fragment" : "SELECT 'col1'"
  } ]
}


-- !query
DROP TABLE t
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE IDENTIFIER(1)(c1 INT) USING csv
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NOT_A_CONSTANT_STRING.WRONG_TYPE",
  "sqlState" : "42601",
  "messageParameters" : {
    "dataType" : "int",
    "expr" : "1",
    "name" : "IDENTIFIER"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 25,
    "stopIndex" : 25,
    "fragment" : "1"
  } ]
}


-- !query
CREATE TABLE IDENTIFIER('a.b.c')(c1 INT) USING csv
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "REQUIRES_SINGLE_PART_NAMESPACE",
  "sqlState" : "42K05",
  "messageParameters" : {
    "namespace" : "`a`.`b`",
    "sessionCatalog" : "spark_catalog"
  }
}


-- !query
CREATE VIEW IDENTIFIER('a.b.c')(c1) AS VALUES(1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "REQUIRES_SINGLE_PART_NAMESPACE",
  "sqlState" : "42K05",
  "messageParameters" : {
    "namespace" : "`a`.`b`",
    "sessionCatalog" : "spark_catalog"
  }
}


-- !query
DROP TABLE IDENTIFIER('a.b.c')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "REQUIRES_SINGLE_PART_NAMESPACE",
  "sqlState" : "42K05",
  "messageParameters" : {
    "namespace" : "`a`.`b`",
    "sessionCatalog" : "spark_catalog"
  }
}


-- !query
DROP VIEW IDENTIFIER('a.b.c')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "REQUIRES_SINGLE_PART_NAMESPACE",
  "sqlState" : "42K05",
  "messageParameters" : {
    "namespace" : "`a`.`b`",
    "sessionCatalog" : "spark_catalog"
  }
}


-- !query
COMMENT ON TABLE IDENTIFIER('a.b.c.d') IS 'hello'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "REQUIRES_SINGLE_PART_NAMESPACE",
  "sqlState" : "42K05",
  "messageParameters" : {
    "namespace" : "`a`.`b`.`c`",
    "sessionCatalog" : "spark_catalog"
  }
}


-- !query
VALUES(IDENTIFIER(1)())
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NOT_A_CONSTANT_STRING.WRONG_TYPE",
  "sqlState" : "42601",
  "messageParameters" : {
    "dataType" : "int",
    "expr" : "1",
    "name" : "IDENTIFIER"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 19,
    "stopIndex" : 19,
    "fragment" : "1"
  } ]
}


-- !query
VALUES(IDENTIFIER('a.b.c.d')())
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "REQUIRES_SINGLE_PART_NAMESPACE",
  "sqlState" : "42K05",
  "messageParameters" : {
    "namespace" : "`a`.`b`.`c`",
    "sessionCatalog" : "spark_catalog"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "IDENTIFIER('a.b.c.d')()"
  } ]
}


-- !query
CREATE TEMPORARY FUNCTION IDENTIFIER('default.my' || 'DoubleAvg') AS 'test.org.apache.spark.sql.MyDoubleAvg'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_SQL_SYNTAX.CREATE_TEMP_FUNC_WITH_DATABASE",
  "sqlState" : "42000",
  "messageParameters" : {
    "database" : "`default`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 108,
    "fragment" : "CREATE TEMPORARY FUNCTION IDENTIFIER('default.my' || 'DoubleAvg') AS 'test.org.apache.spark.sql.MyDoubleAvg'"
  } ]
}


-- !query
DROP TEMPORARY FUNCTION IDENTIFIER('default.my' || 'DoubleAvg')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_SQL_SYNTAX.MULTI_PART_NAME",
  "sqlState" : "42000",
  "messageParameters" : {
    "name" : "`default`.`myDoubleAvg`",
    "statement" : "DROP TEMPORARY FUNCTION"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 63,
    "fragment" : "DROP TEMPORARY FUNCTION IDENTIFIER('default.my' || 'DoubleAvg')"
  } ]
}


-- !query
CREATE TEMPORARY VIEW IDENTIFIER('default.v')(c1) AS VALUES(1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "TEMP_VIEW_NAME_TOO_MANY_NAME_PARTS",
  "sqlState" : "428EK",
  "messageParameters" : {
    "actualName" : "`default`.`v`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 62,
    "fragment" : "CREATE TEMPORARY VIEW IDENTIFIER('default.v')(c1) AS VALUES(1)"
  } ]
}


-- !query
create temporary view identifier('v1') as (select my_col from (values (1), (2), (1) as (my_col)) group by 1)
-- !query schema
struct<>
-- !query output



-- !query
cache table identifier('t1') as (select my_col from (values (1), (2), (1) as (my_col)) group by 1)
-- !query schema
struct<>
-- !query output



-- !query
create table identifier('t2') using csv as (select my_col from (values (1), (2), (1) as (my_col)) group by 1)
-- !query schema
struct<>
-- !query output



-- !query
insert into identifier('t2') select my_col from (values (3) as (my_col)) group by 1
-- !query schema
struct<>
-- !query output



-- !query
drop view v1
-- !query schema
struct<>
-- !query output



-- !query
drop table t1
-- !query schema
struct<>
-- !query output



-- !query
drop table t2
-- !query schema
struct<>
-- !query output



-- !query
DECLARE agg = 'max'
-- !query schema
struct<>
-- !query output



-- !query
DECLARE col = 'c1'
-- !query schema
struct<>
-- !query output



-- !query
DECLARE tab = 'T'
-- !query schema
struct<>
-- !query output



-- !query
WITH S(c1, c2) AS (VALUES(1, 2), (2, 3)),
     T(c1, c2) AS (VALUES ('a', 'b'), ('c', 'd'))
SELECT IDENTIFIER(agg)(IDENTIFIER(col)) FROM IDENTIFIER(tab)
-- !query schema
struct<max(c1):string>
-- !query output
c


-- !query
WITH S(c1, c2) AS (VALUES(1, 2), (2, 3)),
     T(c1, c2) AS (VALUES ('a', 'b'), ('c', 'd'))
SELECT IDENTIFIER('max')(IDENTIFIER('c1')) FROM IDENTIFIER('T')
-- !query schema
struct<max(c1):string>
-- !query output
c


-- !query
WITH ABC(c1, c2) AS (VALUES(1, 2), (2, 3))
SELECT IDENTIFIER('max')(IDENTIFIER('c1')) FROM IDENTIFIER('A' || 'BC')
-- !query schema
struct<max(c1):int>
-- !query output
2


-- !query
SELECT row_number() OVER IDENTIFIER('x.win') FROM VALUES(1) AS T(c1) WINDOW win AS (ORDER BY c1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "''x.win''",
    "hint" : ""
  }
}


-- !query
SELECT T1.c1 FROM VALUES(1) AS T1(c1) JOIN VALUES(1) AS T2(c1) USING (IDENTIFIER('c1'))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT IDENTIFIER('t').c1 FROM VALUES(1) AS T(c1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNRESOLVED_COLUMN.WITH_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`t`",
    "proposal" : "`c1`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "IDENTIFIER('t')"
  } ]
}


-- !query
SELECT map('a', 1).IDENTIFIER('a') FROM VALUES(1) AS T(c1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "''a''",
    "hint" : ""
  }
}


-- !query
SELECT named_struct('a', 1).IDENTIFIER('a') FROM VALUES(1) AS T(c1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "''a''",
    "hint" : ""
  }
}


-- !query
SELECT * FROM s.IDENTIFIER('tab')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT * FROM IDENTIFIER('s').IDENTIFIER('tab')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'IDENTIFIER'",
    "hint" : ""
  }
}


-- !query
SELECT * FROM IDENTIFIER('s').tab
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'IDENTIFIER'",
    "hint" : ""
  }
}


-- !query
SELECT row_number() OVER IDENTIFIER('win') FROM VALUES(1) AS T(c1) WINDOW win AS (ORDER BY c1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "''win''",
    "hint" : ""
  }
}


-- !query
SELECT row_number() OVER win FROM VALUES(1) AS T(c1) WINDOW IDENTIFIER('win') AS (ORDER BY c1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ": missing 'AS'"
  }
}


-- !query
SELECT 1 AS IDENTIFIER('col1')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT my_table.* FROM VALUES (1, 2) AS IDENTIFIER('my_table')(IDENTIFIER('c1'), IDENTIFIER('c2'))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "''my_table''",
    "hint" : ""
  }
}


-- !query
WITH identifier('v')(identifier('c1')) AS (VALUES(1)) (SELECT c1 FROM v)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "''v''",
    "hint" : ""
  }
}


-- !query
CREATE OR REPLACE VIEW v(IDENTIFIER('c1')) AS VALUES(1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT c1 FROM v
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`v`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 16,
    "stopIndex" : 16,
    "fragment" : "v"
  } ]
}


-- !query
DROP VIEW IF EXISTS v
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE tab(IDENTIFIER('c1') INT) USING CSV
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
INSERT INTO tab(IDENTIFIER('c1')) VALUES(1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ": missing ')'"
  }
}


-- !query
SELECT c1 FROM tab
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`tab`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 16,
    "stopIndex" : 18,
    "fragment" : "tab"
  } ]
}


-- !query
ALTER TABLE IDENTIFIER('tab') RENAME COLUMN IDENTIFIER('c1') TO IDENTIFIER('col1')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT col1 FROM tab
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`tab`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 18,
    "stopIndex" : 20,
    "fragment" : "tab"
  } ]
}


-- !query
ALTER TABLE IDENTIFIER('tab') ADD COLUMN IDENTIFIER('c2') INT
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT c2 FROM tab
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`tab`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 16,
    "stopIndex" : 18,
    "fragment" : "tab"
  } ]
}


-- !query
ALTER TABLE IDENTIFIER('tab') DROP COLUMN IDENTIFIER('c2')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
ALTER TABLE IDENTIFIER('tab') RENAME TO IDENTIFIER('tab_renamed')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT * FROM tab_renamed
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`tab_renamed`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 25,
    "fragment" : "tab_renamed"
  } ]
}


-- !query
DROP TABLE IF EXISTS tab_renamed
-- !query schema
struct<>
-- !query output



-- !query
DROP TABLE IF EXISTS tab
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE test_col_with_dot(IDENTIFIER('`col.with.dot`') INT) USING CSV
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
DROP TABLE IF EXISTS test_col_with_dot
-- !query schema
struct<>
-- !query output



-- !query
SELECT * FROM VALUES (1, 2) AS IDENTIFIER('schema.table')(c1, c2)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "''schema.table''",
    "hint" : ""
  }
}


-- !query
SELECT 1 AS IDENTIFIER('col1.col2')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
CREATE SCHEMA identifier_clause_test_schema
-- !query schema
struct<>
-- !query output



-- !query
USE identifier_clause_test_schema
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE test_show(c1 INT, c2 STRING) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
SHOW VIEWS IN IDENTIFIER('identifier_clause_test_schema')
-- !query schema
struct<namespace:string,viewName:string,isTemporary:boolean>
-- !query output



-- !query
SHOW PARTITIONS IDENTIFIER('test_show')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_PARTITION_OPERATION.PARTITION_SCHEMA_IS_EMPTY",
  "sqlState" : "42601",
  "messageParameters" : {
    "name" : "`spark_catalog`.`identifier_clause_test_schema`.`test_show`"
  }
}


-- !query
SHOW CREATE TABLE IDENTIFIER('test_show')
-- !query schema
struct<createtab_stmt:string>
-- !query output
CREATE TABLE spark_catalog.identifier_clause_test_schema.test_show (
  c1 INT,
  c2 STRING)
USING CSV


-- !query
DROP TABLE test_show
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE test_desc(c1 INT) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
DESCRIBE TABLE IDENTIFIER('test_desc')
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
c1                  	int


-- !query
DESCRIBE FORMATTED IDENTIFIER('test_desc')
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
c1                  	int                 	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	identifier_clause_test_schema	                    
Table               	test_desc           	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	MANAGED             	                    
Provider            	CSV                 	                    
Location [not included in comparison]/{warehouse_dir}/identifier_clause_test_schema.db/test_desc


-- !query
DESCRIBE EXTENDED IDENTIFIER('test_desc')
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
c1                  	int                 	                    
                    	                    	                    
# Detailed Table Information	                    	                    
Catalog             	spark_catalog       	                    
Database            	identifier_clause_test_schema	                    
Table               	test_desc           	                    
Created Time [not included in comparison]
Last Access [not included in comparison]
Created By [not included in comparison]
Type                	MANAGED             	                    
Provider            	CSV                 	                    
Location [not included in comparison]/{warehouse_dir}/identifier_clause_test_schema.db/test_desc


-- !query
DESC IDENTIFIER('test_desc')
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
c1                  	int


-- !query
DROP TABLE test_desc
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE test_comment(c1 INT, c2 STRING) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
COMMENT ON TABLE IDENTIFIER('test_comment') IS 'table comment'
-- !query schema
struct<>
-- !query output



-- !query
ALTER TABLE test_comment ALTER COLUMN IDENTIFIER('c1') COMMENT 'column comment'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
DROP TABLE test_comment
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE identifier_clause_test_schema.test_table(c1 INT) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
ANALYZE TABLE IDENTIFIER('identifier_clause_test_schema.test_table') COMPUTE STATISTICS
-- !query schema
struct<>
-- !query output



-- !query
REFRESH TABLE IDENTIFIER('identifier_clause_test_schema.test_table')
-- !query schema
struct<>
-- !query output



-- !query
DESCRIBE IDENTIFIER('identifier_clause_test_schema.test_table')
-- !query schema
struct<col_name:string,data_type:string,comment:string>
-- !query output
c1                  	int


-- !query
SHOW COLUMNS FROM IDENTIFIER('identifier_clause_test_schema.test_table')
-- !query schema
struct<col_name:string>
-- !query output
c1


-- !query
DROP TABLE IDENTIFIER('identifier_clause_test_schema.test_table')
-- !query schema
struct<>
-- !query output



-- !query
DECLARE IDENTIFIER('my_var') = 'value'
-- !query schema
struct<>
-- !query output



-- !query
SET VAR IDENTIFIER('my_var') = 'new_value'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ": missing EQ"
  }
}


-- !query
SELECT IDENTIFIER('my_var')
-- !query schema
struct<variablereference(system.session.my_var='value'):string>
-- !query output
value


-- !query
DROP TEMPORARY VARIABLE IDENTIFIER('my_var')
-- !query schema
struct<>
-- !query output



-- !query
CREATE TEMPORARY FUNCTION test_udf(IDENTIFIER('param1') INT, IDENTIFIER('param2') STRING)
RETURNS INT
RETURN IDENTIFIER('param1') + length(IDENTIFIER('param2'))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT test_udf(5, 'hello')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`test_udf`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`identifier_clause_test_schema`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 27,
    "fragment" : "test_udf(5, 'hello')"
  } ]
}


-- !query
DROP TEMPORARY FUNCTION test_udf
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.NoSuchTempFunctionException
{
  "errorClass" : "ROUTINE_NOT_FOUND",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`test_udf`"
  }
}


-- !query
CREATE TEMPORARY FUNCTION test_table_udf(IDENTIFIER('input_val') INT)
RETURNS TABLE(IDENTIFIER('col1') INT, IDENTIFIER('col2') STRING)
RETURN SELECT IDENTIFIER('input_val'), 'result'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT * FROM test_table_udf(42)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVABLE_TABLE_VALUED_FUNCTION",
  "sqlState" : "42883",
  "messageParameters" : {
    "name" : "`test_table_udf`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 32,
    "fragment" : "test_table_udf(42)"
  } ]
}


-- !query
DROP TEMPORARY FUNCTION test_table_udf
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.NoSuchTempFunctionException
{
  "errorClass" : "ROUTINE_NOT_FOUND",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`test_table_udf`"
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT IDENTIFIER(:tab \'b\').c1 FROM VALUES(1) AS tab(c1)' USING 'ta' AS tab
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_EXTRACT_BASE_FIELD_TYPE",
  "sqlState" : "42000",
  "messageParameters" : {
    "base" : "\"variablereference(system.session.tab='T')\"",
    "other" : "\"STRING\""
  }
}


-- !query
EXECUTE IMMEDIATE 'SELECT IDENTIFIER(:col1 ''.c2'') FROM VALUES(named_struct(''c2'', 42)) AS T(c1)'
  USING 'c1' AS col1
-- !query schema
struct<c1.c2:int>
-- !query output
42


-- !query
CREATE TABLE integration_test(c1 INT, c2 STRING) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO integration_test VALUES (1, 'a'), (2, 'b')
-- !query schema
struct<>
-- !query output



-- !query
EXECUTE IMMEDIATE 'SELECT * FROM IDENTIFIER(:schema ''.'' :table) ORDER BY ALL'
  USING 'identifier_clause_test_schema' AS schema, 'integration_test' AS table
-- !query schema
struct<c1:int,c2:string>
-- !query output
1	a
2	b


-- !query
EXECUTE IMMEDIATE 'SELECT IDENTIFIER(:prefix ''1''), IDENTIFIER(:prefix ''2'') FROM integration_test ORDER BY ALL'
  USING 'c' AS prefix
-- !query schema
struct<c1:int,c2:string>
-- !query output
1	a
2	b


-- !query
EXECUTE IMMEDIATE 'SELECT * FROM integration_test WHERE IDENTIFIER(:col) = :val'
  USING 'c1' AS col, 1 AS val
-- !query schema
struct<c1:int,c2:string>
-- !query output
1	a


-- !query
CREATE TABLE integration_test2(c1 INT, c3 STRING) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO integration_test2 VALUES (1, 'x'), (2, 'y')
-- !query schema
struct<>
-- !query output



-- !query
EXECUTE IMMEDIATE 'SELECT t1.*, t2.* FROM IDENTIFIER(:t1) t1 JOIN IDENTIFIER(:t2) t2 USING (IDENTIFIER(:col)) ORDER BY ALL'
  USING 'integration_test' AS t1, 'integration_test2' AS t2, 'c1' AS col
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  },
  "queryContext" : [ {
    "objectType" : "EXECUTE IMMEDIATE",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 103,
    "fragment" : "SELECT t1.*, t2.* FROM IDENTIFIER(:t1) t1 JOIN IDENTIFIER(:t2) t2 USING (IDENTIFIER(:col)) ORDER BY ALL"
  } ]
}


-- !query
EXECUTE IMMEDIATE
  'SELECT IDENTIFIER(:col1), IDENTIFIER(:col2), row_number() OVER (PARTITION BY IDENTIFIER(:part) ORDER BY IDENTIFIER(:ord)) as rn FROM integration_test'
  USING 'c1' AS col1, 'c2' AS col2, 'c2' AS part, 'c1' AS ord
-- !query schema
struct<c1:int,c2:string,rn:int>
-- !query output
1	a	1
2	b	1


-- !query
EXECUTE IMMEDIATE 'SELECT IDENTIFIER(:prefix ''2''), IDENTIFIER(:agg)(IDENTIFIER(:col)) FROM integration_test GROUP BY IDENTIFIER(:prefix ''2'') ORDER BY ALL'
  USING 'c' AS prefix, 'count' AS agg, 'c1' AS col
-- !query schema
struct<c2:string,count(c1):bigint>
-- !query output
a	1
b	1


-- !query
EXECUTE IMMEDIATE 'SELECT * FROM integration_test ORDER BY IDENTIFIER(:col1) DESC, IDENTIFIER(:col2)'
  USING 'c1' AS col1, 'c2' AS col2
-- !query schema
struct<c1:int,c2:string>
-- !query output
2	b
1	a


-- !query
EXECUTE IMMEDIATE 'INSERT INTO integration_test(IDENTIFIER(:col1), IDENTIFIER(:col2)) VALUES (:val1, :val2)'
  USING 'c1' AS col1, 'c2' AS col2, 3 AS val1, 'c' AS val2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ": missing ')'"
  },
  "queryContext" : [ {
    "objectType" : "EXECUTE IMMEDIATE",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 88,
    "fragment" : "INSERT INTO integration_test(IDENTIFIER(:col1), IDENTIFIER(:col2)) VALUES (:val1, :val2)"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELECT IDENTIFIER(concat(:schema, ''.'', :table, ''.c1'')) FROM VALUES(named_struct(''c1'', 100)) AS IDENTIFIER(:alias)(IDENTIFIER(:schema ''.'' :table))'
  USING 'identifier_clause_test_schema' AS schema, 'my_table' AS table, 't' AS alias
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "':'",
    "hint" : ": extra input ':'"
  },
  "queryContext" : [ {
    "objectType" : "EXECUTE IMMEDIATE",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 145,
    "fragment" : "SELECT IDENTIFIER(concat(:schema, '.', :table, '.c1')) FROM VALUES(named_struct('c1', 100)) AS IDENTIFIER(:alias)(IDENTIFIER(:schema '.' :table))"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'WITH IDENTIFIER(:cte_name)(c1) AS (VALUES(1)) SELECT c1 FROM IDENTIFIER(:cte_name)'
  USING 'my_cte' AS cte_name
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "':'",
    "hint" : ""
  },
  "queryContext" : [ {
    "objectType" : "EXECUTE IMMEDIATE",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 82,
    "fragment" : "WITH IDENTIFIER(:cte_name)(c1) AS (VALUES(1)) SELECT c1 FROM IDENTIFIER(:cte_name)"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'CREATE OR REPLACE TEMPORARY VIEW IDENTIFIER(:view_name)(IDENTIFIER(:col_name)) AS VALUES(1)'
  USING 'test_view' AS view_name, 'test_col' AS col_name
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  },
  "queryContext" : [ {
    "objectType" : "EXECUTE IMMEDIATE",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 91,
    "fragment" : "CREATE OR REPLACE TEMPORARY VIEW IDENTIFIER(:view_name)(IDENTIFIER(:col_name)) AS VALUES(1)"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELECT IDENTIFIER(:col) FROM IDENTIFIER(:view)'
  USING 'test_col' AS col, 'test_view' AS view
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`test_view`"
  },
  "queryContext" : [ {
    "objectType" : "EXECUTE IMMEDIATE",
    "objectName" : "",
    "startIndex" : 30,
    "stopIndex" : 46,
    "fragment" : "IDENTIFIER(:view)"
  } ]
}


-- !query
DROP VIEW test_view
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.NoSuchTableException
{
  "errorClass" : "TABLE_OR_VIEW_NOT_FOUND",
  "sqlState" : "42P01",
  "messageParameters" : {
    "relationName" : "`spark_catalog`.`identifier_clause_test_schema`.`test_view`"
  }
}


-- !query
EXECUTE IMMEDIATE 'ALTER TABLE IDENTIFIER(:tab) ADD COLUMN IDENTIFIER(:new_col) INT'
  USING 'integration_test' AS tab, 'c4' AS new_col
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  },
  "queryContext" : [ {
    "objectType" : "EXECUTE IMMEDIATE",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 64,
    "fragment" : "ALTER TABLE IDENTIFIER(:tab) ADD COLUMN IDENTIFIER(:new_col) INT"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'ALTER TABLE IDENTIFIER(:tab) RENAME COLUMN IDENTIFIER(:old_col) TO IDENTIFIER(:new_col)'
  USING 'integration_test' AS tab, 'c4' AS old_col, 'c5' AS new_col
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  },
  "queryContext" : [ {
    "objectType" : "EXECUTE IMMEDIATE",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 87,
    "fragment" : "ALTER TABLE IDENTIFIER(:tab) RENAME COLUMN IDENTIFIER(:old_col) TO IDENTIFIER(:new_col)"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELECT map(:key, :val).IDENTIFIER(:key) AS result'
  USING 'mykey' AS key, 42 AS val
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "':'",
    "hint" : ""
  },
  "queryContext" : [ {
    "objectType" : "EXECUTE IMMEDIATE",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 49,
    "fragment" : "SELECT map(:key, :val).IDENTIFIER(:key) AS result"
  } ]
}


-- !query
EXECUTE IMMEDIATE 'SELECT IDENTIFIER(:alias ''.c1'') FROM integration_test AS IDENTIFIER(:alias) ORDER BY ALL'
  USING 't' AS alias
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "':'",
    "hint" : ": extra input ':'"
  },
  "queryContext" : [ {
    "objectType" : "EXECUTE IMMEDIATE",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 88,
    "fragment" : "SELECT IDENTIFIER(:alias '.c1') FROM integration_test AS IDENTIFIER(:alias) ORDER BY ALL"
  } ]
}


-- !query
EXECUTE IMMEDIATE
  'SELECT IDENTIFIER(:col1), IDENTIFIER(:p ''2'') FROM IDENTIFIER(:schema ''.'' :tab) WHERE IDENTIFIER(:col1) > 0 ORDER BY IDENTIFIER(:p ''1'')'
  USING 'c1' AS col1, 'c' AS p, 'identifier_clause_test_schema' AS schema, 'integration_test' AS tab
-- !query schema
struct<c1:int,c2:string>
-- !query output
1	a
2	b


-- !query
EXECUTE IMMEDIATE 'SELECT * FROM IDENTIFIER(:schema ''.'' :table) WHERE IDENTIFIER(concat(:tab_alias, ''.c1'')) > 0 ORDER BY ALL'
  USING 'identifier_clause_test_schema' AS schema, 'integration_test' AS table, 'integration_test' AS tab_alias
-- !query schema
struct<c1:int,c2:string>
-- !query output
1	a
2	b


-- !query
EXECUTE IMMEDIATE 'SELECT 1 AS IDENTIFIER(:schema ''.'' :col)'
  USING 'identifier_clause_test_schema' AS schema, 'col1' AS col
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  },
  "queryContext" : [ {
    "objectType" : "EXECUTE IMMEDIATE",
    "objectName" : "",
    "startIndex" : 1,
    "stopIndex" : 40,
    "fragment" : "SELECT 1 AS IDENTIFIER(:schema '.' :col)"
  } ]
}


-- !query
DROP TABLE integration_test
-- !query schema
struct<>
-- !query output



-- !query
DROP TABLE integration_test2
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE lateral_test(arr ARRAY<INT>) USING PARQUET
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO lateral_test VALUES (array(1, 2, 3))
-- !query schema
struct<>
-- !query output



-- !query
SELECT * FROM lateral_test LATERAL VIEW explode(arr) IDENTIFIER('tbl') AS IDENTIFIER('col') ORDER BY ALL
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT * FROM lateral_test LATERAL VIEW OUTER explode(arr) IDENTIFIER('my_table') AS IDENTIFIER('my_col') ORDER BY ALL
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
DROP TABLE lateral_test
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE unpivot_test(id INT, a INT, b INT, c INT) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO unpivot_test VALUES (1, 10, 20, 30)
-- !query schema
struct<>
-- !query output



-- !query
SELECT * FROM unpivot_test UNPIVOT (val FOR col IN (a AS IDENTIFIER('col_a'), b AS IDENTIFIER('col_b'))) ORDER BY ALL
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT * FROM unpivot_test UNPIVOT ((v1, v2) FOR col IN ((a, b) AS IDENTIFIER('cols_ab'), (b, c) AS IDENTIFIER('cols_bc'))) ORDER BY ALL
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
DROP TABLE unpivot_test
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE describe_col_test(c1 INT, c2 STRING, c3 DOUBLE) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
DESCRIBE describe_col_test IDENTIFIER('c1')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
DESCRIBE describe_col_test IDENTIFIER('c2')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
DROP TABLE describe_col_test
-- !query schema
struct<>
-- !query output



-- !query
SELECT :IDENTIFIER('param1') FROM VALUES(1) AS T(c1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "''param1''",
    "hint" : ""
  }
}


-- !query
CREATE TABLE hint_test(c1 INT, c2 INT) USING CSV
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO hint_test VALUES (1, 2), (3, 4)
-- !query schema
struct<>
-- !query output



-- !query
SELECT /*+ IDENTIFIER('BROADCAST')(hint_test) */ * FROM hint_test
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT /*+ IDENTIFIER('MERGE')(hint_test) */ * FROM hint_test
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
DROP TABLE hint_test
-- !query schema
struct<>
-- !query output



-- !query
SHOW IDENTIFIER('USER') FUNCTIONS
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT EXTRACT(IDENTIFIER('YEAR') FROM DATE'2024-01-15')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT TIMESTAMPADD(IDENTIFIER('YEAR'), 1, DATE'2024-01-15')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`TIMESTAMPADD`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`identifier_clause_test_schema`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 60,
    "fragment" : "TIMESTAMPADD(IDENTIFIER('YEAR'), 1, DATE'2024-01-15')"
  } ]
}


-- !query
DROP SCHEMA identifier_clause_test_schema
-- !query schema
struct<>
-- !query output

