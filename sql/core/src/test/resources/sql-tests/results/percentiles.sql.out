-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE OR REPLACE TEMPORARY VIEW aggr AS SELECT * FROM VALUES
(0, 0), (0, 10), (0, 20), (0, 30), (0, 40), (1, 10), (1, 20), (2, 10), (2, 20), (2, 25), (2, 30), (3, 60), (4, null)
AS aggr(k, v)
-- !query schema
struct<>
-- !query output



-- !query
CREATE OR REPLACE TEMPORARY VIEW basic_pays AS SELECT * FROM VALUES
('Diane Murphy','Accounting',8435),
('Mary Patterson','Accounting',9998),
('Jeff Firrelli','Accounting',8992),
('William Patterson','Accounting',8870),
('Gerard Bondur','Accounting',11472),
('Anthony Bow','Accounting',6627),
('Leslie Jennings','IT',8113),
('Leslie Thompson','IT',5186),
('Julie Firrelli','Sales',9181),
('Steve Patterson','Sales',9441),
('Foon Yue Tseng','Sales',6660),
('George Vanauf','Sales',10563),
('Loui Bondur','SCM',10449),
('Gerard Hernandez','SCM',6949),
('Pamela Castillo','SCM',11303),
('Larry Bott','SCM',11798),
('Barry Jones','SCM',10586)
AS basic_pays(employee_name, department, salary)
-- !query schema
struct<>
-- !query output



-- !query
SELECT
  percentile_cont(0.25) WITHIN GROUP (ORDER BY v),
  percentile_cont(0.25) WITHIN GROUP (ORDER BY v) FILTER (WHERE k > 0),
  percentile_cont(0.25) WITHIN GROUP (ORDER BY v DESC),
  percentile_cont(0.25) WITHIN GROUP (ORDER BY v DESC) FILTER (WHERE k > 0)
FROM aggr
-- !query schema
struct<percentile_cont(0.25) WITHIN GROUP (ORDER BY v):double,percentile_cont(0.25) WITHIN GROUP (ORDER BY v) FILTER (WHERE (k > 0)):double,percentile_cont(0.25) WITHIN GROUP (ORDER BY v DESC):double,percentile_cont(0.25) WITHIN GROUP (ORDER BY v DESC) FILTER (WHERE (k > 0)):double>
-- !query output
10.0	15.0	30.0	27.5


-- !query
SELECT
  k,
  percentile_cont(0.25) WITHIN GROUP (ORDER BY v),
  percentile_cont(0.25) WITHIN GROUP (ORDER BY v) FILTER (WHERE k > 0),
  percentile_cont(0.25) WITHIN GROUP (ORDER BY v DESC),
  percentile_cont(0.25) WITHIN GROUP (ORDER BY v DESC) FILTER (WHERE k > 0)
FROM aggr
GROUP BY k
ORDER BY k
-- !query schema
struct<k:int,percentile_cont(0.25) WITHIN GROUP (ORDER BY v):double,percentile_cont(0.25) WITHIN GROUP (ORDER BY v) FILTER (WHERE (k > 0)):double,percentile_cont(0.25) WITHIN GROUP (ORDER BY v DESC):double,percentile_cont(0.25) WITHIN GROUP (ORDER BY v DESC) FILTER (WHERE (k > 0)):double>
-- !query output
0	10.0	NULL	30.0	NULL
1	12.5	12.5	17.5	17.5
2	17.5	17.5	26.25	26.25
3	60.0	60.0	60.0	60.0
4	NULL	NULL	NULL	NULL


-- !query
SELECT
  percentile_disc(0.25) WITHIN GROUP (ORDER BY v),
  percentile_disc(0.25) WITHIN GROUP (ORDER BY v) FILTER (WHERE k > 0),
  percentile_disc(0.25) WITHIN GROUP (ORDER BY v DESC),
  percentile_disc(0.25) WITHIN GROUP (ORDER BY v DESC) FILTER (WHERE k > 0)
FROM aggr
-- !query schema
struct<percentile_disc(0.25) WITHIN GROUP (ORDER BY v):double,percentile_disc(0.25) WITHIN GROUP (ORDER BY v) FILTER (WHERE (k > 0)):double,percentile_disc(0.25) WITHIN GROUP (ORDER BY v DESC):double,percentile_disc(0.25) WITHIN GROUP (ORDER BY v DESC) FILTER (WHERE (k > 0)):double>
-- !query output
10.0	10.0	30.0	30.0


-- !query
SELECT
  k,
  percentile_disc(0.25) WITHIN GROUP (ORDER BY v),
  percentile_disc(0.25) WITHIN GROUP (ORDER BY v) FILTER (WHERE k > 0),
  percentile_disc(0.25) WITHIN GROUP (ORDER BY v DESC),
  percentile_disc(0.25) WITHIN GROUP (ORDER BY v DESC) FILTER (WHERE k > 0)
FROM aggr
GROUP BY k
ORDER BY k
-- !query schema
struct<k:int,percentile_disc(0.25) WITHIN GROUP (ORDER BY v):double,percentile_disc(0.25) WITHIN GROUP (ORDER BY v) FILTER (WHERE (k > 0)):double,percentile_disc(0.25) WITHIN GROUP (ORDER BY v DESC):double,percentile_disc(0.25) WITHIN GROUP (ORDER BY v DESC) FILTER (WHERE (k > 0)):double>
-- !query output
0	10.0	NULL	30.0	NULL
1	10.0	10.0	20.0	20.0
2	10.0	10.0	30.0	30.0
3	60.0	60.0	60.0	60.0
4	NULL	NULL	NULL	NULL


-- !query
SELECT
  median(v),
  percentile(v, 0.5),
  percentile_cont(0.5) WITHIN GROUP (ORDER BY v)
FROM aggr
-- !query schema
struct<median(v):double,percentile(v, 0.5, 1):double,percentile_cont(0.5) WITHIN GROUP (ORDER BY v):double>
-- !query output
20.0	20.0	20.0


-- !query
SELECT
  round(v, 0) WITHIN GROUP (ORDER BY v)
FROM aggr
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_SQL_SYNTAX.FUNCTION_WITH_UNSUPPORTED_SYNTAX",
  "sqlState" : "42000",
  "messageParameters" : {
    "prettyName" : "`round`",
    "syntax" : "WITHIN GROUP (ORDER BY ...)"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 46,
    "fragment" : "round(v, 0) WITHIN GROUP (ORDER BY v)"
  } ]
}


-- !query
SELECT
  round(v, 0) WITHIN GROUP (ORDER BY v) OVER (PARTITION BY k)
FROM aggr
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_SQL_SYNTAX.FUNCTION_WITH_UNSUPPORTED_SYNTAX",
  "sqlState" : "42000",
  "messageParameters" : {
    "prettyName" : "`round`",
    "syntax" : "WITHIN GROUP (ORDER BY ...)"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 68,
    "fragment" : "round(v, 0) WITHIN GROUP (ORDER BY v) OVER (PARTITION BY k)"
  } ]
}


-- !query
SELECT
  percentile(v, 0.5) WITHIN GROUP (ORDER BY v)
FROM aggr
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_SQL_SYNTAX.FUNCTION_WITH_UNSUPPORTED_SYNTAX",
  "sqlState" : "42000",
  "messageParameters" : {
    "prettyName" : "`percentile`",
    "syntax" : "WITHIN GROUP (ORDER BY ...)"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 53,
    "fragment" : "percentile(v, 0.5) WITHIN GROUP (ORDER BY v)"
  } ]
}


-- !query
SELECT
  percentile(v, 0.5) WITHIN GROUP (ORDER BY v) OVER (PARTITION BY k)
FROM aggr
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_SQL_SYNTAX.FUNCTION_WITH_UNSUPPORTED_SYNTAX",
  "sqlState" : "42000",
  "messageParameters" : {
    "prettyName" : "`percentile`",
    "syntax" : "WITHIN GROUP (ORDER BY ...)"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 75,
    "fragment" : "percentile(v, 0.5) WITHIN GROUP (ORDER BY v) OVER (PARTITION BY k)"
  } ]
}


-- !query
SELECT
  percentile_cont(DISTINCT 0.5) WITHIN GROUP (ORDER BY v)
FROM aggr
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_WITHIN_GROUP_EXPRESSION.DISTINCT_UNSUPPORTED",
  "sqlState" : "42K0K",
  "messageParameters" : {
    "funcName" : "`percentile_cont`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 64,
    "fragment" : "percentile_cont(DISTINCT 0.5) WITHIN GROUP (ORDER BY v)"
  } ]
}


-- !query
SELECT
  percentile_cont(DISTINCT 0.5) WITHIN GROUP (ORDER BY v) OVER (PARTITION BY k)
FROM aggr
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_WITHIN_GROUP_EXPRESSION.DISTINCT_UNSUPPORTED",
  "sqlState" : "42K0K",
  "messageParameters" : {
    "funcName" : "`percentile_cont`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 86,
    "fragment" : "percentile_cont(DISTINCT 0.5) WITHIN GROUP (ORDER BY v) OVER (PARTITION BY k)"
  } ]
}


-- !query
SELECT
  percentile_cont() WITHIN GROUP (ORDER BY v)
FROM aggr
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITHOUT_SUGGESTION",
  "sqlState" : "42605",
  "messageParameters" : {
    "actualNum" : "0",
    "docroot" : "https://spark.apache.org/docs/latest",
    "expectedNum" : "1",
    "functionName" : "`percentile_cont`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 52,
    "fragment" : "percentile_cont() WITHIN GROUP (ORDER BY v)"
  } ]
}


-- !query
SELECT
  percentile_cont() WITHIN GROUP (ORDER BY v) OVER (PARTITION BY k)
FROM aggr
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITHOUT_SUGGESTION",
  "sqlState" : "42605",
  "messageParameters" : {
    "actualNum" : "0",
    "docroot" : "https://spark.apache.org/docs/latest",
    "expectedNum" : "1",
    "functionName" : "`percentile_cont`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 74,
    "fragment" : "percentile_cont() WITHIN GROUP (ORDER BY v) OVER (PARTITION BY k)"
  } ]
}


-- !query
SELECT
  percentile_cont(0.5)
FROM aggr
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_WITHIN_GROUP_EXPRESSION.WITHIN_GROUP_MISSING",
  "sqlState" : "42K0K",
  "messageParameters" : {
    "funcName" : "`percentile_cont`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 29,
    "fragment" : "percentile_cont(0.5)"
  } ]
}


-- !query
SELECT
  percentile_cont(0.5) OVER (PARTITION BY k)
FROM aggr
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_WITHIN_GROUP_EXPRESSION.WITHIN_GROUP_MISSING",
  "sqlState" : "42K0K",
  "messageParameters" : {
    "funcName" : "`percentile_cont`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 51,
    "fragment" : "percentile_cont(0.5) OVER (PARTITION BY k)"
  } ]
}


-- !query
SELECT
  percentile_cont(0.5) WITHIN GROUP (ORDER BY k, v)
FROM aggr
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_WITHIN_GROUP_EXPRESSION.WRONG_NUM_ORDERINGS",
  "sqlState" : "42K0K",
  "messageParameters" : {
    "actualNum" : "2",
    "expectedNum" : "1",
    "funcName" : "`percentile_cont`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 58,
    "fragment" : "percentile_cont(0.5) WITHIN GROUP (ORDER BY k, v)"
  } ]
}


-- !query
SELECT
  percentile_cont(k, 0.5) WITHIN GROUP (ORDER BY v)
FROM aggr
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITHOUT_SUGGESTION",
  "sqlState" : "42605",
  "messageParameters" : {
    "actualNum" : "2",
    "docroot" : "https://spark.apache.org/docs/latest",
    "expectedNum" : "1",
    "functionName" : "`percentile_cont`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 58,
    "fragment" : "percentile_cont(k, 0.5) WITHIN GROUP (ORDER BY v)"
  } ]
}


-- !query
SELECT
  k,
  median(v),
  percentile(v, 0.5),
  percentile_cont(0.5) WITHIN GROUP (ORDER BY v)
FROM aggr
GROUP BY k
ORDER BY k
-- !query schema
struct<k:int,median(v):double,percentile(v, 0.5, 1):double,percentile_cont(0.5) WITHIN GROUP (ORDER BY v):double>
-- !query output
0	20.0	20.0	20.0
1	15.0	15.0	15.0
2	22.5	22.5	22.5
3	60.0	60.0	60.0
4	NULL	NULL	NULL


-- !query
SELECT
    employee_name,
    department,
    salary,
    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department),
    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department),
    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER (PARTITION BY department),
    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER (PARTITION BY department)
FROM basic_pays
ORDER BY salary
-- !query schema
struct<employee_name:string,department:string,salary:int,percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):double,percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):double,percentile_cont(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):double,percentile_disc(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):double>
-- !query output
Leslie Thompson	IT	5186	5917.75	5186.0	7381.25	8113.0
Anthony Bow	Accounting	6627	8543.75	8435.0	9746.5	9998.0
Foon Yue Tseng	Sales	6660	8550.75	6660.0	9721.5	10563.0
Gerard Hernandez	SCM	6949	10449.0	10449.0	11303.0	11303.0
Leslie Jennings	IT	8113	5917.75	5186.0	7381.25	8113.0
Diane Murphy	Accounting	8435	8543.75	8435.0	9746.5	9998.0
William Patterson	Accounting	8870	8543.75	8435.0	9746.5	9998.0
Jeff Firrelli	Accounting	8992	8543.75	8435.0	9746.5	9998.0
Julie Firrelli	Sales	9181	8550.75	6660.0	9721.5	10563.0
Steve Patterson	Sales	9441	8550.75	6660.0	9721.5	10563.0
Mary Patterson	Accounting	9998	8543.75	8435.0	9746.5	9998.0
Loui Bondur	SCM	10449	10449.0	10449.0	11303.0	11303.0
George Vanauf	Sales	10563	8550.75	6660.0	9721.5	10563.0
Barry Jones	SCM	10586	10449.0	10449.0	11303.0	11303.0
Pamela Castillo	SCM	11303	10449.0	10449.0	11303.0	11303.0
Gerard Bondur	Accounting	11472	8543.75	8435.0	9746.5	9998.0
Larry Bott	SCM	11798	10449.0	10449.0	11303.0	11303.0


-- !query
SELECT
    employee_name,
    department,
    salary,
    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department ORDER BY salary),
    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER (PARTITION BY department ORDER BY salary)
FROM basic_pays
ORDER BY salary
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_WINDOW_SPEC_FOR_AGGREGATION_FUNC",
  "sqlState" : "42601",
  "messageParameters" : {
    "aggFunc" : "\"percentile_cont(salary, 0.25)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 59,
    "stopIndex" : 157,
    "fragment" : "percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department ORDER BY salary)"
  } ]
}


-- !query
SELECT
    employee_name,
    department,
    salary,
    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department ORDER BY salary),
    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER (PARTITION BY department ORDER BY salary)
FROM basic_pays
ORDER BY salary
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_WINDOW_SPEC_FOR_AGGREGATION_FUNC",
  "sqlState" : "42601",
  "messageParameters" : {
    "aggFunc" : "\"percentile_disc(salary, 0.25)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 59,
    "stopIndex" : 157,
    "fragment" : "percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department ORDER BY salary)"
  } ]
}


-- !query
SELECT
    employee_name,
    department,
    salary,
    median(salary) OVER (PARTITION BY department ORDER BY salary)
FROM basic_pays
ORDER BY salary
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_WINDOW_SPEC_FOR_AGGREGATION_FUNC",
  "sqlState" : "42601",
  "messageParameters" : {
    "aggFunc" : "\"median(salary)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 59,
    "stopIndex" : 119,
    "fragment" : "median(salary) OVER (PARTITION BY department ORDER BY salary)"
  } ]
}


-- !query
SELECT
    employee_name,
    department,
    salary,
    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING),
    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING)
FROM basic_pays
ORDER BY salary
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_WINDOW_SPEC_FOR_AGGREGATION_FUNC",
  "sqlState" : "42601",
  "messageParameters" : {
    "aggFunc" : "\"percentile_cont(salary, 0.25)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 59,
    "stopIndex" : 190,
    "fragment" : "percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING)"
  } ]
}


-- !query
SELECT
    employee_name,
    department,
    salary,
    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING),
    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING)
FROM basic_pays
ORDER BY salary
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_WINDOW_SPEC_FOR_AGGREGATION_FUNC",
  "sqlState" : "42601",
  "messageParameters" : {
    "aggFunc" : "\"percentile_disc(salary, 0.25)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 59,
    "stopIndex" : 190,
    "fragment" : "percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING)"
  } ]
}


-- !query
SELECT
    employee_name,
    department,
    salary,
    median(salary) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING)
FROM basic_pays
ORDER BY salary
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_WINDOW_SPEC_FOR_AGGREGATION_FUNC",
  "sqlState" : "42601",
  "messageParameters" : {
    "aggFunc" : "\"median(salary)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 59,
    "stopIndex" : 152,
    "fragment" : "median(salary) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING)"
  } ]
}


-- !query
SELECT
    employee_name,
    department,
    salary,
    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) OVER w,
    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) OVER w,
    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER w,
    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER w
FROM basic_pays
WINDOW w AS (PARTITION BY department)
ORDER BY salary
-- !query schema
struct<employee_name:string,department:string,salary:int,percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):double,percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):double,percentile_cont(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):double,percentile_disc(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):double>
-- !query output
Leslie Thompson	IT	5186	5917.75	5186.0	7381.25	8113.0
Anthony Bow	Accounting	6627	8543.75	8435.0	9746.5	9998.0
Foon Yue Tseng	Sales	6660	8550.75	6660.0	9721.5	10563.0
Gerard Hernandez	SCM	6949	10449.0	10449.0	11303.0	11303.0
Leslie Jennings	IT	8113	5917.75	5186.0	7381.25	8113.0
Diane Murphy	Accounting	8435	8543.75	8435.0	9746.5	9998.0
William Patterson	Accounting	8870	8543.75	8435.0	9746.5	9998.0
Jeff Firrelli	Accounting	8992	8543.75	8435.0	9746.5	9998.0
Julie Firrelli	Sales	9181	8550.75	6660.0	9721.5	10563.0
Steve Patterson	Sales	9441	8550.75	6660.0	9721.5	10563.0
Mary Patterson	Accounting	9998	8543.75	8435.0	9746.5	9998.0
Loui Bondur	SCM	10449	10449.0	10449.0	11303.0	11303.0
George Vanauf	Sales	10563	8550.75	6660.0	9721.5	10563.0
Barry Jones	SCM	10586	10449.0	10449.0	11303.0	11303.0
Pamela Castillo	SCM	11303	10449.0	10449.0	11303.0	11303.0
Gerard Bondur	Accounting	11472	8543.75	8435.0	9746.5	9998.0
Larry Bott	SCM	11798	10449.0	10449.0	11303.0	11303.0


-- !query
SELECT
    employee_name,
    department,
    salary,
    median(salary) OVER w,
    percentile_cont(0.5) WITHIN GROUP (ORDER BY salary) OVER w,
    percentile_disc(0.5) WITHIN GROUP (ORDER BY salary) OVER w,
    percentile_cont(0.5) WITHIN GROUP (ORDER BY salary DESC) OVER w,
    percentile_disc(0.5) WITHIN GROUP (ORDER BY salary DESC) OVER w
FROM basic_pays
WHERE salary > 8900
WINDOW w AS (PARTITION BY department)
ORDER BY salary
-- !query schema
struct<employee_name:string,department:string,salary:int,median(salary) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):double,percentile_cont(0.5) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):double,percentile_disc(0.5) WITHIN GROUP (ORDER BY salary) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):double,percentile_cont(0.5) WITHIN GROUP (ORDER BY salary DESC) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):double,percentile_disc(0.5) WITHIN GROUP (ORDER BY salary DESC) OVER (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING):double>
-- !query output
Jeff Firrelli	Accounting	8992	9998.0	9998.0	9998.0	9998.0	9998.0
Julie Firrelli	Sales	9181	9441.0	9441.0	9441.0	9441.0	9441.0
Steve Patterson	Sales	9441	9441.0	9441.0	9441.0	9441.0	9441.0
Mary Patterson	Accounting	9998	9998.0	9998.0	9998.0	9998.0	9998.0
Loui Bondur	SCM	10449	10944.5	10944.5	10586.0	10944.5	11303.0
George Vanauf	Sales	10563	9441.0	9441.0	9441.0	9441.0	9441.0
Barry Jones	SCM	10586	10944.5	10944.5	10586.0	10944.5	11303.0
Pamela Castillo	SCM	11303	10944.5	10944.5	10586.0	10944.5	11303.0
Gerard Bondur	Accounting	11472	9998.0	9998.0	9998.0	9998.0	9998.0
Larry Bott	SCM	11798	10944.5	10944.5	10586.0	10944.5	11303.0


-- !query
SELECT
    employee_name,
    department,
    salary,
    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) OVER w,
    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER w
FROM basic_pays
WINDOW w AS (PARTITION BY department ORDER BY salary)
ORDER BY salary
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_WINDOW_SPEC_FOR_AGGREGATION_FUNC",
  "sqlState" : "42601",
  "messageParameters" : {
    "aggFunc" : "\"percentile_cont(salary, 0.25)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 59,
    "stopIndex" : 117,
    "fragment" : "percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) OVER w"
  } ]
}


-- !query
SELECT
    employee_name,
    department,
    salary,
    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) OVER w,
    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER w
FROM basic_pays
WINDOW w AS (PARTITION BY department ORDER BY salary)
ORDER BY salary
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_WINDOW_SPEC_FOR_AGGREGATION_FUNC",
  "sqlState" : "42601",
  "messageParameters" : {
    "aggFunc" : "\"percentile_disc(salary, 0.25)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 59,
    "stopIndex" : 117,
    "fragment" : "percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) OVER w"
  } ]
}


-- !query
SELECT
    employee_name,
    department,
    salary,
    median(salary) OVER w
FROM basic_pays
WINDOW w AS (PARTITION BY department ORDER BY salary)
ORDER BY salary
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_WINDOW_SPEC_FOR_AGGREGATION_FUNC",
  "sqlState" : "42601",
  "messageParameters" : {
    "aggFunc" : "\"median(salary)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 59,
    "stopIndex" : 79,
    "fragment" : "median(salary) OVER w"
  } ]
}


-- !query
SELECT
    employee_name,
    department,
    salary,
    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) OVER w,
    percentile_cont(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER w
FROM basic_pays
WINDOW w AS (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING)
ORDER BY salary
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_WINDOW_SPEC_FOR_AGGREGATION_FUNC",
  "sqlState" : "42601",
  "messageParameters" : {
    "aggFunc" : "\"percentile_cont(salary, 0.25)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 59,
    "stopIndex" : 117,
    "fragment" : "percentile_cont(0.25) WITHIN GROUP (ORDER BY salary) OVER w"
  } ]
}


-- !query
SELECT
    employee_name,
    department,
    salary,
    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) OVER w,
    percentile_disc(0.25) WITHIN GROUP (ORDER BY salary DESC) OVER w
FROM basic_pays
WINDOW w AS (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING)
ORDER BY salary
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_WINDOW_SPEC_FOR_AGGREGATION_FUNC",
  "sqlState" : "42601",
  "messageParameters" : {
    "aggFunc" : "\"percentile_disc(salary, 0.25)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 59,
    "stopIndex" : 117,
    "fragment" : "percentile_disc(0.25) WITHIN GROUP (ORDER BY salary) OVER w"
  } ]
}


-- !query
SELECT
    employee_name,
    department,
    salary,
    median(salary) OVER w
FROM basic_pays
WINDOW w AS (PARTITION BY department ROWS BETWEEN UNBOUNDED PRECEDING AND 1 FOLLOWING)
ORDER BY salary
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_WINDOW_SPEC_FOR_AGGREGATION_FUNC",
  "sqlState" : "42601",
  "messageParameters" : {
    "aggFunc" : "\"median(salary)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 59,
    "stopIndex" : 79,
    "fragment" : "median(salary) OVER w"
  } ]
}


-- !query
CREATE OR REPLACE TEMPORARY VIEW intervals AS SELECT * FROM VALUES
(0, INTERVAL '0' MONTH, INTERVAL '0' SECOND, INTERVAL '0' MINUTE),
(0, INTERVAL '10' MONTH, INTERVAL '10' SECOND, INTERVAL '10' MINUTE),
(0, INTERVAL '20' MONTH, INTERVAL '20' SECOND, INTERVAL '20' MINUTE),
(0, INTERVAL '30' MONTH, INTERVAL '30' SECOND, INTERVAL '30' MINUTE),
(0, INTERVAL '40' MONTH, INTERVAL '40' SECOND, INTERVAL '40' MINUTE),
(1, INTERVAL '10' MONTH, INTERVAL '10' SECOND, INTERVAL '10' MINUTE),
(1, INTERVAL '20' MONTH, INTERVAL '20' SECOND, INTERVAL '20' MINUTE),
(2, INTERVAL '10' MONTH, INTERVAL '10' SECOND, INTERVAL '10' MINUTE),
(2, INTERVAL '20' MONTH, INTERVAL '20' SECOND, INTERVAL '20' MINUTE),
(2, INTERVAL '25' MONTH, INTERVAL '25' SECOND, INTERVAL '25' MINUTE),
(2, INTERVAL '30' MONTH, INTERVAL '30' SECOND, INTERVAL '30' MINUTE),
(3, INTERVAL '60' MONTH, INTERVAL '60' SECOND, INTERVAL '60' MINUTE),
(4, null, null, null)
AS intervals(k, dt, ym, dt2)
-- !query schema
struct<>
-- !query output



-- !query
SELECT
  percentile_cont(0.25) WITHIN GROUP (ORDER BY dt),
  percentile_cont(0.25) WITHIN GROUP (ORDER BY dt DESC)
FROM intervals
-- !query schema
struct<percentile_cont(0.25) WITHIN GROUP (ORDER BY dt):interval year to month,percentile_cont(0.25) WITHIN GROUP (ORDER BY dt DESC):interval year to month>
-- !query output
0-10	2-6


-- !query
SELECT
  k,
  percentile_cont(0.25) WITHIN GROUP (ORDER BY ym),
  percentile_cont(0.25) WITHIN GROUP (ORDER BY ym DESC)
FROM intervals
GROUP BY k
ORDER BY k
-- !query schema
struct<k:int,percentile_cont(0.25) WITHIN GROUP (ORDER BY ym):interval day to second,percentile_cont(0.25) WITHIN GROUP (ORDER BY ym DESC):interval day to second>
-- !query output
0	0 00:00:10.000000000	0 00:00:30.000000000
1	0 00:00:12.500000000	0 00:00:17.500000000
2	0 00:00:17.500000000	0 00:00:26.250000000
3	0 00:01:00.000000000	0 00:01:00.000000000
4	NULL	NULL


-- !query
SELECT
  k,
  percentile_cont(0.25) WITHIN GROUP (ORDER BY dt2),
  percentile_cont(0.25) WITHIN GROUP (ORDER BY dt2 DESC)
FROM intervals
GROUP BY k
ORDER BY k
-- !query schema
struct<k:int,percentile_cont(0.25) WITHIN GROUP (ORDER BY dt2):interval day to second,percentile_cont(0.25) WITHIN GROUP (ORDER BY dt2 DESC):interval day to second>
-- !query output
0	0 00:10:00.000000000	0 00:30:00.000000000
1	0 00:12:30.000000000	0 00:17:30.000000000
2	0 00:17:30.000000000	0 00:26:15.000000000
3	0 01:00:00.000000000	0 01:00:00.000000000
4	NULL	NULL


-- !query
SELECT
  percentile_disc(0.25) WITHIN GROUP (ORDER BY dt),
  percentile_disc(0.25) WITHIN GROUP (ORDER BY dt DESC)
FROM intervals
-- !query schema
struct<percentile_disc(0.25) WITHIN GROUP (ORDER BY dt):interval year to month,percentile_disc(0.25) WITHIN GROUP (ORDER BY dt DESC):interval year to month>
-- !query output
0-10	2-6


-- !query
SELECT
  k,
  percentile_disc(0.25) WITHIN GROUP (ORDER BY ym),
  percentile_disc(0.25) WITHIN GROUP (ORDER BY ym DESC)
FROM intervals
GROUP BY k
ORDER BY k
-- !query schema
struct<k:int,percentile_disc(0.25) WITHIN GROUP (ORDER BY ym):interval day to second,percentile_disc(0.25) WITHIN GROUP (ORDER BY ym DESC):interval day to second>
-- !query output
0	0 00:00:10.000000000	0 00:00:30.000000000
1	0 00:00:10.000000000	0 00:00:20.000000000
2	0 00:00:10.000000000	0 00:00:30.000000000
3	0 00:01:00.000000000	0 00:01:00.000000000
4	NULL	NULL


-- !query
SELECT
  k,
  percentile_disc(0.25) WITHIN GROUP (ORDER BY dt2),
  percentile_disc(0.25) WITHIN GROUP (ORDER BY dt2 DESC)
FROM intervals
GROUP BY k
ORDER BY k
-- !query schema
struct<k:int,percentile_disc(0.25) WITHIN GROUP (ORDER BY dt2):interval day to second,percentile_disc(0.25) WITHIN GROUP (ORDER BY dt2 DESC):interval day to second>
-- !query output
0	0 00:10:00.000000000	0 00:30:00.000000000
1	0 00:10:00.000000000	0 00:20:00.000000000
2	0 00:10:00.000000000	0 00:30:00.000000000
3	0 01:00:00.000000000	0 01:00:00.000000000
4	NULL	NULL


-- !query
SELECT
  median(dt),
  percentile(dt, 0.5),
  percentile_cont(0.5) WITHIN GROUP (ORDER BY dt)
FROM intervals
-- !query schema
struct<median(dt):interval year to month,percentile(dt, 0.5, 1):interval year to month,percentile_cont(0.5) WITHIN GROUP (ORDER BY dt):interval year to month>
-- !query output
1-8	1-8	1-8


-- !query
SELECT
  k,
  median(ym),
  percentile(ym, 0.5),
  percentile_cont(0.5) WITHIN GROUP (ORDER BY ym)
FROM intervals
GROUP BY k
ORDER BY k
-- !query schema
struct<k:int,median(ym):interval day to second,percentile(ym, 0.5, 1):interval day to second,percentile_cont(0.5) WITHIN GROUP (ORDER BY ym):interval day to second>
-- !query output
0	0 00:00:20.000000000	0 00:00:20.000000000	0 00:00:20.000000000
1	0 00:00:15.000000000	0 00:00:15.000000000	0 00:00:15.000000000
2	0 00:00:22.500000000	0 00:00:22.500000000	0 00:00:22.500000000
3	0 00:01:00.000000000	0 00:01:00.000000000	0 00:01:00.000000000
4	NULL	NULL	NULL


-- !query
SELECT
  k,
  median(dt2),
  percentile(dt2, 0.5),
  percentile_cont(0.5) WITHIN GROUP (ORDER BY dt2)
FROM intervals
GROUP BY k
ORDER BY k
-- !query schema
struct<k:int,median(dt2):interval day to second,percentile(dt2, 0.5, 1):interval day to second,percentile_cont(0.5) WITHIN GROUP (ORDER BY dt2):interval day to second>
-- !query output
0	0 00:20:00.000000000	0 00:20:00.000000000	0 00:20:00.000000000
1	0 00:15:00.000000000	0 00:15:00.000000000	0 00:15:00.000000000
2	0 00:22:30.000000000	0 00:22:30.000000000	0 00:22:30.000000000
3	0 01:00:00.000000000	0 01:00:00.000000000	0 01:00:00.000000000
4	NULL	NULL	NULL


-- !query
SELECT
  percentile_disc(0.0) WITHIN GROUP (ORDER BY a) as p0,
  percentile_disc(0.1) WITHIN GROUP (ORDER BY a) as p1,
  percentile_disc(0.2) WITHIN GROUP (ORDER BY a) as p2,
  percentile_disc(0.3) WITHIN GROUP (ORDER BY a) as p3,
  percentile_disc(0.4) WITHIN GROUP (ORDER BY a) as p4,
  percentile_disc(0.5) WITHIN GROUP (ORDER BY a) as p5,
  percentile_disc(0.6) WITHIN GROUP (ORDER BY a) as p6,
  percentile_disc(0.7) WITHIN GROUP (ORDER BY a) as p7,
  percentile_disc(0.8) WITHIN GROUP (ORDER BY a) as p8,
  percentile_disc(0.9) WITHIN GROUP (ORDER BY a) as p9,
  percentile_disc(1.0) WITHIN GROUP (ORDER BY a) as p10
FROM VALUES (0) AS v(a)
-- !query schema
struct<p0:double,p1:double,p2:double,p3:double,p4:double,p5:double,p6:double,p7:double,p8:double,p9:double,p10:double>
-- !query output
0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0


-- !query
SELECT
  percentile_disc(0.0) WITHIN GROUP (ORDER BY a) as p0,
  percentile_disc(0.1) WITHIN GROUP (ORDER BY a) as p1,
  percentile_disc(0.2) WITHIN GROUP (ORDER BY a) as p2,
  percentile_disc(0.3) WITHIN GROUP (ORDER BY a) as p3,
  percentile_disc(0.4) WITHIN GROUP (ORDER BY a) as p4,
  percentile_disc(0.5) WITHIN GROUP (ORDER BY a) as p5,
  percentile_disc(0.6) WITHIN GROUP (ORDER BY a) as p6,
  percentile_disc(0.7) WITHIN GROUP (ORDER BY a) as p7,
  percentile_disc(0.8) WITHIN GROUP (ORDER BY a) as p8,
  percentile_disc(0.9) WITHIN GROUP (ORDER BY a) as p9,
  percentile_disc(1.0) WITHIN GROUP (ORDER BY a) as p10
FROM VALUES (0), (1) AS v(a)
-- !query schema
struct<p0:double,p1:double,p2:double,p3:double,p4:double,p5:double,p6:double,p7:double,p8:double,p9:double,p10:double>
-- !query output
0.0	0.0	0.0	0.0	0.0	0.0	1.0	1.0	1.0	1.0	1.0


-- !query
SELECT
  percentile_disc(0.0) WITHIN GROUP (ORDER BY a) as p0,
  percentile_disc(0.1) WITHIN GROUP (ORDER BY a) as p1,
  percentile_disc(0.2) WITHIN GROUP (ORDER BY a) as p2,
  percentile_disc(0.3) WITHIN GROUP (ORDER BY a) as p3,
  percentile_disc(0.4) WITHIN GROUP (ORDER BY a) as p4,
  percentile_disc(0.5) WITHIN GROUP (ORDER BY a) as p5,
  percentile_disc(0.6) WITHIN GROUP (ORDER BY a) as p6,
  percentile_disc(0.7) WITHIN GROUP (ORDER BY a) as p7,
  percentile_disc(0.8) WITHIN GROUP (ORDER BY a) as p8,
  percentile_disc(0.9) WITHIN GROUP (ORDER BY a) as p9,
  percentile_disc(1.0) WITHIN GROUP (ORDER BY a) as p10
FROM VALUES (0), (1), (2) AS v(a)
-- !query schema
struct<p0:double,p1:double,p2:double,p3:double,p4:double,p5:double,p6:double,p7:double,p8:double,p9:double,p10:double>
-- !query output
0.0	0.0	0.0	0.0	1.0	1.0	1.0	2.0	2.0	2.0	2.0


-- !query
SELECT
  percentile_disc(0.0) WITHIN GROUP (ORDER BY a) as p0,
  percentile_disc(0.1) WITHIN GROUP (ORDER BY a) as p1,
  percentile_disc(0.2) WITHIN GROUP (ORDER BY a) as p2,
  percentile_disc(0.3) WITHIN GROUP (ORDER BY a) as p3,
  percentile_disc(0.4) WITHIN GROUP (ORDER BY a) as p4,
  percentile_disc(0.5) WITHIN GROUP (ORDER BY a) as p5,
  percentile_disc(0.6) WITHIN GROUP (ORDER BY a) as p6,
  percentile_disc(0.7) WITHIN GROUP (ORDER BY a) as p7,
  percentile_disc(0.8) WITHIN GROUP (ORDER BY a) as p8,
  percentile_disc(0.9) WITHIN GROUP (ORDER BY a) as p9,
  percentile_disc(1.0) WITHIN GROUP (ORDER BY a) as p10
FROM VALUES (0), (1), (2), (3), (4) AS v(a)
-- !query schema
struct<p0:double,p1:double,p2:double,p3:double,p4:double,p5:double,p6:double,p7:double,p8:double,p9:double,p10:double>
-- !query output
0.0	0.0	0.0	1.0	1.0	2.0	2.0	3.0	3.0	4.0	4.0


-- !query
SET spark.sql.legacy.percentileDiscCalculation = true
-- !query schema
struct<key:string,value:string>
-- !query output
spark.sql.legacy.percentileDiscCalculation	true


-- !query
SELECT
  percentile_disc(0.0) WITHIN GROUP (ORDER BY a) as p0,
  percentile_disc(0.1) WITHIN GROUP (ORDER BY a) as p1,
  percentile_disc(0.2) WITHIN GROUP (ORDER BY a) as p2,
  percentile_disc(0.3) WITHIN GROUP (ORDER BY a) as p3,
  percentile_disc(0.4) WITHIN GROUP (ORDER BY a) as p4,
  percentile_disc(0.5) WITHIN GROUP (ORDER BY a) as p5,
  percentile_disc(0.6) WITHIN GROUP (ORDER BY a) as p6,
  percentile_disc(0.7) WITHIN GROUP (ORDER BY a) as p7,
  percentile_disc(0.8) WITHIN GROUP (ORDER BY a) as p8,
  percentile_disc(0.9) WITHIN GROUP (ORDER BY a) as p9,
  percentile_disc(1.0) WITHIN GROUP (ORDER BY a) as p10
FROM VALUES (0), (1), (2), (3), (4) AS v(a)
-- !query schema
struct<p0:double,p1:double,p2:double,p3:double,p4:double,p5:double,p6:double,p7:double,p8:double,p9:double,p10:double>
-- !query output
0.0	0.0	0.0	1.0	1.0	2.0	2.0	2.0	3.0	3.0	4.0


-- !query
SELECT
  percentile_cont(b) WITHIN GROUP (ORDER BY a DESC) as p0
FROM values (12, 0.25), (13, 0.25), (22, 0.25) as v(a, b)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.NON_FOLDABLE_INPUT",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputExpr" : "\"b\"",
    "inputName" : "`percentage`",
    "inputType" : "\"DOUBLE\"",
    "sqlExpr" : "\"percentile_cont(a, b)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 58,
    "fragment" : "percentile_cont(b) WITHIN GROUP (ORDER BY a DESC)"
  } ]
}


-- !query
SET spark.sql.legacy.percentileDiscCalculation = false
-- !query schema
struct<key:string,value:string>
-- !query output
spark.sql.legacy.percentileDiscCalculation	false
