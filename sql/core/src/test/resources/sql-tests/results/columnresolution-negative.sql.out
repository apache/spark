-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE DATABASE mydb1
-- !query schema
struct<>
-- !query output



-- !query
USE mydb1
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE t1 USING parquet AS SELECT 1 AS i1
-- !query schema
struct<>
-- !query output



-- !query
CREATE DATABASE mydb2
-- !query schema
struct<>
-- !query output



-- !query
USE mydb2
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE t1 USING parquet AS SELECT 20 AS i1
-- !query schema
struct<>
-- !query output



-- !query
SET spark.sql.crossJoin.enabled = true
-- !query schema
struct<key:string,value:string>
-- !query output
spark.sql.crossJoin.enabled	true


-- !query
USE mydb1
-- !query schema
struct<>
-- !query output



-- !query
SELECT i1 FROM t1, mydb1.t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "condition" : "AMBIGUOUS_REFERENCE",
  "sqlState" : "42704",
  "messageParameters" : {
    "name" : "`i1`",
    "referenceNames" : "[`spark_catalog`.`mydb1`.`t1`.`i1`, `spark_catalog`.`mydb1`.`t1`.`i1`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 9,
    "fragment" : "i1"
  } ]
}


-- !query
SELECT t1.i1 FROM t1, mydb1.t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "condition" : "AMBIGUOUS_REFERENCE",
  "sqlState" : "42704",
  "messageParameters" : {
    "name" : "`t1`.`i1`",
    "referenceNames" : "[`spark_catalog`.`mydb1`.`t1`.`i1`, `spark_catalog`.`mydb1`.`t1`.`i1`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 12,
    "fragment" : "t1.i1"
  } ]
}


-- !query
SELECT mydb1.t1.i1 FROM t1, mydb1.t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "condition" : "AMBIGUOUS_REFERENCE",
  "sqlState" : "42704",
  "messageParameters" : {
    "name" : "`mydb1`.`t1`.`i1`",
    "referenceNames" : "[`spark_catalog`.`mydb1`.`t1`.`i1`, `spark_catalog`.`mydb1`.`t1`.`i1`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 18,
    "fragment" : "mydb1.t1.i1"
  } ]
}


-- !query
SELECT i1 FROM t1, mydb2.t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "condition" : "AMBIGUOUS_REFERENCE",
  "sqlState" : "42704",
  "messageParameters" : {
    "name" : "`i1`",
    "referenceNames" : "[`spark_catalog`.`mydb1`.`t1`.`i1`, `spark_catalog`.`mydb2`.`t1`.`i1`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 9,
    "fragment" : "i1"
  } ]
}


-- !query
SELECT t1.i1 FROM t1, mydb2.t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "condition" : "AMBIGUOUS_REFERENCE",
  "sqlState" : "42704",
  "messageParameters" : {
    "name" : "`t1`.`i1`",
    "referenceNames" : "[`spark_catalog`.`mydb1`.`t1`.`i1`, `spark_catalog`.`mydb2`.`t1`.`i1`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 12,
    "fragment" : "t1.i1"
  } ]
}


-- !query
USE mydb2
-- !query schema
struct<>
-- !query output



-- !query
SELECT i1 FROM t1, mydb1.t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "condition" : "AMBIGUOUS_REFERENCE",
  "sqlState" : "42704",
  "messageParameters" : {
    "name" : "`i1`",
    "referenceNames" : "[`spark_catalog`.`mydb1`.`t1`.`i1`, `spark_catalog`.`mydb2`.`t1`.`i1`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 9,
    "fragment" : "i1"
  } ]
}


-- !query
SELECT t1.i1 FROM t1, mydb1.t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "condition" : "AMBIGUOUS_REFERENCE",
  "sqlState" : "42704",
  "messageParameters" : {
    "name" : "`t1`.`i1`",
    "referenceNames" : "[`spark_catalog`.`mydb1`.`t1`.`i1`, `spark_catalog`.`mydb2`.`t1`.`i1`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 12,
    "fragment" : "t1.i1"
  } ]
}


-- !query
SELECT i1 FROM t1, mydb2.t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "condition" : "AMBIGUOUS_REFERENCE",
  "sqlState" : "42704",
  "messageParameters" : {
    "name" : "`i1`",
    "referenceNames" : "[`spark_catalog`.`mydb2`.`t1`.`i1`, `spark_catalog`.`mydb2`.`t1`.`i1`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 9,
    "fragment" : "i1"
  } ]
}


-- !query
SELECT t1.i1 FROM t1, mydb2.t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "condition" : "AMBIGUOUS_REFERENCE",
  "sqlState" : "42704",
  "messageParameters" : {
    "name" : "`t1`.`i1`",
    "referenceNames" : "[`spark_catalog`.`mydb2`.`t1`.`i1`, `spark_catalog`.`mydb2`.`t1`.`i1`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 12,
    "fragment" : "t1.i1"
  } ]
}


-- !query
SELECT db1.t1.i1 FROM t1, mydb2.t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "UNRESOLVED_COLUMN.WITH_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`db1`.`t1`.`i1`",
    "proposal" : "`spark_catalog`.`mydb2`.`t1`.`i1`, `spark_catalog`.`mydb2`.`t1`.`i1`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 16,
    "fragment" : "db1.t1.i1"
  } ]
}


-- !query
SET spark.sql.crossJoin.enabled = false
-- !query schema
struct<key:string,value:string>
-- !query output
spark.sql.crossJoin.enabled	false


-- !query
USE mydb1
-- !query schema
struct<>
-- !query output



-- !query
SELECT mydb1.t1 FROM t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "UNRESOLVED_COLUMN.WITH_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`mydb1`.`t1`",
    "proposal" : "`t1`.`i1`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 15,
    "fragment" : "mydb1.t1"
  } ]
}


-- !query
SELECT t1.x.y.* FROM t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "condition" : "CANNOT_RESOLVE_STAR_EXPAND",
  "sqlState" : "42704",
  "messageParameters" : {
    "columns" : "`i1`",
    "targetString" : "`t1`.`x`.`y`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 15,
    "fragment" : "t1.x.y.*"
  } ]
}


-- !query
SELECT t1 FROM mydb1.t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "UNRESOLVED_COLUMN.WITH_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`t1`",
    "proposal" : "`i1`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 9,
    "fragment" : "t1"
  } ]
}


-- !query
USE mydb2
-- !query schema
struct<>
-- !query output



-- !query
SELECT mydb1.t1.i1 FROM t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "UNRESOLVED_COLUMN.WITH_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`mydb1`.`t1`.`i1`",
    "proposal" : "`spark_catalog`.`mydb2`.`t1`.`i1`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 18,
    "fragment" : "mydb1.t1.i1"
  } ]
}


-- !query
USE mydb1
-- !query schema
struct<>
-- !query output



-- !query
CREATE VIEW v1 AS SELECT * FROM t1
-- !query schema
struct<>
-- !query output



-- !query
DROP TABLE t1
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE t1 USING parquet AS SELECT 1 AS i2
-- !query schema
struct<>
-- !query output



-- !query
SELECT * FROM v1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "condition" : "INCOMPATIBLE_VIEW_SCHEMA_CHANGE",
  "sqlState" : "51024",
  "messageParameters" : {
    "actualCols" : "[]",
    "colName" : "i1",
    "expectedNum" : "1",
    "suggestion" : "CREATE OR REPLACE VIEW spark_catalog.mydb1.v1 AS SELECT * FROM t1",
    "viewName" : "`spark_catalog`.`mydb1`.`v1`"
  }
}


-- !query
USE mydb2
-- !query schema
struct<>
-- !query output



-- !query
CREATE TEMP VIEW v2 AS SELECT * FROM t1
-- !query schema
struct<>
-- !query output



-- !query
DROP TABLE t1
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE t1 USING parquet AS SELECT 1 AS i2
-- !query schema
struct<>
-- !query output



-- !query
SELECT * FROM v2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "condition" : "INCOMPATIBLE_VIEW_SCHEMA_CHANGE",
  "sqlState" : "51024",
  "messageParameters" : {
    "actualCols" : "[]",
    "colName" : "i1",
    "expectedNum" : "1",
    "suggestion" : "CREATE OR REPLACE TEMPORARY VIEW",
    "viewName" : "`v2`"
  }
}


-- !query
DROP DATABASE mydb1 CASCADE
-- !query schema
struct<>
-- !query output



-- !query
DROP DATABASE mydb2 CASCADE
-- !query schema
struct<>
-- !query output

