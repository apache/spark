-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE DATABASE IF NOT EXISTS sql_on_files
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE sql_on_files.test_parquet USING PARQUET AS SELECT 1
-- !query schema
struct<>
-- !query output



-- !query
SELECT * FROM parquet.``
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_EMPTY_LOCATION",
  "sqlState" : "42K05",
  "messageParameters" : {
    "location" : ""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 24,
    "fragment" : "parquet.``"
  } ]
}


-- !query
SELECT * FROM parquet.`/file/not/found`
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "PATH_NOT_FOUND",
  "sqlState" : "42K03",
  "messageParameters" : {
    "path" : "file:/file/not/found"
  }
}


-- !query
SELECT * FROM parquet.`${spark.sql.warehouse.dir}/sql_on_files.db/test_parquet`
-- !query schema
struct<1:int>
-- !query output
1


-- !query
DROP TABLE sql_on_files.test_parquet
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE sql_on_files.test_orc USING ORC AS SELECT 1
-- !query schema
struct<>
-- !query output



-- !query
SELECT * FROM orc.``
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_EMPTY_LOCATION",
  "sqlState" : "42K05",
  "messageParameters" : {
    "location" : ""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 20,
    "fragment" : "orc.``"
  } ]
}


-- !query
SELECT * FROM orc.`/file/not/found`
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "PATH_NOT_FOUND",
  "sqlState" : "42K03",
  "messageParameters" : {
    "path" : "file:/file/not/found"
  }
}


-- !query
SELECT * FROM orc.`${spark.sql.warehouse.dir}/sql_on_files.db/test_orc`
-- !query schema
struct<1:int>
-- !query output
1


-- !query
DROP TABLE sql_on_files.test_orc
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE sql_on_files.test_csv USING CSV AS SELECT 1
-- !query schema
struct<>
-- !query output



-- !query
SELECT * FROM csv.``
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_EMPTY_LOCATION",
  "sqlState" : "42K05",
  "messageParameters" : {
    "location" : ""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 20,
    "fragment" : "csv.``"
  } ]
}


-- !query
SELECT * FROM csv.`/file/not/found`
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "PATH_NOT_FOUND",
  "sqlState" : "42K03",
  "messageParameters" : {
    "path" : "file:/file/not/found"
  }
}


-- !query
SELECT * FROM csv.`${spark.sql.warehouse.dir}/sql_on_files.db/test_csv`
-- !query schema
struct<_c0:string>
-- !query output
1


-- !query
DROP TABLE sql_on_files.test_csv
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE sql_on_files.test_json USING JSON AS SELECT 1
-- !query schema
struct<>
-- !query output



-- !query
SELECT * FROM json.``
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_EMPTY_LOCATION",
  "sqlState" : "42K05",
  "messageParameters" : {
    "location" : ""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 21,
    "fragment" : "json.``"
  } ]
}


-- !query
SELECT * FROM json.`/file/not/found`
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "PATH_NOT_FOUND",
  "sqlState" : "42K03",
  "messageParameters" : {
    "path" : "file:/file/not/found"
  }
}


-- !query
SELECT * FROM json.`${spark.sql.warehouse.dir}/sql_on_files.db/test_json`
-- !query schema
struct<1:bigint>
-- !query output
1


-- !query
DROP TABLE sql_on_files.test_json
-- !query schema
struct<>
-- !query output



-- !query
DROP DATABASE sql_on_files
-- !query schema
struct<>
-- !query output



-- !query
SELECT * FROM json.`https://raw.githubusercontent.com/apache/spark/refs/heads/master/examples/src/main/resources/employees.json`
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "FAILED_READ_FILE.UNSUPPORTED_FILE_SYSTEM",
  "sqlState" : "KD001",
  "messageParameters" : {
    "fileSystemClass" : "org.apache.hadoop.fs.http.HttpsFileSystem",
    "method" : "listStatus",
    "path" : "https://raw.githubusercontent.com/apache/spark/refs/heads/master/examples/src/main/resources/employees.json"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 128,
    "fragment" : "json.`https://raw.githubusercontent.com/apache/spark/refs/heads/master/examples/src/main/resources/employees.json`"
  } ]
}
