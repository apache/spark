-- Automatically generated by SQLQueryTestSuite
-- !query
select * from dummy(3)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVABLE_TABLE_VALUED_FUNCTION",
  "sqlState" : "42883",
  "messageParameters" : {
    "name" : "`dummy`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 22,
    "fragment" : "dummy(3)"
  } ]
}


-- !query
select * from range(6 + cos(3))
-- !query schema
struct<id:bigint>
-- !query output
0
1
2
3
4


-- !query
select * from range(5, 10)
-- !query schema
struct<id:bigint>
-- !query output
5
6
7
8
9


-- !query
select * from range(0, 10, 2)
-- !query schema
struct<id:bigint>
-- !query output
0
2
4
6
8


-- !query
select * from range(0, 10, 1, 200)
-- !query schema
struct<id:bigint>
-- !query output
0
1
2
3
4
5
6
7
8
9


-- !query
select * from range(1, 1, 1, 1, 1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITHOUT_SUGGESTION",
  "sqlState" : "42605",
  "messageParameters" : {
    "actualNum" : "5",
    "docroot" : "https://spark.apache.org/docs/latest",
    "expectedNum" : "[1, 2, 3, 4]",
    "functionName" : "`range`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 34,
    "fragment" : "range(1, 1, 1, 1, 1)"
  } ]
}


-- !query
select * from range(1, null)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "functionName" : "`range`",
    "inputSql" : "\"NULL\"",
    "inputType" : "\"VOID\"",
    "paramIndex" : "second",
    "requiredType" : "\"BIGINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 28,
    "fragment" : "range(1, null)"
  } ]
}


-- !query
select * from range(array(1, 2, 3))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "functionName" : "`range`",
    "inputSql" : "\"array(1, 2, 3)\"",
    "inputType" : "\"ARRAY<INT>\"",
    "paramIndex" : "second",
    "requiredType" : "\"BIGINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 35,
    "fragment" : "range(array(1, 2, 3))"
  } ]
}


-- !query
select * from range(0, 5, 0)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "FAILED_FUNCTION_CALL",
  "sqlState" : "38000",
  "messageParameters" : {
    "funcName" : "`range`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 28,
    "fragment" : "range(0, 5, 0)"
  } ]
}


-- !query
select * from RaNgE(2)
-- !query schema
struct<id:bigint>
-- !query output
0
1


-- !query
select i from range(0, 2) t(i)
-- !query schema
struct<i:bigint>
-- !query output
0
1


-- !query
select * from range(0, (select 1))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NON_FOLDABLE_ARGUMENT",
  "sqlState" : "42K08",
  "messageParameters" : {
    "funcName" : "`range`",
    "paramName" : "`end`",
    "paramType" : "\"BIGINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 34,
    "fragment" : "range(0, (select 1))"
  } ]
}


-- !query
select * from values (0, 1) t(c1, c2), lateral range(0, c2)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NON_FOLDABLE_ARGUMENT",
  "sqlState" : "42K08",
  "messageParameters" : {
    "funcName" : "`range`",
    "paramName" : "`end`",
    "paramType" : "\"BIGINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 48,
    "stopIndex" : 59,
    "fragment" : "range(0, c2)"
  } ]
}


-- !query
select * from explode(array(1, 2))
-- !query schema
struct<col:int>
-- !query output
1
2


-- !query
select * from explode(map('a', 1, 'b', 2))
-- !query schema
struct<key:string,value:int>
-- !query output
a	1
b	2


-- !query
select * from explode(array())
-- !query schema
struct<col:void>
-- !query output



-- !query
select * from explode(map())
-- !query schema
struct<key:void,value:void>
-- !query output



-- !query
select * from explode(array(1, 2)) t(c1)
-- !query schema
struct<c1:int>
-- !query output
1
2


-- !query
select * from explode(map('a', 1, 'b', 2)) t(k, v)
-- !query schema
struct<k:string,v:int>
-- !query output
a	1
b	2


-- !query
select * from explode(array(rand(0)))
-- !query schema
struct<col:double>
-- !query output
0.7604953758285915


-- !query
select * from explode(null)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"NULL\"",
    "inputType" : "\"VOID\"",
    "paramIndex" : "first",
    "requiredType" : "(\"ARRAY\" or \"MAP\")",
    "sqlExpr" : "\"explode(NULL)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 27,
    "fragment" : "explode(null)"
  } ]
}


-- !query
select * from explode(null) t(c1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"NULL\"",
    "inputType" : "\"VOID\"",
    "paramIndex" : "first",
    "requiredType" : "(\"ARRAY\" or \"MAP\")",
    "sqlExpr" : "\"explode(NULL)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 33,
    "fragment" : "explode(null) t(c1)"
  } ]
}


-- !query
select * from explode(1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"1\"",
    "inputType" : "\"INT\"",
    "paramIndex" : "first",
    "requiredType" : "(\"ARRAY\" or \"MAP\")",
    "sqlExpr" : "\"explode(1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 24,
    "fragment" : "explode(1)"
  } ]
}


-- !query
select * from explode(1, 2)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITHOUT_SUGGESTION",
  "sqlState" : "42605",
  "messageParameters" : {
    "actualNum" : "2",
    "docroot" : "https://spark.apache.org/docs/latest",
    "expectedNum" : "1",
    "functionName" : "`explode`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 27,
    "fragment" : "explode(1, 2)"
  } ]
}


-- !query
select * from explode(explode(array(1)))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_GENERATOR.NESTED_IN_EXPRESSIONS",
  "sqlState" : "42K0E",
  "messageParameters" : {
    "expression" : "\"explode(explode(array(1)))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 40,
    "fragment" : "explode(explode(array(1)))"
  } ]
}


-- !query
select * from explode(array(1, 2)) t(c1, c2)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NUM_TABLE_VALUE_ALIASES_MISMATCH",
  "sqlState" : "42826",
  "messageParameters" : {
    "aliasesNum" : "2",
    "funcName" : "`explode`",
    "outColsNum" : "1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 44,
    "fragment" : "explode(array(1, 2)) t(c1, c2)"
  } ]
}


-- !query
select * from explode_outer(array(1, 2))
-- !query schema
struct<col:int>
-- !query output
1
2


-- !query
select * from explode_outer(map('a', 1, 'b', 2))
-- !query schema
struct<key:string,value:int>
-- !query output
a	1
b	2


-- !query
select * from explode_outer(array())
-- !query schema
struct<col:void>
-- !query output
NULL


-- !query
select * from explode_outer(map())
-- !query schema
struct<key:void,value:void>
-- !query output
NULL	NULL


-- !query
select * from range(2) join explode(array(1, 2))
-- !query schema
struct<id:bigint,col:int>
-- !query output
0	1
0	2
1	1
1	2


-- !query
select * from range(2) join explode_outer(array())
-- !query schema
struct<id:bigint,col:void>
-- !query output
0	NULL
1	NULL


-- !query
select * from inline(array(struct(1, 'a'), struct(2, 'b')))
-- !query schema
struct<col1:int,col2:string>
-- !query output
1	a
2	b


-- !query
select * from inline(array(struct(1, 'a'), struct(2, 'b'))) t(x, y)
-- !query schema
struct<x:int,y:string>
-- !query output
1	a
2	b


-- !query
select * from inline(array_remove(array(struct(1, 'a')), struct(1, 'a')))
-- !query schema
struct<col1:int,col2:string>
-- !query output



-- !query
select * from inline(null)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"NULL\"",
    "inputType" : "\"VOID\"",
    "paramIndex" : "first",
    "requiredType" : "\"ARRAY<STRUCT>\"",
    "sqlExpr" : "\"inline(NULL)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 26,
    "fragment" : "inline(null)"
  } ]
}


-- !query
select * from inline(array(struct(1, 2), struct(2, 3))) t(a, b, c)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NUM_TABLE_VALUE_ALIASES_MISMATCH",
  "sqlState" : "42826",
  "messageParameters" : {
    "aliasesNum" : "3",
    "funcName" : "`inline`",
    "outColsNum" : "2"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 66,
    "fragment" : "inline(array(struct(1, 2), struct(2, 3))) t(a, b, c)"
  } ]
}


-- !query
select * from inline_outer(array(struct(1, 'a'), struct(2, 'b')))
-- !query schema
struct<col1:int,col2:string>
-- !query output
1	a
2	b


-- !query
select * from inline_outer(array_remove(array(struct(1, 'a')), struct(1, 'a')))
-- !query schema
struct<col1:int,col2:string>
-- !query output
NULL	NULL


-- !query
select * from posexplode(array())
-- !query schema
struct<pos:int,col:void>
-- !query output



-- !query
select * from posexplode(array(1, 2))
-- !query schema
struct<pos:int,col:int>
-- !query output
0	1
1	2


-- !query
select * from posexplode(array(1, 2)) t(pos, x)
-- !query schema
struct<pos:int,x:int>
-- !query output
0	1
1	2


-- !query
select * from posexplode(map())
-- !query schema
struct<pos:int,key:void,value:void>
-- !query output



-- !query
select * from posexplode(map('a', 1, 'b', 2))
-- !query schema
struct<pos:int,key:string,value:int>
-- !query output
0	a	1
1	b	2


-- !query
select * from posexplode(map('a', 1, 'b', 2)) t(pos, k, v)
-- !query schema
struct<pos:int,k:string,v:int>
-- !query output
0	a	1
1	b	2


-- !query
select * from posexplode(1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"1\"",
    "inputType" : "\"INT\"",
    "paramIndex" : "first",
    "requiredType" : "(\"ARRAY\" or \"MAP\")",
    "sqlExpr" : "\"posexplode(1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 27,
    "fragment" : "posexplode(1)"
  } ]
}


-- !query
select * from posexplode(1, 2)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITHOUT_SUGGESTION",
  "sqlState" : "42605",
  "messageParameters" : {
    "actualNum" : "2",
    "docroot" : "https://spark.apache.org/docs/latest",
    "expectedNum" : "1",
    "functionName" : "`posexplode`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 30,
    "fragment" : "posexplode(1, 2)"
  } ]
}


-- !query
select * from posexplode(explode(array(1)))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_GENERATOR.NESTED_IN_EXPRESSIONS",
  "sqlState" : "42K0E",
  "messageParameters" : {
    "expression" : "\"posexplode(explode(array(1)))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 43,
    "fragment" : "posexplode(explode(array(1)))"
  } ]
}


-- !query
select * from posexplode(array(1, 2)) t(x)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NUM_TABLE_VALUE_ALIASES_MISMATCH",
  "sqlState" : "42826",
  "messageParameters" : {
    "aliasesNum" : "1",
    "funcName" : "`posexplode`",
    "outColsNum" : "2"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 42,
    "fragment" : "posexplode(array(1, 2)) t(x)"
  } ]
}


-- !query
select * from posexplode_outer(array())
-- !query schema
struct<pos:int,col:void>
-- !query output
NULL	NULL


-- !query
select * from posexplode_outer(array(1, 2))
-- !query schema
struct<pos:int,col:int>
-- !query output
0	1
1	2


-- !query
select * from posexplode_outer(map())
-- !query schema
struct<pos:int,key:void,value:void>
-- !query output
NULL	NULL	NULL


-- !query
select * from posexplode_outer(map('a', 1, 'b', 2))
-- !query schema
struct<pos:int,key:string,value:int>
-- !query output
0	a	1
1	b	2


-- !query
select * from json_tuple('{"a": 1, "b": 2}', 'a', 'b')
-- !query schema
struct<c0:string,c1:string>
-- !query output
1	2


-- !query
select * from json_tuple('{"a": 1, "b": 2}', 'a', 'c')
-- !query schema
struct<c0:string,c1:string>
-- !query output
1	NULL


-- !query
select * from json_tuple('{"a": 1, "b": 2}', 'a', 'a')
-- !query schema
struct<c0:string,c1:string>
-- !query output
1	1


-- !query
select * from json_tuple('{"a": 1, "b": 2}', 'a', 'b') AS t(x, y)
-- !query schema
struct<x:string,y:string>
-- !query output
1	2


-- !query
select * from json_tuple('{"a": bad, "b": string}', 'a', 'b')
-- !query schema
struct<c0:string,c1:string>
-- !query output
NULL	NULL


-- !query
select * from json_tuple()
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITHOUT_SUGGESTION",
  "sqlState" : "42605",
  "messageParameters" : {
    "actualNum" : "0",
    "docroot" : "https://spark.apache.org/docs/latest",
    "expectedNum" : "> 1",
    "functionName" : "`json_tuple`"
  }
}


-- !query
select * from json_tuple('{"a": 1}')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITHOUT_SUGGESTION",
  "sqlState" : "42605",
  "messageParameters" : {
    "actualNum" : "1",
    "docroot" : "https://spark.apache.org/docs/latest",
    "expectedNum" : "> 1",
    "functionName" : "`json_tuple`"
  }
}


-- !query
select * from json_tuple('{"a": 1}', 1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.NON_STRING_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "funcName" : "`json_tuple`",
    "sqlExpr" : "\"json_tuple({\"a\": 1}, 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 39,
    "fragment" : "json_tuple('{\"a\": 1}', 1)"
  } ]
}


-- !query
select * from json_tuple('{"a": 1}', null)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.NON_STRING_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "funcName" : "`json_tuple`",
    "sqlExpr" : "\"json_tuple({\"a\": 1}, NULL)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 42,
    "fragment" : "json_tuple('{\"a\": 1}', null)"
  } ]
}


-- !query
select * from json_tuple('{"a": 1, "b": 2}', 'a', 'b') AS t(x)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NUM_TABLE_VALUE_ALIASES_MISMATCH",
  "sqlState" : "42826",
  "messageParameters" : {
    "aliasesNum" : "1",
    "funcName" : "`json_tuple`",
    "outColsNum" : "2"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 62,
    "fragment" : "json_tuple('{\"a\": 1, \"b\": 2}', 'a', 'b') AS t(x)"
  } ]
}


-- !query
select * from stack(1, 1, 2, 3)
-- !query schema
struct<col0:int,col1:int,col2:int>
-- !query output
1	2	3


-- !query
select * from stack(2, 1, 2, 3)
-- !query schema
struct<col0:int,col1:int>
-- !query output
1	2
3	NULL


-- !query
select * from stack(3, 1, 2, 3) t(x)
-- !query schema
struct<x:int>
-- !query output
1
2
3


-- !query
select * from stack(4, 1, 2, 3) t(x)
-- !query schema
struct<x:int>
-- !query output
1
2
3
NULL


-- !query
select * from stack(2, 1, 1.1, 'a', 2, 2.2, 'b') t(a, b, c)
-- !query schema
struct<a:int,b:decimal(2,1),c:string>
-- !query output
1	1.1	a
2	2.2	b


-- !query
select * from stack(2, 1, 1.1, null, 2, null, 'b') t(a, b, c)
-- !query schema
struct<a:int,b:decimal(2,1),c:string>
-- !query output
1	1.1	NULL
2	NULL	b


-- !query
select * from stack()
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS.WITHOUT_SUGGESTION",
  "sqlState" : "42605",
  "messageParameters" : {
    "actualNum" : "0",
    "docroot" : "https://spark.apache.org/docs/latest",
    "expectedNum" : "> 1",
    "functionName" : "`stack`"
  }
}


-- !query
select * from stack(2, 1, 2, 3) t(a, b, c)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "NUM_TABLE_VALUE_ALIASES_MISMATCH",
  "sqlState" : "42826",
  "messageParameters" : {
    "aliasesNum" : "3",
    "funcName" : "`stack`",
    "outColsNum" : "2"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 42,
    "fragment" : "stack(2, 1, 2, 3) t(a, b, c)"
  } ]
}


-- !query
select * from stack(2, 1, '1.1', 'a', 2, 2.2, 'b')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.STACK_COLUMN_DIFF_TYPES",
  "sqlState" : "42K09",
  "messageParameters" : {
    "columnIndex" : "1",
    "leftParamIndex" : "2",
    "leftType" : "\"STRING\"",
    "rightParamIndex" : "5",
    "rightType" : "\"DECIMAL(2,1)\"",
    "sqlExpr" : "\"stack(2, 1, 1.1, a, 2, 2.2, b)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 50,
    "fragment" : "stack(2, 1, '1.1', 'a', 2, 2.2, 'b')"
  } ]
}


-- !query
select * from stack(2, explode(array(1, 2, 3)))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_GENERATOR.NESTED_IN_EXPRESSIONS",
  "sqlState" : "42K0E",
  "messageParameters" : {
    "expression" : "\"stack(2, explode(array(1, 2, 3)))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 47,
    "fragment" : "stack(2, explode(array(1, 2, 3)))"
  } ]
}
