-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TEMPORARY VIEW t AS SELECT 1
-- !query schema
struct<>
-- !query output



-- !query
SELECT '1' + cast(1 as tinyint)                         FROM t
-- !query schema
struct<(1 + CAST(1 AS TINYINT)):bigint>
-- !query output
2


-- !query
SELECT '1' + cast(1 as smallint)                        FROM t
-- !query schema
struct<(1 + CAST(1 AS SMALLINT)):bigint>
-- !query output
2


-- !query
SELECT '1' + cast(1 as int)                             FROM t
-- !query schema
struct<(1 + CAST(1 AS INT)):bigint>
-- !query output
2


-- !query
SELECT '1' + cast(1 as bigint)                          FROM t
-- !query schema
struct<(1 + CAST(1 AS BIGINT)):bigint>
-- !query output
2


-- !query
SELECT '1' + cast(1 as float)                           FROM t
-- !query schema
struct<(1 + CAST(1 AS FLOAT)):double>
-- !query output
2.0


-- !query
SELECT '1' + cast(1 as double)                          FROM t
-- !query schema
struct<(1 + CAST(1 AS DOUBLE)):double>
-- !query output
2.0


-- !query
SELECT '1' + cast(1 as decimal(10, 0))                  FROM t
-- !query schema
struct<(1 + CAST(1 AS DECIMAL(10,0))):double>
-- !query output
2.0


-- !query
SELECT '1' + '1'                                        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"STRING\"",
    "inputType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(1 + 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 16,
    "fragment" : "'1' + '1'"
  } ]
}


-- !query
SELECT '1' + cast('1' as binary)                        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BINARY\"",
    "inputType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(1 + CAST(1 AS BINARY))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 32,
    "fragment" : "'1' + cast('1' as binary)"
  } ]
}


-- !query
SELECT '1' + cast(1 as boolean)                         FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BOOLEAN\"",
    "inputType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(1 + CAST(1 AS BOOLEAN))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "'1' + cast(1 as boolean)"
  } ]
}


-- !query
SELECT '1' + cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"TIMESTAMP\"",
    "inputType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(1 + CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "'1' + cast('2017-12-11 09:30:00.0' as timestamp)"
  } ]
}


-- !query
SELECT '1' + cast('2017-12-11 09:30:00' as date)        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"CAST(2017-12-11 09:30:00 AS DATE)\"",
    "inputType" : "\"DATE\"",
    "paramIndex" : "second",
    "requiredType" : "(\"INT\" or \"SMALLINT\" or \"TINYINT\")",
    "sqlExpr" : "\"date_add(1, CAST(2017-12-11 09:30:00 AS DATE))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 48,
    "fragment" : "'1' + cast('2017-12-11 09:30:00' as date)"
  } ]
}


-- !query
SELECT '1' - cast(1 as tinyint)                         FROM t
-- !query schema
struct<(1 - CAST(1 AS TINYINT)):bigint>
-- !query output
0


-- !query
SELECT '1' - cast(1 as smallint)                        FROM t
-- !query schema
struct<(1 - CAST(1 AS SMALLINT)):bigint>
-- !query output
0


-- !query
SELECT '1' - cast(1 as int)                             FROM t
-- !query schema
struct<(1 - CAST(1 AS INT)):bigint>
-- !query output
0


-- !query
SELECT '1' - cast(1 as bigint)                          FROM t
-- !query schema
struct<(1 - CAST(1 AS BIGINT)):bigint>
-- !query output
0


-- !query
SELECT '1' - cast(1 as float)                           FROM t
-- !query schema
struct<(1 - CAST(1 AS FLOAT)):double>
-- !query output
0.0


-- !query
SELECT '1' - cast(1 as double)                          FROM t
-- !query schema
struct<(1 - CAST(1 AS DOUBLE)):double>
-- !query output
0.0


-- !query
SELECT '1' - cast(1 as decimal(10, 0))                  FROM t
-- !query schema
struct<(1 - CAST(1 AS DECIMAL(10,0))):double>
-- !query output
0.0


-- !query
SELECT '1' - '1'                                        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"STRING\"",
    "inputType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(1 - 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 16,
    "fragment" : "'1' - '1'"
  } ]
}


-- !query
SELECT '1' - cast('1' as binary)                        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BINARY\"",
    "inputType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(1 - CAST(1 AS BINARY))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 32,
    "fragment" : "'1' - cast('1' as binary)"
  } ]
}


-- !query
SELECT '1' - cast(1 as boolean)                         FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BOOLEAN\"",
    "inputType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(1 - CAST(1 AS BOOLEAN))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "'1' - cast(1 as boolean)"
  } ]
}


-- !query
SELECT '1' - cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "'1' - cast('2017-12-11 09:30:00.0' as timestamp)"
  } ]
}


-- !query
SELECT '1' - cast('2017-12-11 09:30:00' as date)        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 48,
    "fragment" : "'1' - cast('2017-12-11 09:30:00' as date)"
  } ]
}


-- !query
SELECT '1' * cast(1 as tinyint)                         FROM t
-- !query schema
struct<(1 * CAST(1 AS TINYINT)):bigint>
-- !query output
1


-- !query
SELECT '1' * cast(1 as smallint)                        FROM t
-- !query schema
struct<(1 * CAST(1 AS SMALLINT)):bigint>
-- !query output
1


-- !query
SELECT '1' * cast(1 as int)                             FROM t
-- !query schema
struct<(1 * CAST(1 AS INT)):bigint>
-- !query output
1


-- !query
SELECT '1' * cast(1 as bigint)                          FROM t
-- !query schema
struct<(1 * CAST(1 AS BIGINT)):bigint>
-- !query output
1


-- !query
SELECT '1' * cast(1 as float)                           FROM t
-- !query schema
struct<(1 * CAST(1 AS FLOAT)):double>
-- !query output
1.0


-- !query
SELECT '1' * cast(1 as double)                          FROM t
-- !query schema
struct<(1 * CAST(1 AS DOUBLE)):double>
-- !query output
1.0


-- !query
SELECT '1' * cast(1 as decimal(10, 0))                  FROM t
-- !query schema
struct<(1 * CAST(1 AS DECIMAL(10,0))):double>
-- !query output
1.0


-- !query
SELECT '1' * '1'                                        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"STRING\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(1 * 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 16,
    "fragment" : "'1' * '1'"
  } ]
}


-- !query
SELECT '1' * cast('1' as binary)                        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BINARY\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(1 * CAST(1 AS BINARY))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 32,
    "fragment" : "'1' * cast('1' as binary)"
  } ]
}


-- !query
SELECT '1' * cast(1 as boolean)                         FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BOOLEAN\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(1 * CAST(1 AS BOOLEAN))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "'1' * cast(1 as boolean)"
  } ]
}


-- !query
SELECT '1' * cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"TIMESTAMP\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(1 * CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "'1' * cast('2017-12-11 09:30:00.0' as timestamp)"
  } ]
}


-- !query
SELECT '1' * cast('2017-12-11 09:30:00' as date)        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"DATE\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(1 * CAST(2017-12-11 09:30:00 AS DATE))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 48,
    "fragment" : "'1' * cast('2017-12-11 09:30:00' as date)"
  } ]
}


-- !query
SELECT '1' / cast(1 as tinyint)                         FROM t
-- !query schema
struct<(1 / CAST(1 AS TINYINT)):double>
-- !query output
1.0


-- !query
SELECT '1' / cast(1 as smallint)                        FROM t
-- !query schema
struct<(1 / CAST(1 AS SMALLINT)):double>
-- !query output
1.0


-- !query
SELECT '1' / cast(1 as int)                             FROM t
-- !query schema
struct<(1 / CAST(1 AS INT)):double>
-- !query output
1.0


-- !query
SELECT '1' / cast(1 as bigint)                          FROM t
-- !query schema
struct<(1 / CAST(1 AS BIGINT)):double>
-- !query output
1.0


-- !query
SELECT '1' / cast(1 as float)                           FROM t
-- !query schema
struct<(1 / CAST(1 AS FLOAT)):double>
-- !query output
1.0


-- !query
SELECT '1' / cast(1 as double)                          FROM t
-- !query schema
struct<(1 / CAST(1 AS DOUBLE)):double>
-- !query output
1.0


-- !query
SELECT '1' / cast(1 as decimal(10, 0))                  FROM t
-- !query schema
struct<(1 / CAST(1 AS DECIMAL(10,0))):double>
-- !query output
1.0


-- !query
SELECT '1' / '1'                                        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"STRING\"",
    "inputType" : "(\"DOUBLE\" or \"DECIMAL\")",
    "sqlExpr" : "\"(1 / 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 16,
    "fragment" : "'1' / '1'"
  } ]
}


-- !query
SELECT '1' / cast('1' as binary)                        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BINARY\"",
    "inputType" : "(\"DOUBLE\" or \"DECIMAL\")",
    "sqlExpr" : "\"(1 / CAST(1 AS BINARY))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 32,
    "fragment" : "'1' / cast('1' as binary)"
  } ]
}


-- !query
SELECT '1' / cast(1 as boolean)                         FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BOOLEAN\"",
    "inputType" : "(\"DOUBLE\" or \"DECIMAL\")",
    "sqlExpr" : "\"(1 / CAST(1 AS BOOLEAN))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "'1' / cast(1 as boolean)"
  } ]
}


-- !query
SELECT '1' / cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"TIMESTAMP\"",
    "inputType" : "(\"DOUBLE\" or \"DECIMAL\")",
    "sqlExpr" : "\"(1 / CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "'1' / cast('2017-12-11 09:30:00.0' as timestamp)"
  } ]
}


-- !query
SELECT '1' / cast('2017-12-11 09:30:00' as date)        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"DATE\"",
    "inputType" : "(\"DOUBLE\" or \"DECIMAL\")",
    "sqlExpr" : "\"(1 / CAST(2017-12-11 09:30:00 AS DATE))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 48,
    "fragment" : "'1' / cast('2017-12-11 09:30:00' as date)"
  } ]
}


-- !query
SELECT '1' % cast(1 as tinyint)                         FROM t
-- !query schema
struct<(1 % CAST(1 AS TINYINT)):bigint>
-- !query output
0


-- !query
SELECT '1' % cast(1 as smallint)                        FROM t
-- !query schema
struct<(1 % CAST(1 AS SMALLINT)):bigint>
-- !query output
0


-- !query
SELECT '1' % cast(1 as int)                             FROM t
-- !query schema
struct<(1 % CAST(1 AS INT)):bigint>
-- !query output
0


-- !query
SELECT '1' % cast(1 as bigint)                          FROM t
-- !query schema
struct<(1 % CAST(1 AS BIGINT)):bigint>
-- !query output
0


-- !query
SELECT '1' % cast(1 as float)                           FROM t
-- !query schema
struct<(1 % CAST(1 AS FLOAT)):double>
-- !query output
0.0


-- !query
SELECT '1' % cast(1 as double)                          FROM t
-- !query schema
struct<(1 % CAST(1 AS DOUBLE)):double>
-- !query output
0.0


-- !query
SELECT '1' % cast(1 as decimal(10, 0))                  FROM t
-- !query schema
struct<(1 % CAST(1 AS DECIMAL(10,0))):double>
-- !query output
0.0


-- !query
SELECT '1' % '1'                                        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"STRING\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(1 % 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 16,
    "fragment" : "'1' % '1'"
  } ]
}


-- !query
SELECT '1' % cast('1' as binary)                        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BINARY\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(1 % CAST(1 AS BINARY))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 32,
    "fragment" : "'1' % cast('1' as binary)"
  } ]
}


-- !query
SELECT '1' % cast(1 as boolean)                         FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BOOLEAN\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(1 % CAST(1 AS BOOLEAN))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "'1' % cast(1 as boolean)"
  } ]
}


-- !query
SELECT '1' % cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"TIMESTAMP\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(1 % CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "'1' % cast('2017-12-11 09:30:00.0' as timestamp)"
  } ]
}


-- !query
SELECT '1' % cast('2017-12-11 09:30:00' as date)        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"DATE\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(1 % CAST(2017-12-11 09:30:00 AS DATE))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 48,
    "fragment" : "'1' % cast('2017-12-11 09:30:00' as date)"
  } ]
}


-- !query
SELECT pmod('1', cast(1 as tinyint))                         FROM t
-- !query schema
struct<pmod(1, CAST(1 AS TINYINT)):bigint>
-- !query output
0


-- !query
SELECT pmod('1', cast(1 as smallint))                        FROM t
-- !query schema
struct<pmod(1, CAST(1 AS SMALLINT)):bigint>
-- !query output
0


-- !query
SELECT pmod('1', cast(1 as int))                             FROM t
-- !query schema
struct<pmod(1, CAST(1 AS INT)):bigint>
-- !query output
0


-- !query
SELECT pmod('1', cast(1 as bigint))                          FROM t
-- !query schema
struct<pmod(1, CAST(1 AS BIGINT)):bigint>
-- !query output
0


-- !query
SELECT pmod('1', cast(1 as float))                           FROM t
-- !query schema
struct<pmod(1, CAST(1 AS FLOAT)):double>
-- !query output
0.0


-- !query
SELECT pmod('1', cast(1 as double))                          FROM t
-- !query schema
struct<pmod(1, CAST(1 AS DOUBLE)):double>
-- !query output
0.0


-- !query
SELECT pmod('1', cast(1 as decimal(10, 0)))                  FROM t
-- !query schema
struct<pmod(1, CAST(1 AS DECIMAL(10,0))):double>
-- !query output
0.0


-- !query
SELECT pmod('1', '1')                                        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"STRING\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"pmod(1, 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 21,
    "fragment" : "pmod('1', '1')"
  } ]
}


-- !query
SELECT pmod('1', cast('1' as binary))                        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BINARY\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"pmod(1, CAST(1 AS BINARY))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 37,
    "fragment" : "pmod('1', cast('1' as binary))"
  } ]
}


-- !query
SELECT pmod('1', cast(1 as boolean))                         FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BOOLEAN\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"pmod(1, CAST(1 AS BOOLEAN))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 36,
    "fragment" : "pmod('1', cast(1 as boolean))"
  } ]
}


-- !query
SELECT pmod('1', cast('2017-12-11 09:30:00.0' as timestamp)) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"TIMESTAMP\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"pmod(1, CAST(2017-12-11 09:30:00.0 AS TIMESTAMP))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 60,
    "fragment" : "pmod('1', cast('2017-12-11 09:30:00.0' as timestamp))"
  } ]
}


-- !query
SELECT pmod('1', cast('2017-12-11 09:30:00' as date))        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"DATE\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"pmod(1, CAST(2017-12-11 09:30:00 AS DATE))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 53,
    "fragment" : "pmod('1', cast('2017-12-11 09:30:00' as date))"
  } ]
}


-- !query
SELECT cast(1 as tinyint)                         + '1' FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) + 1):bigint>
-- !query output
2


-- !query
SELECT cast(1 as smallint)                        + '1' FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) + 1):bigint>
-- !query output
2


-- !query
SELECT cast(1 as int)                             + '1' FROM t
-- !query schema
struct<(CAST(1 AS INT) + 1):bigint>
-- !query output
2


-- !query
SELECT cast(1 as bigint)                          + '1' FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) + 1):bigint>
-- !query output
2


-- !query
SELECT cast(1 as float)                           + '1' FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) + 1):double>
-- !query output
2.0


-- !query
SELECT cast(1 as double)                          + '1' FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) + 1):double>
-- !query output
2.0


-- !query
SELECT cast(1 as decimal(10, 0))                  + '1' FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) + 1):double>
-- !query output
2.0


-- !query
SELECT cast('1' as binary)                        + '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BINARY\"",
    "inputType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(CAST(1 AS BINARY) + 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('1' as binary)                        + '1'"
  } ]
}


-- !query
SELECT cast(1 as boolean)                         + '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BOOLEAN\"",
    "inputType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) + 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast(1 as boolean)                         + '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) + '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"TIMESTAMP\"",
    "inputType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) + 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00.0' as timestamp) + '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date)        + '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"1\"",
    "inputType" : "\"DATE\"",
    "paramIndex" : "second",
    "requiredType" : "(\"INT\" or \"SMALLINT\" or \"TINYINT\")",
    "sqlExpr" : "\"date_add(CAST(2017-12-11 09:30:00 AS DATE), 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00' as date)        + '1'"
  } ]
}


-- !query
SELECT cast(1 as tinyint)                         - '1' FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) - 1):bigint>
-- !query output
0


-- !query
SELECT cast(1 as smallint)                        - '1' FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) - 1):bigint>
-- !query output
0


-- !query
SELECT cast(1 as int)                             - '1' FROM t
-- !query schema
struct<(CAST(1 AS INT) - 1):bigint>
-- !query output
0


-- !query
SELECT cast(1 as bigint)                          - '1' FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) - 1):bigint>
-- !query output
0


-- !query
SELECT cast(1 as float)                           - '1' FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) - 1):double>
-- !query output
0.0


-- !query
SELECT cast(1 as double)                          - '1' FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) - 1):double>
-- !query output
0.0


-- !query
SELECT cast(1 as decimal(10, 0))                  - '1' FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) - 1):double>
-- !query output
0.0


-- !query
SELECT cast('1' as binary)                        - '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BINARY\"",
    "inputType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(CAST(1 AS BINARY) - 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('1' as binary)                        - '1'"
  } ]
}


-- !query
SELECT cast(1 as boolean)                         - '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BOOLEAN\"",
    "inputType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) - 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast(1 as boolean)                         - '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) - '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00.0' as timestamp) - '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date)        - '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00' as date)        - '1'"
  } ]
}


-- !query
SELECT cast(1 as tinyint)                         * '1' FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) * 1):bigint>
-- !query output
1


-- !query
SELECT cast(1 as smallint)                        * '1' FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) * 1):bigint>
-- !query output
1


-- !query
SELECT cast(1 as int)                             * '1' FROM t
-- !query schema
struct<(CAST(1 AS INT) * 1):bigint>
-- !query output
1


-- !query
SELECT cast(1 as bigint)                          * '1' FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) * 1):bigint>
-- !query output
1


-- !query
SELECT cast(1 as float)                           * '1' FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) * 1):double>
-- !query output
1.0


-- !query
SELECT cast(1 as double)                          * '1' FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) * 1):double>
-- !query output
1.0


-- !query
SELECT cast(1 as decimal(10, 0))                  * '1' FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) * 1):double>
-- !query output
1.0


-- !query
SELECT cast('1' as binary)                        * '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BINARY\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(CAST(1 AS BINARY) * 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('1' as binary)                        * '1'"
  } ]
}


-- !query
SELECT cast(1 as boolean)                         * '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BOOLEAN\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) * 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast(1 as boolean)                         * '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) * '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"TIMESTAMP\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) * 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00.0' as timestamp) * '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date)        * '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"DATE\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) * 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00' as date)        * '1'"
  } ]
}


-- !query
SELECT cast(1 as tinyint)                         / '1' FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) / 1):double>
-- !query output
1.0


-- !query
SELECT cast(1 as smallint)                        / '1' FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) / 1):double>
-- !query output
1.0


-- !query
SELECT cast(1 as int)                             / '1' FROM t
-- !query schema
struct<(CAST(1 AS INT) / 1):double>
-- !query output
1.0


-- !query
SELECT cast(1 as bigint)                          / '1' FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) / 1):double>
-- !query output
1.0


-- !query
SELECT cast(1 as float)                           / '1' FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) / 1):double>
-- !query output
1.0


-- !query
SELECT cast(1 as double)                          / '1' FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) / 1):double>
-- !query output
1.0


-- !query
SELECT cast(1 as decimal(10, 0))                  / '1' FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) / 1):double>
-- !query output
1.0


-- !query
SELECT cast('1' as binary)                        / '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BINARY\"",
    "inputType" : "(\"DOUBLE\" or \"DECIMAL\")",
    "sqlExpr" : "\"(CAST(1 AS BINARY) / 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('1' as binary)                        / '1'"
  } ]
}


-- !query
SELECT cast(1 as boolean)                         / '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BOOLEAN\"",
    "inputType" : "(\"DOUBLE\" or \"DECIMAL\")",
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) / 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast(1 as boolean)                         / '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) / '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"TIMESTAMP\"",
    "inputType" : "(\"DOUBLE\" or \"DECIMAL\")",
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) / 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00.0' as timestamp) / '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date)        / '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"DATE\"",
    "inputType" : "(\"DOUBLE\" or \"DECIMAL\")",
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) / 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00' as date)        / '1'"
  } ]
}


-- !query
SELECT cast(1 as tinyint)                         % '1' FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) % 1):bigint>
-- !query output
0


-- !query
SELECT cast(1 as smallint)                        % '1' FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) % 1):bigint>
-- !query output
0


-- !query
SELECT cast(1 as int)                             % '1' FROM t
-- !query schema
struct<(CAST(1 AS INT) % 1):bigint>
-- !query output
0


-- !query
SELECT cast(1 as bigint)                          % '1' FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) % 1):bigint>
-- !query output
0


-- !query
SELECT cast(1 as float)                           % '1' FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) % 1):double>
-- !query output
0.0


-- !query
SELECT cast(1 as double)                          % '1' FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) % 1):double>
-- !query output
0.0


-- !query
SELECT cast(1 as decimal(10, 0))                  % '1' FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) % 1):double>
-- !query output
0.0


-- !query
SELECT cast('1' as binary)                        % '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BINARY\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(CAST(1 AS BINARY) % 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('1' as binary)                        % '1'"
  } ]
}


-- !query
SELECT cast(1 as boolean)                         % '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BOOLEAN\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(CAST(1 AS BOOLEAN) % 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast(1 as boolean)                         % '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) % '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"TIMESTAMP\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP) % 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00.0' as timestamp) % '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date)        % '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"DATE\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"(CAST(2017-12-11 09:30:00 AS DATE) % 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00' as date)        % '1'"
  } ]
}


-- !query
SELECT pmod(cast(1 as tinyint), '1')                         FROM t
-- !query schema
struct<pmod(CAST(1 AS TINYINT), 1):bigint>
-- !query output
0


-- !query
SELECT pmod(cast(1 as smallint), '1')                        FROM t
-- !query schema
struct<pmod(CAST(1 AS SMALLINT), 1):bigint>
-- !query output
0


-- !query
SELECT pmod(cast(1 as int), '1')                             FROM t
-- !query schema
struct<pmod(CAST(1 AS INT), 1):bigint>
-- !query output
0


-- !query
SELECT pmod(cast(1 as bigint), '1')                          FROM t
-- !query schema
struct<pmod(CAST(1 AS BIGINT), 1):bigint>
-- !query output
0


-- !query
SELECT pmod(cast(1 as float), '1')                           FROM t
-- !query schema
struct<pmod(CAST(1 AS FLOAT), 1):double>
-- !query output
0.0


-- !query
SELECT pmod(cast(1 as double), '1')                          FROM t
-- !query schema
struct<pmod(CAST(1 AS DOUBLE), 1):double>
-- !query output
0.0


-- !query
SELECT pmod(cast(1 as decimal(10, 0)), '1')                  FROM t
-- !query schema
struct<pmod(CAST(1 AS DECIMAL(10,0)), 1):double>
-- !query output
0.0


-- !query
SELECT pmod(cast('1' as binary), '1')                        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BINARY\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"pmod(CAST(1 AS BINARY), 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 37,
    "fragment" : "pmod(cast('1' as binary), '1')"
  } ]
}


-- !query
SELECT pmod(cast(1 as boolean), '1')                         FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"BOOLEAN\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"pmod(CAST(1 AS BOOLEAN), 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 36,
    "fragment" : "pmod(cast(1 as boolean), '1')"
  } ]
}


-- !query
SELECT pmod(cast('2017-12-11 09:30:00.0' as timestamp), '1') FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"TIMESTAMP\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"pmod(CAST(2017-12-11 09:30:00.0 AS TIMESTAMP), 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 60,
    "fragment" : "pmod(cast('2017-12-11 09:30:00.0' as timestamp), '1')"
  } ]
}


-- !query
SELECT pmod(cast('2017-12-11 09:30:00' as date), '1')        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.BINARY_OP_WRONG_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "actualDataType" : "\"DATE\"",
    "inputType" : "\"NUMERIC\"",
    "sqlExpr" : "\"pmod(CAST(2017-12-11 09:30:00 AS DATE), 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 53,
    "fragment" : "pmod(cast('2017-12-11 09:30:00' as date), '1')"
  } ]
}


-- !query
SELECT '1' = cast(1 as tinyint)                         FROM t
-- !query schema
struct<(1 = CAST(1 AS TINYINT)):boolean>
-- !query output
true


-- !query
SELECT '1' = cast(1 as smallint)                        FROM t
-- !query schema
struct<(1 = CAST(1 AS SMALLINT)):boolean>
-- !query output
true


-- !query
SELECT '1' = cast(1 as int)                             FROM t
-- !query schema
struct<(1 = CAST(1 AS INT)):boolean>
-- !query output
true


-- !query
SELECT '1' = cast(1 as bigint)                          FROM t
-- !query schema
struct<(1 = CAST(1 AS BIGINT)):boolean>
-- !query output
true


-- !query
SELECT '1' = cast(1 as float)                           FROM t
-- !query schema
struct<(1 = CAST(1 AS FLOAT)):boolean>
-- !query output
true


-- !query
SELECT '1' = cast(1 as double)                          FROM t
-- !query schema
struct<(1 = CAST(1 AS DOUBLE)):boolean>
-- !query output
true


-- !query
SELECT '1' = cast(1 as decimal(10, 0))                  FROM t
-- !query schema
struct<(1 = CAST(1 AS DECIMAL(10,0))):boolean>
-- !query output
true


-- !query
SELECT '1' = '1'                                        FROM t
-- !query schema
struct<(1 = 1):boolean>
-- !query output
true


-- !query
SELECT '1' = cast('1' as binary)                        FROM t
-- !query schema
struct<(1 = CAST(1 AS BINARY)):boolean>
-- !query output
true


-- !query
SELECT '1' = cast(1 as boolean)                         FROM t
-- !query schema
struct<(1 = CAST(1 AS BOOLEAN)):boolean>
-- !query output
true


-- !query
SELECT '1' = cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "'1' = cast('2017-12-11 09:30:00.0' as timestamp)"
  } ]
}


-- !query
SELECT '1' = cast('2017-12-11 09:30:00' as date)        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 48,
    "fragment" : "'1' = cast('2017-12-11 09:30:00' as date)"
  } ]
}


-- !query
SELECT cast(1 as tinyint)                         = '1' FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) = 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as smallint)                        = '1' FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) = 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as int)                             = '1' FROM t
-- !query schema
struct<(CAST(1 AS INT) = 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as bigint)                          = '1' FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) = 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as float)                           = '1' FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) = 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as double)                          = '1' FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) = 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as decimal(10, 0))                  = '1' FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) = 1):boolean>
-- !query output
true


-- !query
SELECT cast('1' as binary)                        = '1' FROM t
-- !query schema
struct<(CAST(1 AS BINARY) = 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as boolean)                         = '1' FROM t
-- !query schema
struct<(CAST(1 AS BOOLEAN) = 1):boolean>
-- !query output
true


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) = '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00.0' as timestamp) = '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date)        = '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00' as date)        = '1'"
  } ]
}


-- !query
SELECT '1' <=> cast(1 as tinyint)                         FROM t
-- !query schema
struct<(1 <=> CAST(1 AS TINYINT)):boolean>
-- !query output
true


-- !query
SELECT '1' <=> cast(1 as smallint)                        FROM t
-- !query schema
struct<(1 <=> CAST(1 AS SMALLINT)):boolean>
-- !query output
true


-- !query
SELECT '1' <=> cast(1 as int)                             FROM t
-- !query schema
struct<(1 <=> CAST(1 AS INT)):boolean>
-- !query output
true


-- !query
SELECT '1' <=> cast(1 as bigint)                          FROM t
-- !query schema
struct<(1 <=> CAST(1 AS BIGINT)):boolean>
-- !query output
true


-- !query
SELECT '1' <=> cast(1 as float)                           FROM t
-- !query schema
struct<(1 <=> CAST(1 AS FLOAT)):boolean>
-- !query output
true


-- !query
SELECT '1' <=> cast(1 as double)                          FROM t
-- !query schema
struct<(1 <=> CAST(1 AS DOUBLE)):boolean>
-- !query output
true


-- !query
SELECT '1' <=> cast(1 as decimal(10, 0))                  FROM t
-- !query schema
struct<(1 <=> CAST(1 AS DECIMAL(10,0))):boolean>
-- !query output
true


-- !query
SELECT '1' <=> '1'                                        FROM t
-- !query schema
struct<(1 <=> 1):boolean>
-- !query output
true


-- !query
SELECT '1' <=> cast('1' as binary)                        FROM t
-- !query schema
struct<(1 <=> CAST(1 AS BINARY)):boolean>
-- !query output
true


-- !query
SELECT '1' <=> cast(1 as boolean)                         FROM t
-- !query schema
struct<(1 <=> CAST(1 AS BOOLEAN)):boolean>
-- !query output
true


-- !query
SELECT '1' <=> cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 57,
    "fragment" : "'1' <=> cast('2017-12-11 09:30:00.0' as timestamp)"
  } ]
}


-- !query
SELECT '1' <=> cast('2017-12-11 09:30:00' as date)        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 50,
    "fragment" : "'1' <=> cast('2017-12-11 09:30:00' as date)"
  } ]
}


-- !query
SELECT cast(1 as tinyint)                         <=> '1' FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) <=> 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as smallint)                        <=> '1' FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) <=> 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as int)                             <=> '1' FROM t
-- !query schema
struct<(CAST(1 AS INT) <=> 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as bigint)                          <=> '1' FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) <=> 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as float)                           <=> '1' FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) <=> 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as double)                          <=> '1' FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) <=> 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as decimal(10, 0))                  <=> '1' FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) <=> 1):boolean>
-- !query output
true


-- !query
SELECT cast('1' as binary)                        <=> '1' FROM t
-- !query schema
struct<(CAST(1 AS BINARY) <=> 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as boolean)                         <=> '1' FROM t
-- !query schema
struct<(CAST(1 AS BOOLEAN) <=> 1):boolean>
-- !query output
true


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) <=> '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 57,
    "fragment" : "cast('2017-12-11 09:30:00.0' as timestamp) <=> '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date)        <=> '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 57,
    "fragment" : "cast('2017-12-11 09:30:00' as date)        <=> '1'"
  } ]
}


-- !query
SELECT '1' < cast(1 as tinyint)                         FROM t
-- !query schema
struct<(1 < CAST(1 AS TINYINT)):boolean>
-- !query output
false


-- !query
SELECT '1' < cast(1 as smallint)                        FROM t
-- !query schema
struct<(1 < CAST(1 AS SMALLINT)):boolean>
-- !query output
false


-- !query
SELECT '1' < cast(1 as int)                             FROM t
-- !query schema
struct<(1 < CAST(1 AS INT)):boolean>
-- !query output
false


-- !query
SELECT '1' < cast(1 as bigint)                          FROM t
-- !query schema
struct<(1 < CAST(1 AS BIGINT)):boolean>
-- !query output
false


-- !query
SELECT '1' < cast(1 as float)                           FROM t
-- !query schema
struct<(1 < CAST(1 AS FLOAT)):boolean>
-- !query output
false


-- !query
SELECT '1' < cast(1 as double)                          FROM t
-- !query schema
struct<(1 < CAST(1 AS DOUBLE)):boolean>
-- !query output
false


-- !query
SELECT '1' < cast(1 as decimal(10, 0))                  FROM t
-- !query schema
struct<(1 < CAST(1 AS DECIMAL(10,0))):boolean>
-- !query output
false


-- !query
SELECT '1' < '1'                                        FROM t
-- !query schema
struct<(1 < 1):boolean>
-- !query output
false


-- !query
SELECT '1' < cast('1' as binary)                        FROM t
-- !query schema
struct<(1 < CAST(1 AS BINARY)):boolean>
-- !query output
false


-- !query
SELECT '1' < cast(1 as boolean)                         FROM t
-- !query schema
struct<(1 < CAST(1 AS BOOLEAN)):boolean>
-- !query output
false


-- !query
SELECT '1' < cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "'1' < cast('2017-12-11 09:30:00.0' as timestamp)"
  } ]
}


-- !query
SELECT '1' < cast('2017-12-11 09:30:00' as date)        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 48,
    "fragment" : "'1' < cast('2017-12-11 09:30:00' as date)"
  } ]
}


-- !query
SELECT '1' <= cast(1 as tinyint)                         FROM t
-- !query schema
struct<(1 <= CAST(1 AS TINYINT)):boolean>
-- !query output
true


-- !query
SELECT '1' <= cast(1 as smallint)                        FROM t
-- !query schema
struct<(1 <= CAST(1 AS SMALLINT)):boolean>
-- !query output
true


-- !query
SELECT '1' <= cast(1 as int)                             FROM t
-- !query schema
struct<(1 <= CAST(1 AS INT)):boolean>
-- !query output
true


-- !query
SELECT '1' <= cast(1 as bigint)                          FROM t
-- !query schema
struct<(1 <= CAST(1 AS BIGINT)):boolean>
-- !query output
true


-- !query
SELECT '1' <= cast(1 as float)                           FROM t
-- !query schema
struct<(1 <= CAST(1 AS FLOAT)):boolean>
-- !query output
true


-- !query
SELECT '1' <= cast(1 as double)                          FROM t
-- !query schema
struct<(1 <= CAST(1 AS DOUBLE)):boolean>
-- !query output
true


-- !query
SELECT '1' <= cast(1 as decimal(10, 0))                  FROM t
-- !query schema
struct<(1 <= CAST(1 AS DECIMAL(10,0))):boolean>
-- !query output
true


-- !query
SELECT '1' <= '1'                                        FROM t
-- !query schema
struct<(1 <= 1):boolean>
-- !query output
true


-- !query
SELECT '1' <= cast('1' as binary)                        FROM t
-- !query schema
struct<(1 <= CAST(1 AS BINARY)):boolean>
-- !query output
true


-- !query
SELECT '1' <= cast(1 as boolean)                         FROM t
-- !query schema
struct<(1 <= CAST(1 AS BOOLEAN)):boolean>
-- !query output
true


-- !query
SELECT '1' <= cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 56,
    "fragment" : "'1' <= cast('2017-12-11 09:30:00.0' as timestamp)"
  } ]
}


-- !query
SELECT '1' <= cast('2017-12-11 09:30:00' as date)        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 49,
    "fragment" : "'1' <= cast('2017-12-11 09:30:00' as date)"
  } ]
}


-- !query
SELECT '1' > cast(1 as tinyint)                         FROM t
-- !query schema
struct<(1 > CAST(1 AS TINYINT)):boolean>
-- !query output
false


-- !query
SELECT '1' > cast(1 as smallint)                        FROM t
-- !query schema
struct<(1 > CAST(1 AS SMALLINT)):boolean>
-- !query output
false


-- !query
SELECT '1' > cast(1 as int)                             FROM t
-- !query schema
struct<(1 > CAST(1 AS INT)):boolean>
-- !query output
false


-- !query
SELECT '1' > cast(1 as bigint)                          FROM t
-- !query schema
struct<(1 > CAST(1 AS BIGINT)):boolean>
-- !query output
false


-- !query
SELECT '1' > cast(1 as float)                           FROM t
-- !query schema
struct<(1 > CAST(1 AS FLOAT)):boolean>
-- !query output
false


-- !query
SELECT '1' > cast(1 as double)                          FROM t
-- !query schema
struct<(1 > CAST(1 AS DOUBLE)):boolean>
-- !query output
false


-- !query
SELECT '1' > cast(1 as decimal(10, 0))                  FROM t
-- !query schema
struct<(1 > CAST(1 AS DECIMAL(10,0))):boolean>
-- !query output
false


-- !query
SELECT '1' > '1'                                        FROM t
-- !query schema
struct<(1 > 1):boolean>
-- !query output
false


-- !query
SELECT '1' > cast('1' as binary)                        FROM t
-- !query schema
struct<(1 > CAST(1 AS BINARY)):boolean>
-- !query output
false


-- !query
SELECT '1' > cast(1 as boolean)                         FROM t
-- !query schema
struct<(1 > CAST(1 AS BOOLEAN)):boolean>
-- !query output
false


-- !query
SELECT '1' > cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "'1' > cast('2017-12-11 09:30:00.0' as timestamp)"
  } ]
}


-- !query
SELECT '1' > cast('2017-12-11 09:30:00' as date)        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 48,
    "fragment" : "'1' > cast('2017-12-11 09:30:00' as date)"
  } ]
}


-- !query
SELECT '1' >= cast(1 as tinyint)                         FROM t
-- !query schema
struct<(1 >= CAST(1 AS TINYINT)):boolean>
-- !query output
true


-- !query
SELECT '1' >= cast(1 as smallint)                        FROM t
-- !query schema
struct<(1 >= CAST(1 AS SMALLINT)):boolean>
-- !query output
true


-- !query
SELECT '1' >= cast(1 as int)                             FROM t
-- !query schema
struct<(1 >= CAST(1 AS INT)):boolean>
-- !query output
true


-- !query
SELECT '1' >= cast(1 as bigint)                          FROM t
-- !query schema
struct<(1 >= CAST(1 AS BIGINT)):boolean>
-- !query output
true


-- !query
SELECT '1' >= cast(1 as float)                           FROM t
-- !query schema
struct<(1 >= CAST(1 AS FLOAT)):boolean>
-- !query output
true


-- !query
SELECT '1' >= cast(1 as double)                          FROM t
-- !query schema
struct<(1 >= CAST(1 AS DOUBLE)):boolean>
-- !query output
true


-- !query
SELECT '1' >= cast(1 as decimal(10, 0))                  FROM t
-- !query schema
struct<(1 >= CAST(1 AS DECIMAL(10,0))):boolean>
-- !query output
true


-- !query
SELECT '1' >= '1'                                        FROM t
-- !query schema
struct<(1 >= 1):boolean>
-- !query output
true


-- !query
SELECT '1' >= cast('1' as binary)                        FROM t
-- !query schema
struct<(1 >= CAST(1 AS BINARY)):boolean>
-- !query output
true


-- !query
SELECT '1' >= cast(1 as boolean)                         FROM t
-- !query schema
struct<(1 >= CAST(1 AS BOOLEAN)):boolean>
-- !query output
true


-- !query
SELECT '1' >= cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 56,
    "fragment" : "'1' >= cast('2017-12-11 09:30:00.0' as timestamp)"
  } ]
}


-- !query
SELECT '1' >= cast('2017-12-11 09:30:00' as date)        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 49,
    "fragment" : "'1' >= cast('2017-12-11 09:30:00' as date)"
  } ]
}


-- !query
SELECT '1' <> cast(1 as tinyint)                         FROM t
-- !query schema
struct<(NOT (1 = CAST(1 AS TINYINT))):boolean>
-- !query output
false


-- !query
SELECT '1' <> cast(1 as smallint)                        FROM t
-- !query schema
struct<(NOT (1 = CAST(1 AS SMALLINT))):boolean>
-- !query output
false


-- !query
SELECT '1' <> cast(1 as int)                             FROM t
-- !query schema
struct<(NOT (1 = CAST(1 AS INT))):boolean>
-- !query output
false


-- !query
SELECT '1' <> cast(1 as bigint)                          FROM t
-- !query schema
struct<(NOT (1 = CAST(1 AS BIGINT))):boolean>
-- !query output
false


-- !query
SELECT '1' <> cast(1 as float)                           FROM t
-- !query schema
struct<(NOT (1 = CAST(1 AS FLOAT))):boolean>
-- !query output
false


-- !query
SELECT '1' <> cast(1 as double)                          FROM t
-- !query schema
struct<(NOT (1 = CAST(1 AS DOUBLE))):boolean>
-- !query output
false


-- !query
SELECT '1' <> cast(1 as decimal(10, 0))                  FROM t
-- !query schema
struct<(NOT (1 = CAST(1 AS DECIMAL(10,0)))):boolean>
-- !query output
false


-- !query
SELECT '1' <> '1'                                        FROM t
-- !query schema
struct<(NOT (1 = 1)):boolean>
-- !query output
false


-- !query
SELECT '1' <> cast('1' as binary)                        FROM t
-- !query schema
struct<(NOT (1 = CAST(1 AS BINARY))):boolean>
-- !query output
false


-- !query
SELECT '1' <> cast(1 as boolean)                         FROM t
-- !query schema
struct<(NOT (1 = CAST(1 AS BOOLEAN))):boolean>
-- !query output
false


-- !query
SELECT '1' <> cast('2017-12-11 09:30:00.0' as timestamp) FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 56,
    "fragment" : "'1' <> cast('2017-12-11 09:30:00.0' as timestamp)"
  } ]
}


-- !query
SELECT '1' <> cast('2017-12-11 09:30:00' as date)        FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 49,
    "fragment" : "'1' <> cast('2017-12-11 09:30:00' as date)"
  } ]
}


-- !query
SELECT cast(1 as tinyint)                         < '1' FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) < 1):boolean>
-- !query output
false


-- !query
SELECT cast(1 as smallint)                        < '1' FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) < 1):boolean>
-- !query output
false


-- !query
SELECT cast(1 as int)                             < '1' FROM t
-- !query schema
struct<(CAST(1 AS INT) < 1):boolean>
-- !query output
false


-- !query
SELECT cast(1 as bigint)                          < '1' FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) < 1):boolean>
-- !query output
false


-- !query
SELECT cast(1 as float)                           < '1' FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) < 1):boolean>
-- !query output
false


-- !query
SELECT cast(1 as double)                          < '1' FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) < 1):boolean>
-- !query output
false


-- !query
SELECT cast(1 as decimal(10, 0))                  < '1' FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) < 1):boolean>
-- !query output
false


-- !query
SELECT '1'                                        < '1' FROM t
-- !query schema
struct<(1 < 1):boolean>
-- !query output
false


-- !query
SELECT cast('1' as binary)                        < '1' FROM t
-- !query schema
struct<(CAST(1 AS BINARY) < 1):boolean>
-- !query output
false


-- !query
SELECT cast(1 as boolean)                         < '1' FROM t
-- !query schema
struct<(CAST(1 AS BOOLEAN) < 1):boolean>
-- !query output
false


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) < '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00.0' as timestamp) < '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date)        < '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00' as date)        < '1'"
  } ]
}


-- !query
SELECT cast(1 as tinyint)                         <= '1' FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) <= 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as smallint)                        <= '1' FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) <= 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as int)                             <= '1' FROM t
-- !query schema
struct<(CAST(1 AS INT) <= 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as bigint)                          <= '1' FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) <= 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as float)                           <= '1' FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) <= 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as double)                          <= '1' FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) <= 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as decimal(10, 0))                  <= '1' FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) <= 1):boolean>
-- !query output
true


-- !query
SELECT '1'                                        <= '1' FROM t
-- !query schema
struct<(1 <= 1):boolean>
-- !query output
true


-- !query
SELECT cast('1' as binary)                        <= '1' FROM t
-- !query schema
struct<(CAST(1 AS BINARY) <= 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as boolean)                         <= '1' FROM t
-- !query schema
struct<(CAST(1 AS BOOLEAN) <= 1):boolean>
-- !query output
true


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) <= '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 56,
    "fragment" : "cast('2017-12-11 09:30:00.0' as timestamp) <= '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date)        <= '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 56,
    "fragment" : "cast('2017-12-11 09:30:00' as date)        <= '1'"
  } ]
}


-- !query
SELECT cast(1 as tinyint)                         > '1' FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) > 1):boolean>
-- !query output
false


-- !query
SELECT cast(1 as smallint)                        > '1' FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) > 1):boolean>
-- !query output
false


-- !query
SELECT cast(1 as int)                             > '1' FROM t
-- !query schema
struct<(CAST(1 AS INT) > 1):boolean>
-- !query output
false


-- !query
SELECT cast(1 as bigint)                          > '1' FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) > 1):boolean>
-- !query output
false


-- !query
SELECT cast(1 as float)                           > '1' FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) > 1):boolean>
-- !query output
false


-- !query
SELECT cast(1 as double)                          > '1' FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) > 1):boolean>
-- !query output
false


-- !query
SELECT cast(1 as decimal(10, 0))                  > '1' FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) > 1):boolean>
-- !query output
false


-- !query
SELECT '1'                                        > '1' FROM t
-- !query schema
struct<(1 > 1):boolean>
-- !query output
false


-- !query
SELECT cast('1' as binary)                        > '1' FROM t
-- !query schema
struct<(CAST(1 AS BINARY) > 1):boolean>
-- !query output
false


-- !query
SELECT cast(1 as boolean)                         > '1' FROM t
-- !query schema
struct<(CAST(1 AS BOOLEAN) > 1):boolean>
-- !query output
false


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) > '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00.0' as timestamp) > '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date)        > '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 55,
    "fragment" : "cast('2017-12-11 09:30:00' as date)        > '1'"
  } ]
}


-- !query
SELECT cast(1 as tinyint)                         >= '1' FROM t
-- !query schema
struct<(CAST(1 AS TINYINT) >= 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as smallint)                        >= '1' FROM t
-- !query schema
struct<(CAST(1 AS SMALLINT) >= 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as int)                             >= '1' FROM t
-- !query schema
struct<(CAST(1 AS INT) >= 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as bigint)                          >= '1' FROM t
-- !query schema
struct<(CAST(1 AS BIGINT) >= 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as float)                           >= '1' FROM t
-- !query schema
struct<(CAST(1 AS FLOAT) >= 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as double)                          >= '1' FROM t
-- !query schema
struct<(CAST(1 AS DOUBLE) >= 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as decimal(10, 0))                  >= '1' FROM t
-- !query schema
struct<(CAST(1 AS DECIMAL(10,0)) >= 1):boolean>
-- !query output
true


-- !query
SELECT '1'                                        >= '1' FROM t
-- !query schema
struct<(1 >= 1):boolean>
-- !query output
true


-- !query
SELECT cast('1' as binary)                        >= '1' FROM t
-- !query schema
struct<(CAST(1 AS BINARY) >= 1):boolean>
-- !query output
true


-- !query
SELECT cast(1 as boolean)                         >= '1' FROM t
-- !query schema
struct<(CAST(1 AS BOOLEAN) >= 1):boolean>
-- !query output
true


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) >= '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 56,
    "fragment" : "cast('2017-12-11 09:30:00.0' as timestamp) >= '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date)        >= '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 56,
    "fragment" : "cast('2017-12-11 09:30:00' as date)        >= '1'"
  } ]
}


-- !query
SELECT cast(1 as tinyint)                         <> '1' FROM t
-- !query schema
struct<(NOT (CAST(1 AS TINYINT) = 1)):boolean>
-- !query output
false


-- !query
SELECT cast(1 as smallint)                        <> '1' FROM t
-- !query schema
struct<(NOT (CAST(1 AS SMALLINT) = 1)):boolean>
-- !query output
false


-- !query
SELECT cast(1 as int)                             <> '1' FROM t
-- !query schema
struct<(NOT (CAST(1 AS INT) = 1)):boolean>
-- !query output
false


-- !query
SELECT cast(1 as bigint)                          <> '1' FROM t
-- !query schema
struct<(NOT (CAST(1 AS BIGINT) = 1)):boolean>
-- !query output
false


-- !query
SELECT cast(1 as float)                           <> '1' FROM t
-- !query schema
struct<(NOT (CAST(1 AS FLOAT) = 1)):boolean>
-- !query output
false


-- !query
SELECT cast(1 as double)                          <> '1' FROM t
-- !query schema
struct<(NOT (CAST(1 AS DOUBLE) = 1)):boolean>
-- !query output
false


-- !query
SELECT cast(1 as decimal(10, 0))                  <> '1' FROM t
-- !query schema
struct<(NOT (CAST(1 AS DECIMAL(10,0)) = 1)):boolean>
-- !query output
false


-- !query
SELECT '1'                                        <> '1' FROM t
-- !query schema
struct<(NOT (1 = 1)):boolean>
-- !query output
false


-- !query
SELECT cast('1' as binary)                        <> '1' FROM t
-- !query schema
struct<(NOT (CAST(1 AS BINARY) = 1)):boolean>
-- !query output
false


-- !query
SELECT cast(1 as boolean)                         <> '1' FROM t
-- !query schema
struct<(NOT (CAST(1 AS BOOLEAN) = 1)):boolean>
-- !query output
false


-- !query
SELECT cast('2017-12-11 09:30:00.0' as timestamp) <> '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 56,
    "fragment" : "cast('2017-12-11 09:30:00.0' as timestamp) <> '1'"
  } ]
}


-- !query
SELECT cast('2017-12-11 09:30:00' as date)        <> '1' FROM t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 56,
    "fragment" : "cast('2017-12-11 09:30:00' as date)        <> '1'"
  } ]
}


-- !query
SELECT abs('1') FROM t
-- !query schema
struct<abs(1):double>
-- !query output
1.0


-- !query
SELECT sum('1') FROM t
-- !query schema
struct<sum(1):double>
-- !query output
1.0


-- !query
SELECT avg('1') FROM t
-- !query schema
struct<avg(1):double>
-- !query output
1.0


-- !query
SELECT stddev_pop('1') FROM t
-- !query schema
struct<stddev_pop(1):double>
-- !query output
0.0


-- !query
SELECT stddev_samp('1') FROM t
-- !query schema
struct<stddev_samp(1):double>
-- !query output
NULL


-- !query
SELECT - '1' FROM t
-- !query schema
struct<(- 1):double>
-- !query output
-1.0


-- !query
SELECT + '1' FROM t
-- !query schema
struct<(+ 1):double>
-- !query output
1.0


-- !query
SELECT var_pop('1') FROM t
-- !query schema
struct<var_pop(1):double>
-- !query output
0.0


-- !query
SELECT var_samp('1') FROM t
-- !query schema
struct<var_samp(1):double>
-- !query output
NULL


-- !query
SELECT skewness('1') FROM t
-- !query schema
struct<skewness(1):double>
-- !query output
NULL


-- !query
SELECT kurtosis('1') FROM t
-- !query schema
struct<kurtosis(1):double>
-- !query output
NULL
