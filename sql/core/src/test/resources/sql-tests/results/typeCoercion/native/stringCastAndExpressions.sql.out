-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TEMPORARY VIEW t AS SELECT 'aa' as a
-- !query schema
struct<>
-- !query output



-- !query
select cast(a as byte) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TINYINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "cast(a as byte)"
  } ]
}


-- !query
select cast(a as short) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"SMALLINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 23,
    "fragment" : "cast(a as short)"
  } ]
}


-- !query
select cast(a as int) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 21,
    "fragment" : "cast(a as int)"
  } ]
}


-- !query
select cast(a as long) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"BIGINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "cast(a as long)"
  } ]
}


-- !query
select cast(a as float) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"FLOAT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 23,
    "fragment" : "cast(a as float)"
  } ]
}


-- !query
select cast(a as double) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 24,
    "fragment" : "cast(a as double)"
  } ]
}


-- !query
select cast(a as decimal) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DECIMAL(10,0)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "cast(a as decimal)"
  } ]
}


-- !query
select cast(a as boolean) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkRuntimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"BOOLEAN\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "cast(a as boolean)"
  } ]
}


-- !query
select cast(a as timestamp) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 27,
    "fragment" : "cast(a as timestamp)"
  } ]
}


-- !query
select cast(a as date) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 22,
    "fragment" : "cast(a as date)"
  } ]
}


-- !query
select cast(a as binary) from t
-- !query schema
struct<a:binary>
-- !query output
aa


-- !query
select cast(a as array<string>) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.CAST_WITHOUT_SUGGESTION",
  "sqlState" : "42K09",
  "messageParameters" : {
    "sqlExpr" : "\"a\"",
    "srcType" : "\"STRING\"",
    "targetType" : "\"ARRAY<STRING>\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "cast(a as array<string>)"
  } ]
}


-- !query
select cast(a as struct<s:string>) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.CAST_WITHOUT_SUGGESTION",
  "sqlState" : "42K09",
  "messageParameters" : {
    "sqlExpr" : "\"a\"",
    "srcType" : "\"STRING\"",
    "targetType" : "\"STRUCT<s: STRING>\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 34,
    "fragment" : "cast(a as struct<s:string>)"
  } ]
}


-- !query
select cast(a as map<string, string>) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.CAST_WITHOUT_SUGGESTION",
  "sqlState" : "42K09",
  "messageParameters" : {
    "sqlExpr" : "\"a\"",
    "srcType" : "\"STRING\"",
    "targetType" : "\"MAP<STRING, STRING>\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 37,
    "fragment" : "cast(a as map<string, string>)"
  } ]
}


-- !query
select to_timestamp(a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "fragment" : ""
  } ]
}


-- !query
select to_timestamp('2018-01-01', a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUpgradeException
{
  "errorClass" : "INCONSISTENT_BEHAVIOR_CROSS_VERSION.DATETIME_PATTERN_RECOGNITION",
  "sqlState" : "42K0B",
  "messageParameters" : {
    "config" : "\"spark.sql.legacy.timeParserPolicy\"",
    "docroot" : "https://spark.apache.org/docs/latest",
    "pattern" : "'aa'"
  }
}


-- !query
select to_unix_timestamp(a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "func" : "`try_to_timestamp`",
    "message" : "Text 'aa' could not be parsed at index 0"
  }
}


-- !query
select to_unix_timestamp('2018-01-01', a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUpgradeException
{
  "errorClass" : "INCONSISTENT_BEHAVIOR_CROSS_VERSION.DATETIME_PATTERN_RECOGNITION",
  "sqlState" : "42K0B",
  "messageParameters" : {
    "config" : "\"spark.sql.legacy.timeParserPolicy\"",
    "docroot" : "https://spark.apache.org/docs/latest",
    "pattern" : "'aa'"
  }
}


-- !query
select unix_timestamp(a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CANNOT_PARSE_TIMESTAMP",
  "sqlState" : "22007",
  "messageParameters" : {
    "func" : "`try_to_timestamp`",
    "message" : "Text 'aa' could not be parsed at index 0"
  }
}


-- !query
select unix_timestamp('2018-01-01', a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUpgradeException
{
  "errorClass" : "INCONSISTENT_BEHAVIOR_CROSS_VERSION.DATETIME_PATTERN_RECOGNITION",
  "sqlState" : "42K0B",
  "messageParameters" : {
    "config" : "\"spark.sql.legacy.timeParserPolicy\"",
    "docroot" : "https://spark.apache.org/docs/latest",
    "pattern" : "'aa'"
  }
}


-- !query
select from_unixtime(a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"BIGINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 23,
    "fragment" : "from_unixtime(a)"
  } ]
}


-- !query
select from_unixtime('2018-01-01', a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'2018-01-01'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"BIGINT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 37,
    "fragment" : "from_unixtime('2018-01-01', a)"
  } ]
}


-- !query
select next_day(a, 'MO') from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 24,
    "fragment" : "next_day(a, 'MO')"
  } ]
}


-- !query
select next_day('2018-01-01', a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkIllegalArgumentException
{
  "errorClass" : "ILLEGAL_DAY_OF_WEEK",
  "sqlState" : "22009",
  "messageParameters" : {
    "string" : "aa"
  }
}


-- !query
select trunc(a, 'MM') from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 21,
    "fragment" : "trunc(a, 'MM')"
  } ]
}


-- !query
select trunc('2018-01-01', a) from t
-- !query schema
struct<trunc(2018-01-01, a):date>
-- !query output
NULL


-- !query
select unhex('-123')
-- !query schema
struct<unhex(-123):binary>
-- !query output
NULL


-- !query
select sha2(a, a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "22018",
  "messageParameters" : {
    "expression" : "'aa'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"INT\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 17,
    "fragment" : "sha2(a, a)"
  } ]
}


-- !query
select get_json_object(a, a) from t
-- !query schema
struct<get_json_object(a, a):string>
-- !query output
NULL


-- !query
select json_tuple(a, a) from t
-- !query schema
struct<c0:string>
-- !query output
NULL


-- !query
select from_json(a, 'a INT') from t
-- !query schema
struct<from_json(a):struct<a:int>>
-- !query output
{"a":null}
