-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TEMPORARY VIEW t AS SELECT 'aa' as a
-- !query schema
struct<>
-- !query output



-- !query
select cast(a as byte) from t
-- !query schema
struct<a:tinyint>
-- !query output
NULL


-- !query
select cast(a as short) from t
-- !query schema
struct<a:smallint>
-- !query output
NULL


-- !query
select cast(a as int) from t
-- !query schema
struct<a:int>
-- !query output
NULL


-- !query
select cast(a as long) from t
-- !query schema
struct<a:bigint>
-- !query output
NULL


-- !query
select cast(a as float) from t
-- !query schema
struct<a:float>
-- !query output
NULL


-- !query
select cast(a as double) from t
-- !query schema
struct<a:double>
-- !query output
NULL


-- !query
select cast(a as decimal) from t
-- !query schema
struct<a:decimal(10,0)>
-- !query output
NULL


-- !query
select cast(a as boolean) from t
-- !query schema
struct<a:boolean>
-- !query output
NULL


-- !query
select cast(a as timestamp) from t
-- !query schema
struct<a:timestamp>
-- !query output
NULL


-- !query
select cast(a as date) from t
-- !query schema
struct<a:date>
-- !query output
NULL


-- !query
select cast(a as binary) from t
-- !query schema
struct<a:binary>
-- !query output
aa


-- !query
select cast(a as array<string>) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "DATATYPE_MISMATCH.CAST_WITHOUT_SUGGESTION",
  "sqlState" : "42K09",
  "messageParameters" : {
    "sqlExpr" : "\"a\"",
    "srcType" : "\"STRING\"",
    "targetType" : "\"ARRAY<STRING>\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "cast(a as array<string>)"
  } ]
}


-- !query
select cast(a as struct<s:string>) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "DATATYPE_MISMATCH.CAST_WITHOUT_SUGGESTION",
  "sqlState" : "42K09",
  "messageParameters" : {
    "sqlExpr" : "\"a\"",
    "srcType" : "\"STRING\"",
    "targetType" : "\"STRUCT<s: STRING>\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 34,
    "fragment" : "cast(a as struct<s:string>)"
  } ]
}


-- !query
select cast(a as map<string, string>) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "condition" : "DATATYPE_MISMATCH.CAST_WITHOUT_SUGGESTION",
  "sqlState" : "42K09",
  "messageParameters" : {
    "sqlExpr" : "\"a\"",
    "srcType" : "\"STRING\"",
    "targetType" : "\"MAP<STRING, STRING>\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 37,
    "fragment" : "cast(a as map<string, string>)"
  } ]
}


-- !query
select to_timestamp(a) from t
-- !query schema
struct<to_timestamp(a):timestamp>
-- !query output
NULL


-- !query
select to_timestamp('2018-01-01', a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUpgradeException
{
  "condition" : "INCONSISTENT_BEHAVIOR_CROSS_VERSION.DATETIME_PATTERN_RECOGNITION",
  "sqlState" : "42K0B",
  "messageParameters" : {
    "config" : "\"spark.sql.legacy.timeParserPolicy\"",
    "docroot" : "https://spark.apache.org/docs/latest",
    "pattern" : "'aa'"
  }
}


-- !query
select to_unix_timestamp(a) from t
-- !query schema
struct<to_unix_timestamp(a, yyyy-MM-dd HH:mm:ss):bigint>
-- !query output
NULL


-- !query
select to_unix_timestamp('2018-01-01', a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUpgradeException
{
  "condition" : "INCONSISTENT_BEHAVIOR_CROSS_VERSION.DATETIME_PATTERN_RECOGNITION",
  "sqlState" : "42K0B",
  "messageParameters" : {
    "config" : "\"spark.sql.legacy.timeParserPolicy\"",
    "docroot" : "https://spark.apache.org/docs/latest",
    "pattern" : "'aa'"
  }
}


-- !query
select unix_timestamp(a) from t
-- !query schema
struct<unix_timestamp(a, yyyy-MM-dd HH:mm:ss):bigint>
-- !query output
NULL


-- !query
select unix_timestamp('2018-01-01', a) from t
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkUpgradeException
{
  "condition" : "INCONSISTENT_BEHAVIOR_CROSS_VERSION.DATETIME_PATTERN_RECOGNITION",
  "sqlState" : "42K0B",
  "messageParameters" : {
    "config" : "\"spark.sql.legacy.timeParserPolicy\"",
    "docroot" : "https://spark.apache.org/docs/latest",
    "pattern" : "'aa'"
  }
}


-- !query
select from_unixtime(a) from t
-- !query schema
struct<from_unixtime(a, yyyy-MM-dd HH:mm:ss):string>
-- !query output
NULL


-- !query
select from_unixtime('2018-01-01', a) from t
-- !query schema
struct<from_unixtime(2018-01-01, a):string>
-- !query output
NULL


-- !query
select next_day(a, 'MO') from t
-- !query schema
struct<next_day(a, MO):date>
-- !query output
NULL


-- !query
select next_day('2018-01-01', a) from t
-- !query schema
struct<next_day(2018-01-01, a):date>
-- !query output
NULL


-- !query
select trunc(a, 'MM') from t
-- !query schema
struct<trunc(a, MM):date>
-- !query output
NULL


-- !query
select trunc('2018-01-01', a) from t
-- !query schema
struct<trunc(2018-01-01, a):date>
-- !query output
NULL


-- !query
select unhex('-123')
-- !query schema
struct<unhex(-123):binary>
-- !query output
NULL


-- !query
select sha2(a, a) from t
-- !query schema
struct<sha2(a, a):string>
-- !query output
NULL


-- !query
select get_json_object(a, a) from t
-- !query schema
struct<get_json_object(a, a):string>
-- !query output
NULL


-- !query
select json_tuple(a, a) from t
-- !query schema
struct<c0:string>
-- !query output
NULL


-- !query
select from_json(a, 'a INT') from t
-- !query schema
struct<from_json(a):struct<a:int>>
-- !query output
{"a":null}
