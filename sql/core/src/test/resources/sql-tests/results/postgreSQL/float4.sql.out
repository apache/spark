-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TABLE FLOAT4_TBL (f1  float) USING parquet
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO FLOAT4_TBL VALUES (float('    0.0'))
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO FLOAT4_TBL VALUES (float('1004.30   '))
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO FLOAT4_TBL VALUES (float('     -34.84    '))
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO FLOAT4_TBL VALUES (float('1.2345678901234e+20'))
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO FLOAT4_TBL VALUES (float('1.2345678901234e-20'))
-- !query schema
struct<>
-- !query output



-- !query
SELECT float('NaN')
-- !query schema
struct<NaN:float>
-- !query output
NaN


-- !query
SELECT float('nan')
-- !query schema
struct<nan:float>
-- !query output
NaN


-- !query
SELECT float('   NAN  ')
-- !query schema
struct<   NAN  :float>
-- !query output
NaN


-- !query
SELECT float('infinity')
-- !query schema
struct<infinity:float>
-- !query output
Infinity


-- !query
SELECT float('          -INFINiTY   ')
-- !query schema
struct<          -INFINiTY   :float>
-- !query output
-Infinity


-- !query
SELECT float('N A N')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
[CAST_INVALID_INPUT] The value 'N A N' of the type "STRING" cannot be cast to "FLOAT" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 1, position 8) ==
SELECT float('N A N')
       ^^^^^^^^^^^^^^


-- !query
SELECT float('NaN x')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
[CAST_INVALID_INPUT] The value 'NaN x' of the type "STRING" cannot be cast to "FLOAT" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 1, position 8) ==
SELECT float('NaN x')
       ^^^^^^^^^^^^^^


-- !query
SELECT float(' INFINITY    x')
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
[CAST_INVALID_INPUT] The value ' INFINITY    x' of the type "STRING" cannot be cast to "FLOAT" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 1, position 8) ==
SELECT float(' INFINITY    x')
       ^^^^^^^^^^^^^^^^^^^^^^^


-- !query
SELECT float('Infinity') + 100.0
-- !query schema
struct<(Infinity + 100.0):double>
-- !query output
Infinity


-- !query
SELECT float('Infinity') / float('Infinity')
-- !query schema
struct<(Infinity / Infinity):double>
-- !query output
NaN


-- !query
SELECT float('nan') / float('nan')
-- !query schema
struct<(nan / nan):double>
-- !query output
NaN


-- !query
SELECT float(decimal('nan'))
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
[CAST_INVALID_INPUT] The value 'nan' of the type "STRING" cannot be cast to "DECIMAL(10,0)" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.
== SQL(line 1, position 14) ==
SELECT float(decimal('nan'))
             ^^^^^^^^^^^^^^


-- !query
SELECT '' AS five, * FROM FLOAT4_TBL
-- !query schema
struct<five:string,f1:float>
-- !query output
	-34.84
	0.0
	1.2345679E-20
	1.2345679E20
	1004.3


-- !query
SELECT '' AS four, f.* FROM FLOAT4_TBL f WHERE f.f1 <> '1004.3'
-- !query schema
struct<four:string,f1:float>
-- !query output
	-34.84
	0.0
	1.2345679E-20
	1.2345679E20
	1004.3


-- !query
SELECT '' AS one, f.* FROM FLOAT4_TBL f WHERE f.f1 = '1004.3'
-- !query schema
struct<one:string,f1:float>
-- !query output



-- !query
SELECT '' AS three, f.* FROM FLOAT4_TBL f WHERE '1004.3' > f.f1
-- !query schema
struct<three:string,f1:float>
-- !query output
	-34.84
	0.0
	1.2345679E-20
	1004.3


-- !query
SELECT '' AS three, f.* FROM FLOAT4_TBL f WHERE  f.f1 < '1004.3'
-- !query schema
struct<three:string,f1:float>
-- !query output
	-34.84
	0.0
	1.2345679E-20
	1004.3


-- !query
SELECT '' AS four, f.* FROM FLOAT4_TBL f WHERE '1004.3' >= f.f1
-- !query schema
struct<four:string,f1:float>
-- !query output
	-34.84
	0.0
	1.2345679E-20
	1004.3


-- !query
SELECT '' AS four, f.* FROM FLOAT4_TBL f WHERE  f.f1 <= '1004.3'
-- !query schema
struct<four:string,f1:float>
-- !query output
	-34.84
	0.0
	1.2345679E-20
	1004.3


-- !query
SELECT '' AS three, f.f1, f.f1 * '-10' AS x FROM FLOAT4_TBL f
   WHERE f.f1 > '0.0'
-- !query schema
struct<three:string,f1:float,x:double>
-- !query output
	1.2345679E-20	-1.2345678720289608E-19
	1.2345679E20	-1.2345678955701443E21
	1004.3	-10042.999877929688


-- !query
SELECT '' AS three, f.f1, f.f1 + '-10' AS x FROM FLOAT4_TBL f
   WHERE f.f1 > '0.0'
-- !query schema
struct<three:string,f1:float,x:double>
-- !query output
	1.2345679E-20	-10.0
	1.2345679E20	1.2345678955701443E20
	1004.3	994.2999877929688


-- !query
SELECT '' AS three, f.f1, f.f1 / '-10' AS x FROM FLOAT4_TBL f
   WHERE f.f1 > '0.0'
-- !query schema
struct<three:string,f1:float,x:double>
-- !query output
	1.2345679E-20	-1.2345678720289608E-21
	1.2345679E20	-1.2345678955701443E19
	1004.3	-100.42999877929688


-- !query
SELECT '' AS three, f.f1, f.f1 - '-10' AS x FROM FLOAT4_TBL f
   WHERE f.f1 > '0.0'
-- !query schema
struct<three:string,f1:float,x:double>
-- !query output
	1.2345679E-20	10.0
	1.2345679E20	1.2345678955701443E20
	1004.3	1014.2999877929688


-- !query
SELECT '' AS five, * FROM FLOAT4_TBL
-- !query schema
struct<five:string,f1:float>
-- !query output
	-34.84
	0.0
	1.2345679E-20
	1.2345679E20
	1004.3


-- !query
SELECT smallint(float('32767.4'))
-- !query schema
struct<32767.4:smallint>
-- !query output
32767


-- !query
SELECT smallint(float('32767.6'))
-- !query schema
struct<32767.6:smallint>
-- !query output
32767


-- !query
SELECT smallint(float('-32768.4'))
-- !query schema
struct<-32768.4:smallint>
-- !query output
-32768


-- !query
SELECT smallint(float('-32768.6'))
-- !query schema
struct<-32768.6:smallint>
-- !query output
-32768


-- !query
SELECT int(float('2147483520'))
-- !query schema
struct<2147483520:int>
-- !query output
2147483520


-- !query
SELECT int(float('2147483647'))
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
[CAST_OVERFLOW] The value 2.14748365E9 of the type "FLOAT" cannot be cast to "INT" due to an overflow. Use `try_cast` to tolerate overflow and return NULL instead. If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.


-- !query
SELECT int(float('-2147483648.5'))
-- !query schema
struct<-2147483648.5:int>
-- !query output
-2147483648


-- !query
SELECT int(float('-2147483900'))
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
[CAST_OVERFLOW] The value -2.1474839E9 of the type "FLOAT" cannot be cast to "INT" due to an overflow. Use `try_cast` to tolerate overflow and return NULL instead. If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.


-- !query
SELECT bigint(float('9223369837831520256'))
-- !query schema
struct<9223369837831520256:bigint>
-- !query output
9223369837831520256


-- !query
SELECT bigint(float('9223372036854775807'))
-- !query schema
struct<9223372036854775807:bigint>
-- !query output
9223372036854775807


-- !query
SELECT bigint(float('-9223372036854775808.5'))
-- !query schema
struct<-9223372036854775808.5:bigint>
-- !query output
-9223372036854775808


-- !query
SELECT bigint(float('-9223380000000000000'))
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
[CAST_OVERFLOW] The value -9.22338E18 of the type "FLOAT" cannot be cast to "BIGINT" due to an overflow. Use `try_cast` to tolerate overflow and return NULL instead. If necessary set "spark.sql.ansi.enabled" to "false" to bypass this error.


-- !query
DROP TABLE FLOAT4_TBL
-- !query schema
struct<>
-- !query output

