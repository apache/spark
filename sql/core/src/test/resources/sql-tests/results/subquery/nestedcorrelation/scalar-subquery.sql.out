-- Automatically generated by SQLQueryTestSuite
-- !query
set spark.sql.optimizer.supportNestedCorrelatedSubqueries.enabled=true
-- !query analysis
SetCommand (spark.sql.optimizer.supportNestedCorrelatedSubqueries.enabled,Some(true))


-- !query
DROP TABLE IF EXISTS t0
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t0


-- !query
CREATE TABLE t0(c0 INT)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t0`, false


-- !query
SELECT 1 FROM (SELECT 1) t0(c0) WHERE (SELECT (SELECT c0))
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "MISSING_ATTRIBUTES.RESOLVED_ATTRIBUTE_MISSING_FROM_INPUT",
  "sqlState" : "XX000",
  "messageParameters" : {
    "input" : "",
    "missingAttributes" : "\"c0\"",
    "operator" : "!Project [scalar-subquery#x [c0#x] AS scalarsubquery(c0)#x]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 40,
    "stopIndex" : 57,
    "fragment" : "SELECT (SELECT c0)"
  } ]
}


-- !query
SELECT 1 FROM (SELECT 1) t0(c0) WHERE (SELECT (SELECT 1 ORDER BY c0))
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"c0 ASC NULLS FIRST\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 57,
    "stopIndex" : 67,
    "fragment" : "ORDER BY c0"
  } ]
}


-- !query
SELECT 1 FROM (SELECT 1) t0(c0) WHERE (SELECT (SELECT 1 LIMIT c0))
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_LIMIT_LIKE_EXPRESSION.IS_UNFOLDABLE",
  "sqlState" : "42K0E",
  "messageParameters" : {
    "expr" : "\"outer(t0.c0)\"",
    "name" : "limit"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 63,
    "stopIndex" : 64,
    "fragment" : "c0"
  } ]
}


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(ps_supplycost INT, n_name INT)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT NULL
FROM
    t AS ref_2,
    (SELECT (SELECT NULL
         FROM (FROM t AS ref_5,
              (SELECT ref_2.n_name AS c1))))
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNRESOLVED_COLUMN.WITHOUT_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`ref_2`.`n_name`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 113,
    "stopIndex" : 124,
    "fragment" : "ref_2.n_name"
  } ]
}


-- !query
SELECT NULL
FROM
    t AS ref_2,
    (SELECT (SELECT NULL
         FROM (FROM t AS ref_5,
              (SELECT ref_5.ps_supplycost AS c0,
                      ref_2.n_name AS c1))))
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNRESOLVED_COLUMN.WITHOUT_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`ref_5`.`ps_supplycost`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 113,
    "stopIndex" : 131,
    "fragment" : "ref_5.ps_supplycost"
  } ]
}


-- !query
DROP TABLE IF EXISTS integers
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.integers


-- !query
CREATE TABLE integers(i INTEGER)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`integers`, false


-- !query
INSERT INTO integers VALUES (1), (2), (3), (NULL)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/integers, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/integers], Append, `spark_catalog`.`default`.`integers`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/integers), [i]
+- Project [cast(col1#x as int) AS i#x]
   +- LocalRelation [col1#x]


-- !query
SELECT i, (SELECT (SELECT 42+i1.i)+42+i1.i) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "MISSING_ATTRIBUTES.RESOLVED_ATTRIBUTE_MISSING_FROM_INPUT",
  "sqlState" : "XX000",
  "messageParameters" : {
    "input" : "",
    "missingAttributes" : "\"i\"",
    "operator" : "!Project [((scalar-subquery#x [i#x] + 42) + outer(i#x)) AS ((scalarsubquery(i) + 42) + outer(i1.i))#x]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 12,
    "stopIndex" : 42,
    "fragment" : "SELECT (SELECT 42+i1.i)+42+i1.i"
  } ]
}


-- !query
SELECT i, (SELECT (SELECT (SELECT (SELECT 42+i1.i)++i1.i)+42+i1.i)+42+i1.i) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "MISSING_ATTRIBUTES.RESOLVED_ATTRIBUTE_MISSING_FROM_INPUT",
  "sqlState" : "XX000",
  "messageParameters" : {
    "input" : "",
    "missingAttributes" : "\"i\"",
    "operator" : "!Project [(scalar-subquery#x [i#x] + positive(outer(i#x))) AS (scalarsubquery(i) + (+ outer(i1.i)))#x]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 28,
    "stopIndex" : 56,
    "fragment" : "SELECT (SELECT 42+i1.i)++i1.i"
  } ]
}


-- !query
SELECT i, (SELECT (SELECT i1.i+SUM(i2.i)) FROM integers i2) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"(i + sum(i)) AS `(outer(i1.i) + sum(outer(i2.i)))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 20,
    "stopIndex" : 40,
    "fragment" : "SELECT i1.i+SUM(i2.i)"
  } ]
}


-- !query
SELECT i, (SELECT (SELECT (SELECT (SELECT i1.i+i1.i+i1.i+i1.i+i1.i)))) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "MISSING_ATTRIBUTES.RESOLVED_ATTRIBUTE_MISSING_FROM_INPUT",
  "sqlState" : "XX000",
  "messageParameters" : {
    "input" : "",
    "missingAttributes" : "\"i\"",
    "operator" : "!Project [scalar-subquery#x [i#x && i#x && i#x && i#x && i#x] AS scalarsubquery(i, i, i, i, i)#x]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 28,
    "stopIndex" : 67,
    "fragment" : "SELECT (SELECT i1.i+i1.i+i1.i+i1.i+i1.i)"
  } ]
}


-- !query
SELECT i, (SELECT SUM(i)+(SELECT 42+i1.i) FROM integers) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "SCALAR_SUBQUERY_IS_IN_GROUP_BY_OR_AGGREGATE_FUNCTION",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExpr" : "\"scalarsubquery(i)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 26,
    "stopIndex" : 41,
    "fragment" : "(SELECT 42+i1.i)"
  } ]
}


-- !query
SELECT i, (SELECT ((SELECT ((SELECT ((SELECT SUM(i)+SUM(i4.i)+SUM(i3.i)+SUM(i2.i)+SUM(i1.i) FROM integers i5)) FROM integers i4)) FROM integers i3)) FROM integers i2) AS j FROM integers i1 GROUP BY i ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"((((sum(i) + sum(i)) + sum(i)) + sum(i)) + sum(i)) AS `((((sum(i) + sum(outer(i4.i))) + sum(outer(i3.i))) + sum(outer(i2.i))) + sum(outer(i1.i)))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 39,
    "stopIndex" : 108,
    "fragment" : "SELECT SUM(i)+SUM(i4.i)+SUM(i3.i)+SUM(i2.i)+SUM(i1.i) FROM integers i5"
  } ]
}


-- !query
SELECT i, (SELECT (SELECT (SELECT (SELECT i1.i+i1.i+i1.i+i1.i+i1.i+i2.i) FROM integers i2 WHERE i2.i=i1.i))) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "MISSING_ATTRIBUTES.RESOLVED_ATTRIBUTE_MISSING_FROM_INPUT",
  "sqlState" : "XX000",
  "messageParameters" : {
    "input" : "",
    "missingAttributes" : "\"i\"",
    "operator" : "!Project [scalar-subquery#x [i#x] AS scalarsubquery(i)#x]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 20,
    "stopIndex" : 106,
    "fragment" : "SELECT (SELECT (SELECT i1.i+i1.i+i1.i+i1.i+i1.i+i2.i) FROM integers i2 WHERE i2.i=i1.i)"
  } ]
}


-- !query
SELECT (SELECT (SELECT SUM(i1.i)+SUM(i2.i)+SUM(i3.i) FROM integers i3) FROM integers i2) FROM integers i1 ORDER BY 1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"((sum(i) + sum(i)) + sum(i)) AS `((sum(outer(i1.i)) + sum(outer(i2.i))) + sum(i))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 69,
    "fragment" : "SELECT SUM(i1.i)+SUM(i2.i)+SUM(i3.i) FROM integers i3"
  } ]
}


-- !query
SELECT i, (SELECT SUM(s1.i) FROM integers s1 INNER JOIN integers s2 ON (SELECT i1.i+s1.i)=(SELECT i1.i+s2.i)) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.UNSUPPORTED_CORRELATED_SCALAR_SUBQUERY",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Join Inner, (scalar-subquery#x [i#x && i#x] = scalar-subquery#x [i#x && i#x])\n:  :- Project [(outer(i#x) + outer(i#x)) AS (outer(i1.i) + outer(s1.i))#x]\n:  :  +- OneRowRelation\n:  +- Project [(outer(i#x) + outer(i#x)) AS (outer(i1.i) + outer(s2.i))#x]\n:     +- OneRowRelation\n:- SubqueryAlias s1\n:  +- SubqueryAlias spark_catalog.default.integers\n:     +- Relation spark_catalog.default.integers[i#x] parquet\n+- SubqueryAlias s2\n   +- SubqueryAlias spark_catalog.default.integers\n      +- Relation spark_catalog.default.integers[i#x] parquet\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 46,
    "stopIndex" : 108,
    "fragment" : "INNER JOIN integers s2 ON (SELECT i1.i+s1.i)=(SELECT i1.i+s2.i)"
  } ]
}


-- !query
SELECT i, SUM(i), (SELECT (SELECT SUM(i)+SUM(i1.i)+SUM(i2.i) FROM integers) FROM integers i2) FROM integers i1 GROUP BY i ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"((sum(i) + sum(i)) + sum(i)) AS `((sum(i) + sum(outer(i1.i))) + sum(outer(i2.i)))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 28,
    "stopIndex" : 74,
    "fragment" : "SELECT SUM(i)+SUM(i1.i)+SUM(i2.i) FROM integers"
  } ]
}


-- !query
SELECT i, (SELECT SUM(ss1.i) FROM (SELECT i FROM integers s1 WHERE i>ANY(SELECT i FROM integers WHERE i<>s1.i)) ss1) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT i, (SELECT SUM(ss2.i) FROM (SELECT i FROM integers s1 WHERE i=i1.i AND i=ANY(SELECT i FROM integers WHERE i=s1.i)) ss2) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT i, (SELECT SUM(s1.i) FROM integers s1 LEFT OUTER JOIN integers s2 ON (SELECT i1.i+s1.i)=(SELECT i1.i+s2.i)) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.UNSUPPORTED_CORRELATED_SCALAR_SUBQUERY",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Join LeftOuter, (scalar-subquery#x [i#x && i#x] = scalar-subquery#x [i#x && i#x])\n:  :- Project [(outer(i#x) + outer(i#x)) AS (outer(i1.i) + outer(s1.i))#x]\n:  :  +- OneRowRelation\n:  +- Project [(outer(i#x) + outer(i#x)) AS (outer(i1.i) + outer(s2.i))#x]\n:     +- OneRowRelation\n:- SubqueryAlias s1\n:  +- SubqueryAlias spark_catalog.default.integers\n:     +- Relation spark_catalog.default.integers[i#x] parquet\n+- SubqueryAlias s2\n   +- SubqueryAlias spark_catalog.default.integers\n      +- Relation spark_catalog.default.integers[i#x] parquet\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 46,
    "stopIndex" : 113,
    "fragment" : "LEFT OUTER JOIN integers s2 ON (SELECT i1.i+s1.i)=(SELECT i1.i+s2.i)"
  } ]
}


-- !query
SELECT i, (SELECT SUM(ss1.i)+SUM(ss2.i) FROM (SELECT i FROM integers s1 WHERE i>ANY(SELECT i FROM integers WHERE i<>s1.i)) ss1 LEFT OUTER JOIN (SELECT i FROM integers s1 WHERE i=ANY(SELECT i FROM integers WHERE i=s1.i)) ss2 ON ss1.i=ss2.i) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT i, (SELECT SUM(s1.i) FROM (SELECT i FROM integers WHERE i=i1.i) s1 LEFT OUTER JOIN integers s2 ON s1.i=s2.i) AS j FROM integers i1 ORDER BY i
-- !query analysis
Sort [i#x ASC NULLS FIRST], true
+- Project [i#x, scalar-subquery#x [i#x] AS j#xL]
   :  +- Aggregate [sum(i#x) AS sum(i)#xL]
   :     +- Join LeftOuter, (i#x = i#x)
   :        :- SubqueryAlias s1
   :        :  +- Project [i#x]
   :        :     +- Filter (i#x = outer(i#x))
   :        :        +- SubqueryAlias spark_catalog.default.integers
   :        :           +- Relation spark_catalog.default.integers[i#x] parquet
   :        +- SubqueryAlias s2
   :           +- SubqueryAlias spark_catalog.default.integers
   :              +- Relation spark_catalog.default.integers[i#x] parquet
   +- SubqueryAlias i1
      +- SubqueryAlias spark_catalog.default.integers
         +- Relation spark_catalog.default.integers[i#x] parquet


-- !query
SELECT i, (SELECT SUM(s1.i) FROM (SELECT i FROM integers WHERE i<>i1.i) s1 LEFT OUTER JOIN integers s2 ON s1.i=s2.i) AS j FROM integers i1 ORDER BY i
-- !query analysis
Sort [i#x ASC NULLS FIRST], true
+- Project [i#x, scalar-subquery#x [i#x] AS j#xL]
   :  +- Aggregate [sum(i#x) AS sum(i)#xL]
   :     +- Join LeftOuter, (i#x = i#x)
   :        :- SubqueryAlias s1
   :        :  +- Project [i#x]
   :        :     +- Filter NOT (i#x = outer(i#x))
   :        :        +- SubqueryAlias spark_catalog.default.integers
   :        :           +- Relation spark_catalog.default.integers[i#x] parquet
   :        +- SubqueryAlias s2
   :           +- SubqueryAlias spark_catalog.default.integers
   :              +- Relation spark_catalog.default.integers[i#x] parquet
   +- SubqueryAlias i1
      +- SubqueryAlias spark_catalog.default.integers
         +- Relation spark_catalog.default.integers[i#x] parquet


-- !query
SELECT i, (SELECT SUM(s2.i) FROM integers s1 LEFT OUTER JOIN (SELECT i FROM integers WHERE i=i1.i) s2 ON s1.i=s2.i) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.ACCESSING_OUTER_QUERY_COLUMN_IS_NOT_ALLOWED",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Filter (i#x = outer(i#x))\n+- SubqueryAlias spark_catalog.default.integers\n   +- Relation spark_catalog.default.integers[i#x] parquet\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 63,
    "stopIndex" : 97,
    "fragment" : "SELECT i FROM integers WHERE i=i1.i"
  } ]
}


-- !query
SELECT i, (SELECT SUM(s2.i) FROM integers s1 LEFT OUTER JOIN (SELECT i FROM integers WHERE i<>i1.i) s2 ON s1.i=s2.i) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.ACCESSING_OUTER_QUERY_COLUMN_IS_NOT_ALLOWED",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Filter NOT (i#x = outer(i#x))\n+- SubqueryAlias spark_catalog.default.integers\n   +- Relation spark_catalog.default.integers[i#x] parquet\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 63,
    "stopIndex" : 98,
    "fragment" : "SELECT i FROM integers WHERE i<>i1.i"
  } ]
}


-- !query
SELECT i, (SELECT SUM(ss2.i) FROM (SELECT i FROM integers s1 WHERE CASE WHEN (i=i1.i AND i=ANY(SELECT i FROM integers WHERE i=s1.i)) THEN true ELSE false END) ss2) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'WHEN'",
    "hint" : ": missing ')'"
  }
}


-- !query
SELECT i, (SELECT SUM(ss2.i) FROM (SELECT i FROM integers s1 WHERE i=i1.i AND i=ANY(SELECT i FROM integers WHERE i=s1.i)) ss2) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT i, (SELECT SUM(ss2.i) FROM (SELECT i FROM integers s1 WHERE i=i1.i) ss2) AS j FROM integers i1 ORDER BY i
-- !query analysis
Sort [i#x ASC NULLS FIRST], true
+- Project [i#x, scalar-subquery#x [i#x] AS j#xL]
   :  +- Aggregate [sum(i#x) AS sum(i)#xL]
   :     +- SubqueryAlias ss2
   :        +- Project [i#x]
   :           +- Filter (i#x = outer(i#x))
   :              +- SubqueryAlias s1
   :                 +- SubqueryAlias spark_catalog.default.integers
   :                    +- Relation spark_catalog.default.integers[i#x] parquet
   +- SubqueryAlias i1
      +- SubqueryAlias spark_catalog.default.integers
         +- Relation spark_catalog.default.integers[i#x] parquet


-- !query
SELECT i, (SELECT SUM(ss2.i) FROM (SELECT i FROM integers s1 WHERE i=ANY(SELECT i FROM integers WHERE i=s1.i)) ss2) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT i, (SELECT i=ANY(SELECT i FROM integers WHERE i=s1.i) FROM integers s1 WHERE i=i1.i) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'i'",
    "hint" : ""
  }
}


-- !query
SELECT i, (SELECT SUM(ss2.i) FROM (SELECT i FROM integers s1 WHERE i=i1.i OR i=ANY(SELECT i FROM integers WHERE i=s1.i)) ss2) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT i, (SELECT SUM(ss2.i) FROM (SELECT i FROM integers s1 WHERE CASE WHEN (i=i1.i AND i=ANY(SELECT i FROM integers WHERE i=s1.i)) THEN true ELSE false END) ss2) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'WHEN'",
    "hint" : ": missing ')'"
  }
}


-- !query
SELECT i, (SELECT SUM(ss2.i) FROM (SELECT i FROM integers s1 WHERE i=i1.i AND EXISTS(SELECT i FROM integers WHERE i=s1.i)) ss2) AS j FROM integers i1 ORDER BY i
-- !query analysis
Sort [i#x ASC NULLS FIRST], true
+- Project [i#x, scalar-subquery#x [i#x] AS j#xL]
   :  +- Aggregate [sum(i#x) AS sum(i)#xL]
   :     +- SubqueryAlias ss2
   :        +- Project [i#x]
   :           +- Filter ((i#x = outer(i#x)) AND exists#x [i#x])
   :              :  +- Project [i#x]
   :              :     +- Filter (i#x = outer(i#x))
   :              :        +- SubqueryAlias spark_catalog.default.integers
   :              :           +- Relation spark_catalog.default.integers[i#x] parquet
   :              +- SubqueryAlias s1
   :                 +- SubqueryAlias spark_catalog.default.integers
   :                    +- Relation spark_catalog.default.integers[i#x] parquet
   +- SubqueryAlias i1
      +- SubqueryAlias spark_catalog.default.integers
         +- Relation spark_catalog.default.integers[i#x] parquet


-- !query
SELECT i, (SELECT SUM(ss1.i) FROM (SELECT i FROM integers s1 WHERE i>ANY(SELECT i FROM integers WHERE i<>s1.i)) ss1) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT i, (SELECT SUM(ss1.i) FROM (SELECT i FROM integers s1 WHERE i>ANY(SELECT i FROM integers WHERE i<>s1.i)) ss1 LEFT OUTER JOIN (SELECT i FROM integers s1 WHERE i=i1.i AND i=ANY(SELECT i FROM integers WHERE i=s1.i)) ss2 ON ss1.i=ss2.i) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT i, (SELECT SUM(ss2.i) FROM (SELECT i FROM integers s1 WHERE i>ANY(SELECT i FROM integers WHERE i<>s1.i)) ss1 LEFT OUTER JOIN (SELECT i FROM integers s1 WHERE i=i1.i AND i=ANY(SELECT i FROM integers WHERE i=s1.i)) ss2 ON ss1.i=ss2.i) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT i, (SELECT SUM(ss1.i)+SUM(ss2.i) FROM (SELECT i FROM integers s1 WHERE i>ANY(SELECT i FROM integers WHERE i<>s1.i)) ss1 LEFT OUTER JOIN (SELECT i FROM integers s1 WHERE i=i1.i AND i=ANY(SELECT i FROM integers WHERE i=s1.i)) ss2 ON ss1.i=ss2.i) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT i, (SELECT SUM(ss1.i)+SUM(ss2.i) FROM (SELECT i FROM integers s1 WHERE i=i1.i AND i>ANY(SELECT i FROM integers WHERE i<>s1.i)) ss1 LEFT OUTER JOIN (SELECT i FROM integers s1 WHERE i=ANY(SELECT i FROM integers WHERE i=s1.i)) ss2 ON ss1.i=ss2.i) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT i, (SELECT SUM(ss1.i)+SUM(ss2.i) FROM (SELECT i FROM integers s1 WHERE i=i1.i AND i>ANY(SELECT i FROM integers WHERE i<>s1.i)) ss1 LEFT OUTER JOIN (SELECT i FROM integers s1 WHERE i<>i1.i OR i=ANY(SELECT i FROM integers WHERE i=s1.i)) ss2 ON ss1.i=ss2.i) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ""
  }
}


-- !query
SELECT i, (SELECT * FROM (SELECT (SELECT 42+i1.i)) s1) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "MISSING_ATTRIBUTES.RESOLVED_ATTRIBUTE_MISSING_FROM_INPUT",
  "sqlState" : "XX000",
  "messageParameters" : {
    "input" : "",
    "missingAttributes" : "\"i\"",
    "operator" : "!Project [scalar-subquery#x [i#x] AS scalarsubquery(i)#x]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 27,
    "stopIndex" : 49,
    "fragment" : "SELECT (SELECT 42+i1.i)"
  } ]
}


-- !query
SELECT i, (SELECT s1.k+s2.k FROM (SELECT (SELECT 42+i1.i) AS k) s1, (SELECT (SELECT 42+i1.i) AS k) s2) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "MISSING_ATTRIBUTES.RESOLVED_ATTRIBUTE_MISSING_FROM_INPUT",
  "sqlState" : "XX000",
  "messageParameters" : {
    "input" : "",
    "missingAttributes" : "\"i\"",
    "operator" : "!Project [scalar-subquery#x [i#x] AS k#x]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 35,
    "stopIndex" : 62,
    "fragment" : "SELECT (SELECT 42+i1.i) AS k"
  } ]
}


-- !query
SELECT i, (SELECT s1.k+s2.k FROM (SELECT (SELECT 42+i1.i) AS k) s1 LEFT OUTER JOIN (SELECT (SELECT 42+i1.i) AS k) s2 ON s1.k=s2.k) AS j FROM integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "MISSING_ATTRIBUTES.RESOLVED_ATTRIBUTE_MISSING_FROM_INPUT",
  "sqlState" : "XX000",
  "messageParameters" : {
    "input" : "",
    "missingAttributes" : "\"i\"",
    "operator" : "!Project [scalar-subquery#x [i#x] AS k#x]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 35,
    "stopIndex" : 62,
    "fragment" : "SELECT (SELECT 42+i1.i) AS k"
  } ]
}


-- !query
SELECT i, (SELECT i1.i IN (1, 2, 3, 4, 5, 6, 7, 8)) AS j FROM integers i1 ORDER BY i
-- !query analysis
Sort [i#x ASC NULLS FIRST], true
+- Project [i#x, scalar-subquery#x [i#x] AS j#x]
   :  +- Project [outer(i#x) IN (1,2,3,4,5,6,7,8) AS (outer(i1.i) IN (1, 2, 3, 4, 5, 6, 7, 8))#x]
   :     +- OneRowRelation
   +- SubqueryAlias i1
      +- SubqueryAlias spark_catalog.default.integers
         +- Relation spark_catalog.default.integers[i#x] parquet


-- !query
SELECT (SELECT (SELECT COVAR_POP(i1.i, i3.i) FROM integers i3) FROM integers i2 LIMIT 1) FROM integers i1 ORDER BY 1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.AGGREGATE_FUNCTION_MIXED_OUTER_LOCAL_REFERENCES",
  "sqlState" : "0A000",
  "messageParameters" : {
    "function" : "covar_pop(CAST(outer(i1.i) AS DOUBLE), CAST(i3.i AS DOUBLE))"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 24,
    "stopIndex" : 44,
    "fragment" : "COVAR_POP(i1.i, i3.i)"
  } ]
}


-- !query
SELECT (SELECT (SELECT COVAR_POP(i2.i, i3.i) FROM integers i3) FROM integers i2 ORDER BY i NULLS LAST LIMIT 1) FROM integers i1 ORDER BY 1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.AGGREGATE_FUNCTION_MIXED_OUTER_LOCAL_REFERENCES",
  "sqlState" : "0A000",
  "messageParameters" : {
    "function" : "covar_pop(CAST(outer(i2.i) AS DOUBLE), CAST(i3.i AS DOUBLE))"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 24,
    "stopIndex" : 44,
    "fragment" : "COVAR_POP(i2.i, i3.i)"
  } ]
}
