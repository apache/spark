-- Automatically generated by SQLQueryTestSuite
-- !query
set spark.sql.optimizer.supportNestedCorrelatedSubqueries.enabled=true
-- !query analysis
SetCommand (spark.sql.optimizer.supportNestedCorrelatedSubqueries.enabled,Some(true))


-- !query
DROP TABLE IF EXISTS tbl_ProductSales
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.tbl_ProductSales


-- !query
DROP TABLE IF EXISTS another_T
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.another_T


-- !query
CREATE TABLE tbl_ProductSales (ColID int, Product_Category  varchar(64), Product_Name  varchar(64), TotalSales int)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`tbl_ProductSales`, false


-- !query
CREATE TABLE another_T (col1 INT, col2 INT, col3 INT, col4 INT, col5 INT, col6 INT, col7 INT, col8 INT)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`another_T`, false


-- !query
INSERT INTO tbl_ProductSales VALUES (1,'Game','Mobo Game',200),(2,'Game','PKO Game',400),(3,'Fashion','Shirt',500),(4,'Fashion','Shorts',100)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/tbl_productsales, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/tbl_productsales], Append, `spark_catalog`.`default`.`tbl_productsales`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/tbl_productsales), [ColID, Product_Category, Product_Name, TotalSales]
+- Project [cast(col1#x as int) AS ColID#x, static_invoke(CharVarcharCodegenUtils.varcharTypeWriteSideCheck(cast(col2#x as string), 64)) AS Product_Category#x, static_invoke(CharVarcharCodegenUtils.varcharTypeWriteSideCheck(cast(col3#x as string), 64)) AS Product_Name#x, cast(col4#x as int) AS TotalSales#x]
   +- LocalRelation [col1#x, col2#x, col3#x, col4#x]


-- !query
INSERT INTO another_T VALUES (1,2,3,4,5,6,7,8), (11,22,33,44,55,66,77,88), (111,222,333,444,555,666,777,888), (1111,2222,3333,4444,5555,6666,7777,8888)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/another_t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/another_t], Append, `spark_catalog`.`default`.`another_t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/another_t), [col1, col2, col3, col4, col5, col6, col7, col8]
+- LocalRelation [col1#x, col2#x, col3#x, col4#x, col5#x, col6#x, col7#x, col8#x]


-- !query
SELECT CASE WHEN 1 IN (SELECT (SELECT MAX(col7))) THEN 2 ELSE NULL END FROM another_T t1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"max(col7) AS `max(outer(t1.col7))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 32,
    "stopIndex" : 47,
    "fragment" : "SELECT MAX(col7)"
  } ]
}


-- !query
SELECT CASE WHEN 1 IN (SELECT (SELECT MAX(col7)) UNION ALL (SELECT MIN(ColID) FROM tbl_ProductSales INNER JOIN another_T t2 ON t2.col5 = t2.col1)) THEN 2 ELSE NULL END FROM another_T t1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"max(col7) AS `max(outer(t1.col7))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 32,
    "stopIndex" : 47,
    "fragment" : "SELECT MAX(col7)"
  } ]
}


-- !query
SELECT CASE WHEN 1 IN (SELECT (SELECT MIN(ColID) FROM tbl_ProductSales INNER JOIN another_T t2 ON t2.col5 = t2.col1) UNION ALL (SELECT MAX(col7))) THEN 2 ELSE NULL END FROM another_T t1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"max(col7) AS `max(outer(t1.col7))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 129,
    "stopIndex" : 144,
    "fragment" : "SELECT MAX(col7)"
  } ]
}


-- !query
SELECT (SELECT MIN(ColID) FROM tbl_ProductSales INNER JOIN another_T t2 ON t1.col7 <> (SELECT MAX(t1.col1 + t3.col4) FROM another_T t3)) FROM another_T t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.AGGREGATE_FUNCTION_MIXED_OUTER_LOCAL_REFERENCES",
  "sqlState" : "0A000",
  "messageParameters" : {
    "function" : "max((outer(t1.col1) + t3.col4))"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 95,
    "stopIndex" : 116,
    "fragment" : "MAX(t1.col1 + t3.col4)"
  } ]
}


-- !query
SELECT (SELECT MIN(ColID) FROM tbl_ProductSales INNER JOIN another_T t2 ON t1.col7 <> ANY(SELECT MAX(t1.col1 + t3.col4) FROM another_T t3)) FROM another_T t1
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'('",
    "hint" : ": missing ')'"
  }
}


-- !query
SELECT CASE WHEN NOT col1 NOT IN (SELECT (SELECT MAX(col7)) UNION (SELECT MIN(ColID) FROM tbl_ProductSales LEFT JOIN another_T t2 ON t2.col5 = t1.col1)) THEN 1 ELSE 2 END FROM another_T t1 GROUP BY col1 ORDER BY 1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"max(col7) AS `max(outer(t1.col7))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 43,
    "stopIndex" : 58,
    "fragment" : "SELECT MAX(col7)"
  } ]
}
