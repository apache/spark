-- Automatically generated by SQLQueryTestSuite
-- !query
set spark.sql.optimizer.supportNestedCorrelatedSubqueries.enabled=true
-- !query analysis
SetCommand (spark.sql.optimizer.supportNestedCorrelatedSubqueries.enabled,Some(true))


-- !query
SELECT 1 FROM (SELECT 1) t0(c0) WHERE (SELECT (SELECT 1 ORDER BY c0)) = 1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"c0 ASC NULLS FIRST\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 57,
    "stopIndex" : 67,
    "fragment" : "ORDER BY c0"
  } ]
}


-- !query
SELECT 1 FROM (SELECT 1) t0(c0) WHERE (SELECT (SELECT 1 LIMIT c0)) = 1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "INVALID_LIMIT_LIKE_EXPRESSION.IS_UNFOLDABLE",
  "sqlState" : "42K0E",
  "messageParameters" : {
    "expr" : "\"outer(t0.c0)\"",
    "name" : "limit"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 63,
    "stopIndex" : 64,
    "fragment" : "c0"
  } ]
}


-- !query
DROP TABLE IF EXISTS t
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.t


-- !query
CREATE TABLE t(ps_supplycost INT, n_name INT)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`t`, false


-- !query
SELECT NULL
FROM
    t AS ref_2,
    (SELECT (SELECT NULL
         FROM (FROM t AS ref_5,
              (SELECT ref_2.n_name AS c1))))
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNRESOLVED_COLUMN.WITHOUT_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`ref_2`.`n_name`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 113,
    "stopIndex" : 124,
    "fragment" : "ref_2.n_name"
  } ]
}


-- !query
SELECT NULL
FROM
    t AS ref_2,
    (SELECT (SELECT NULL
         FROM (FROM t AS ref_5,
              (SELECT ref_5.ps_supplycost AS c0,
                      ref_2.n_name AS c1))))
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNRESOLVED_COLUMN.WITHOUT_SUGGESTION",
  "sqlState" : "42703",
  "messageParameters" : {
    "objectName" : "`ref_5`.`ps_supplycost`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 113,
    "stopIndex" : 131,
    "fragment" : "ref_5.ps_supplycost"
  } ]
}


-- !query
DROP TABLE IF EXISTS table_integers
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.table_integers


-- !query
CREATE TABLE table_integers(i INTEGER)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`table_integers`, false


-- !query
INSERT INTO table_integers VALUES (1), (2), (3), (NULL)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/table_integers, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/table_integers], Append, `spark_catalog`.`default`.`table_integers`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/table_integers), [i]
+- Project [cast(col1#x as int) AS i#x]
   +- LocalRelation [col1#x]


-- !query
SELECT i, (SELECT (SELECT i1.i+SUM(i2.i)) FROM table_integers i2) AS j FROM table_integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"(i + sum(i)) AS `(outer(i1.i) + sum(outer(i2.i)))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 20,
    "stopIndex" : 40,
    "fragment" : "SELECT i1.i+SUM(i2.i)"
  } ]
}


-- !query
SELECT i, (SELECT ((SELECT ((SELECT ((SELECT SUM(i)+SUM(i4.i)+SUM(i3.i)+SUM(i2.i)+SUM(i1.i) FROM table_integers i5)) FROM table_integers i4)) FROM table_integers i3)) FROM table_integers i2) AS j FROM table_integers i1 GROUP BY i ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"((((sum(i) + sum(i)) + sum(i)) + sum(i)) + sum(i)) AS `((((sum(i) + sum(outer(i4.i))) + sum(outer(i3.i))) + sum(outer(i2.i))) + sum(outer(i1.i)))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 39,
    "stopIndex" : 114,
    "fragment" : "SELECT SUM(i)+SUM(i4.i)+SUM(i3.i)+SUM(i2.i)+SUM(i1.i) FROM table_integers i5"
  } ]
}


-- !query
SELECT (SELECT (SELECT SUM(i1.i)+SUM(i2.i)+SUM(i3.i) FROM table_integers i3) FROM table_integers i2) FROM table_integers i1 ORDER BY 1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"((sum(i) + sum(i)) + sum(i)) AS `((sum(outer(i1.i)) + sum(outer(i2.i))) + sum(i))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 17,
    "stopIndex" : 75,
    "fragment" : "SELECT SUM(i1.i)+SUM(i2.i)+SUM(i3.i) FROM table_integers i3"
  } ]
}


-- !query
SELECT i, SUM(i), (SELECT (SELECT SUM(i)+SUM(i1.i)+SUM(i2.i) FROM table_integers) FROM table_integers i2) FROM table_integers i1 GROUP BY i ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"((sum(i) + sum(i)) + sum(i)) AS `((sum(i) + sum(outer(i1.i))) + sum(outer(i2.i)))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 28,
    "stopIndex" : 80,
    "fragment" : "SELECT SUM(i)+SUM(i1.i)+SUM(i2.i) FROM table_integers"
  } ]
}


-- !query
SELECT i, (SELECT SUM(i)+(SELECT 42+i1.i) FROM table_integers) AS j FROM table_integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "SCALAR_SUBQUERY_IS_IN_GROUP_BY_OR_AGGREGATE_FUNCTION",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExpr" : "\"scalarsubquery(i)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 26,
    "stopIndex" : 41,
    "fragment" : "(SELECT 42+i1.i)"
  } ]
}


-- !query
SELECT i, (SELECT SUM(s1.i) FROM table_integers s1 INNER JOIN table_integers s2 ON (SELECT i1.i+s1.i)=(SELECT i1.i+s2.i)) AS j FROM table_integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.UNSUPPORTED_CORRELATED_SCALAR_SUBQUERY",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Join Inner, (scalar-subquery#x [i#x && i#x] = scalar-subquery#x [i#x && i#x])\n:  :- Project [(outer(i#x) + outer(i#x)) AS (outer(i1.i) + outer(s1.i))#x]\n:  :  +- OneRowRelation\n:  +- Project [(outer(i#x) + outer(i#x)) AS (outer(i1.i) + outer(s2.i))#x]\n:     +- OneRowRelation\n:- SubqueryAlias s1\n:  +- SubqueryAlias spark_catalog.default.table_integers\n:     +- Relation spark_catalog.default.table_integers[i#x] parquet\n+- SubqueryAlias s2\n   +- SubqueryAlias spark_catalog.default.table_integers\n      +- Relation spark_catalog.default.table_integers[i#x] parquet\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 52,
    "stopIndex" : 120,
    "fragment" : "INNER JOIN table_integers s2 ON (SELECT i1.i+s1.i)=(SELECT i1.i+s2.i)"
  } ]
}


-- !query
SELECT i, (SELECT SUM(s1.i) FROM table_integers s1 LEFT OUTER JOIN table_integers s2 ON (SELECT i1.i+s1.i)=(SELECT i1.i+s2.i)) AS j FROM table_integers i1 ORDER BY i

SELECT (SELECT (SELECT COVAR_POP(i2.i, i3.i) FROM table_integers i3) FROM table_integers i2 ORDER BY i NULLS LAST LIMIT 1) FROM table_integers i1 ORDER BY 1
-- !query analysis
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'SELECT'",
    "hint" : ""
  }
}


-- !query
SELECT (SELECT (SELECT COVAR_POP(i1.i, i3.i) FROM table_integers i3) FROM table_integers i2 LIMIT 1) FROM table_integers i1 ORDER BY 1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.AGGREGATE_FUNCTION_MIXED_OUTER_LOCAL_REFERENCES",
  "sqlState" : "0A000",
  "messageParameters" : {
    "function" : "covar_pop(CAST(outer(i1.i) AS DOUBLE), CAST(i3.i AS DOUBLE))"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 24,
    "stopIndex" : 44,
    "fragment" : "COVAR_POP(i1.i, i3.i)"
  } ]
}


-- !query
SELECT i, (SELECT SUM(ss1.i) FROM (SELECT i FROM table_integers s1 WHERE EXISTS(SELECT i FROM table_integers WHERE i<>s1.i AND s1.i > i)) ss1 LEFT OUTER JOIN (SELECT i FROM table_integers s1 WHERE i=i1.i AND EXISTS(SELECT i FROM table_integers WHERE i=s1.i)) ss2 ON ss1.i=ss2.i) AS j FROM table_integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.ACCESSING_OUTER_QUERY_COLUMN_IS_NOT_ALLOWED",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Filter ((i#x = outer(i#x)) AND exists#x [i#x])\n:  +- Project [i#x]\n:     +- Filter (i#x = outer(i#x))\n:        +- SubqueryAlias spark_catalog.default.table_integers\n:           +- Relation spark_catalog.default.table_integers[i#x] parquet\n+- SubqueryAlias s1\n   +- SubqueryAlias spark_catalog.default.table_integers\n      +- Relation spark_catalog.default.table_integers[i#x] parquet\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 160,
    "stopIndex" : 257,
    "fragment" : "SELECT i FROM table_integers s1 WHERE i=i1.i AND EXISTS(SELECT i FROM table_integers WHERE i=s1.i)"
  } ]
}


-- !query
SELECT i, (SELECT SUM(ss2.i) FROM (SELECT i FROM table_integers s1 WHERE EXISTS(SELECT i FROM table_integers WHERE i<>s1.i AND s1.i > i)) ss1 LEFT OUTER JOIN (SELECT i FROM table_integers s1 WHERE i=i1.i AND EXISTS(SELECT i FROM table_integers WHERE i=s1.i)) ss2 ON ss1.i=ss2.i) AS j FROM table_integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.ACCESSING_OUTER_QUERY_COLUMN_IS_NOT_ALLOWED",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Filter ((i#x = outer(i#x)) AND exists#x [i#x])\n:  +- Project [i#x]\n:     +- Filter (i#x = outer(i#x))\n:        +- SubqueryAlias spark_catalog.default.table_integers\n:           +- Relation spark_catalog.default.table_integers[i#x] parquet\n+- SubqueryAlias s1\n   +- SubqueryAlias spark_catalog.default.table_integers\n      +- Relation spark_catalog.default.table_integers[i#x] parquet\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 160,
    "stopIndex" : 257,
    "fragment" : "SELECT i FROM table_integers s1 WHERE i=i1.i AND EXISTS(SELECT i FROM table_integers WHERE i=s1.i)"
  } ]
}


-- !query
SELECT i, (SELECT SUM(ss1.i)+SUM(ss2.i) FROM (SELECT i FROM table_integers s1 WHERE EXISTS(SELECT i FROM table_integers WHERE i<>s1.i AND s1.i > i)) ss1 LEFT OUTER JOIN (SELECT i FROM table_integers s1 WHERE i=i1.i AND EXISTS(SELECT i FROM table_integers WHERE i=s1.i)) ss2 ON ss1.i=ss2.i) AS j FROM table_integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.ACCESSING_OUTER_QUERY_COLUMN_IS_NOT_ALLOWED",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Filter ((i#x = outer(i#x)) AND exists#x [i#x])\n:  +- Project [i#x]\n:     +- Filter (i#x = outer(i#x))\n:        +- SubqueryAlias spark_catalog.default.table_integers\n:           +- Relation spark_catalog.default.table_integers[i#x] parquet\n+- SubqueryAlias s1\n   +- SubqueryAlias spark_catalog.default.table_integers\n      +- Relation spark_catalog.default.table_integers[i#x] parquet\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 171,
    "stopIndex" : 268,
    "fragment" : "SELECT i FROM table_integers s1 WHERE i=i1.i AND EXISTS(SELECT i FROM table_integers WHERE i=s1.i)"
  } ]
}


-- !query
SELECT i, (SELECT SUM(ss1.i)+SUM(ss2.i) FROM (SELECT i FROM table_integers s1 WHERE i=i1.i AND EXISTS(SELECT i FROM table_integers WHERE i<>s1.i AND s1.i>i)) ss1 LEFT OUTER JOIN (SELECT i FROM table_integers s1 WHERE i<>i1.i OR EXISTS(SELECT i FROM table_integers WHERE i=s1.i)) ss2 ON ss1.i=ss2.i) AS j FROM table_integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.ACCESSING_OUTER_QUERY_COLUMN_IS_NOT_ALLOWED",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Filter (NOT (i#x = outer(i#x)) OR exists#x [i#x])\n:  +- Project [i#x]\n:     +- Filter (i#x = outer(i#x))\n:        +- SubqueryAlias spark_catalog.default.table_integers\n:           +- Relation spark_catalog.default.table_integers[i#x] parquet\n+- SubqueryAlias s1\n   +- SubqueryAlias spark_catalog.default.table_integers\n      +- Relation spark_catalog.default.table_integers[i#x] parquet\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 180,
    "stopIndex" : 277,
    "fragment" : "SELECT i FROM table_integers s1 WHERE i<>i1.i OR EXISTS(SELECT i FROM table_integers WHERE i=s1.i)"
  } ]
}


-- !query
SELECT i, (SELECT SUM(s2.i) FROM table_integers s1 LEFT OUTER JOIN (SELECT i FROM table_integers WHERE i=i1.i) s2 ON s1.i=s2.i) AS j FROM table_integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.ACCESSING_OUTER_QUERY_COLUMN_IS_NOT_ALLOWED",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Filter (i#x = outer(i#x))\n+- SubqueryAlias spark_catalog.default.table_integers\n   +- Relation spark_catalog.default.table_integers[i#x] parquet\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 69,
    "stopIndex" : 109,
    "fragment" : "SELECT i FROM table_integers WHERE i=i1.i"
  } ]
}


-- !query
SELECT i, (SELECT SUM(s2.i) FROM table_integers s1 LEFT OUTER JOIN (SELECT i FROM table_integers WHERE i<>i1.i) s2 ON s1.i=s2.i) AS j FROM table_integers i1 ORDER BY i
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.ACCESSING_OUTER_QUERY_COLUMN_IS_NOT_ALLOWED",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "Filter NOT (i#x = outer(i#x))\n+- SubqueryAlias spark_catalog.default.table_integers\n   +- Relation spark_catalog.default.table_integers[i#x] parquet\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 69,
    "stopIndex" : 110,
    "fragment" : "SELECT i FROM table_integers WHERE i<>i1.i"
  } ]
}


-- !query
DROP TABLE IF EXISTS tbl_ProductSales
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.tbl_ProductSales


-- !query
DROP TABLE IF EXISTS another_T
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.another_T


-- !query
CREATE TABLE tbl_ProductSales (ColID int, Product_Category  varchar(64), Product_Name  varchar(64), TotalSales int)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`tbl_ProductSales`, false


-- !query
CREATE TABLE another_T (col1 INT, col2 INT, col3 INT, col4 INT, col5 INT, col6 INT, col7 INT, col8 INT)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`another_T`, false


-- !query
INSERT INTO tbl_ProductSales VALUES (1,'Game','Mobo Game',200),(2,'Game','PKO Game',400),(3,'Fashion','Shirt',500),(4,'Fashion','Shorts',100)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/tbl_productsales, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/tbl_productsales], Append, `spark_catalog`.`default`.`tbl_productsales`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/tbl_productsales), [ColID, Product_Category, Product_Name, TotalSales]
+- Project [cast(col1#x as int) AS ColID#x, static_invoke(CharVarcharCodegenUtils.varcharTypeWriteSideCheck(cast(col2#x as string), 64)) AS Product_Category#x, static_invoke(CharVarcharCodegenUtils.varcharTypeWriteSideCheck(cast(col3#x as string), 64)) AS Product_Name#x, cast(col4#x as int) AS TotalSales#x]
   +- LocalRelation [col1#x, col2#x, col3#x, col4#x]


-- !query
INSERT INTO another_T VALUES (1,2,3,4,5,6,7,8), (11,22,33,44,55,66,77,88), (111,222,333,444,555,666,777,888), (1111,2222,3333,4444,5555,6666,7777,8888)
-- !query analysis
InsertIntoHadoopFsRelationCommand file:[not included in comparison]/{warehouse_dir}/another_t, false, Parquet, [path=file:[not included in comparison]/{warehouse_dir}/another_t], Append, `spark_catalog`.`default`.`another_t`, org.apache.spark.sql.execution.datasources.InMemoryFileIndex(file:[not included in comparison]/{warehouse_dir}/another_t), [col1, col2, col3, col4, col5, col6, col7, col8]
+- LocalRelation [col1#x, col2#x, col3#x, col4#x, col5#x, col6#x, col7#x, col8#x]


-- !query
SELECT (SELECT MIN(ColID) FROM tbl_ProductSales INNER JOIN another_T t2 ON t1.col7 <> (SELECT MAX(t1.col1 + t3.col4) FROM another_T t3)) FROM another_T t1
-- !query analysis
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.AGGREGATE_FUNCTION_MIXED_OUTER_LOCAL_REFERENCES",
  "sqlState" : "0A000",
  "messageParameters" : {
    "function" : "max((outer(t1.col1) + t3.col4))"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 95,
    "stopIndex" : 116,
    "fragment" : "MAX(t1.col1 + t3.col4)"
  } ]
}


-- !query
SELECT CASE WHEN 1 IN (SELECT (SELECT MAX(col7))) THEN 2 ELSE NULL END FROM another_T t1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"max(col7) AS `max(outer(t1.col7))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 32,
    "stopIndex" : 47,
    "fragment" : "SELECT MAX(col7)"
  } ]
}


-- !query
SELECT CASE WHEN 1 IN (SELECT (SELECT MAX(col7)) UNION ALL (SELECT MIN(ColID) FROM tbl_ProductSales INNER JOIN another_T t2 ON t2.col5 = t2.col1)) THEN 2 ELSE NULL END FROM another_T t1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"max(col7) AS `max(outer(t1.col7))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 32,
    "stopIndex" : 47,
    "fragment" : "SELECT MAX(col7)"
  } ]
}


-- !query
SELECT CASE WHEN 1 IN (SELECT (SELECT MIN(ColID) FROM tbl_ProductSales INNER JOIN another_T t2 ON t2.col5 = t2.col1) UNION ALL (SELECT MAX(col7))) THEN 2 ELSE NULL END FROM another_T t1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"max(col7) AS `max(outer(t1.col7))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 129,
    "stopIndex" : 144,
    "fragment" : "SELECT MAX(col7)"
  } ]
}


-- !query
SELECT CASE WHEN NOT col1 NOT IN (SELECT (SELECT MAX(col7)) UNION (SELECT MIN(ColID) FROM tbl_ProductSales LEFT JOIN another_T t2 ON t2.col5 = t1.col1)) THEN 1 ELSE 2 END FROM another_T t1 GROUP BY col1 ORDER BY 1
-- !query analysis
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.CORRELATED_REFERENCE",
  "sqlState" : "0A000",
  "messageParameters" : {
    "sqlExprs" : "\"max(col7) AS `max(outer(t1.col7))`\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 43,
    "stopIndex" : 58,
    "fragment" : "SELECT MAX(col7)"
  } ]
}


-- !query
DROP TABLE IF EXISTS tbl
-- !query analysis
DropTable true, false
+- ResolvedIdentifier V2SessionCatalog(spark_catalog), default.tbl


-- !query
CREATE TABLE tbl(a TINYINT, b SMALLINT, c INTEGER, d BIGINT, e VARCHAR(1), f DATE, g TIMESTAMP)
-- !query analysis
CreateDataSourceTableCommand `spark_catalog`.`default`.`tbl`, false


-- !query
SELECT 1 FROM tbl t1 JOIN tbl t2 ON (t1.d=t2.d) WHERE EXISTS(SELECT t1.c FROM tbl t3 WHERE t1.d+t3.c<100 AND EXISTS(SELECT 1 FROM tbl t4 WHERE t2.f < DATE '2000-01-01'))
-- !query analysis
[Analyzer test output redacted due to nondeterminism]
