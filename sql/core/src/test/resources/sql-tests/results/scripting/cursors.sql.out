-- Automatically generated by SQLQueryTestSuite
-- !query
BEGIN
  DECLARE x INT DEFAULT 10;
  DECLARE x CURSOR FOR SELECT 1 AS col;
  OPEN x;
  FETCH x INTO x;
  VALUES (x); -- Should return 1
  CLOSE x;
END
-- !query schema
struct<col1:int>
-- !query output
1


-- !query
BEGIN
  DECLARE c1 CURSOR FOR SELECT 1;
  DECLARE c1 CURSOR FOR SELECT 2;
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "CURSOR_ALREADY_EXISTS",
  "sqlState" : "42723",
  "messageParameters" : {
    "cursorName" : "c1"
  }
}


-- !query
BEGIN
  DECLARE y INT;
  DECLARE c1 CURSOR FOR SELECT 1 AS val;
  BEGIN
    DECLARE x INT;
    DECLARE c1 CURSOR FOR SELECT 2 AS val;
    OPEN c1;  -- Opens inner c1
    FETCH c1 INTO x;
    VALUES (x); -- Should return 2
    CLOSE c1;
  END;
  OPEN c1;  -- Opens outer c1
  FETCH c1 INTO y;
  VALUES (y); -- Should return 1
  CLOSE c1;
END
-- !query schema
struct<col1:int>
-- !query output
1


-- !query
BEGIN
  DECLARE c1 CURSOR FOR SELECT 1;
  OPEN c1;
  OPEN c1; -- Should fail
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "CURSOR_ALREADY_OPEN",
  "sqlState" : "24502",
  "messageParameters" : {
    "cursorName" : "c1"
  }
}


-- !query
BEGIN
  DECLARE x INT;
  DECLARE c1 CURSOR FOR SELECT 1 AS val;
  OPEN c1;
  FETCH c1 INTO x;
  VALUES (x); -- Should return 1
  CLOSE c1;
  OPEN c1; -- Should succeed
  FETCH c1 INTO x;
  VALUES (x); -- Should return 1
  CLOSE c1;
END
-- !query schema
struct<col1:int>
-- !query output
1


-- !query
BEGIN
  DECLARE c1 CURSOR FOR SELECT 1;
  CLOSE c1; -- Should fail
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "CURSOR_NOT_OPEN",
  "sqlState" : "24501",
  "messageParameters" : {
    "cursorName" : "c1"
  }
}


-- !query
BEGIN
  DECLARE c1 CURSOR FOR SELECT 1;
  OPEN c1;
  CLOSE c1;
  CLOSE c1; -- Should fail
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "CURSOR_NOT_OPEN",
  "sqlState" : "24501",
  "messageParameters" : {
    "cursorName" : "c1"
  }
}


-- !query
BEGIN
  DECLARE x INT;
  DECLARE c1 CURSOR FOR SELECT 1 AS val;
  FETCH c1 INTO x; -- Should fail
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "CURSOR_NOT_OPEN",
  "sqlState" : "24501",
  "messageParameters" : {
    "cursorName" : "c1"
  }
}


-- !query
BEGIN
  DECLARE x INT;
  DECLARE c1 CURSOR FOR SELECT 1 AS val;
  OPEN c1;
  FETCH c1 INTO x;
  CLOSE c1;
  FETCH c1 INTO x; -- Should fail
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "CURSOR_NOT_OPEN",
  "sqlState" : "24501",
  "messageParameters" : {
    "cursorName" : "c1"
  }
}


-- !query
BEGIN
  DECLARE step, x INT DEFAULT 0;
  REPEAT
    BEGIN
      DECLARE c1 CURSOR FOR SELECT step AS val;
      OPEN c1;
      FETCH c1 INTO x;
      SET step = step + 1;
    END;
  UNTIL step = 10 END REPEAT;
  VALUES(step);
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
{
  "errorClass" : "INTERNAL_ERROR",
  "sqlState" : "XX000",
  "messageParameters" : {
    "message" : "Invalid call to dataType on unresolved object"
  }
}


-- !query
BEGIN
  DECLARE x INT;
  DECLARE c1 CURSOR FOR SELECT 1 AS val;
  OPEN c1;
  BEGIN
    DECLARE y INT;
    DECLARE c1 CURSOR FOR SELECT 2 AS val;
    OPEN c1; -- This is the inner c1, should succeed
    FETCH c1 INTO y;
    VALUES (y); -- Should return 2
    CLOSE c1;
  END;
  FETCH c1 INTO x; -- This is the outer c1, should still be open
  VALUES (x); -- Should return 1
  CLOSE c1;
END
-- !query schema
struct<col1:int>
-- !query output
1


-- !query
CREATE TABLE cursor_sensitivity_test (id INT, value STRING) USING parquet
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO cursor_sensitivity_test VALUES (1, 'row1'), (2, 'row2')
-- !query schema
struct<>
-- !query output



-- !query
BEGIN
  DECLARE fetched_id INT;
  DECLARE fetched_value STRING;
  DECLARE row_count_first_open INT DEFAULT 0;
  DECLARE row_count_second_open INT DEFAULT 0;
  DECLARE nomorerows BOOLEAN DEFAULT false;

  DECLARE cur CURSOR FOR SELECT id, value FROM cursor_sensitivity_test ORDER BY id;

  DECLARE CONTINUE HANDLER FOR NOT FOUND SET nomorerows = true;

  INSERT INTO cursor_sensitivity_test VALUES (3, 'row3'), (4, 'row4');

  OPEN cur;

  INSERT INTO cursor_sensitivity_test VALUES (5, 'row5'), (6, 'row6');

  REPEAT
    FETCH cur INTO fetched_id, fetched_value;
    IF NOT nomorerows THEN
      SET row_count_first_open = row_count_first_open + 1;
    END IF;
  UNTIL nomorerows END REPEAT;

  CLOSE cur;

  SET nomorerows = false;
  OPEN cur;

  REPEAT
    FETCH cur INTO fetched_id, fetched_value;
    IF NOT nomorerows THEN
      SET row_count_second_open = row_count_second_open + 1;
    END IF;
  UNTIL nomorerows END REPEAT;

  VALUES (row_count_first_open, row_count_second_open);

  CLOSE cur;
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
{
  "errorClass" : "INTERNAL_ERROR",
  "sqlState" : "XX000",
  "messageParameters" : {
    "message" : "Invalid call to dataType on unresolved object"
  }
}


-- !query
DROP TABLE cursor_sensitivity_test
-- !query schema
struct<>
-- !query output



-- !query
BEGIN
  DECLARE min_id INT DEFAULT 2;
  DECLARE max_id INT DEFAULT 4;
  DECLARE fetched_id INT;
  DECLARE fetched_value STRING;
  DECLARE nomorerows BOOLEAN DEFAULT false;
  DECLARE result STRING DEFAULT '';
  DECLARE cur CURSOR FOR SELECT id, value FROM VALUES(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd'), (5, 'e') AS t(id, value) WHERE id >= ? AND id <= ?;
  DECLARE CONTINUE HANDLER FOR NOT FOUND SET nomorerows = true;

  OPEN cur USING min_id, max_id;

  REPEAT
    FETCH cur INTO fetched_id, fetched_value;
    IF NOT nomorerows THEN
      SET result = result || fetched_value;
    END IF;
  UNTIL nomorerows END REPEAT;

  CLOSE cur;
  VALUES (result);
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
{
  "errorClass" : "INTERNAL_ERROR",
  "sqlState" : "XX000",
  "messageParameters" : {
    "message" : "Invalid call to dataType on unresolved object"
  }
}


-- !query
BEGIN
  DECLARE search_value STRING DEFAULT 'c';
  DECLARE fetched_id INT;
  DECLARE fetched_value STRING;
  DECLARE nomorerows BOOLEAN DEFAULT false;
  DECLARE id_sum INT DEFAULT 0;
  DECLARE cur CURSOR FOR SELECT id, value FROM VALUES(1, 'a'), (2, 'b'), (3, 'c'), (4, 'c'), (5, 'e') AS t(id, value) WHERE value = :search_val;
  DECLARE CONTINUE HANDLER FOR NOT FOUND SET nomorerows = true;

  OPEN cur USING search_value AS search_val;

  REPEAT
    FETCH cur INTO fetched_id, fetched_value;
    IF NOT nomorerows THEN
      SET id_sum = id_sum + fetched_id;
    END IF;
  UNTIL nomorerows END REPEAT;

  CLOSE cur;
  VALUES (id_sum);
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
{
  "errorClass" : "INTERNAL_ERROR",
  "sqlState" : "XX000",
  "messageParameters" : {
    "message" : "Invalid call to dataType on unresolved object"
  }
}


-- !query
BEGIN
  DECLARE fetched_id INT;
  DECLARE nomorerows BOOLEAN DEFAULT false;
  DECLARE count1 INT DEFAULT 0;
  DECLARE count2 INT DEFAULT 0;
  DECLARE cur CURSOR FOR SELECT id FROM VALUES(1), (2), (3), (4), (5) AS t(id) WHERE id >= ? AND id <= ?;
  DECLARE CONTINUE HANDLER FOR NOT FOUND SET nomorerows = true;

  OPEN cur USING 2, 3;
  REPEAT
    FETCH cur INTO fetched_id;
    IF NOT nomorerows THEN
      SET count1 = count1 + 1;
    END IF;
  UNTIL nomorerows END REPEAT;
  CLOSE cur;

  SET nomorerows = false;
  OPEN cur USING 1, 5;
  REPEAT
    FETCH cur INTO fetched_id;
    IF NOT nomorerows THEN
      SET count2 = count2 + 1;
    END IF;
  UNTIL nomorerows END REPEAT;
  CLOSE cur;

  VALUES (count1, count2);
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
{
  "errorClass" : "INTERNAL_ERROR",
  "sqlState" : "XX000",
  "messageParameters" : {
    "message" : "Invalid call to dataType on unresolved object"
  }
}


-- !query
BEGIN
  DECLARE base INT DEFAULT 10;
  DECLARE fetched_id INT;
  DECLARE nomorerows BOOLEAN DEFAULT false;
  DECLARE sum INT DEFAULT 0;
  DECLARE cur CURSOR FOR SELECT id FROM VALUES(5), (10), (15), (20), (25) AS t(id) WHERE id > ?;
  DECLARE CONTINUE HANDLER FOR NOT FOUND SET nomorerows = true;

  OPEN cur USING base + 5;

  REPEAT
    FETCH cur INTO fetched_id;
    IF NOT nomorerows THEN
      SET sum = sum + fetched_id;
    END IF;
  UNTIL nomorerows END REPEAT;

  CLOSE cur;
  VALUES (sum); -- Should be 20 + 25 = 45
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
{
  "errorClass" : "INTERNAL_ERROR",
  "sqlState" : "XX000",
  "messageParameters" : {
    "message" : "Invalid call to dataType on unresolved object"
  }
}


-- !query
BEGIN
  outer: BEGIN
    DECLARE x INT;
    DECLARE c1 CURSOR FOR SELECT 42 AS val;
    OPEN outer.c1;
    FETCH outer.c1 INTO x;
    VALUES (x); -- Should return 42
    CLOSE outer.c1;
  END;
END
-- !query schema
struct<col1:int>
-- !query output
42


-- !query
BEGIN
  outer_lbl: BEGIN
    DECLARE x, y INT;
    DECLARE cur CURSOR FOR SELECT 1 AS val;

    inner_lbl: BEGIN
      DECLARE cur CURSOR FOR SELECT 2 AS val;

      OPEN outer_lbl.cur;  -- Opens outer cursor
      OPEN inner_lbl.cur;  -- Opens inner cursor

      FETCH cur INTO x;

      FETCH outer_lbl.cur INTO y;

      CLOSE inner_lbl.cur;
    END;

    CLOSE outer_lbl.cur;

    VALUES (x, y);
  END;
END
-- !query schema
struct<col1:int,col2:int>
-- !query output
2	1


-- !query
BEGIN
  lbl: BEGIN
    DECLARE min_val INT DEFAULT 3;
    DECLARE max_val INT DEFAULT 4;
    DECLARE fetched_id INT;
    DECLARE result STRING DEFAULT '';
    DECLARE cur CURSOR FOR SELECT id FROM VALUES(1), (2), (3), (4), (5) AS t(id) WHERE id >= ? AND id <= ?;

    OPEN lbl.cur USING min_val, max_val;

    FETCH lbl.cur INTO fetched_id;
    SET result = result || CAST(fetched_id AS STRING);
    FETCH lbl.cur INTO fetched_id;
    SET result = result || CAST(fetched_id AS STRING);

    CLOSE lbl.cur;
    VALUES (result); -- Should be '34'
  END;
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.analysis.UnresolvedException
{
  "errorClass" : "INTERNAL_ERROR",
  "sqlState" : "XX000",
  "messageParameters" : {
    "message" : "Invalid call to dataType on unresolved object"
  }
}


-- !query
BEGIN
  DECLARE x, y INT;
  DECLARE cur CURSOR FOR SELECT 1 AS a, 2 AS b;
  OPEN cur;
  FETCH cur INTO x, x;  -- Should fail - duplicate variable
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DUPLICATE_ASSIGNMENTS",
  "sqlState" : "42701",
  "messageParameters" : {
    "nameList" : "`x`"
  }
}


-- !query
BEGIN
  DECLARE int_var INT;
  DECLARE str_var STRING;
  DECLARE cur CURSOR FOR SELECT 100.7 AS double_val, 42 AS int_val;

  OPEN cur;
  FETCH cur INTO int_var, str_var;  -- double->int cast, int->string cast
  CLOSE cur;

  VALUES (int_var, str_var);  -- Should be (100, '42') with ANSI rounding
END
-- !query schema
struct<col1:int,col2:string>
-- !query output
100	42


-- !query
BEGIN
  DECLARE x INT;
  DECLARE cur CURSOR FOR SELECT 1, 2, 3;
  OPEN cur;
  FETCH cur INTO x;  -- Should fail - 1 target but 3 columns
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ASSIGNMENT_ARITY_MISMATCH",
  "sqlState" : "42802",
  "messageParameters" : {
    "numExpr" : "3",
    "numTarget" : "1"
  }
}


-- !query
BEGIN
  DECLARE x, y, z, w INT;
  DECLARE cur CURSOR FOR SELECT 1, 2;
  OPEN cur;
  FETCH cur INTO x, y, z, w;  -- Should fail - 4 targets but 2 columns
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ASSIGNMENT_ARITY_MISMATCH",
  "sqlState" : "42802",
  "messageParameters" : {
    "numExpr" : "2",
    "numTarget" : "4"
  }
}


-- !query
BEGIN
  DECLARE x INT;
  DECLARE cur INSENSITIVE CURSOR FOR SELECT 42 AS val;
  OPEN cur;
  FETCH cur INTO x;
  CLOSE cur;
  VALUES (x); -- Should return 42
END
-- !query schema
struct<col1:int>
-- !query output
42


-- !query
BEGIN
  DECLARE y INT;
  DECLARE cur ASENSITIVE CURSOR FOR SELECT 99 AS val;
  OPEN cur;
  FETCH cur INTO y;
  CLOSE cur;
  VALUES (y); -- Should return 99
END
-- !query schema
struct<col1:int>
-- !query output
99


-- !query
BEGIN
  DECLARE z INT;
  DECLARE cur CURSOR FOR SELECT 77 AS val FOR READ ONLY;
  OPEN cur;
  FETCH cur INTO z;
  CLOSE cur;
  VALUES (z); -- Should return 77
END
-- !query schema
struct<col1:int>
-- !query output
77


-- !query
BEGIN
  DECLARE w INT;
  DECLARE cur INSENSITIVE CURSOR FOR SELECT 123 AS val FOR READ ONLY;
  OPEN cur;
  FETCH cur INTO w;
  CLOSE cur;
  VALUES (w); -- Should return 123
END
-- !query schema
struct<col1:int>
-- !query output
123


-- !query
BEGIN
  DECLARE a INT;
  DECLARE cur CURSOR FOR SELECT 55 AS val;
  OPEN cur;
  FETCH NEXT cur INTO a;
  CLOSE cur;
  VALUES (a); -- Should return 55
END
-- !query schema
struct<col1:int>
-- !query output
55


-- !query
BEGIN
  DECLARE b INT;
  DECLARE cur CURSOR FOR SELECT 66 AS val;
  OPEN cur;
  FETCH FROM cur INTO b;
  CLOSE cur;
  VALUES (b); -- Should return 66
END
-- !query schema
struct<col1:int>
-- !query output
66


-- !query
BEGIN
  DECLARE c INT;
  DECLARE cur CURSOR FOR SELECT 88 AS val;
  OPEN cur;
  FETCH NEXT FROM cur INTO c;
  CLOSE cur;
  VALUES (c); -- Should return 88
END
-- !query schema
struct<col1:int>
-- !query output
88


-- !query
BEGIN
  DECLARE person_record STRUCT<name STRING, age INT>;
  DECLARE cur CURSOR FOR SELECT 'Alice' AS name, 30 AS age;
  OPEN cur;
  FETCH cur INTO person_record;
  CLOSE cur;
  VALUES (person_record.name, person_record.age); -- Should return 'Alice', 30
END
-- !query schema
struct<col1:string,col2:int>
-- !query output
Alice	30


-- !query
BEGIN
  DECLARE record_var STRUCT<id INT, value STRING>;
  DECLARE cur CURSOR FOR SELECT 42.7 AS id, 100 AS value;
  OPEN cur;
  FETCH cur INTO record_var;
  CLOSE cur;
  VALUES (record_var.id, record_var.value); -- Should return 42, '100' (with casting)
END
-- !query schema
struct<col1:int,col2:string>
-- !query output
42	100


-- !query
BEGIN
  DECLARE record_var STRUCT<a INT, b INT>;
  DECLARE cur CURSOR FOR SELECT 1, 2, 3;
  OPEN cur;
  FETCH cur INTO record_var;  -- Should fail - 2 struct fields but 3 cursor columns
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ASSIGNMENT_ARITY_MISMATCH",
  "sqlState" : "42802",
  "messageParameters" : {
    "numExpr" : "3",
    "numTarget" : "2"
  }
}


-- !query
BEGIN
  DECLARE x INT;
  DECLARE cur CURSOR FOR SELECT 1, 2;
  OPEN cur;
  FETCH cur INTO x;  -- Should fail - single non-struct variable but 2 columns
END
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "ASSIGNMENT_ARITY_MISMATCH",
  "sqlState" : "42802",
  "messageParameters" : {
    "numExpr" : "2",
    "numTarget" : "1"
  }
}


-- !query
BEGIN
  DECLARE complex_record STRUCT<id BIGINT, name STRING, value DOUBLE>;
  DECLARE cur CURSOR FOR SELECT 100 AS id, 'test' AS name, 99.5 AS value;
  OPEN cur;
  FETCH cur INTO complex_record;
  CLOSE cur;
  VALUES (complex_record); -- Should return struct(100, 'test', 99.5)
END
-- !query schema
struct<col1:struct<id:bigint,name:string,value:double>>
-- !query output
{"id":100,"name":"test","value":99.5}
