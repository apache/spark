-- Automatically generated by SQLQueryTestSuite
-- !query
select from_csv('1, 3.14', 'a INT, f FLOAT')
-- !query schema
struct<from_csv(1, 3.14):struct<a:int,f:float>>
-- !query output
{"a":1,"f":3.14}


-- !query
select from_csv('26/08/2015', 'time Timestamp', map('timestampFormat', 'dd/MM/yyyy'))
-- !query schema
struct<from_csv(26/08/2015):struct<time:timestamp>>
-- !query output
{"time":2015-08-26 00:00:00}


-- !query
select from_csv('1', 1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_SCHEMA.NON_STRING_LITERAL",
  "messageParameters" : {
    "inputSchema" : "\"1\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 23,
    "fragment" : "from_csv('1', 1)"
  } ]
}


-- !query
select from_csv('1', 'a InvalidType')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42000",
  "messageParameters" : {
    "error" : "'InvalidType'",
    "hint" : ": extra input 'InvalidType'"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 37,
    "fragment" : "from_csv('1', 'a InvalidType')"
  } ]
}


-- !query
select from_csv('1', 'Array<int>')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_SCHEMA.NON_STRUCT_TYPE",
  "messageParameters" : {
    "dataType" : "\"ARRAY<INT>\"",
    "inputSchema" : "\"Array<int>\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 34,
    "fragment" : "from_csv('1', 'Array<int>')"
  } ]
}


-- !query
select from_csv('1', 'a INT', named_struct('mode', 'PERMISSIVE'))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_OPTIONS.NON_MAP_FUNCTION",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 65,
    "fragment" : "from_csv('1', 'a INT', named_struct('mode', 'PERMISSIVE'))"
  } ]
}


-- !query
select from_csv('1', 'a INT', map('mode', 1))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_OPTIONS.NON_STRING_TYPE",
  "messageParameters" : {
    "mapType" : "\"MAP<STRING, INT>\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 45,
    "fragment" : "from_csv('1', 'a INT', map('mode', 1))"
  } ]
}


-- !query
select from_csv()
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "WRONG_NUM_ARGS",
  "messageParameters" : {
    "actualNum" : "0",
    "expectedNum" : "[2, 3]",
    "functionName" : "`from_csv`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 17,
    "fragment" : "from_csv()"
  } ]
}


-- !query
select from_csv('1,abc', schema_of_csv('1,abc'))
-- !query schema
struct<from_csv(1,abc):struct<_c0:int,_c1:string>>
-- !query output
{"_c0":1,"_c1":"abc"}


-- !query
select schema_of_csv('1|abc', map('delimiter', '|'))
-- !query schema
struct<schema_of_csv(1|abc):string>
-- !query output
STRUCT<_c0: INT, _c1: STRING>


-- !query
select schema_of_csv(null)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_NULL",
  "messageParameters" : {
    "exprName" : "csv",
    "sqlExpr" : "\"schema_of_csv(NULL)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 26,
    "fragment" : "schema_of_csv(null)"
  } ]
}


-- !query
CREATE TEMPORARY VIEW csvTable(csvField, a) AS SELECT * FROM VALUES ('1,abc', 'a')
-- !query schema
struct<>
-- !query output



-- !query
SELECT schema_of_csv(csvField) FROM csvTable
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.NON_FOLDABLE_INPUT",
  "messageParameters" : {
    "inputExpr" : "\"csvField\"",
    "inputName" : "csv",
    "inputType" : "\"STRING\"",
    "sqlExpr" : "\"schema_of_csv(csvField)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "schema_of_csv(csvField)"
  } ]
}


-- !query
DROP VIEW IF EXISTS csvTable
-- !query schema
struct<>
-- !query output



-- !query
select to_csv(named_struct('a', 1, 'b', 2))
-- !query schema
struct<to_csv(named_struct(a, 1, b, 2)):string>
-- !query output
1,2


-- !query
select to_csv(named_struct('time', to_timestamp('2015-08-26', 'yyyy-MM-dd')), map('timestampFormat', 'dd/MM/yyyy'))
-- !query schema
struct<to_csv(named_struct(time, to_timestamp(2015-08-26, yyyy-MM-dd))):string>
-- !query output
26/08/2015


-- !query
select to_csv(named_struct('a', 1, 'b', 2), named_struct('mode', 'PERMISSIVE'))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_OPTIONS.NON_MAP_FUNCTION",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 79,
    "fragment" : "to_csv(named_struct('a', 1, 'b', 2), named_struct('mode', 'PERMISSIVE'))"
  } ]
}


-- !query
select to_csv(named_struct('a', 1, 'b', 2), map('mode', 1))
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_OPTIONS.NON_STRING_TYPE",
  "messageParameters" : {
    "mapType" : "\"MAP<STRING, INT>\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 59,
    "fragment" : "to_csv(named_struct('a', 1, 'b', 2), map('mode', 1))"
  } ]
}
