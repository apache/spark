-- Automatically generated by SQLQueryTestSuite
-- Number of queries: 13


-- !query
select element_at(map(1, 'a', 2, 'b'), 5)
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNoSuchElementException
Key 5 does not exist. To return NULL instead, use 'try_element_at'. If necessary set spark.sql.ansi.enabled to false to bypass this error.
== SQL(line 1, position 7) ==
select element_at(map(1, 'a', 2, 'b'), 5)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


-- !query
select map(1, 'a', 2, 'b')[5]
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNoSuchElementException
Key 5 does not exist. If necessary set spark.sql.ansi.strictIndexOperator to false to bypass this error.
== SQL(line 1, position 7) ==
select map(1, 'a', 2, 'b')[5]
       ^^^^^^^^^^^^^^^^^^^^^^


-- !query
select map_contains_key(map(1, 'a', 2, 'b'), 5)
-- !query schema
struct<map_contains_key(map(1, a, 2, b), 5):boolean>
-- !query output
false


-- !query
select map_contains_key(map(1, 'a', 2, 'b'), 1)
-- !query schema
struct<map_contains_key(map(1, a, 2, b), 1):boolean>
-- !query output
true


-- !query
select map_contains_key(map(1, 'a', 2, 'b'), 5.0)
-- !query schema
struct<map_contains_key(map(1, a, 2, b), 5.0):boolean>
-- !query output
false


-- !query
select map_contains_key(map(1, 'a', 2, 'b'), 1.0)
-- !query schema
struct<map_contains_key(map(1, a, 2, b), 1.0):boolean>
-- !query output
true


-- !query
select map_contains_key(map(1.0, 'a', 2, 'b'), 5)
-- !query schema
struct<map_contains_key(map(1.0, a, 2, b), 5):boolean>
-- !query output
false


-- !query
select map_contains_key(map(1.0, 'a', 2, 'b'), 1)
-- !query schema
struct<map_contains_key(map(1.0, a, 2, b), 1):boolean>
-- !query output
true


-- !query
select map_contains_key(map('1', 'a', '2', 'b'), 1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
cannot resolve 'map_contains_key(map('1', 'a', '2', 'b'), 1)' due to data type mismatch: Input to function map_contains_key should have been map followed by a value with same key type, but it's [map<string,string>, int].; line 1 pos 7


-- !query
select map_contains_key(map(1, 'a', 2, 'b'), '1')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
cannot resolve 'map_contains_key(map(1, 'a', 2, 'b'), '1')' due to data type mismatch: Input to function map_contains_key should have been map followed by a value with same key type, but it's [map<int,string>, string].; line 1 pos 7


-- !query
set spark.sql.ansi.strictIndexOperator=false
-- !query schema
struct<key:string,value:string>
-- !query output
spark.sql.ansi.strictIndexOperator	false


-- !query
select map(1, 'a', 2, 'b')[5]
-- !query schema
struct<map(1, a, 2, b)[5]:string>
-- !query output
NULL


-- !query
select element_at(map(1, 'a', 2, 'b'), 5)
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNoSuchElementException
Key 5 does not exist. To return NULL instead, use 'try_element_at'. If necessary set spark.sql.ansi.enabled to false to bypass this error.
== SQL(line 1, position 7) ==
select element_at(map(1, 'a', 2, 'b'), 5)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
