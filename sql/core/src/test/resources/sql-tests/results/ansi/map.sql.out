-- Automatically generated by SQLQueryTestSuite
-- Number of queries: 10


-- !query
select element_at(map(1, 'a', 2, 'b'), 5)
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNoSuchElementException
Key 5 does not exist. To return NULL instead, use 'try_element_at'. If necessary set spark.sql.ansi.enabled to false to bypass this error.


-- !query
select map(1, 'a', 2, 'b')[5]
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNoSuchElementException
Key 5 does not exist. To return NULL instead, use 'try_element_at'. If necessary set spark.sql.ansi.enabled to false to bypass this error.


-- !query
select map_contains_key(map(1, 'a', 2, 'b'), 5)
-- !query schema
struct<map_contains_key(map(1, a, 2, b), 5):boolean>
-- !query output
false


-- !query
select map_contains_key(map(1, 'a', 2, 'b'), 1)
-- !query schema
struct<map_contains_key(map(1, a, 2, b), 1):boolean>
-- !query output
true


-- !query
select map_contains_key(map(1, 'a', 2, 'b'), 5.0)
-- !query schema
struct<map_contains_key(map(1, a, 2, b), 5.0):boolean>
-- !query output
false


-- !query
select map_contains_key(map(1, 'a', 2, 'b'), 1.0)
-- !query schema
struct<map_contains_key(map(1, a, 2, b), 1.0):boolean>
-- !query output
true


-- !query
select map_contains_key(map(1.0, 'a', 2, 'b'), 5)
-- !query schema
struct<map_contains_key(map(1.0, a, 2, b), 5):boolean>
-- !query output
false


-- !query
select map_contains_key(map(1.0, 'a', 2, 'b'), 1)
-- !query schema
struct<map_contains_key(map(1.0, a, 2, b), 1):boolean>
-- !query output
true


-- !query
select map_contains_key(map('1', 'a', '2', 'b'), 1)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
cannot resolve 'array_contains(map_keys(map('1', 'a', '2', 'b')), 1)' due to data type mismatch: Input to function array_contains should have been array followed by a value with same element type, but it's [array<string>, int].; line 1 pos 7


-- !query
select map_contains_key(map(1, 'a', 2, 'b'), '1')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
cannot resolve 'array_contains(map_keys(map(1, 'a', 2, 'b')), '1')' due to data type mismatch: Input to function array_contains should have been array followed by a value with same element type, but it's [array<int>, string].; line 1 pos 7
