-- Automatically generated by SQLQueryTestSuite
-- !query
select 3 * (timestamp'2019-10-15 10:11:12.001002' - date'2019-10-15')
-- !query schema
struct<((TIMESTAMP '2019-10-15 10:11:12.001002' - DATE '2019-10-15') * 3):interval day to second>
-- !query output
1 06:33:36.003006000


-- !query
select interval 4 month 2 weeks 3 microseconds * 1.5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot mix year-month and day-time fields: interval 4 month 2 weeks 3 microseconds(line 1, pos 7)

== SQL ==
select interval 4 month 2 weeks 3 microseconds * 1.5
-------^^^


-- !query
select interval 2 years 4 months
-- !query schema
struct<INTERVAL '2-4' YEAR TO MONTH:interval year to month>
-- !query output
2-4


-- !query
select interval 2 weeks 3 microseconds * 1.5
-- !query schema
struct<(INTERVAL '14 00:00:00.000003' DAY TO SECOND * 1.5):interval day to second>
-- !query output
21 00:00:00.000005000


-- !query
select (timestamp'2019-10-15' - timestamp'2019-10-14') / 1.5
-- !query schema
struct<((TIMESTAMP '2019-10-15 00:00:00' - TIMESTAMP '2019-10-14 00:00:00') / 1.5):interval day to second>
-- !query output
0 16:00:00.000000000


-- !query
select interval 2147483647 month * 2
-- !query schema
struct<>
-- !query output
java.lang.ArithmeticException
integer overflow


-- !query
select interval 2147483647 month / 0.5
-- !query schema
struct<>
-- !query output
java.lang.ArithmeticException
Overflow


-- !query
select interval 2147483647 day * 2
-- !query schema
struct<>
-- !query output
java.lang.ArithmeticException
long overflow


-- !query
select interval 2147483647 day / 0.5
-- !query schema
struct<>
-- !query output
java.lang.ArithmeticException
long overflow


-- !query
select interval 2 second * '2'
-- !query schema
struct<(INTERVAL '02' SECOND * 2):interval day to second>
-- !query output
0 00:00:04.000000000


-- !query
select interval 2 second / '2'
-- !query schema
struct<(INTERVAL '02' SECOND / 2):interval day to second>
-- !query output
0 00:00:01.000000000


-- !query
select interval 2 year * '2'
-- !query schema
struct<(INTERVAL '2' YEAR * 2):interval year to month>
-- !query output
4-0


-- !query
select interval 2 year / '2'
-- !query schema
struct<(INTERVAL '2' YEAR / 2):interval year to month>
-- !query output
1-0


-- !query
select interval 2 second * 'a'
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "42000",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "expression" : "'a'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "interval 2 second * 'a'"
  } ]
}


-- !query
select interval 2 second / 'a'
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "42000",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "expression" : "'a'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "interval 2 second / 'a'"
  } ]
}


-- !query
select interval 2 year * 'a'
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "42000",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "expression" : "'a'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 28,
    "fragment" : "interval 2 year * 'a'"
  } ]
}


-- !query
select interval 2 year / 'a'
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "42000",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "expression" : "'a'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 28,
    "fragment" : "interval 2 year / 'a'"
  } ]
}


-- !query
select '2' * interval 2 second
-- !query schema
struct<(INTERVAL '02' SECOND * 2):interval day to second>
-- !query output
0 00:00:04.000000000


-- !query
select '2' * interval 2 year
-- !query schema
struct<(INTERVAL '2' YEAR * 2):interval year to month>
-- !query output
4-0


-- !query
select 'a' * interval 2 second
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "42000",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "expression" : "'a'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "'a' * interval 2 second"
  } ]
}


-- !query
select 'a' * interval 2 year
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkNumberFormatException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "42000",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "expression" : "'a'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"DOUBLE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 28,
    "fragment" : "'a' * interval 2 year"
  } ]
}


-- !query
select '2' / interval 2 second
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL SECOND\"",
    "sqlExpr" : "\"(2 / INTERVAL '02' SECOND)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "'2' / interval 2 second"
  } ]
}


-- !query
select '2' / interval 2 year
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL YEAR\"",
    "sqlExpr" : "\"(2 / INTERVAL '2' YEAR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 28,
    "fragment" : "'2' / interval 2 year"
  } ]
}


-- !query
select interval '2 seconds' / 0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "INTERVAL_DIVIDED_BY_ZERO",
  "sqlState" : "22012",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "interval '2 seconds' / 0"
  } ]
}


-- !query
select interval '2 seconds' / null
-- !query schema
struct<(INTERVAL '02' SECOND / NULL):interval day to second>
-- !query output
NULL


-- !query
select interval '2 seconds' * null
-- !query schema
struct<(INTERVAL '02' SECOND * NULL):interval day to second>
-- !query output
NULL


-- !query
select null * interval '2 seconds'
-- !query schema
struct<(INTERVAL '02' SECOND * NULL):interval day to second>
-- !query output
NULL


-- !query
select interval '2' year / 0
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "INTERVAL_DIVIDED_BY_ZERO",
  "sqlState" : "22012",
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 28,
    "fragment" : "interval '2' year / 0"
  } ]
}


-- !query
select interval '2' year / null
-- !query schema
struct<(INTERVAL '2' YEAR / NULL):interval year to month>
-- !query output
NULL


-- !query
select interval '2' year * null
-- !query schema
struct<(INTERVAL '2' YEAR * NULL):interval year to month>
-- !query output
NULL


-- !query
select null * interval '2' year
-- !query schema
struct<(INTERVAL '2' YEAR * NULL):interval year to month>
-- !query output
NULL


-- !query
select 2 / interval '2' year
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INT\"",
    "right" : "\"INTERVAL YEAR\"",
    "sqlExpr" : "\"(2 / INTERVAL '2' YEAR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 28,
    "fragment" : "2 / interval '2' year"
  } ]
}


-- !query
select 2 / interval '2' hour
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INT\"",
    "right" : "\"INTERVAL HOUR\"",
    "sqlExpr" : "\"(2 / INTERVAL '02' HOUR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 28,
    "fragment" : "2 / interval '2' hour"
  } ]
}


-- !query
select null / interval '2' year
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"VOID\"",
    "right" : "\"INTERVAL YEAR\"",
    "sqlExpr" : "\"(NULL / INTERVAL '2' YEAR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "null / interval '2' year"
  } ]
}


-- !query
select null / interval '2' hour
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"VOID\"",
    "right" : "\"INTERVAL HOUR\"",
    "sqlExpr" : "\"(NULL / INTERVAL '02' HOUR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 31,
    "fragment" : "null / interval '2' hour"
  } ]
}


-- !query
select -interval '-1 month 1 day -1 second'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot mix year-month and day-time fields: interval '-1 month 1 day -1 second'(line 1, pos 8)

== SQL ==
select -interval '-1 month 1 day -1 second'
--------^^^


-- !query
select -interval '-1 year 1 month'
-- !query schema
struct<(- INTERVAL '-0-11' YEAR TO MONTH):interval year to month>
-- !query output
0-11


-- !query
select -interval '-1 day 1 hour -1 minute 1 second'
-- !query schema
struct<(- INTERVAL '-0 23:00:59' DAY TO SECOND):interval day to second>
-- !query output
0 23:00:59.000000000


-- !query
select -interval -1 month 1 day -1 second
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot mix year-month and day-time fields: interval -1 month 1 day -1 second(line 1, pos 8)

== SQL ==
select -interval -1 month 1 day -1 second
--------^^^


-- !query
select -interval -1 year 1 month
-- !query schema
struct<(- INTERVAL '-0-11' YEAR TO MONTH):interval year to month>
-- !query output
0-11


-- !query
select -interval -1 day 1 hour -1 minute 1 second
-- !query schema
struct<(- INTERVAL '-0 23:00:59' DAY TO SECOND):interval day to second>
-- !query output
0 23:00:59.000000000


-- !query
select +interval '-1 month 1 day -1 second'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot mix year-month and day-time fields: interval '-1 month 1 day -1 second'(line 1, pos 8)

== SQL ==
select +interval '-1 month 1 day -1 second'
--------^^^


-- !query
select +interval '-1 year 1 month'
-- !query schema
struct<(+ INTERVAL '-0-11' YEAR TO MONTH):interval year to month>
-- !query output
-0-11


-- !query
select +interval '-1 day 1 hour -1 minute 1 second'
-- !query schema
struct<(+ INTERVAL '-0 23:00:59' DAY TO SECOND):interval day to second>
-- !query output
-0 23:00:59.000000000


-- !query
select +interval -1 month 1 day -1 second
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot mix year-month and day-time fields: interval -1 month 1 day -1 second(line 1, pos 8)

== SQL ==
select +interval -1 month 1 day -1 second
--------^^^


-- !query
select +interval -1 year 1 month
-- !query schema
struct<(+ INTERVAL '-0-11' YEAR TO MONTH):interval year to month>
-- !query output
-0-11


-- !query
select +interval -1 day 1 hour -1 minute 1 second
-- !query schema
struct<(+ INTERVAL '-0 23:00:59' DAY TO SECOND):interval day to second>
-- !query output
-0 23:00:59.000000000


-- !query
select interval -'1-1' year to month
-- !query schema
struct<INTERVAL '-1-1' YEAR TO MONTH:interval year to month>
-- !query output
-1-1


-- !query
select interval -'-1-1' year to month
-- !query schema
struct<INTERVAL '1-1' YEAR TO MONTH:interval year to month>
-- !query output
1-1


-- !query
select interval +'-1-1' year to month
-- !query schema
struct<INTERVAL '-1-1' YEAR TO MONTH:interval year to month>
-- !query output
-1-1


-- !query
select interval - '1 2:3:4.001' day to second
-- !query schema
struct<INTERVAL '-1 02:03:04.001' DAY TO SECOND:interval day to second>
-- !query output
-1 02:03:04.001000000


-- !query
select interval +'1 2:3:4.001' day to second
-- !query schema
struct<INTERVAL '1 02:03:04.001' DAY TO SECOND:interval day to second>
-- !query output
1 02:03:04.001000000


-- !query
select interval -'-1 2:3:4.001' day to second
-- !query schema
struct<INTERVAL '1 02:03:04.001' DAY TO SECOND:interval day to second>
-- !query output
1 02:03:04.001000000


-- !query
select interval -'1' year
-- !query schema
struct<INTERVAL '-1' YEAR:interval year>
-- !query output
-1-0


-- !query
select interval -'-1' year
-- !query schema
struct<INTERVAL '1' YEAR:interval year>
-- !query output
1-0


-- !query
select interval -'11' month
-- !query schema
struct<INTERVAL '-11' MONTH:interval month>
-- !query output
-0-11


-- !query
select interval -'-11' month
-- !query schema
struct<INTERVAL '11' MONTH:interval month>
-- !query output
0-11


-- !query
select interval -'1' day
-- !query schema
struct<INTERVAL '-1' DAY:interval day>
-- !query output
-1 00:00:00.000000000


-- !query
select interval -'-1' day
-- !query schema
struct<INTERVAL '1' DAY:interval day>
-- !query output
1 00:00:00.000000000


-- !query
select interval -'23' hour
-- !query schema
struct<INTERVAL '-23' HOUR:interval hour>
-- !query output
-0 23:00:00.000000000


-- !query
select interval -'-23' hour
-- !query schema
struct<INTERVAL '23' HOUR:interval hour>
-- !query output
0 23:00:00.000000000


-- !query
select interval -'59' minute
-- !query schema
struct<INTERVAL '-59' MINUTE:interval minute>
-- !query output
-0 00:59:00.000000000


-- !query
select interval -'-59' minute
-- !query schema
struct<INTERVAL '59' MINUTE:interval minute>
-- !query output
0 00:59:00.000000000


-- !query
select interval -'59' second
-- !query schema
struct<INTERVAL '-59' SECOND:interval second>
-- !query output
-0 00:00:59.000000000


-- !query
select interval -'-59' second
-- !query schema
struct<INTERVAL '59' SECOND:interval second>
-- !query output
0 00:00:59.000000000


-- !query
select make_interval(1)
-- !query schema
struct<make_interval(1, 0, 0, 0, 0, 0, 0.000000):interval>
-- !query output
1 years


-- !query
select make_interval(1, 2)
-- !query schema
struct<make_interval(1, 2, 0, 0, 0, 0, 0.000000):interval>
-- !query output
1 years 2 months


-- !query
select make_interval(1, 2, 3)
-- !query schema
struct<make_interval(1, 2, 3, 0, 0, 0, 0.000000):interval>
-- !query output
1 years 2 months 21 days


-- !query
select make_interval(1, 2, 3, 4)
-- !query schema
struct<make_interval(1, 2, 3, 4, 0, 0, 0.000000):interval>
-- !query output
1 years 2 months 25 days


-- !query
select make_interval(1, 2, 3, 4, 5)
-- !query schema
struct<make_interval(1, 2, 3, 4, 5, 0, 0.000000):interval>
-- !query output
1 years 2 months 25 days 5 hours


-- !query
select make_interval(1, 2, 3, 4, 5, 6)
-- !query schema
struct<make_interval(1, 2, 3, 4, 5, 6, 0.000000):interval>
-- !query output
1 years 2 months 25 days 5 hours 6 minutes


-- !query
select make_interval(1, 2, 3, 4, 5, 6, 7.008009)
-- !query schema
struct<make_interval(1, 2, 3, 4, 5, 6, 7.008009):interval>
-- !query output
1 years 2 months 25 days 5 hours 6 minutes 7.008009 seconds


-- !query
select make_interval(1, 2, 3, 4, 0, 0, 123456789012.123456)
-- !query schema
struct<make_interval(1, 2, 3, 4, 0, 0, 123456789012.123456):interval>
-- !query output
1 years 2 months 25 days 34293552 hours 30 minutes 12.123456 seconds


-- !query
select make_interval(0, 0, 0, 0, 0, 0, 1234567890123456789)
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "NUMERIC_VALUE_OUT_OF_RANGE",
  "sqlState" : "22005",
  "messageParameters" : {
    "config" : "\"spark.sql.ansi.enabled\"",
    "precision" : "18",
    "scale" : "6",
    "value" : "1234567890123456789"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 59,
    "fragment" : "make_interval(0, 0, 0, 0, 0, 0, 1234567890123456789)"
  } ]
}


-- !query
select make_dt_interval(1)
-- !query schema
struct<make_dt_interval(1, 0, 0, 0.000000):interval day to second>
-- !query output
1 00:00:00.000000000


-- !query
select make_dt_interval(1, 2)
-- !query schema
struct<make_dt_interval(1, 2, 0, 0.000000):interval day to second>
-- !query output
1 02:00:00.000000000


-- !query
select make_dt_interval(1, 2, 3)
-- !query schema
struct<make_dt_interval(1, 2, 3, 0.000000):interval day to second>
-- !query output
1 02:03:00.000000000


-- !query
select make_dt_interval(1, 2, 3, 4.005006)
-- !query schema
struct<make_dt_interval(1, 2, 3, 4.005006):interval day to second>
-- !query output
1 02:03:04.005006000


-- !query
select make_dt_interval(1, 0, 0, 123456789012.123456)
-- !query schema
struct<make_dt_interval(1, 0, 0, 123456789012.123456):interval day to second>
-- !query output
1428899 00:30:12.123456000


-- !query
select make_dt_interval(2147483647)
-- !query schema
struct<>
-- !query output
java.lang.ArithmeticException
long overflow


-- !query
select make_ym_interval(1)
-- !query schema
struct<make_ym_interval(1, 0):interval year to month>
-- !query output
1-0


-- !query
select make_ym_interval(1, 2)
-- !query schema
struct<make_ym_interval(1, 2):interval year to month>
-- !query output
1-2


-- !query
select make_ym_interval(0, 1)
-- !query schema
struct<make_ym_interval(0, 1):interval year to month>
-- !query output
0-1


-- !query
select make_ym_interval(178956970, 7)
-- !query schema
struct<make_ym_interval(178956970, 7):interval year to month>
-- !query output
178956970-7


-- !query
select make_ym_interval(178956970, 8)
-- !query schema
struct<>
-- !query output
java.lang.ArithmeticException
integer overflow


-- !query
select make_ym_interval(-178956970, -8)
-- !query schema
struct<make_ym_interval(-178956970, -8):interval year to month>
-- !query output
-178956970-8


-- !query
select make_ym_interval(-178956970, -9)
-- !query schema
struct<>
-- !query output
java.lang.ArithmeticException
integer overflow


-- !query
select cast('1 second' as interval)
-- !query schema
struct<CAST(1 second AS INTERVAL):interval>
-- !query output
1 seconds


-- !query
select cast('+1 second' as interval)
-- !query schema
struct<CAST(+1 second AS INTERVAL):interval>
-- !query output
1 seconds


-- !query
select cast('-1 second' as interval)
-- !query schema
struct<CAST(-1 second AS INTERVAL):interval>
-- !query output
-1 seconds


-- !query
select cast('+     1 second' as interval)
-- !query schema
struct<CAST(+     1 second AS INTERVAL):interval>
-- !query output
1 seconds


-- !query
select cast('-     1 second' as interval)
-- !query schema
struct<CAST(-     1 second AS INTERVAL):interval>
-- !query output
-1 seconds


-- !query
select cast('- -1 second' as interval)
-- !query schema
struct<CAST(- -1 second AS INTERVAL):interval>
-- !query output
NULL


-- !query
select cast('- +1 second' as interval)
-- !query schema
struct<CAST(- +1 second AS INTERVAL):interval>
-- !query output
NULL


-- !query
select interval 13.123456789 seconds, interval -13.123456789 second
-- !query schema
struct<INTERVAL '13.123456' SECOND:interval second,INTERVAL '-13.123456' SECOND:interval second>
-- !query output
0 00:00:13.123456000	-0 00:00:13.123456000


-- !query
select interval 1 year 2 month 3 week 4 day 5 hour 6 minute 7 seconds 8 millisecond 9 microsecond
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot mix year-month and day-time fields: interval 1 year 2 month 3 week 4 day 5 hour 6 minute 7 seconds 8 millisecond 9 microsecond(line 1, pos 7)

== SQL ==
select interval 1 year 2 month 3 week 4 day 5 hour 6 minute 7 seconds 8 millisecond 9 microsecond
-------^^^


-- !query
select interval 1 year 2 month
-- !query schema
struct<INTERVAL '1-2' YEAR TO MONTH:interval year to month>
-- !query output
1-2


-- !query
select interval 4 day 5 hour 6 minute 7 seconds
-- !query schema
struct<INTERVAL '4 05:06:07' DAY TO SECOND:interval day to second>
-- !query output
4 05:06:07.000000000


-- !query
select interval 3 week 8 millisecond 9 microsecond
-- !query schema
struct<INTERVAL '21 00:00:00.008009' DAY TO SECOND:interval day to second>
-- !query output
21 00:00:00.008009000


-- !query
select interval '30' year '25' month '-100' day '40' hour '80' minute '299.889987299' second
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot mix year-month and day-time fields: interval '30' year '25' month '-100' day '40' hour '80' minute '299.889987299' second(line 1, pos 7)

== SQL ==
select interval '30' year '25' month '-100' day '40' hour '80' minute '299.889987299' second
-------^^^


-- !query
select interval '30' year '25' month
-- !query schema
struct<INTERVAL '32-1' YEAR TO MONTH:interval year to month>
-- !query output
32-1


-- !query
select interval '-100' day '40' hour '80' minute '299.889987299' second
-- !query schema
struct<INTERVAL '-98 06:35:00.110013' DAY TO SECOND:interval day to second>
-- !query output
-98 06:35:00.110013000


-- !query
select interval '0-0' year to month
-- !query schema
struct<INTERVAL '0-0' YEAR TO MONTH:interval year to month>
-- !query output
0-0


-- !query
select interval '0 0:0:0' day to second
-- !query schema
struct<INTERVAL '0 00:00:00' DAY TO SECOND:interval day to second>
-- !query output
0 00:00:00.000000000


-- !query
select interval '0 0:0:0.1' day to second
-- !query schema
struct<INTERVAL '0 00:00:00.1' DAY TO SECOND:interval day to second>
-- !query output
0 00:00:00.100000000


-- !query
select interval '10-9' year to month
-- !query schema
struct<INTERVAL '10-9' YEAR TO MONTH:interval year to month>
-- !query output
10-9


-- !query
select interval '20 15' day to hour
-- !query schema
struct<INTERVAL '20 15' DAY TO HOUR:interval day to hour>
-- !query output
20 15:00:00.000000000


-- !query
select interval '20 15:40' day to minute
-- !query schema
struct<INTERVAL '20 15:40' DAY TO MINUTE:interval day to minute>
-- !query output
20 15:40:00.000000000


-- !query
select interval '20 15:40:32.99899999' day to second
-- !query schema
struct<INTERVAL '20 15:40:32.998999' DAY TO SECOND:interval day to second>
-- !query output
20 15:40:32.998999000


-- !query
select interval '15:40' hour to minute
-- !query schema
struct<INTERVAL '15:40' HOUR TO MINUTE:interval hour to minute>
-- !query output
0 15:40:00.000000000


-- !query
select interval '15:40:32.99899999' hour to second
-- !query schema
struct<INTERVAL '15:40:32.998999' HOUR TO SECOND:interval hour to second>
-- !query output
0 15:40:32.998999000


-- !query
select interval '40:32.99899999' minute to second
-- !query schema
struct<INTERVAL '40:32.998999' MINUTE TO SECOND:interval minute to second>
-- !query output
0 00:40:32.998999000


-- !query
select interval '40:32' minute to second
-- !query schema
struct<INTERVAL '40:32' MINUTE TO SECOND:interval minute to second>
-- !query output
0 00:40:32.000000000


-- !query
select interval 30 day day
-- !query schema
struct<day:interval day>
-- !query output
30 00:00:00.000000000


-- !query
select interval 30 days days
-- !query schema
struct<days:interval day>
-- !query output
30 00:00:00.000000000


-- !query
select interval '20 15:40:32.99899999' day to hour
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Interval string does not match day-time format of `[+|-]d h`, `INTERVAL [+|-]'[+|-]d h' DAY TO HOUR` when cast to interval day to hour: 20 15:40:32.99899999, set spark.sql.legacy.fromDayTimeString.enabled to true to restore the behavior before Spark 3.0.(line 1, pos 16)

== SQL ==
select interval '20 15:40:32.99899999' day to hour
----------------^^^


-- !query
select interval '20 15:40:32.99899999' day to minute
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Interval string does not match day-time format of `[+|-]d h:m`, `INTERVAL [+|-]'[+|-]d h:m' DAY TO MINUTE` when cast to interval day to minute: 20 15:40:32.99899999, set spark.sql.legacy.fromDayTimeString.enabled to true to restore the behavior before Spark 3.0.(line 1, pos 16)

== SQL ==
select interval '20 15:40:32.99899999' day to minute
----------------^^^


-- !query
select interval '15:40:32.99899999' hour to minute
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Interval string does not match day-time format of `[+|-]h:m`, `INTERVAL [+|-]'[+|-]h:m' HOUR TO MINUTE` when cast to interval hour to minute: 15:40:32.99899999, set spark.sql.legacy.fromDayTimeString.enabled to true to restore the behavior before Spark 3.0.(line 1, pos 16)

== SQL ==
select interval '15:40:32.99899999' hour to minute
----------------^^^


-- !query
select interval '15:40.99899999' hour to second
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Interval string does not match day-time format of `[+|-]h:m:s.n`, `INTERVAL [+|-]'[+|-]h:m:s.n' HOUR TO SECOND` when cast to interval hour to second: 15:40.99899999, set spark.sql.legacy.fromDayTimeString.enabled to true to restore the behavior before Spark 3.0.(line 1, pos 16)

== SQL ==
select interval '15:40.99899999' hour to second
----------------^^^


-- !query
select interval '15:40' hour to second
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Interval string does not match day-time format of `[+|-]h:m:s.n`, `INTERVAL [+|-]'[+|-]h:m:s.n' HOUR TO SECOND` when cast to interval hour to second: 15:40, set spark.sql.legacy.fromDayTimeString.enabled to true to restore the behavior before Spark 3.0.(line 1, pos 16)

== SQL ==
select interval '15:40' hour to second
----------------^^^


-- !query
select interval '20 40:32.99899999' minute to second
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Interval string does not match day-time format of `[+|-]m:s.n`, `INTERVAL [+|-]'[+|-]m:s.n' MINUTE TO SECOND` when cast to interval minute to second: 20 40:32.99899999, set spark.sql.legacy.fromDayTimeString.enabled to true to restore the behavior before Spark 3.0.(line 1, pos 16)

== SQL ==
select interval '20 40:32.99899999' minute to second
----------------^^^


-- !query
select interval 10 nanoseconds
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Error parsing ' 10 nanoseconds' to interval, invalid unit 'nanoseconds'(line 1, pos 16)

== SQL ==
select interval 10 nanoseconds
----------------^^^


-- !query
select map(1, interval 1 day, 2, interval 3 week)
-- !query schema
struct<map(1, INTERVAL '1' DAY, 2, INTERVAL '21' DAY):map<int,interval day>>
-- !query output
{1:1 00:00:00.000000000,2:21 00:00:00.000000000}


-- !query
select map(1, interval 1 day, 2, interval 2 day)
-- !query schema
struct<map(1, INTERVAL '1' DAY, 2, INTERVAL '2' DAY):map<int,interval day>>
-- !query output
{1:1 00:00:00.000000000,2:2 00:00:00.000000000}


-- !query
select map(1, interval 1 year, 2, interval 2 month)
-- !query schema
struct<map(1, INTERVAL '1' YEAR, 2, INTERVAL '2' MONTH):map<int,interval year to month>>
-- !query output
{1:1-0,2:0-2}


-- !query
select map(1, interval 1 month, 2, interval 2 month)
-- !query schema
struct<map(1, INTERVAL '1' MONTH, 2, INTERVAL '2' MONTH):map<int,interval month>>
-- !query output
{1:0-1,2:0-2}


-- !query
select map(1, interval 1 week, 2, interval 2 day)
-- !query schema
struct<map(1, INTERVAL '7' DAY, 2, INTERVAL '2' DAY):map<int,interval day>>
-- !query output
{1:7 00:00:00.000000000,2:2 00:00:00.000000000}


-- !query
select map(1, interval 2 millisecond, 3, interval 3 microsecond)
-- !query schema
struct<map(1, INTERVAL '00.002' SECOND, 3, INTERVAL '00.000003' SECOND):map<int,interval second>>
-- !query output
{1:0 00:00:00.002000000,3:0 00:00:00.000003000}


-- !query
select interval 'interval 3 year 1 month'
-- !query schema
struct<INTERVAL '3-1' YEAR TO MONTH:interval year to month>
-- !query output
3-1


-- !query
select interval '3 year 1 month'
-- !query schema
struct<INTERVAL '3-1' YEAR TO MONTH:interval year to month>
-- !query output
3-1


-- !query
SELECT interval 'interval 2 weeks 2 days 1 hour 3 minutes 2 seconds 100 millisecond 200 microseconds'
-- !query schema
struct<INTERVAL '16 01:03:02.1002' DAY TO SECOND:interval day to second>
-- !query output
16 01:03:02.100200000


-- !query
SELECT interval '2 weeks 2 days 1 hour 3 minutes 2 seconds 100 millisecond 200 microseconds'
-- !query schema
struct<INTERVAL '16 01:03:02.1002' DAY TO SECOND:interval day to second>
-- !query output
16 01:03:02.100200000


-- !query
select interval
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

at least one time unit should be given for interval literal(line 1, pos 7)

== SQL ==
select interval
-------^^^


-- !query
select interval 1 fake_unit
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Error parsing ' 1 fake_unit' to interval, invalid unit 'fake_unit'(line 1, pos 16)

== SQL ==
select interval 1 fake_unit
----------------^^^


-- !query
select interval 1 year to month
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

The value of from-to unit must be a string(line 1, pos 16)

== SQL ==
select interval 1 year to month
----------------^^^


-- !query
select interval '1' year to second
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Intervals FROM year TO second are not supported.(line 1, pos 16)

== SQL ==
select interval '1' year to second
----------------^^^


-- !query
select interval '10-9' year to month '2-1' year to month
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Can only have a single from-to unit in the interval literal syntax(line 1, pos 37)

== SQL ==
select interval '10-9' year to month '2-1' year to month
-------------------------------------^^^


-- !query
select interval '10-9' year to month '12:11:10' hour to second
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Can only have a single from-to unit in the interval literal syntax(line 1, pos 37)

== SQL ==
select interval '10-9' year to month '12:11:10' hour to second
-------------------------------------^^^


-- !query
select interval '1 15:11' day to minute '12:11:10' hour to second
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Can only have a single from-to unit in the interval literal syntax(line 1, pos 40)

== SQL ==
select interval '1 15:11' day to minute '12:11:10' hour to second
----------------------------------------^^^


-- !query
select interval 1 year '2-1' year to month
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Can only have a single from-to unit in the interval literal syntax(line 1, pos 23)

== SQL ==
select interval 1 year '2-1' year to month
-----------------------^^^


-- !query
select interval 1 year '12:11:10' hour to second
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Can only have a single from-to unit in the interval literal syntax(line 1, pos 23)

== SQL ==
select interval 1 year '12:11:10' hour to second
-----------------------^^^


-- !query
select interval '10-9' year to month '1' year
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Can only have a single from-to unit in the interval literal syntax(line 1, pos 37)

== SQL ==
select interval '10-9' year to month '1' year
-------------------------------------^^^


-- !query
select interval '12:11:10' hour to second '1' year
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Can only have a single from-to unit in the interval literal syntax(line 1, pos 42)

== SQL ==
select interval '12:11:10' hour to second '1' year
------------------------------------------^^^


-- !query
select interval (-30) day
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Undefined function: interval. This function is neither a built-in/temporary function, nor a persistent function that is qualified as spark_catalog.default.interval.; line 1 pos 7


-- !query
select interval (a + 1) day
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Undefined function: interval. This function is neither a built-in/temporary function, nor a persistent function that is qualified as spark_catalog.default.interval.; line 1 pos 7


-- !query
select interval 30 day day day
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42000",
  "messageParameters" : {
    "error" : "'day'",
    "hint" : ": extra input 'day'"
  }
}


-- !query
select interval (-30) days
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Undefined function: interval. This function is neither a built-in/temporary function, nor a persistent function that is qualified as spark_catalog.default.interval.; line 1 pos 7


-- !query
select interval (a + 1) days
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Undefined function: interval. This function is neither a built-in/temporary function, nor a persistent function that is qualified as spark_catalog.default.interval.; line 1 pos 7


-- !query
select interval 30 days days days
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42000",
  "messageParameters" : {
    "error" : "'days'",
    "hint" : ": extra input 'days'"
  }
}


-- !query
SELECT INTERVAL '178956970-7' YEAR TO MONTH
-- !query schema
struct<INTERVAL '178956970-7' YEAR TO MONTH:interval year to month>
-- !query output
178956970-7


-- !query
SELECT INTERVAL '178956970-8' YEAR TO MONTH
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Error parsing interval year-month string: integer overflow(line 1, pos 16)

== SQL ==
SELECT INTERVAL '178956970-8' YEAR TO MONTH
----------------^^^


-- !query
SELECT INTERVAL '-178956970-8' YEAR TO MONTH
-- !query schema
struct<INTERVAL '-178956970-8' YEAR TO MONTH:interval year to month>
-- !query output
-178956970-8


-- !query
SELECT INTERVAL -'178956970-8' YEAR TO MONTH
-- !query schema
struct<INTERVAL '-178956970-8' YEAR TO MONTH:interval year to month>
-- !query output
-178956970-8


-- !query
select
  interval '2-2' year to month + interval '3' month,
  interval '2' year - interval '3-3' year to month,
  interval '99 11:22:33.123456789' day to second + interval '10 9:8' day to minute,
  interval '22:33.123456789' minute to second - interval '10' day
-- !query schema
struct<(INTERVAL '2-2' YEAR TO MONTH + INTERVAL '3' MONTH):interval year to month,(INTERVAL '2' YEAR - INTERVAL '3-3' YEAR TO MONTH):interval year to month,(INTERVAL '99 11:22:33.123456' DAY TO SECOND + INTERVAL '10 09:08' DAY TO MINUTE):interval day to second,(INTERVAL '22:33.123456' MINUTE TO SECOND - INTERVAL '10' DAY):interval day to second>
-- !query output
2-5	-1-3	109 20:30:33.123456000	-9 23:37:26.876544000


-- !query
select
  interval '2' year + '3-3 year to month',
  interval '2' year - '3 month',
  '3-2 year to month' + interval '2-2' year to month,
  '3 year' - interval '2-2' year to month,
  interval '99 11:22:33.123456789' day to second + '12:12 hour to second',
  interval '99 11:22:33.123456789' day to second - '12 hour',
  '4 day' + interval '10' day,
  '4 22 day to hour' - interval '10' day
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '2' YEAR + 3-3 year to month)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 10,
    "stopIndex" : 48,
    "fragment" : "interval '2' year + '3-3 year to month'"
  } ]
}


-- !query
select
  interval '2' year + null,
  interval '2' year - null,
  interval '2' hour + null,
  interval '2' hour - null,
  null + interval '2' year,
  null - interval '2' year,
  null + interval '2' hour,
  null - interval '2' hour
-- !query schema
struct<(INTERVAL '2' YEAR + NULL):interval year,(INTERVAL '2' YEAR - NULL):interval year,(INTERVAL '02' HOUR + NULL):interval hour,(INTERVAL '02' HOUR - NULL):interval hour,(NULL + INTERVAL '2' YEAR):interval year,(NULL - INTERVAL '2' YEAR):interval year,(NULL + INTERVAL '02' HOUR):interval hour,(NULL - INTERVAL '02' HOUR):interval hour>
-- !query output
NULL	NULL	NULL	NULL	NULL	NULL	NULL	NULL


-- !query
select interval '2' year + '3-3'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '2' YEAR + 3-3)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 32,
    "fragment" : "interval '2' year + '3-3'"
  } ]
}


-- !query
select interval '2' year - '4'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '2' YEAR - 4)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "interval '2' year - '4'"
  } ]
}


-- !query
select '4 11:11' - interval '4 22:12' day to minute
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "42000",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "expression" : "'4 11:11'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 51,
    "fragment" : "'4 11:11' - interval '4 22:12' day to minute"
  } ]
}


-- !query
select '4 12:12:12' + interval '4 22:12' day to minute
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "42000",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "expression" : "'4 12:12:12'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 54,
    "fragment" : "'4 12:12:12' + interval '4 22:12' day to minute"
  } ]
}


-- !query
create temporary view interval_view as select '1' str
-- !query schema
struct<>
-- !query output



-- !query
select interval '2' year + str from interval_view
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '2' YEAR + str)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "interval '2' year + str"
  } ]
}


-- !query
select interval '2' year - str from interval_view
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '2' YEAR - str)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "interval '2' year - str"
  } ]
}


-- !query
select str - interval '4 22:12' day to minute from interval_view
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "42000",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 45,
    "fragment" : "str - interval '4 22:12' day to minute"
  } ]
}


-- !query
select str + interval '4 22:12' day to minute from interval_view
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkDateTimeException
{
  "errorClass" : "CAST_INVALID_INPUT",
  "sqlState" : "42000",
  "messageParameters" : {
    "ansiConfig" : "\"spark.sql.ansi.enabled\"",
    "expression" : "'1'",
    "sourceType" : "\"STRING\"",
    "targetType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 45,
    "fragment" : "str + interval '4 22:12' day to minute"
  } ]
}


-- !query
select interval '2-2' year to month + interval '3' day
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "UNEXPECTED_INPUT_TYPE",
  "messageParameters" : {
    "inputSql" : "\"INTERVAL '2-2' YEAR TO MONTH\"",
    "inputType" : "\"INTERVAL YEAR TO MONTH\"",
    "paramIndex" : "1",
    "requiredType" : "\"(TIMESTAMP OR TIMESTAMP WITHOUT TIME ZONE)\"",
    "sqlExpr" : "\"INTERVAL '2-2' YEAR TO MONTH + INTERVAL '3' DAY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 54,
    "fragment" : "interval '2-2' year to month + interval '3' day"
  } ]
}


-- !query
select interval '3' day + interval '2-2' year to month
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "UNEXPECTED_INPUT_TYPE",
  "messageParameters" : {
    "inputSql" : "\"INTERVAL '2-2' YEAR TO MONTH\"",
    "inputType" : "\"INTERVAL YEAR TO MONTH\"",
    "paramIndex" : "1",
    "requiredType" : "\"(TIMESTAMP OR TIMESTAMP WITHOUT TIME ZONE)\"",
    "sqlExpr" : "\"INTERVAL '2-2' YEAR TO MONTH + INTERVAL '3' DAY\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 54,
    "fragment" : "interval '3' day + interval '2-2' year to month"
  } ]
}


-- !query
select interval '2-2' year to month - interval '3' day
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "UNEXPECTED_INPUT_TYPE",
  "messageParameters" : {
    "inputSql" : "\"INTERVAL '2-2' YEAR TO MONTH\"",
    "inputType" : "\"INTERVAL YEAR TO MONTH\"",
    "paramIndex" : "1",
    "requiredType" : "\"(TIMESTAMP OR TIMESTAMP WITHOUT TIME ZONE)\"",
    "sqlExpr" : "\"INTERVAL '2-2' YEAR TO MONTH + (- INTERVAL '3' DAY)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 54,
    "fragment" : "interval '2-2' year to month - interval '3' day"
  } ]
}


-- !query
select interval '3' day - interval '2-2' year to month
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL DAY\"",
    "right" : "\"INTERVAL YEAR TO MONTH\"",
    "sqlExpr" : "\"(INTERVAL '3' DAY - INTERVAL '2-2' YEAR TO MONTH)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 54,
    "fragment" : "interval '3' day - interval '2-2' year to month"
  } ]
}


-- !query
select 1 - interval '2' second
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "UNEXPECTED_INPUT_TYPE",
  "messageParameters" : {
    "inputSql" : "\"1\"",
    "inputType" : "\"INT\"",
    "paramIndex" : "1",
    "requiredType" : "\"(TIMESTAMP OR TIMESTAMP WITHOUT TIME ZONE)\"",
    "sqlExpr" : "\"1 + (- INTERVAL '02' SECOND)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "1 - interval '2' second"
  } ]
}


-- !query
select 1 + interval '2' month
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INT\"",
    "right" : "\"INTERVAL MONTH\"",
    "sqlExpr" : "\"(1 + INTERVAL '2' MONTH)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "1 + interval '2' month"
  } ]
}


-- !query
select interval '2' second + 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "UNEXPECTED_INPUT_TYPE",
  "messageParameters" : {
    "inputSql" : "\"1\"",
    "inputType" : "\"INT\"",
    "paramIndex" : "1",
    "requiredType" : "\"(TIMESTAMP OR TIMESTAMP WITHOUT TIME ZONE)\"",
    "sqlExpr" : "\"1 + INTERVAL '02' SECOND\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "interval '2' second + 1"
  } ]
}


-- !query
select interval '2' month - 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL MONTH\"",
    "right" : "\"INT\"",
    "sqlExpr" : "\"(INTERVAL '2' MONTH - 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "interval '2' month - 1"
  } ]
}


-- !query
select interval '\t interval 1 day'
-- !query schema
struct<INTERVAL '1' DAY:interval day>
-- !query output
1 00:00:00.000000000


-- !query
select interval 'interval \t 1\tday'
-- !query schema
struct<INTERVAL '1' DAY:interval day>
-- !query output
1 00:00:00.000000000


-- !query
select interval 'interval\t1\tday'
-- !query schema
struct<INTERVAL '1' DAY:interval day>
-- !query output
1 00:00:00.000000000


-- !query
select interval '1\t' day
-- !query schema
struct<INTERVAL '1' DAY:interval day>
-- !query output
1 00:00:00.000000000


-- !query
select interval '1 ' day
-- !query schema
struct<INTERVAL '1' DAY:interval day>
-- !query output
1 00:00:00.000000000


-- !query
select interval '2-2\t' year to month
-- !query schema
struct<INTERVAL '2-2' YEAR TO MONTH:interval year to month>
-- !query output
2-2


-- !query
select interval '-\t2-2\t' year to month
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Interval string does not match year-month format of `[+|-]d h`, `INTERVAL [+|-]'[+|-]d h' DAY TO HOUR` when cast to interval year to month: -	2-2	(line 1, pos 16)

== SQL ==
select interval '-\t2-2\t' year to month
----------------^^^


-- !query
select interval '\n0 12:34:46.789\t' day to second
-- !query schema
struct<INTERVAL '0 12:34:46.789' DAY TO SECOND:interval day to second>
-- !query output
0 12:34:46.789000000


-- !query
select interval '\n-\t10\t 12:34:46.789\t' day to second
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Interval string does not match day-time format of `[+|-]d h:m:s.n`, `INTERVAL [+|-]'[+|-]d h:m:s.n' DAY TO SECOND` when cast to interval day to second: 
-	10	 12:34:46.789	, set spark.sql.legacy.fromDayTimeString.enabled to true to restore the behavior before Spark 3.0.(line 1, pos 16)

== SQL ==
select interval '\n-\t10\t 12:34:46.789\t' day to second
----------------^^^


-- !query
select interval ' interval 1 day'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot parse the INTERVAL value:  interval 1 day(line 1, pos 7)

== SQL ==
select interval ' interval 1 day'
-------^^^


-- !query
select interval 'interval 1 day'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot parse the INTERVAL value: interval 1 day(line 1, pos 7)

== SQL ==
select interval 'interval 1 day'
-------^^^


-- !query
select interval 'interval 1day'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot parse the INTERVAL value: interval 1day(line 1, pos 7)

== SQL ==
select interval 'interval 1day'
-------^^^


-- !query
select -(a) from values (interval '-2147483648 months', interval '2147483647 months') t(a, b)
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "INTERVAL_ARITHMETIC_OVERFLOW",
  "sqlState" : "22003",
  "messageParameters" : {
    "alternative" : "",
    "message" : "integer overflow"
  }
}


-- !query
select a - b from values (interval '-2147483648 months', interval '2147483647 months') t(a, b)
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "INTERVAL_ARITHMETIC_OVERFLOW",
  "sqlState" : "22003",
  "messageParameters" : {
    "alternative" : " Use 'try_subtract' to tolerate overflow and return NULL instead.",
    "message" : "integer overflow"
  }
}


-- !query
select b + interval '1 month' from values (interval '-2147483648 months', interval '2147483647 months') t(a, b)
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "INTERVAL_ARITHMETIC_OVERFLOW",
  "sqlState" : "22003",
  "messageParameters" : {
    "alternative" : " Use 'try_add' to tolerate overflow and return NULL instead.",
    "message" : "integer overflow"
  }
}


-- !query
select a * 1.1 from values (interval '-2147483648 months', interval '2147483647 months') t(a, b)
-- !query schema
struct<>
-- !query output
java.lang.ArithmeticException
Overflow


-- !query
select a / 0.5 from values (interval '-2147483648 months', interval '2147483647 months') t(a, b)
-- !query schema
struct<>
-- !query output
java.lang.ArithmeticException
Overflow


-- !query
SELECT
  from_csv('1, 1 day', 'a INT, b interval'),
  from_csv('1, 1', 'a INT, b interval day'),
  to_csv(from_csv('1, 1 day', 'a INT, b interval')),
  to_csv(from_csv('1, 1', 'a INT, b interval day')),
  to_csv(named_struct('a', interval 32 hour, 'b', interval 70 minute)),
  from_csv(to_csv(named_struct('a', interval 32 hour, 'b', interval 70 minute)), 'a interval hour, b interval minute')
-- !query schema
struct<from_csv(1, 1 day):struct<a:int,b:interval>,from_csv(1, 1):struct<a:int,b:interval day>,to_csv(from_csv(1, 1 day)):string,to_csv(from_csv(1, 1)):string,to_csv(named_struct(a, INTERVAL '32' HOUR, b, INTERVAL '70' MINUTE)):string,from_csv(to_csv(named_struct(a, INTERVAL '32' HOUR, b, INTERVAL '70' MINUTE))):struct<a:interval hour,b:interval minute>>
-- !query output
{"a":1,"b":1 days}	{"a":1,"b":1 00:00:00.000000000}	1,1 days	1,INTERVAL '1' DAY	INTERVAL '32' HOUR,INTERVAL '70' MINUTE	{"a":1 08:00:00.000000000,"b":0 01:10:00.000000000}


-- !query
SELECT
  from_json('{"a":"1 days"}', 'a interval'),
  from_csv('1, 1', 'a INT, b interval year'),
  to_json(from_json('{"a":"1 days"}', 'a interval')),
  to_csv(from_csv('1, 1', 'a INT, b interval year')),
  to_csv(named_struct('a', interval 32 year, 'b', interval 10 month)),
  from_csv(to_csv(named_struct('a', interval 32 year, 'b', interval 10 month)), 'a interval year, b interval month')
-- !query schema
struct<from_json({"a":"1 days"}):struct<a:interval>,from_csv(1, 1):struct<a:int,b:interval year>,to_json(from_json({"a":"1 days"})):string,to_csv(from_csv(1, 1)):string,to_csv(named_struct(a, INTERVAL '32' YEAR, b, INTERVAL '10' MONTH)):string,from_csv(to_csv(named_struct(a, INTERVAL '32' YEAR, b, INTERVAL '10' MONTH))):struct<a:interval year,b:interval month>>
-- !query output
{"a":1 days}	{"a":1,"b":1-0}	{"a":"1 days"}	1,INTERVAL '1' YEAR	INTERVAL '32' YEAR,INTERVAL '10' MONTH	{"a":32-0,"b":0-10}


-- !query
SELECT
  from_json('{"a":"1"}', 'a interval day'),
  to_json(from_json('{"a":"1"}', 'a interval day')),
  to_json(map('a', interval 100 day 130 minute)),
  from_json(to_json(map('a', interval 100 day 130 minute)), 'a interval day to minute')
-- !query schema
struct<from_json({"a":"1"}):struct<a:interval day>,to_json(from_json({"a":"1"})):string,to_json(map(a, INTERVAL '100 02:10' DAY TO MINUTE)):string,from_json(to_json(map(a, INTERVAL '100 02:10' DAY TO MINUTE))):struct<a:interval day to minute>>
-- !query output
{"a":1 00:00:00.000000000}	{"a":"INTERVAL '1' DAY"}	{"a":"INTERVAL '100 02:10' DAY TO MINUTE"}	{"a":100 02:10:00.000000000}


-- !query
SELECT
  from_json('{"a":"1"}', 'a interval year'),
  to_json(from_json('{"a":"1"}', 'a interval year')),
  to_json(map('a', interval 32 year 10 month)),
  from_json(to_json(map('a', interval 32 year 10 month)), 'a interval year to month')
-- !query schema
struct<from_json({"a":"1"}):struct<a:interval year>,to_json(from_json({"a":"1"})):string,to_json(map(a, INTERVAL '32-10' YEAR TO MONTH)):string,from_json(to_json(map(a, INTERVAL '32-10' YEAR TO MONTH))):struct<a:interval year to month>>
-- !query output
{"a":1-0}	{"a":"INTERVAL '1' YEAR"}	{"a":"INTERVAL '32-10' YEAR TO MONTH"}	{"a":32-10}


-- !query
select interval '+'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot parse the INTERVAL value: +(line 1, pos 7)

== SQL ==
select interval '+'
-------^^^


-- !query
select interval '+.'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot parse the INTERVAL value: +.(line 1, pos 7)

== SQL ==
select interval '+.'
-------^^^


-- !query
select interval '1'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot parse the INTERVAL value: 1(line 1, pos 7)

== SQL ==
select interval '1'
-------^^^


-- !query
select interval '1.2'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot parse the INTERVAL value: 1.2(line 1, pos 7)

== SQL ==
select interval '1.2'
-------^^^


-- !query
select interval '- 2'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot parse the INTERVAL value: - 2(line 1, pos 7)

== SQL ==
select interval '- 2'
-------^^^


-- !query
select interval '1 day -'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot parse the INTERVAL value: 1 day -(line 1, pos 7)

== SQL ==
select interval '1 day -'
-------^^^


-- !query
select interval '1 day 1'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Cannot parse the INTERVAL value: 1 day 1(line 1, pos 7)

== SQL ==
select interval '1 day 1'
-------^^^


-- !query
select interval '1 day 2' day
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Can only use numbers in the interval value part for multiple unit value pairs interval form, but got invalid value: 1 day 2(line 1, pos 16)

== SQL ==
select interval '1 day 2' day
----------------^^^


-- !query
select interval 'interval 1' day
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

Can only use numbers in the interval value part for multiple unit value pairs interval form, but got invalid value: interval 1(line 1, pos 16)

== SQL ==
select interval 'interval 1' day
----------------^^^


-- !query
select interval '-\t 1' day
-- !query schema
struct<INTERVAL '-1' DAY:interval day>
-- !query output
-1 00:00:00.000000000


-- !query
SELECT (INTERVAL '-178956970-8' YEAR TO MONTH) / 2
-- !query schema
struct<(INTERVAL '-178956970-8' YEAR TO MONTH / 2):interval year to month>
-- !query output
-89478485-4


-- !query
SELECT (INTERVAL '-178956970-8' YEAR TO MONTH) / 5
-- !query schema
struct<(INTERVAL '-178956970-8' YEAR TO MONTH / 5):interval year to month>
-- !query output
-35791394-2


-- !query
SELECT (INTERVAL '-178956970-8' YEAR TO MONTH) / -1
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "INTERVAL_ARITHMETIC_OVERFLOW",
  "sqlState" : "22003",
  "messageParameters" : {
    "alternative" : " Use 'try_divide' to tolerate overflow and return NULL instead.",
    "message" : "Interval value overflows after being divided by -1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 51,
    "fragment" : "(INTERVAL '-178956970-8' YEAR TO MONTH) / -1"
  } ]
}


-- !query
SELECT (INTERVAL '-178956970-8' YEAR TO MONTH) / -1L
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "INTERVAL_ARITHMETIC_OVERFLOW",
  "sqlState" : "22003",
  "messageParameters" : {
    "alternative" : " Use 'try_divide' to tolerate overflow and return NULL instead.",
    "message" : "Interval value overflows after being divided by -1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 52,
    "fragment" : "(INTERVAL '-178956970-8' YEAR TO MONTH) / -1L"
  } ]
}


-- !query
SELECT (INTERVAL '-178956970-8' YEAR TO MONTH) / -1.0
-- !query schema
struct<>
-- !query output
java.lang.ArithmeticException
Overflow


-- !query
SELECT (INTERVAL '-178956970-8' YEAR TO MONTH) / -1.0D
-- !query schema
struct<>
-- !query output
java.lang.ArithmeticException
not in range


-- !query
SELECT (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND) / 2
-- !query schema
struct<(INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND / 2):interval day to second>
-- !query output
-53375995 14:00:27.387904000


-- !query
SELECT (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND) / 5
-- !query schema
struct<(INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND / 5):interval day to second>
-- !query output
-21350398 05:36:10.955162000


-- !query
SELECT (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND) / -1
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "INTERVAL_ARITHMETIC_OVERFLOW",
  "sqlState" : "22003",
  "messageParameters" : {
    "alternative" : " Use 'try_divide' to tolerate overflow and return NULL instead.",
    "message" : "Interval value overflows after being divided by -1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 65,
    "fragment" : "(INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND) / -1"
  } ]
}


-- !query
SELECT (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND) / -1L
-- !query schema
struct<>
-- !query output
org.apache.spark.SparkArithmeticException
{
  "errorClass" : "INTERVAL_ARITHMETIC_OVERFLOW",
  "sqlState" : "22003",
  "messageParameters" : {
    "alternative" : " Use 'try_divide' to tolerate overflow and return NULL instead.",
    "message" : "Interval value overflows after being divided by -1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 66,
    "fragment" : "(INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND) / -1L"
  } ]
}


-- !query
SELECT (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND) / -1.0
-- !query schema
struct<>
-- !query output
java.lang.ArithmeticException
Overflow


-- !query
SELECT (INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND) / -1.0D
-- !query schema
struct<>
-- !query output
java.lang.ArithmeticException
not in range


-- !query
SELECT INTERVAL '106751991 04' DAY TO HOUR
-- !query schema
struct<INTERVAL '106751991 04' DAY TO HOUR:interval day to hour>
-- !query output
106751991 04:00:00.000000000


-- !query
SELECT INTERVAL '106751991 04:00' DAY TO MINUTE
-- !query schema
struct<INTERVAL '106751991 04:00' DAY TO MINUTE:interval day to minute>
-- !query output
106751991 04:00:00.000000000


-- !query
SELECT INTERVAL '106751991 04:00:54.775807' DAY TO SECOND
-- !query schema
struct<INTERVAL '106751991 04:00:54.775807' DAY TO SECOND:interval day to second>
-- !query output
106751991 04:00:54.775807000


-- !query
SELECT INTERVAL '2562047788:00' HOUR TO MINUTE
-- !query schema
struct<INTERVAL '2562047788:00' HOUR TO MINUTE:interval hour to minute>
-- !query output
106751991 04:00:00.000000000


-- !query
SELECT INTERVAL '2562047788:00:54.775807' HOUR TO SECOND
-- !query schema
struct<INTERVAL '2562047788:00:54.775807' HOUR TO SECOND:interval hour to second>
-- !query output
106751991 04:00:54.775807000


-- !query
SELECT INTERVAL '153722867280:54.775807' MINUTE TO SECOND
-- !query schema
struct<INTERVAL '153722867280:54.775807' MINUTE TO SECOND:interval minute to second>
-- !query output
106751991 04:00:54.775807000


-- !query
SELECT INTERVAL '-106751991 04' DAY TO HOUR
-- !query schema
struct<INTERVAL '-106751991 04' DAY TO HOUR:interval day to hour>
-- !query output
-106751991 04:00:00.000000000


-- !query
SELECT INTERVAL '-106751991 04:00' DAY TO MINUTE
-- !query schema
struct<INTERVAL '-106751991 04:00' DAY TO MINUTE:interval day to minute>
-- !query output
-106751991 04:00:00.000000000


-- !query
SELECT INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND
-- !query schema
struct<INTERVAL '-106751991 04:00:54.775808' DAY TO SECOND:interval day to second>
-- !query output
-106751991 04:00:54.775808000


-- !query
SELECT INTERVAL '-2562047788:00' HOUR TO MINUTE
-- !query schema
struct<INTERVAL '-2562047788:00' HOUR TO MINUTE:interval hour to minute>
-- !query output
-106751991 04:00:00.000000000


-- !query
SELECT INTERVAL '-2562047788:00:54.775808' HOUR TO SECOND
-- !query schema
struct<INTERVAL '-2562047788:00:54.775808' HOUR TO SECOND:interval hour to second>
-- !query output
-106751991 04:00:54.775808000


-- !query
SELECT INTERVAL '-153722867280:54.775808' MINUTE TO SECOND
-- !query schema
struct<INTERVAL '-153722867280:54.775808' MINUTE TO SECOND:interval minute to second>
-- !query output
-106751991 04:00:54.775808000


-- !query
SELECT INTERVAL '106751992 04' DAY TO HOUR
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

requirement failed: day 106751992 outside range [0, 106751991](line 1, pos 16)

== SQL ==
SELECT INTERVAL '106751992 04' DAY TO HOUR
----------------^^^


-- !query
SELECT INTERVAL '-106751992 04' DAY TO HOUR
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

requirement failed: day 106751992 outside range [0, 106751991](line 1, pos 16)

== SQL ==
SELECT INTERVAL '-106751992 04' DAY TO HOUR
----------------^^^


-- !query
SELECT INTERVAL '2562047789:00' HOUR TO MINUTE
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

requirement failed: hour 2562047789 outside range [0, 2562047788](line 1, pos 16)

== SQL ==
SELECT INTERVAL '2562047789:00' HOUR TO MINUTE
----------------^^^


-- !query
SELECT INTERVAL '-2562047789:00' HOUR TO MINUTE
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

requirement failed: hour 2562047789 outside range [0, 2562047788](line 1, pos 16)

== SQL ==
SELECT INTERVAL '-2562047789:00' HOUR TO MINUTE
----------------^^^


-- !query
SELECT INTERVAL '153722867281:54.775808' MINUTE TO SECOND
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

requirement failed: minute 153722867281 outside range [0, 153722867280](line 1, pos 16)

== SQL ==
SELECT INTERVAL '153722867281:54.775808' MINUTE TO SECOND
----------------^^^


-- !query
SELECT INTERVAL '-153722867281:54.775808' MINUTE TO SECOND
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException

requirement failed: minute 153722867281 outside range [0, 153722867280](line 1, pos 16)

== SQL ==
SELECT INTERVAL '-153722867281:54.775808' MINUTE TO SECOND
----------------^^^


-- !query
SELECT INTERVAL '178956970' YEAR
-- !query schema
struct<INTERVAL '178956970' YEAR:interval year>
-- !query output
178956970-0


-- !query
SELECT INTERVAL '-178956970' YEAR
-- !query schema
struct<INTERVAL '-178956970' YEAR:interval year>
-- !query output
-178956970-0


-- !query
SELECT INTERVAL '2147483647' MONTH
-- !query schema
struct<INTERVAL '2147483647' MONTH:interval month>
-- !query output
178956970-7


-- !query
SELECT INTERVAL '-2147483647' MONTH
-- !query schema
struct<INTERVAL '-2147483647' MONTH:interval month>
-- !query output
-178956970-7


-- !query
SELECT INTERVAL '106751991' DAY
-- !query schema
struct<INTERVAL '106751991' DAY:interval day>
-- !query output
106751991 00:00:00.000000000


-- !query
SELECT INTERVAL '-106751991' DAY
-- !query schema
struct<INTERVAL '-106751991' DAY:interval day>
-- !query output
-106751991 00:00:00.000000000


-- !query
SELECT INTERVAL '2562047788' HOUR
-- !query schema
struct<INTERVAL '2562047788' HOUR:interval hour>
-- !query output
106751991 04:00:00.000000000


-- !query
SELECT INTERVAL '-2562047788' HOUR
-- !query schema
struct<INTERVAL '-2562047788' HOUR:interval hour>
-- !query output
-106751991 04:00:00.000000000


-- !query
SELECT INTERVAL '153722867280' MINUTE
-- !query schema
struct<INTERVAL '153722867280' MINUTE:interval minute>
-- !query output
106751991 04:00:00.000000000


-- !query
SELECT INTERVAL '-153722867280' MINUTE
-- !query schema
struct<INTERVAL '-153722867280' MINUTE:interval minute>
-- !query output
-106751991 04:00:00.000000000


-- !query
SELECT INTERVAL '54.775807' SECOND
-- !query schema
struct<INTERVAL '54.775807' SECOND:interval second>
-- !query output
0 00:00:54.775807000


-- !query
SELECT INTERVAL '-54.775807' SECOND
-- !query schema
struct<INTERVAL '-54.775807' SECOND:interval second>
-- !query output
-0 00:00:54.775807000


-- !query
SELECT INTERVAL '1' DAY > INTERVAL '1' HOUR
-- !query schema
struct<(INTERVAL '1' DAY > INTERVAL '01' HOUR):boolean>
-- !query output
true


-- !query
SELECT INTERVAL '1 02' DAY TO HOUR = INTERVAL '02:10:55' HOUR TO SECOND
-- !query schema
struct<(INTERVAL '1 02' DAY TO HOUR = INTERVAL '02:10:55' HOUR TO SECOND):boolean>
-- !query output
false


-- !query
SELECT INTERVAL '1' YEAR < INTERVAL '1' MONTH
-- !query schema
struct<(INTERVAL '1' YEAR < INTERVAL '1' MONTH):boolean>
-- !query output
false


-- !query
SELECT INTERVAL '-1-1' YEAR TO MONTH = INTERVAL '-13' MONTH
-- !query schema
struct<(INTERVAL '-1-1' YEAR TO MONTH = INTERVAL '-13' MONTH):boolean>
-- !query output
true


-- !query
SELECT INTERVAL 1 MONTH > INTERVAL 20 DAYS
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL MONTH\"",
    "right" : "\"INTERVAL DAY\"",
    "sqlExpr" : "\"(INTERVAL '1' MONTH > INTERVAL '20' DAY)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 42,
    "fragment" : "INTERVAL 1 MONTH > INTERVAL 20 DAYS"
  } ]
}


-- !query
SELECT INTERVAL '1' DAY < '1'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL DAY\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '1' DAY < 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "INTERVAL '1' DAY < '1'"
  } ]
}


-- !query
SELECT INTERVAL '1' DAY = '1'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL DAY\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '1' DAY = 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "INTERVAL '1' DAY = '1'"
  } ]
}


-- !query
SELECT INTERVAL '1' DAY > '1'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL DAY\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '1' DAY > 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "INTERVAL '1' DAY > '1'"
  } ]
}


-- !query
SELECT '1' < INTERVAL '1' DAY
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL DAY\"",
    "sqlExpr" : "\"(1 < INTERVAL '1' DAY)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "'1' < INTERVAL '1' DAY"
  } ]
}


-- !query
SELECT '1' = INTERVAL '1' DAY
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL DAY\"",
    "sqlExpr" : "\"(1 = INTERVAL '1' DAY)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "'1' = INTERVAL '1' DAY"
  } ]
}


-- !query
SELECT '1' > INTERVAL '1' DAY
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL DAY\"",
    "sqlExpr" : "\"(1 > INTERVAL '1' DAY)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 29,
    "fragment" : "'1' > INTERVAL '1' DAY"
  } ]
}


-- !query
SELECT INTERVAL '1' YEAR < '1'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '1' YEAR < 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "INTERVAL '1' YEAR < '1'"
  } ]
}


-- !query
SELECT INTERVAL '1' YEAR = '1'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '1' YEAR = 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "INTERVAL '1' YEAR = '1'"
  } ]
}


-- !query
SELECT INTERVAL '1' YEAR > '1'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL YEAR\"",
    "right" : "\"STRING\"",
    "sqlExpr" : "\"(INTERVAL '1' YEAR > 1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "INTERVAL '1' YEAR > '1'"
  } ]
}


-- !query
SELECT '1' < INTERVAL '1' YEAR
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL YEAR\"",
    "sqlExpr" : "\"(1 < INTERVAL '1' YEAR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "'1' < INTERVAL '1' YEAR"
  } ]
}


-- !query
SELECT '1' = INTERVAL '1' YEAR
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL YEAR\"",
    "sqlExpr" : "\"(1 = INTERVAL '1' YEAR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "'1' = INTERVAL '1' YEAR"
  } ]
}


-- !query
SELECT '1' > INTERVAL '1' YEAR
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"STRING\"",
    "right" : "\"INTERVAL YEAR\"",
    "sqlExpr" : "\"(1 > INTERVAL '1' YEAR)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "'1' > INTERVAL '1' YEAR"
  } ]
}


-- !query
SELECT array(INTERVAL '1' YEAR, INTERVAL '1' MONTH)
-- !query schema
struct<array(INTERVAL '1' YEAR, INTERVAL '1' MONTH):array<interval year to month>>
-- !query output
[1-0,0-1]


-- !query
SELECT array(INTERVAL '1' DAY, INTERVAL '01:01' HOUR TO MINUTE)
-- !query schema
struct<array(INTERVAL '1' DAY, INTERVAL '01:01' HOUR TO MINUTE):array<interval day to minute>>
-- !query output
[1 00:00:00.000000000,0 01:01:00.000000000]


-- !query
SELECT array(INTERVAL 1 MONTH, INTERVAL 20 DAYS)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
cannot resolve 'array(INTERVAL '1' MONTH, INTERVAL '20' DAY)' due to data type mismatch: input to function array should all be the same type, but it's [interval month, interval day]; line 1 pos 7


-- !query
SELECT coalesce(INTERVAL '1' YEAR, INTERVAL '1' MONTH)
-- !query schema
struct<coalesce(INTERVAL '1' YEAR, INTERVAL '1' MONTH):interval year to month>
-- !query output
1-0


-- !query
SELECT coalesce(INTERVAL '1' DAY, INTERVAL '01:01' HOUR TO MINUTE)
-- !query schema
struct<coalesce(INTERVAL '1' DAY, INTERVAL '01:01' HOUR TO MINUTE):interval day to minute>
-- !query output
1 00:00:00.000000000


-- !query
SELECT coalesce(INTERVAL 1 MONTH, INTERVAL 20 DAYS)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
cannot resolve 'coalesce(INTERVAL '1' MONTH, INTERVAL '20' DAY)' due to data type mismatch: input to function coalesce should all be the same type, but it's [interval month, interval day]; line 1 pos 7


-- !query
SELECT abs(INTERVAL '-10' YEAR)
-- !query schema
struct<abs(INTERVAL '-10' YEAR):interval year>
-- !query output
10-0


-- !query
SELECT abs(INTERVAL -'1 02:03:04.123' DAY TO SECOND)
-- !query schema
struct<abs(INTERVAL '-1 02:03:04.123' DAY TO SECOND):interval day to second>
-- !query output
1 02:03:04.123000000


-- !query
SELECT div(INTERVAL '1-1' YEAR TO MONTH, INTERVAL '1' YEAR)
-- !query schema
struct<(INTERVAL '1-1' YEAR TO MONTH div INTERVAL '1' YEAR):bigint>
-- !query output
1


-- !query
SELECT div(INTERVAL '1-1' YEAR TO MONTH, INTERVAL '-1' MONTH)
-- !query schema
struct<(INTERVAL '1-1' YEAR TO MONTH div INTERVAL '-1' MONTH):bigint>
-- !query output
-13


-- !query
SELECT div(INTERVAL '1 06' DAY TO HOUR, INTERVAL '1' DAY)
-- !query schema
struct<(INTERVAL '1 06' DAY TO HOUR div INTERVAL '1' DAY):bigint>
-- !query output
1


-- !query
SELECT div(INTERVAL '1 06' DAY TO HOUR, INTERVAL '-1' HOUR)
-- !query schema
struct<(INTERVAL '1 06' DAY TO HOUR div INTERVAL '-01' HOUR):bigint>
-- !query output
-30


-- !query
SELECT div(INTERVAL '1' MONTH, INTERVAL '-1' DAY)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH",
  "errorSubClass" : "BINARY_OP_DIFF_TYPES",
  "messageParameters" : {
    "left" : "\"INTERVAL MONTH\"",
    "right" : "\"INTERVAL DAY\"",
    "sqlExpr" : "\"(INTERVAL '1' MONTH div INTERVAL '-1' DAY)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 49,
    "fragment" : "div(INTERVAL '1' MONTH, INTERVAL '-1' DAY)"
  } ]
}


-- !query
SELECT signum(INTERVAL '-10' YEAR)
-- !query schema
struct<SIGNUM(INTERVAL '-10' YEAR):double>
-- !query output
-1.0


-- !query
SELECT signum(INTERVAL '10' MONTH)
-- !query schema
struct<SIGNUM(INTERVAL '10' MONTH):double>
-- !query output
1.0


-- !query
SELECT signum(INTERVAL '0-0' YEAR TO MONTH)
-- !query schema
struct<SIGNUM(INTERVAL '0-0' YEAR TO MONTH):double>
-- !query output
0.0


-- !query
SELECT signum(INTERVAL '-10' DAY)
-- !query schema
struct<SIGNUM(INTERVAL '-10' DAY):double>
-- !query output
-1.0


-- !query
SELECT signum(INTERVAL '10' HOUR)
-- !query schema
struct<SIGNUM(INTERVAL '10' HOUR):double>
-- !query output
1.0


-- !query
SELECT signum(INTERVAL '0 0:0:0' DAY TO SECOND)
-- !query schema
struct<SIGNUM(INTERVAL '0 00:00:00' DAY TO SECOND):double>
-- !query output
0.0


-- !query
SELECT width_bucket(INTERVAL '0' YEAR, INTERVAL '0' YEAR, INTERVAL '10' YEAR, 10)
-- !query schema
struct<width_bucket(INTERVAL '0' YEAR, INTERVAL '0' YEAR, INTERVAL '10' YEAR, 10):bigint>
-- !query output
1


-- !query
SELECT width_bucket(INTERVAL '-1' YEAR, INTERVAL -'1-2' YEAR TO MONTH, INTERVAL '1-2' YEAR TO MONTH, 10)
-- !query schema
struct<width_bucket(INTERVAL '-1' YEAR, INTERVAL '-1-2' YEAR TO MONTH, INTERVAL '1-2' YEAR TO MONTH, 10):bigint>
-- !query output
1


-- !query
SELECT width_bucket(INTERVAL '0' DAY, INTERVAL '0' DAY, INTERVAL '10' DAY, 10)
-- !query schema
struct<width_bucket(INTERVAL '0' DAY, INTERVAL '0' DAY, INTERVAL '10' DAY, 10):bigint>
-- !query output
1


-- !query
SELECT width_bucket(INTERVAL '-59' MINUTE, INTERVAL -'1 01' DAY TO HOUR, INTERVAL '1 2:3:4.001' DAY TO SECOND, 10)
-- !query schema
struct<width_bucket(INTERVAL '-59' MINUTE, INTERVAL '-1 01' DAY TO HOUR, INTERVAL '1 02:03:04.001' DAY TO SECOND, 10):bigint>
-- !query output
5
