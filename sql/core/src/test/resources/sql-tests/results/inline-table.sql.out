-- Automatically generated by SQLQueryTestSuite
-- !query
select * from values ("one", 1)
-- !query schema
struct<col1:string,col2:int>
-- !query output
one	1


-- !query
select * from values ("one", 1) as data
-- !query schema
struct<col1:string,col2:int>
-- !query output
one	1


-- !query
select * from values ("one", 1) as data(a, b)
-- !query schema
struct<a:string,b:int>
-- !query output
one	1


-- !query
select * from values 1, 2, 3 as data(a)
-- !query schema
struct<a:int>
-- !query output
1
2
3


-- !query
select * from values ("one", 1), ("two", 2), ("three", null) as data(a, b)
-- !query schema
struct<a:string,b:int>
-- !query output
one	1
three	NULL
two	2


-- !query
select * from values ("one", null), ("two", null) as data(a, b)
-- !query schema
struct<a:string,b:void>
-- !query output
one	NULL
two	NULL


-- !query
select * from values ("one", 1), ("two", 2L) as data(a, b)
-- !query schema
struct<a:string,b:bigint>
-- !query output
one	1
two	2


-- !query
select * from values ("one", 1 + 0), ("two", 1 + 3L) as data(a, b)
-- !query schema
struct<a:string,b:bigint>
-- !query output
one	1
two	4


-- !query
select * from values ("one", 1 as one) as data(a, b)
-- !query schema
struct<a:string,b:int>
-- !query output
one	1


-- !query
select a from values ("one", current_timestamp) as data(a, b)
-- !query schema
struct<a:string>
-- !query output
one


-- !query
select * from values ("one", array(0, 1)), ("two", array(2, 3)) as data(a, b)
-- !query schema
struct<a:string,b:array<int>>
-- !query output
one	[0,1]
two	[2,3]


-- !query
select * from values ("one", 2.0), ("two", 3.0D) as data(a, b)
-- !query schema
struct<a:string,b:double>
-- !query output
one	2.0
two	3.0


-- !query
select * from values ("one", rand(5)), ("two", 3.0D) as data(a, b)
-- !query schema
struct<a:string,b:double>
-- !query output
one	0.02390696427502892
two	3.0


-- !query
select * from values ("one", 2.0), ("two") as data(a, b)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_INLINE_TABLE.NUM_COLUMNS_MISMATCH",
  "sqlState" : "42000",
  "messageParameters" : {
    "actualNumCols" : "1",
    "expectedNumCols" : "2",
    "rowIndex" : "1"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 56,
    "fragment" : "values (\"one\", 2.0), (\"two\") as data(a, b)"
  } ]
}


-- !query
select * from values ("one", array(0, 1)), ("two", struct(1, 2)) as data(a, b)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_INLINE_TABLE.INCOMPATIBLE_TYPES_IN_INLINE_TABLE",
  "sqlState" : "42000",
  "messageParameters" : {
    "colName" : "`b`"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 78,
    "fragment" : "values (\"one\", array(0, 1)), (\"two\", struct(1, 2)) as data(a, b)"
  } ]
}


-- !query
select * from values ("one"), ("two") as data(a, b)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_INLINE_TABLE.NUM_COLUMNS_MISMATCH",
  "sqlState" : "42000",
  "messageParameters" : {
    "actualNumCols" : "1",
    "expectedNumCols" : "2",
    "rowIndex" : "0"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 51,
    "fragment" : "values (\"one\"), (\"two\") as data(a, b)"
  } ]
}


-- !query
select * from values ("one", random_not_exist_func(1)), ("two", 2) as data(a, b)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "UNRESOLVED_ROUTINE",
  "sqlState" : "42883",
  "messageParameters" : {
    "routineName" : "`random_not_exist_func`",
    "searchPath" : "[`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`]"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 30,
    "stopIndex" : 53,
    "fragment" : "random_not_exist_func(1)"
  } ]
}


-- !query
select * from values ("one", count(1)), ("two", 2) as data(a, b)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_EXPR_FOR_OPERATOR",
  "sqlState" : "42K0E",
  "messageParameters" : {
    "invalidExprSqls" : "\"count(1)\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 64,
    "fragment" : "values (\"one\", count(1)), (\"two\", 2) as data(a, b)"
  } ]
}


-- !query
select * from values (timestamp('1991-12-06 00:00:00.0'), array(timestamp('1991-12-06 01:00:00.0'), timestamp('1991-12-06 12:00:00.0'))) as data(a, b)
-- !query schema
struct<a:timestamp,b:array<timestamp>>
-- !query output
1991-12-06 00:00:00	[1991-12-06 01:00:00,1991-12-06 12:00:00]


-- !query
select * from values (try_add(5, 0))
-- !query schema
struct<col1:int>
-- !query output
5


-- !query
select * from values (try_divide(5, 0))
-- !query schema
struct<col1:double>
-- !query output
NULL


-- !query
select * from values (10 + try_divide(5, 0))
-- !query schema
struct<col1:double>
-- !query output
NULL


-- !query
select count(distinct ct) from values now(), now(), now() as data(ct)
-- !query schema
struct<count(DISTINCT ct):bigint>
-- !query output
1


-- !query
select count(distinct ct) from values current_timestamp(), current_timestamp() as data(ct)
-- !query schema
struct<count(DISTINCT ct):bigint>
-- !query output
1


-- !query
select * from values (rand()), (rand()), (rand()) as data(a)
-- !query schema
struct<a:double>
-- !query output
0.31695535108691264
0.4517497534237762
0.9819075640707866


-- !query
select * from values (rand(1)), (rand(2)), (rand(3)) as data(a)
-- !query schema
struct<a:double>
-- !query output
0.25738143505962285
0.5311207224659675
0.6363787615254752


-- !query
select * from values (random()), (random()) as data(a)
-- !query schema
struct<a:double>
-- !query output
0.11735918929648681
0.20319457587269207


-- !query
select length(a) from values (uuid()), (uuid()) as data(a)
-- !query schema
struct<length(a):int>
-- !query output
36
36


-- !query
select * from values (1, rand(5)), (2, rand(5)) as data(a, b)
-- !query schema
struct<a:int,b:double>
-- !query output
1	0.02390696427502892
2	0.02390696427502892


-- !query
select * from values (1 + rand(5)), (2 + rand(5)) as data(a)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "INVALID_INLINE_TABLE.FAILED_SQL_EXPRESSION_EVALUATION",
  "sqlState" : "42000",
  "messageParameters" : {
    "sqlExpr" : "\"(1 + rand(5))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 15,
    "stopIndex" : 60,
    "fragment" : "values (1 + rand(5)), (2 + rand(5)) as data(a)"
  } ]
}


-- !query
select * from values (1) as t(c1), lateral (values (t.c1)) as s(c2)
-- !query schema
struct<c1:int,c2:int>
-- !query output
1	1


-- !query
select * from values (1, 2) as t(c1, c2), lateral (values (t.c1, t.c2)) as s(c3, c4)
-- !query schema
struct<c1:int,c2:int,c3:int,c4:int>
-- !query output
1	2	1	2


-- !query
select * from values (1, 2) as t(c1, c2), lateral (values (t.c1 + t.c2)) as s(c3)
-- !query schema
struct<c1:int,c2:int,c3:int>
-- !query output
1	2	3


-- !query
select * from values (1), (2), (3) as t(c1), lateral (values (t.c1 * 2)) as s(c2) order by c1
-- !query schema
struct<c1:int,c2:int>
-- !query output
1	2
2	4
3	6


-- !query
select * from values (1, 2) as t(c1, c2), lateral (values (t.c1), (t.c2)) as s(c3) order by c3
-- !query schema
struct<c1:int,c2:int,c3:int>
-- !query output
1	2	1
1	2	2


-- !query
select * from values (1), (2) as t(c1), lateral (values (t.c1), (t.c1 + 10)) as s(c2) order by c1, c2
-- !query schema
struct<c1:int,c2:int>
-- !query output
1	1
1	11
2	2
2	12


-- !query
select * from values (1, 2) as t(c1, c2),
  lateral (values (t.c1, t.c2, t.c1 + t.c2)) as s(c3, c4, c5)
-- !query schema
struct<c1:int,c2:int,c3:int,c4:int,c5:int>
-- !query output
1	2	1	2	3


-- !query
select t.c1, s.c2 from values (1) as t(c1),
  lateral (values (t.c1, rand())) as s(c2, c3) order by c1
-- !query schema
struct<c1:int,c2:int>
-- !query output
1	1


-- !query
select t.c1 from values (1), (2) as t(c1),
  lateral (values (t.c1, rand())) as s(c2, c3) order by c1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.ExtendedAnalysisException
{
  "errorClass" : "UNSUPPORTED_SUBQUERY_EXPRESSION_CATEGORY.NON_DETERMINISTIC_LATERAL_SUBQUERIES",
  "sqlState" : "0A000",
  "messageParameters" : {
    "treeNode" : "LateralJoin lateral-subquery#x [c1#x], Inner\n:  +- SubqueryAlias s\n:     +- Project [col1#x AS c2#x, col2#x AS c3#x]\n:        +- ResolvedInlineTable [[outer(c1#x), rand(number)]], [col1#x, col2#x]\n+- SubqueryAlias t\n   +- LocalRelation [c1#x]\n"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 13,
    "stopIndex" : 89,
    "fragment" : "from values (1), (2) as t(c1),\n  lateral (values (t.c1, rand())) as s(c2, c3)"
  } ]
}


-- !query
select t.c1 from values (1) as t(c1),
  lateral (values (t.c1, rand()), (t.c1 + 1, rand())) as s(c2, c3) order by c2
-- !query schema
struct<c1:int>
-- !query output
1
1


-- !query
select * from values (1) as t(c1),
  lateral (values (t.c1, current_date)) as s(c2, c3)
-- !query schema
struct<c1:int,c2:int,c3:date>
-- !query output
1	1	2026-01-02


-- !query
select * from values (1) as t(c1),
  lateral (values (t.c1, 2.0), (t.c1 + 1, 3.0)) as s(c2, c3) order by c2
-- !query schema
struct<c1:int,c2:int,c3:decimal(2,1)>
-- !query output
1	1	2.0
1	2	3.0


-- !query
select * from values (1, null) as t(c1, c2),
  lateral (values (t.c1, t.c2)) as s(c3, c4)
-- !query schema
struct<c1:int,c2:void,c3:int,c4:void>
-- !query output



-- !query
select * from values (1, 2, 3) as t(c1, c2, c3),
  lateral (values (t.c1 * t.c2 + t.c3)) as s(c4)
-- !query schema
struct<c1:int,c2:int,c3:int,c4:int>
-- !query output
1	2	3	5


-- !query
select * from values (1), (2) as t(c1)
  left join lateral (values (t.c1 * 10)) as s(c2) on true order by c1
-- !query schema
struct<c1:int,c2:int>
-- !query output
1	10
2	20
