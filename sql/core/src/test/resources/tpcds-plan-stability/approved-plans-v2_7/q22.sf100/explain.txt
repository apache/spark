== Physical Plan ==
TakeOrderedAndProject (28)
+- * HashAggregate (27)
   +- Exchange (26)
      +- * HashAggregate (25)
         +- * Expand (24)
            +- BroadcastNestedLoopJoin Inner BuildRight (23)
               :- * Project (19)
               :  +- * SortMergeJoin Inner (18)
               :     :- * Sort (12)
               :     :  +- Exchange (11)
               :     :     +- * Project (10)
               :     :        +- * BroadcastHashJoin Inner BuildRight (9)
               :     :           :- * Filter (3)
               :     :           :  +- * ColumnarToRow (2)
               :     :           :     +- Scan parquet default.inventory (1)
               :     :           +- BroadcastExchange (8)
               :     :              +- * Project (7)
               :     :                 +- * Filter (6)
               :     :                    +- * ColumnarToRow (5)
               :     :                       +- Scan parquet default.date_dim (4)
               :     +- * Sort (17)
               :        +- Exchange (16)
               :           +- * Filter (15)
               :              +- * ColumnarToRow (14)
               :                 +- Scan parquet default.item (13)
               +- BroadcastExchange (22)
                  +- * ColumnarToRow (21)
                     +- Scan parquet default.warehouse (20)


(1) Scan parquet default.inventory
Output [3]: [inv_item_sk#1, inv_quantity_on_hand#2, inv_date_sk#3]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(inv_date_sk#3), dynamicpruningexpression(inv_date_sk#3 IN dynamicpruning#4)]
PushedFilters: [IsNotNull(inv_item_sk)]
ReadSchema: struct<inv_item_sk:int,inv_quantity_on_hand:int>

(2) ColumnarToRow [codegen id : 2]
Input [3]: [inv_item_sk#1, inv_quantity_on_hand#2, inv_date_sk#3]

(3) Filter [codegen id : 2]
Input [3]: [inv_item_sk#1, inv_quantity_on_hand#2, inv_date_sk#3]
Condition : isnotnull(inv_item_sk#1)

(4) Scan parquet default.date_dim
Output [2]: [d_date_sk#5, d_month_seq#6]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1200), LessThanOrEqual(d_month_seq,1211), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_month_seq:int>

(5) ColumnarToRow [codegen id : 1]
Input [2]: [d_date_sk#5, d_month_seq#6]

(6) Filter [codegen id : 1]
Input [2]: [d_date_sk#5, d_month_seq#6]
Condition : (((isnotnull(d_month_seq#6) AND (d_month_seq#6 >= 1200)) AND (d_month_seq#6 <= 1211)) AND isnotnull(d_date_sk#5))

(7) Project [codegen id : 1]
Output [1]: [d_date_sk#5]
Input [2]: [d_date_sk#5, d_month_seq#6]

(8) BroadcastExchange
Input [1]: [d_date_sk#5]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [id=#7]

(9) BroadcastHashJoin [codegen id : 2]
Left keys [1]: [inv_date_sk#3]
Right keys [1]: [d_date_sk#5]
Join condition: None

(10) Project [codegen id : 2]
Output [2]: [inv_item_sk#1, inv_quantity_on_hand#2]
Input [4]: [inv_item_sk#1, inv_quantity_on_hand#2, inv_date_sk#3, d_date_sk#5]

(11) Exchange
Input [2]: [inv_item_sk#1, inv_quantity_on_hand#2]
Arguments: hashpartitioning(inv_item_sk#1, 5), ENSURE_REQUIREMENTS, [id=#8]

(12) Sort [codegen id : 3]
Input [2]: [inv_item_sk#1, inv_quantity_on_hand#2]
Arguments: [inv_item_sk#1 ASC NULLS FIRST], false, 0

(13) Scan parquet default.item
Output [5]: [i_item_sk#9, i_brand#10, i_class#11, i_category#12, i_product_name#13]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_brand:string,i_class:string,i_category:string,i_product_name:string>

(14) ColumnarToRow [codegen id : 4]
Input [5]: [i_item_sk#9, i_brand#10, i_class#11, i_category#12, i_product_name#13]

(15) Filter [codegen id : 4]
Input [5]: [i_item_sk#9, i_brand#10, i_class#11, i_category#12, i_product_name#13]
Condition : isnotnull(i_item_sk#9)

(16) Exchange
Input [5]: [i_item_sk#9, i_brand#10, i_class#11, i_category#12, i_product_name#13]
Arguments: hashpartitioning(i_item_sk#9, 5), ENSURE_REQUIREMENTS, [id=#14]

(17) Sort [codegen id : 5]
Input [5]: [i_item_sk#9, i_brand#10, i_class#11, i_category#12, i_product_name#13]
Arguments: [i_item_sk#9 ASC NULLS FIRST], false, 0

(18) SortMergeJoin [codegen id : 6]
Left keys [1]: [inv_item_sk#1]
Right keys [1]: [i_item_sk#9]
Join condition: None

(19) Project [codegen id : 6]
Output [5]: [inv_quantity_on_hand#2, i_brand#10, i_class#11, i_category#12, i_product_name#13]
Input [7]: [inv_item_sk#1, inv_quantity_on_hand#2, i_item_sk#9, i_brand#10, i_class#11, i_category#12, i_product_name#13]

(20) Scan parquet default.warehouse
Output: []
Batched: true
Location [not included in comparison]/{warehouse_dir}/warehouse]
ReadSchema: struct<>

(21) ColumnarToRow [codegen id : 7]
Input: []

(22) BroadcastExchange
Input: []
Arguments: IdentityBroadcastMode, [id=#15]

(23) BroadcastNestedLoopJoin
Join condition: None

(24) Expand [codegen id : 8]
Input [5]: [inv_quantity_on_hand#2, i_brand#10, i_class#11, i_category#12, i_product_name#13]
Arguments: [List(inv_quantity_on_hand#2, i_product_name#13, i_brand#10, i_class#11, i_category#12, 0), List(inv_quantity_on_hand#2, i_product_name#13, i_brand#10, i_class#11, null, 1), List(inv_quantity_on_hand#2, i_product_name#13, i_brand#10, null, null, 3), List(inv_quantity_on_hand#2, i_product_name#13, null, null, null, 7), List(inv_quantity_on_hand#2, null, null, null, null, 15)], [inv_quantity_on_hand#2, i_product_name#16, i_brand#17, i_class#18, i_category#19, spark_grouping_id#20]

(25) HashAggregate [codegen id : 8]
Input [6]: [inv_quantity_on_hand#2, i_product_name#16, i_brand#17, i_class#18, i_category#19, spark_grouping_id#20]
Keys [5]: [i_product_name#16, i_brand#17, i_class#18, i_category#19, spark_grouping_id#20]
Functions [1]: [partial_avg(inv_quantity_on_hand#2)]
Aggregate Attributes [2]: [sum#21, count#22]
Results [7]: [i_product_name#16, i_brand#17, i_class#18, i_category#19, spark_grouping_id#20, sum#23, count#24]

(26) Exchange
Input [7]: [i_product_name#16, i_brand#17, i_class#18, i_category#19, spark_grouping_id#20, sum#23, count#24]
Arguments: hashpartitioning(i_product_name#16, i_brand#17, i_class#18, i_category#19, spark_grouping_id#20, 5), ENSURE_REQUIREMENTS, [id=#25]

(27) HashAggregate [codegen id : 9]
Input [7]: [i_product_name#16, i_brand#17, i_class#18, i_category#19, spark_grouping_id#20, sum#23, count#24]
Keys [5]: [i_product_name#16, i_brand#17, i_class#18, i_category#19, spark_grouping_id#20]
Functions [1]: [avg(inv_quantity_on_hand#2)]
Aggregate Attributes [1]: [avg(inv_quantity_on_hand#2)#26]
Results [5]: [i_product_name#16, i_brand#17, i_class#18, i_category#19, avg(inv_quantity_on_hand#2)#26 AS qoh#27]

(28) TakeOrderedAndProject
Input [5]: [i_product_name#16, i_brand#17, i_class#18, i_category#19, qoh#27]
Arguments: 100, [qoh#27 ASC NULLS FIRST, i_product_name#16 ASC NULLS FIRST, i_brand#17 ASC NULLS FIRST, i_class#18 ASC NULLS FIRST, i_category#19 ASC NULLS FIRST], [i_product_name#16, i_brand#17, i_class#18, i_category#19, qoh#27]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = inv_date_sk#3 IN dynamicpruning#4
ReusedExchange (29)


(29) ReusedExchange [Reuses operator id: 8]
Output [1]: [d_date_sk#5]


