== Physical Plan ==
* BroadcastNestedLoopJoin Inner BuildRight (182)
:- * BroadcastNestedLoopJoin Inner BuildRight (160)
:  :- * BroadcastNestedLoopJoin Inner BuildRight (138)
:  :  :- * BroadcastNestedLoopJoin Inner BuildRight (116)
:  :  :  :- * BroadcastNestedLoopJoin Inner BuildRight (94)
:  :  :  :  :- * BroadcastNestedLoopJoin Inner BuildRight (72)
:  :  :  :  :  :- * BroadcastNestedLoopJoin Inner BuildRight (50)
:  :  :  :  :  :  :- * HashAggregate (28)
:  :  :  :  :  :  :  +- Exchange (27)
:  :  :  :  :  :  :     +- * HashAggregate (26)
:  :  :  :  :  :  :        +- * Project (25)
:  :  :  :  :  :  :           +- * BroadcastHashJoin Inner BuildRight (24)
:  :  :  :  :  :  :              :- * Project (18)
:  :  :  :  :  :  :              :  +- * BroadcastHashJoin Inner BuildRight (17)
:  :  :  :  :  :  :              :     :- * Project (11)
:  :  :  :  :  :  :              :     :  +- * BroadcastHashJoin Inner BuildRight (10)
:  :  :  :  :  :  :              :     :     :- * Project (4)
:  :  :  :  :  :  :              :     :     :  +- * Filter (3)
:  :  :  :  :  :  :              :     :     :     +- * ColumnarToRow (2)
:  :  :  :  :  :  :              :     :     :        +- Scan parquet spark_catalog.default.store_sales (1)
:  :  :  :  :  :  :              :     :     +- BroadcastExchange (9)
:  :  :  :  :  :  :              :     :        +- * Project (8)
:  :  :  :  :  :  :              :     :           +- * Filter (7)
:  :  :  :  :  :  :              :     :              +- * ColumnarToRow (6)
:  :  :  :  :  :  :              :     :                 +- Scan parquet spark_catalog.default.time_dim (5)
:  :  :  :  :  :  :              :     +- BroadcastExchange (16)
:  :  :  :  :  :  :              :        +- * Project (15)
:  :  :  :  :  :  :              :           +- * Filter (14)
:  :  :  :  :  :  :              :              +- * ColumnarToRow (13)
:  :  :  :  :  :  :              :                 +- Scan parquet spark_catalog.default.store (12)
:  :  :  :  :  :  :              +- BroadcastExchange (23)
:  :  :  :  :  :  :                 +- * Project (22)
:  :  :  :  :  :  :                    +- * Filter (21)
:  :  :  :  :  :  :                       +- * ColumnarToRow (20)
:  :  :  :  :  :  :                          +- Scan parquet spark_catalog.default.household_demographics (19)
:  :  :  :  :  :  +- BroadcastExchange (49)
:  :  :  :  :  :     +- * HashAggregate (48)
:  :  :  :  :  :        +- Exchange (47)
:  :  :  :  :  :           +- * HashAggregate (46)
:  :  :  :  :  :              +- * Project (45)
:  :  :  :  :  :                 +- * BroadcastHashJoin Inner BuildRight (44)
:  :  :  :  :  :                    :- * Project (42)
:  :  :  :  :  :                    :  +- * BroadcastHashJoin Inner BuildRight (41)
:  :  :  :  :  :                    :     :- * Project (39)
:  :  :  :  :  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (38)
:  :  :  :  :  :                    :     :     :- * Project (32)
:  :  :  :  :  :                    :     :     :  +- * Filter (31)
:  :  :  :  :  :                    :     :     :     +- * ColumnarToRow (30)
:  :  :  :  :  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (29)
:  :  :  :  :  :                    :     :     +- BroadcastExchange (37)
:  :  :  :  :  :                    :     :        +- * Project (36)
:  :  :  :  :  :                    :     :           +- * Filter (35)
:  :  :  :  :  :                    :     :              +- * ColumnarToRow (34)
:  :  :  :  :  :                    :     :                 +- Scan parquet spark_catalog.default.time_dim (33)
:  :  :  :  :  :                    :     +- ReusedExchange (40)
:  :  :  :  :  :                    +- ReusedExchange (43)
:  :  :  :  :  +- BroadcastExchange (71)
:  :  :  :  :     +- * HashAggregate (70)
:  :  :  :  :        +- Exchange (69)
:  :  :  :  :           +- * HashAggregate (68)
:  :  :  :  :              +- * Project (67)
:  :  :  :  :                 +- * BroadcastHashJoin Inner BuildRight (66)
:  :  :  :  :                    :- * Project (64)
:  :  :  :  :                    :  +- * BroadcastHashJoin Inner BuildRight (63)
:  :  :  :  :                    :     :- * Project (61)
:  :  :  :  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (60)
:  :  :  :  :                    :     :     :- * Project (54)
:  :  :  :  :                    :     :     :  +- * Filter (53)
:  :  :  :  :                    :     :     :     +- * ColumnarToRow (52)
:  :  :  :  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (51)
:  :  :  :  :                    :     :     +- BroadcastExchange (59)
:  :  :  :  :                    :     :        +- * Project (58)
:  :  :  :  :                    :     :           +- * Filter (57)
:  :  :  :  :                    :     :              +- * ColumnarToRow (56)
:  :  :  :  :                    :     :                 +- Scan parquet spark_catalog.default.time_dim (55)
:  :  :  :  :                    :     +- ReusedExchange (62)
:  :  :  :  :                    +- ReusedExchange (65)
:  :  :  :  +- BroadcastExchange (93)
:  :  :  :     +- * HashAggregate (92)
:  :  :  :        +- Exchange (91)
:  :  :  :           +- * HashAggregate (90)
:  :  :  :              +- * Project (89)
:  :  :  :                 +- * BroadcastHashJoin Inner BuildRight (88)
:  :  :  :                    :- * Project (86)
:  :  :  :                    :  +- * BroadcastHashJoin Inner BuildRight (85)
:  :  :  :                    :     :- * Project (83)
:  :  :  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (82)
:  :  :  :                    :     :     :- * Project (76)
:  :  :  :                    :     :     :  +- * Filter (75)
:  :  :  :                    :     :     :     +- * ColumnarToRow (74)
:  :  :  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (73)
:  :  :  :                    :     :     +- BroadcastExchange (81)
:  :  :  :                    :     :        +- * Project (80)
:  :  :  :                    :     :           +- * Filter (79)
:  :  :  :                    :     :              +- * ColumnarToRow (78)
:  :  :  :                    :     :                 +- Scan parquet spark_catalog.default.time_dim (77)
:  :  :  :                    :     +- ReusedExchange (84)
:  :  :  :                    +- ReusedExchange (87)
:  :  :  +- BroadcastExchange (115)
:  :  :     +- * HashAggregate (114)
:  :  :        +- Exchange (113)
:  :  :           +- * HashAggregate (112)
:  :  :              +- * Project (111)
:  :  :                 +- * BroadcastHashJoin Inner BuildRight (110)
:  :  :                    :- * Project (108)
:  :  :                    :  +- * BroadcastHashJoin Inner BuildRight (107)
:  :  :                    :     :- * Project (105)
:  :  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (104)
:  :  :                    :     :     :- * Project (98)
:  :  :                    :     :     :  +- * Filter (97)
:  :  :                    :     :     :     +- * ColumnarToRow (96)
:  :  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (95)
:  :  :                    :     :     +- BroadcastExchange (103)
:  :  :                    :     :        +- * Project (102)
:  :  :                    :     :           +- * Filter (101)
:  :  :                    :     :              +- * ColumnarToRow (100)
:  :  :                    :     :                 +- Scan parquet spark_catalog.default.time_dim (99)
:  :  :                    :     +- ReusedExchange (106)
:  :  :                    +- ReusedExchange (109)
:  :  +- BroadcastExchange (137)
:  :     +- * HashAggregate (136)
:  :        +- Exchange (135)
:  :           +- * HashAggregate (134)
:  :              +- * Project (133)
:  :                 +- * BroadcastHashJoin Inner BuildRight (132)
:  :                    :- * Project (130)
:  :                    :  +- * BroadcastHashJoin Inner BuildRight (129)
:  :                    :     :- * Project (127)
:  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (126)
:  :                    :     :     :- * Project (120)
:  :                    :     :     :  +- * Filter (119)
:  :                    :     :     :     +- * ColumnarToRow (118)
:  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (117)
:  :                    :     :     +- BroadcastExchange (125)
:  :                    :     :        +- * Project (124)
:  :                    :     :           +- * Filter (123)
:  :                    :     :              +- * ColumnarToRow (122)
:  :                    :     :                 +- Scan parquet spark_catalog.default.time_dim (121)
:  :                    :     +- ReusedExchange (128)
:  :                    +- ReusedExchange (131)
:  +- BroadcastExchange (159)
:     +- * HashAggregate (158)
:        +- Exchange (157)
:           +- * HashAggregate (156)
:              +- * Project (155)
:                 +- * BroadcastHashJoin Inner BuildRight (154)
:                    :- * Project (152)
:                    :  +- * BroadcastHashJoin Inner BuildRight (151)
:                    :     :- * Project (149)
:                    :     :  +- * BroadcastHashJoin Inner BuildRight (148)
:                    :     :     :- * Project (142)
:                    :     :     :  +- * Filter (141)
:                    :     :     :     +- * ColumnarToRow (140)
:                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (139)
:                    :     :     +- BroadcastExchange (147)
:                    :     :        +- * Project (146)
:                    :     :           +- * Filter (145)
:                    :     :              +- * ColumnarToRow (144)
:                    :     :                 +- Scan parquet spark_catalog.default.time_dim (143)
:                    :     +- ReusedExchange (150)
:                    +- ReusedExchange (153)
+- BroadcastExchange (181)
   +- * HashAggregate (180)
      +- Exchange (179)
         +- * HashAggregate (178)
            +- * Project (177)
               +- * BroadcastHashJoin Inner BuildRight (176)
                  :- * Project (174)
                  :  +- * BroadcastHashJoin Inner BuildRight (173)
                  :     :- * Project (171)
                  :     :  +- * BroadcastHashJoin Inner BuildRight (170)
                  :     :     :- * Project (164)
                  :     :     :  +- * Filter (163)
                  :     :     :     +- * ColumnarToRow (162)
                  :     :     :        +- Scan parquet spark_catalog.default.store_sales (161)
                  :     :     +- BroadcastExchange (169)
                  :     :        +- * Project (168)
                  :     :           +- * Filter (167)
                  :     :              +- * ColumnarToRow (166)
                  :     :                 +- Scan parquet spark_catalog.default.time_dim (165)
                  :     +- ReusedExchange (172)
                  +- ReusedExchange (175)


(1) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(2) ColumnarToRow [codegen id : 4]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(3) Filter [codegen id : 4]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Condition : ((isnotnull(ss_hdemo_sk#2) AND isnotnull(ss_sold_time_sk#1)) AND isnotnull(ss_store_sk#3))

(4) Project [codegen id : 4]
Output [3]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(5) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#5, t_hour#6, t_minute#7]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,8), GreaterThanOrEqual(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(6) ColumnarToRow [codegen id : 1]
Input [3]: [t_time_sk#5, t_hour#6, t_minute#7]

(7) Filter [codegen id : 1]
Input [3]: [t_time_sk#5, t_hour#6, t_minute#7]
Condition : ((((isnotnull(t_hour#6) AND isnotnull(t_minute#7)) AND (t_hour#6 = 8)) AND (t_minute#7 >= 30)) AND isnotnull(t_time_sk#5))

(8) Project [codegen id : 1]
Output [1]: [t_time_sk#5]
Input [3]: [t_time_sk#5, t_hour#6, t_minute#7]

(9) BroadcastExchange
Input [1]: [t_time_sk#5]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=1]

(10) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_sold_time_sk#1]
Right keys [1]: [t_time_sk#5]
Join type: Inner
Join condition: None

(11) Project [codegen id : 4]
Output [2]: [ss_hdemo_sk#2, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, t_time_sk#5]

(12) Scan parquet spark_catalog.default.store
Output [2]: [s_store_sk#8, s_store_name#9]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_store_name), EqualTo(s_store_name,ese), IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int,s_store_name:string>

(13) ColumnarToRow [codegen id : 2]
Input [2]: [s_store_sk#8, s_store_name#9]

(14) Filter [codegen id : 2]
Input [2]: [s_store_sk#8, s_store_name#9]
Condition : ((isnotnull(s_store_name#9) AND (s_store_name#9 = ese)) AND isnotnull(s_store_sk#8))

(15) Project [codegen id : 2]
Output [1]: [s_store_sk#8]
Input [2]: [s_store_sk#8, s_store_name#9]

(16) BroadcastExchange
Input [1]: [s_store_sk#8]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=2]

(17) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_store_sk#3]
Right keys [1]: [s_store_sk#8]
Join type: Inner
Join condition: None

(18) Project [codegen id : 4]
Output [1]: [ss_hdemo_sk#2]
Input [3]: [ss_hdemo_sk#2, ss_store_sk#3, s_store_sk#8]

(19) Scan parquet spark_catalog.default.household_demographics
Output [3]: [hd_demo_sk#10, hd_dep_count#11, hd_vehicle_count#12]
Batched: true
Location [not included in comparison]/{warehouse_dir}/household_demographics]
PushedFilters: [Or(Or(And(EqualTo(hd_dep_count,4),LessThanOrEqual(hd_vehicle_count,6)),And(EqualTo(hd_dep_count,2),LessThanOrEqual(hd_vehicle_count,4))),And(EqualTo(hd_dep_count,0),LessThanOrEqual(hd_vehicle_count,2))), IsNotNull(hd_demo_sk)]
ReadSchema: struct<hd_demo_sk:int,hd_dep_count:int,hd_vehicle_count:int>

(20) ColumnarToRow [codegen id : 3]
Input [3]: [hd_demo_sk#10, hd_dep_count#11, hd_vehicle_count#12]

(21) Filter [codegen id : 3]
Input [3]: [hd_demo_sk#10, hd_dep_count#11, hd_vehicle_count#12]
Condition : (((((hd_dep_count#11 = 4) AND (hd_vehicle_count#12 <= 6)) OR ((hd_dep_count#11 = 2) AND (hd_vehicle_count#12 <= 4))) OR ((hd_dep_count#11 = 0) AND (hd_vehicle_count#12 <= 2))) AND isnotnull(hd_demo_sk#10))

(22) Project [codegen id : 3]
Output [1]: [hd_demo_sk#10]
Input [3]: [hd_demo_sk#10, hd_dep_count#11, hd_vehicle_count#12]

(23) BroadcastExchange
Input [1]: [hd_demo_sk#10]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(24) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_hdemo_sk#2]
Right keys [1]: [hd_demo_sk#10]
Join type: Inner
Join condition: None

(25) Project [codegen id : 4]
Output: []
Input [2]: [ss_hdemo_sk#2, hd_demo_sk#10]

(26) HashAggregate [codegen id : 4]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#13]
Results [1]: [count#14]

(27) Exchange
Input [1]: [count#14]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=4]

(28) HashAggregate [codegen id : 40]
Input [1]: [count#14]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#15]
Results [1]: [count(1)#15 AS h8_30_to_9#16]

(29) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#17, ss_hdemo_sk#18, ss_store_sk#19, ss_sold_date_sk#20]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(30) ColumnarToRow [codegen id : 8]
Input [4]: [ss_sold_time_sk#17, ss_hdemo_sk#18, ss_store_sk#19, ss_sold_date_sk#20]

(31) Filter [codegen id : 8]
Input [4]: [ss_sold_time_sk#17, ss_hdemo_sk#18, ss_store_sk#19, ss_sold_date_sk#20]
Condition : ((isnotnull(ss_hdemo_sk#18) AND isnotnull(ss_sold_time_sk#17)) AND isnotnull(ss_store_sk#19))

(32) Project [codegen id : 8]
Output [3]: [ss_sold_time_sk#17, ss_hdemo_sk#18, ss_store_sk#19]
Input [4]: [ss_sold_time_sk#17, ss_hdemo_sk#18, ss_store_sk#19, ss_sold_date_sk#20]

(33) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#21, t_hour#22, t_minute#23]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,9), LessThan(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(34) ColumnarToRow [codegen id : 5]
Input [3]: [t_time_sk#21, t_hour#22, t_minute#23]

(35) Filter [codegen id : 5]
Input [3]: [t_time_sk#21, t_hour#22, t_minute#23]
Condition : ((((isnotnull(t_hour#22) AND isnotnull(t_minute#23)) AND (t_hour#22 = 9)) AND (t_minute#23 < 30)) AND isnotnull(t_time_sk#21))

(36) Project [codegen id : 5]
Output [1]: [t_time_sk#21]
Input [3]: [t_time_sk#21, t_hour#22, t_minute#23]

(37) BroadcastExchange
Input [1]: [t_time_sk#21]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=5]

(38) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ss_sold_time_sk#17]
Right keys [1]: [t_time_sk#21]
Join type: Inner
Join condition: None

(39) Project [codegen id : 8]
Output [2]: [ss_hdemo_sk#18, ss_store_sk#19]
Input [4]: [ss_sold_time_sk#17, ss_hdemo_sk#18, ss_store_sk#19, t_time_sk#21]

(40) ReusedExchange [Reuses operator id: 16]
Output [1]: [s_store_sk#24]

(41) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ss_store_sk#19]
Right keys [1]: [s_store_sk#24]
Join type: Inner
Join condition: None

(42) Project [codegen id : 8]
Output [1]: [ss_hdemo_sk#18]
Input [3]: [ss_hdemo_sk#18, ss_store_sk#19, s_store_sk#24]

(43) ReusedExchange [Reuses operator id: 23]
Output [1]: [hd_demo_sk#25]

(44) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ss_hdemo_sk#18]
Right keys [1]: [hd_demo_sk#25]
Join type: Inner
Join condition: None

(45) Project [codegen id : 8]
Output: []
Input [2]: [ss_hdemo_sk#18, hd_demo_sk#25]

(46) HashAggregate [codegen id : 8]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#26]
Results [1]: [count#27]

(47) Exchange
Input [1]: [count#27]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=6]

(48) HashAggregate [codegen id : 9]
Input [1]: [count#27]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#28]
Results [1]: [count(1)#28 AS h9_to_9_30#29]

(49) BroadcastExchange
Input [1]: [h9_to_9_30#29]
Arguments: IdentityBroadcastMode, [plan_id=7]

(50) BroadcastNestedLoopJoin [codegen id : 40]
Join type: Inner
Join condition: None

(51) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#30, ss_hdemo_sk#31, ss_store_sk#32, ss_sold_date_sk#33]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(52) ColumnarToRow [codegen id : 13]
Input [4]: [ss_sold_time_sk#30, ss_hdemo_sk#31, ss_store_sk#32, ss_sold_date_sk#33]

(53) Filter [codegen id : 13]
Input [4]: [ss_sold_time_sk#30, ss_hdemo_sk#31, ss_store_sk#32, ss_sold_date_sk#33]
Condition : ((isnotnull(ss_hdemo_sk#31) AND isnotnull(ss_sold_time_sk#30)) AND isnotnull(ss_store_sk#32))

(54) Project [codegen id : 13]
Output [3]: [ss_sold_time_sk#30, ss_hdemo_sk#31, ss_store_sk#32]
Input [4]: [ss_sold_time_sk#30, ss_hdemo_sk#31, ss_store_sk#32, ss_sold_date_sk#33]

(55) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#34, t_hour#35, t_minute#36]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,9), GreaterThanOrEqual(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(56) ColumnarToRow [codegen id : 10]
Input [3]: [t_time_sk#34, t_hour#35, t_minute#36]

(57) Filter [codegen id : 10]
Input [3]: [t_time_sk#34, t_hour#35, t_minute#36]
Condition : ((((isnotnull(t_hour#35) AND isnotnull(t_minute#36)) AND (t_hour#35 = 9)) AND (t_minute#36 >= 30)) AND isnotnull(t_time_sk#34))

(58) Project [codegen id : 10]
Output [1]: [t_time_sk#34]
Input [3]: [t_time_sk#34, t_hour#35, t_minute#36]

(59) BroadcastExchange
Input [1]: [t_time_sk#34]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=8]

(60) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ss_sold_time_sk#30]
Right keys [1]: [t_time_sk#34]
Join type: Inner
Join condition: None

(61) Project [codegen id : 13]
Output [2]: [ss_hdemo_sk#31, ss_store_sk#32]
Input [4]: [ss_sold_time_sk#30, ss_hdemo_sk#31, ss_store_sk#32, t_time_sk#34]

(62) ReusedExchange [Reuses operator id: 16]
Output [1]: [s_store_sk#37]

(63) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ss_store_sk#32]
Right keys [1]: [s_store_sk#37]
Join type: Inner
Join condition: None

(64) Project [codegen id : 13]
Output [1]: [ss_hdemo_sk#31]
Input [3]: [ss_hdemo_sk#31, ss_store_sk#32, s_store_sk#37]

(65) ReusedExchange [Reuses operator id: 23]
Output [1]: [hd_demo_sk#38]

(66) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ss_hdemo_sk#31]
Right keys [1]: [hd_demo_sk#38]
Join type: Inner
Join condition: None

(67) Project [codegen id : 13]
Output: []
Input [2]: [ss_hdemo_sk#31, hd_demo_sk#38]

(68) HashAggregate [codegen id : 13]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#39]
Results [1]: [count#40]

(69) Exchange
Input [1]: [count#40]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=9]

(70) HashAggregate [codegen id : 14]
Input [1]: [count#40]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#41]
Results [1]: [count(1)#41 AS h9_30_to_10#42]

(71) BroadcastExchange
Input [1]: [h9_30_to_10#42]
Arguments: IdentityBroadcastMode, [plan_id=10]

(72) BroadcastNestedLoopJoin [codegen id : 40]
Join type: Inner
Join condition: None

(73) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#43, ss_hdemo_sk#44, ss_store_sk#45, ss_sold_date_sk#46]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(74) ColumnarToRow [codegen id : 18]
Input [4]: [ss_sold_time_sk#43, ss_hdemo_sk#44, ss_store_sk#45, ss_sold_date_sk#46]

(75) Filter [codegen id : 18]
Input [4]: [ss_sold_time_sk#43, ss_hdemo_sk#44, ss_store_sk#45, ss_sold_date_sk#46]
Condition : ((isnotnull(ss_hdemo_sk#44) AND isnotnull(ss_sold_time_sk#43)) AND isnotnull(ss_store_sk#45))

(76) Project [codegen id : 18]
Output [3]: [ss_sold_time_sk#43, ss_hdemo_sk#44, ss_store_sk#45]
Input [4]: [ss_sold_time_sk#43, ss_hdemo_sk#44, ss_store_sk#45, ss_sold_date_sk#46]

(77) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#47, t_hour#48, t_minute#49]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,10), LessThan(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(78) ColumnarToRow [codegen id : 15]
Input [3]: [t_time_sk#47, t_hour#48, t_minute#49]

(79) Filter [codegen id : 15]
Input [3]: [t_time_sk#47, t_hour#48, t_minute#49]
Condition : ((((isnotnull(t_hour#48) AND isnotnull(t_minute#49)) AND (t_hour#48 = 10)) AND (t_minute#49 < 30)) AND isnotnull(t_time_sk#47))

(80) Project [codegen id : 15]
Output [1]: [t_time_sk#47]
Input [3]: [t_time_sk#47, t_hour#48, t_minute#49]

(81) BroadcastExchange
Input [1]: [t_time_sk#47]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=11]

(82) BroadcastHashJoin [codegen id : 18]
Left keys [1]: [ss_sold_time_sk#43]
Right keys [1]: [t_time_sk#47]
Join type: Inner
Join condition: None

(83) Project [codegen id : 18]
Output [2]: [ss_hdemo_sk#44, ss_store_sk#45]
Input [4]: [ss_sold_time_sk#43, ss_hdemo_sk#44, ss_store_sk#45, t_time_sk#47]

(84) ReusedExchange [Reuses operator id: 16]
Output [1]: [s_store_sk#50]

(85) BroadcastHashJoin [codegen id : 18]
Left keys [1]: [ss_store_sk#45]
Right keys [1]: [s_store_sk#50]
Join type: Inner
Join condition: None

(86) Project [codegen id : 18]
Output [1]: [ss_hdemo_sk#44]
Input [3]: [ss_hdemo_sk#44, ss_store_sk#45, s_store_sk#50]

(87) ReusedExchange [Reuses operator id: 23]
Output [1]: [hd_demo_sk#51]

(88) BroadcastHashJoin [codegen id : 18]
Left keys [1]: [ss_hdemo_sk#44]
Right keys [1]: [hd_demo_sk#51]
Join type: Inner
Join condition: None

(89) Project [codegen id : 18]
Output: []
Input [2]: [ss_hdemo_sk#44, hd_demo_sk#51]

(90) HashAggregate [codegen id : 18]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#52]
Results [1]: [count#53]

(91) Exchange
Input [1]: [count#53]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=12]

(92) HashAggregate [codegen id : 19]
Input [1]: [count#53]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#54]
Results [1]: [count(1)#54 AS h10_to_10_30#55]

(93) BroadcastExchange
Input [1]: [h10_to_10_30#55]
Arguments: IdentityBroadcastMode, [plan_id=13]

(94) BroadcastNestedLoopJoin [codegen id : 40]
Join type: Inner
Join condition: None

(95) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#56, ss_hdemo_sk#57, ss_store_sk#58, ss_sold_date_sk#59]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(96) ColumnarToRow [codegen id : 23]
Input [4]: [ss_sold_time_sk#56, ss_hdemo_sk#57, ss_store_sk#58, ss_sold_date_sk#59]

(97) Filter [codegen id : 23]
Input [4]: [ss_sold_time_sk#56, ss_hdemo_sk#57, ss_store_sk#58, ss_sold_date_sk#59]
Condition : ((isnotnull(ss_hdemo_sk#57) AND isnotnull(ss_sold_time_sk#56)) AND isnotnull(ss_store_sk#58))

(98) Project [codegen id : 23]
Output [3]: [ss_sold_time_sk#56, ss_hdemo_sk#57, ss_store_sk#58]
Input [4]: [ss_sold_time_sk#56, ss_hdemo_sk#57, ss_store_sk#58, ss_sold_date_sk#59]

(99) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#60, t_hour#61, t_minute#62]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,10), GreaterThanOrEqual(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(100) ColumnarToRow [codegen id : 20]
Input [3]: [t_time_sk#60, t_hour#61, t_minute#62]

(101) Filter [codegen id : 20]
Input [3]: [t_time_sk#60, t_hour#61, t_minute#62]
Condition : ((((isnotnull(t_hour#61) AND isnotnull(t_minute#62)) AND (t_hour#61 = 10)) AND (t_minute#62 >= 30)) AND isnotnull(t_time_sk#60))

(102) Project [codegen id : 20]
Output [1]: [t_time_sk#60]
Input [3]: [t_time_sk#60, t_hour#61, t_minute#62]

(103) BroadcastExchange
Input [1]: [t_time_sk#60]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=14]

(104) BroadcastHashJoin [codegen id : 23]
Left keys [1]: [ss_sold_time_sk#56]
Right keys [1]: [t_time_sk#60]
Join type: Inner
Join condition: None

(105) Project [codegen id : 23]
Output [2]: [ss_hdemo_sk#57, ss_store_sk#58]
Input [4]: [ss_sold_time_sk#56, ss_hdemo_sk#57, ss_store_sk#58, t_time_sk#60]

(106) ReusedExchange [Reuses operator id: 16]
Output [1]: [s_store_sk#63]

(107) BroadcastHashJoin [codegen id : 23]
Left keys [1]: [ss_store_sk#58]
Right keys [1]: [s_store_sk#63]
Join type: Inner
Join condition: None

(108) Project [codegen id : 23]
Output [1]: [ss_hdemo_sk#57]
Input [3]: [ss_hdemo_sk#57, ss_store_sk#58, s_store_sk#63]

(109) ReusedExchange [Reuses operator id: 23]
Output [1]: [hd_demo_sk#64]

(110) BroadcastHashJoin [codegen id : 23]
Left keys [1]: [ss_hdemo_sk#57]
Right keys [1]: [hd_demo_sk#64]
Join type: Inner
Join condition: None

(111) Project [codegen id : 23]
Output: []
Input [2]: [ss_hdemo_sk#57, hd_demo_sk#64]

(112) HashAggregate [codegen id : 23]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#65]
Results [1]: [count#66]

(113) Exchange
Input [1]: [count#66]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=15]

(114) HashAggregate [codegen id : 24]
Input [1]: [count#66]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#67]
Results [1]: [count(1)#67 AS h10_30_to_11#68]

(115) BroadcastExchange
Input [1]: [h10_30_to_11#68]
Arguments: IdentityBroadcastMode, [plan_id=16]

(116) BroadcastNestedLoopJoin [codegen id : 40]
Join type: Inner
Join condition: None

(117) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#69, ss_hdemo_sk#70, ss_store_sk#71, ss_sold_date_sk#72]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(118) ColumnarToRow [codegen id : 28]
Input [4]: [ss_sold_time_sk#69, ss_hdemo_sk#70, ss_store_sk#71, ss_sold_date_sk#72]

(119) Filter [codegen id : 28]
Input [4]: [ss_sold_time_sk#69, ss_hdemo_sk#70, ss_store_sk#71, ss_sold_date_sk#72]
Condition : ((isnotnull(ss_hdemo_sk#70) AND isnotnull(ss_sold_time_sk#69)) AND isnotnull(ss_store_sk#71))

(120) Project [codegen id : 28]
Output [3]: [ss_sold_time_sk#69, ss_hdemo_sk#70, ss_store_sk#71]
Input [4]: [ss_sold_time_sk#69, ss_hdemo_sk#70, ss_store_sk#71, ss_sold_date_sk#72]

(121) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#73, t_hour#74, t_minute#75]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,11), LessThan(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(122) ColumnarToRow [codegen id : 25]
Input [3]: [t_time_sk#73, t_hour#74, t_minute#75]

(123) Filter [codegen id : 25]
Input [3]: [t_time_sk#73, t_hour#74, t_minute#75]
Condition : ((((isnotnull(t_hour#74) AND isnotnull(t_minute#75)) AND (t_hour#74 = 11)) AND (t_minute#75 < 30)) AND isnotnull(t_time_sk#73))

(124) Project [codegen id : 25]
Output [1]: [t_time_sk#73]
Input [3]: [t_time_sk#73, t_hour#74, t_minute#75]

(125) BroadcastExchange
Input [1]: [t_time_sk#73]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=17]

(126) BroadcastHashJoin [codegen id : 28]
Left keys [1]: [ss_sold_time_sk#69]
Right keys [1]: [t_time_sk#73]
Join type: Inner
Join condition: None

(127) Project [codegen id : 28]
Output [2]: [ss_hdemo_sk#70, ss_store_sk#71]
Input [4]: [ss_sold_time_sk#69, ss_hdemo_sk#70, ss_store_sk#71, t_time_sk#73]

(128) ReusedExchange [Reuses operator id: 16]
Output [1]: [s_store_sk#76]

(129) BroadcastHashJoin [codegen id : 28]
Left keys [1]: [ss_store_sk#71]
Right keys [1]: [s_store_sk#76]
Join type: Inner
Join condition: None

(130) Project [codegen id : 28]
Output [1]: [ss_hdemo_sk#70]
Input [3]: [ss_hdemo_sk#70, ss_store_sk#71, s_store_sk#76]

(131) ReusedExchange [Reuses operator id: 23]
Output [1]: [hd_demo_sk#77]

(132) BroadcastHashJoin [codegen id : 28]
Left keys [1]: [ss_hdemo_sk#70]
Right keys [1]: [hd_demo_sk#77]
Join type: Inner
Join condition: None

(133) Project [codegen id : 28]
Output: []
Input [2]: [ss_hdemo_sk#70, hd_demo_sk#77]

(134) HashAggregate [codegen id : 28]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#78]
Results [1]: [count#79]

(135) Exchange
Input [1]: [count#79]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=18]

(136) HashAggregate [codegen id : 29]
Input [1]: [count#79]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#80]
Results [1]: [count(1)#80 AS h11_to_11_30#81]

(137) BroadcastExchange
Input [1]: [h11_to_11_30#81]
Arguments: IdentityBroadcastMode, [plan_id=19]

(138) BroadcastNestedLoopJoin [codegen id : 40]
Join type: Inner
Join condition: None

(139) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#82, ss_hdemo_sk#83, ss_store_sk#84, ss_sold_date_sk#85]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(140) ColumnarToRow [codegen id : 33]
Input [4]: [ss_sold_time_sk#82, ss_hdemo_sk#83, ss_store_sk#84, ss_sold_date_sk#85]

(141) Filter [codegen id : 33]
Input [4]: [ss_sold_time_sk#82, ss_hdemo_sk#83, ss_store_sk#84, ss_sold_date_sk#85]
Condition : ((isnotnull(ss_hdemo_sk#83) AND isnotnull(ss_sold_time_sk#82)) AND isnotnull(ss_store_sk#84))

(142) Project [codegen id : 33]
Output [3]: [ss_sold_time_sk#82, ss_hdemo_sk#83, ss_store_sk#84]
Input [4]: [ss_sold_time_sk#82, ss_hdemo_sk#83, ss_store_sk#84, ss_sold_date_sk#85]

(143) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#86, t_hour#87, t_minute#88]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,11), GreaterThanOrEqual(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(144) ColumnarToRow [codegen id : 30]
Input [3]: [t_time_sk#86, t_hour#87, t_minute#88]

(145) Filter [codegen id : 30]
Input [3]: [t_time_sk#86, t_hour#87, t_minute#88]
Condition : ((((isnotnull(t_hour#87) AND isnotnull(t_minute#88)) AND (t_hour#87 = 11)) AND (t_minute#88 >= 30)) AND isnotnull(t_time_sk#86))

(146) Project [codegen id : 30]
Output [1]: [t_time_sk#86]
Input [3]: [t_time_sk#86, t_hour#87, t_minute#88]

(147) BroadcastExchange
Input [1]: [t_time_sk#86]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=20]

(148) BroadcastHashJoin [codegen id : 33]
Left keys [1]: [ss_sold_time_sk#82]
Right keys [1]: [t_time_sk#86]
Join type: Inner
Join condition: None

(149) Project [codegen id : 33]
Output [2]: [ss_hdemo_sk#83, ss_store_sk#84]
Input [4]: [ss_sold_time_sk#82, ss_hdemo_sk#83, ss_store_sk#84, t_time_sk#86]

(150) ReusedExchange [Reuses operator id: 16]
Output [1]: [s_store_sk#89]

(151) BroadcastHashJoin [codegen id : 33]
Left keys [1]: [ss_store_sk#84]
Right keys [1]: [s_store_sk#89]
Join type: Inner
Join condition: None

(152) Project [codegen id : 33]
Output [1]: [ss_hdemo_sk#83]
Input [3]: [ss_hdemo_sk#83, ss_store_sk#84, s_store_sk#89]

(153) ReusedExchange [Reuses operator id: 23]
Output [1]: [hd_demo_sk#90]

(154) BroadcastHashJoin [codegen id : 33]
Left keys [1]: [ss_hdemo_sk#83]
Right keys [1]: [hd_demo_sk#90]
Join type: Inner
Join condition: None

(155) Project [codegen id : 33]
Output: []
Input [2]: [ss_hdemo_sk#83, hd_demo_sk#90]

(156) HashAggregate [codegen id : 33]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#91]
Results [1]: [count#92]

(157) Exchange
Input [1]: [count#92]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=21]

(158) HashAggregate [codegen id : 34]
Input [1]: [count#92]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#93]
Results [1]: [count(1)#93 AS h11_30_to_12#94]

(159) BroadcastExchange
Input [1]: [h11_30_to_12#94]
Arguments: IdentityBroadcastMode, [plan_id=22]

(160) BroadcastNestedLoopJoin [codegen id : 40]
Join type: Inner
Join condition: None

(161) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#95, ss_hdemo_sk#96, ss_store_sk#97, ss_sold_date_sk#98]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(162) ColumnarToRow [codegen id : 38]
Input [4]: [ss_sold_time_sk#95, ss_hdemo_sk#96, ss_store_sk#97, ss_sold_date_sk#98]

(163) Filter [codegen id : 38]
Input [4]: [ss_sold_time_sk#95, ss_hdemo_sk#96, ss_store_sk#97, ss_sold_date_sk#98]
Condition : ((isnotnull(ss_hdemo_sk#96) AND isnotnull(ss_sold_time_sk#95)) AND isnotnull(ss_store_sk#97))

(164) Project [codegen id : 38]
Output [3]: [ss_sold_time_sk#95, ss_hdemo_sk#96, ss_store_sk#97]
Input [4]: [ss_sold_time_sk#95, ss_hdemo_sk#96, ss_store_sk#97, ss_sold_date_sk#98]

(165) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#99, t_hour#100, t_minute#101]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,12), LessThan(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(166) ColumnarToRow [codegen id : 35]
Input [3]: [t_time_sk#99, t_hour#100, t_minute#101]

(167) Filter [codegen id : 35]
Input [3]: [t_time_sk#99, t_hour#100, t_minute#101]
Condition : ((((isnotnull(t_hour#100) AND isnotnull(t_minute#101)) AND (t_hour#100 = 12)) AND (t_minute#101 < 30)) AND isnotnull(t_time_sk#99))

(168) Project [codegen id : 35]
Output [1]: [t_time_sk#99]
Input [3]: [t_time_sk#99, t_hour#100, t_minute#101]

(169) BroadcastExchange
Input [1]: [t_time_sk#99]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=23]

(170) BroadcastHashJoin [codegen id : 38]
Left keys [1]: [ss_sold_time_sk#95]
Right keys [1]: [t_time_sk#99]
Join type: Inner
Join condition: None

(171) Project [codegen id : 38]
Output [2]: [ss_hdemo_sk#96, ss_store_sk#97]
Input [4]: [ss_sold_time_sk#95, ss_hdemo_sk#96, ss_store_sk#97, t_time_sk#99]

(172) ReusedExchange [Reuses operator id: 16]
Output [1]: [s_store_sk#102]

(173) BroadcastHashJoin [codegen id : 38]
Left keys [1]: [ss_store_sk#97]
Right keys [1]: [s_store_sk#102]
Join type: Inner
Join condition: None

(174) Project [codegen id : 38]
Output [1]: [ss_hdemo_sk#96]
Input [3]: [ss_hdemo_sk#96, ss_store_sk#97, s_store_sk#102]

(175) ReusedExchange [Reuses operator id: 23]
Output [1]: [hd_demo_sk#103]

(176) BroadcastHashJoin [codegen id : 38]
Left keys [1]: [ss_hdemo_sk#96]
Right keys [1]: [hd_demo_sk#103]
Join type: Inner
Join condition: None

(177) Project [codegen id : 38]
Output: []
Input [2]: [ss_hdemo_sk#96, hd_demo_sk#103]

(178) HashAggregate [codegen id : 38]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#104]
Results [1]: [count#105]

(179) Exchange
Input [1]: [count#105]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=24]

(180) HashAggregate [codegen id : 39]
Input [1]: [count#105]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#106]
Results [1]: [count(1)#106 AS h12_to_12_30#107]

(181) BroadcastExchange
Input [1]: [h12_to_12_30#107]
Arguments: IdentityBroadcastMode, [plan_id=25]

(182) BroadcastNestedLoopJoin [codegen id : 40]
Join type: Inner
Join condition: None

