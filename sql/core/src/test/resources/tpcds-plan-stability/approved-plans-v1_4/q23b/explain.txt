== Physical Plan ==
TakeOrderedAndProject (87)
+- Union (86)
   :- * HashAggregate (62)
   :  +- Exchange (61)
   :     +- * HashAggregate (60)
   :        +- * Project (59)
   :           +- * BroadcastHashJoin Inner BuildRight (58)
   :              :- * Project (56)
   :              :  +- * BroadcastHashJoin Inner BuildRight (55)
   :              :     :- * SortMergeJoin LeftSemi (42)
   :              :     :  :- * Sort (25)
   :              :     :  :  +- Exchange (24)
   :              :     :  :     +- * Project (23)
   :              :     :  :        +- * BroadcastHashJoin LeftSemi BuildRight (22)
   :              :     :  :           :- * Filter (3)
   :              :     :  :           :  +- * ColumnarToRow (2)
   :              :     :  :           :     +- Scan parquet spark_catalog.default.catalog_sales (1)
   :              :     :  :           +- BroadcastExchange (21)
   :              :     :  :              +- * Project (20)
   :              :     :  :                 +- * Filter (19)
   :              :     :  :                    +- * HashAggregate (18)
   :              :     :  :                       +- Exchange (17)
   :              :     :  :                          +- * HashAggregate (16)
   :              :     :  :                             +- * Project (15)
   :              :     :  :                                +- * BroadcastHashJoin Inner BuildRight (14)
   :              :     :  :                                   :- * Project (9)
   :              :     :  :                                   :  +- * BroadcastHashJoin Inner BuildRight (8)
   :              :     :  :                                   :     :- * Filter (6)
   :              :     :  :                                   :     :  +- * ColumnarToRow (5)
   :              :     :  :                                   :     :     +- Scan parquet spark_catalog.default.store_sales (4)
   :              :     :  :                                   :     +- ReusedExchange (7)
   :              :     :  :                                   +- BroadcastExchange (13)
   :              :     :  :                                      +- * Filter (12)
   :              :     :  :                                         +- * ColumnarToRow (11)
   :              :     :  :                                            +- Scan parquet spark_catalog.default.item (10)
   :              :     :  +- * Sort (41)
   :              :     :     +- * Project (40)
   :              :     :        +- * Filter (39)
   :              :     :           +- * HashAggregate (38)
   :              :     :              +- Exchange (37)
   :              :     :                 +- * HashAggregate (36)
   :              :     :                    +- * Project (35)
   :              :     :                       +- * BroadcastHashJoin Inner BuildRight (34)
   :              :     :                          :- * Project (29)
   :              :     :                          :  +- * Filter (28)
   :              :     :                          :     +- * ColumnarToRow (27)
   :              :     :                          :        +- Scan parquet spark_catalog.default.store_sales (26)
   :              :     :                          +- BroadcastExchange (33)
   :              :     :                             +- * Filter (32)
   :              :     :                                +- * ColumnarToRow (31)
   :              :     :                                   +- Scan parquet spark_catalog.default.customer (30)
   :              :     +- BroadcastExchange (54)
   :              :        +- * SortMergeJoin LeftSemi (53)
   :              :           :- * Sort (47)
   :              :           :  +- Exchange (46)
   :              :           :     +- * Filter (45)
   :              :           :        +- * ColumnarToRow (44)
   :              :           :           +- Scan parquet spark_catalog.default.customer (43)
   :              :           +- * Sort (52)
   :              :              +- * Project (51)
   :              :                 +- * Filter (50)
   :              :                    +- * HashAggregate (49)
   :              :                       +- ReusedExchange (48)
   :              +- ReusedExchange (57)
   +- * HashAggregate (85)
      +- Exchange (84)
         +- * HashAggregate (83)
            +- * Project (82)
               +- * BroadcastHashJoin Inner BuildRight (81)
                  :- * Project (79)
                  :  +- * BroadcastHashJoin Inner BuildRight (78)
                  :     :- * SortMergeJoin LeftSemi (76)
                  :     :  :- * Sort (70)
                  :     :  :  +- Exchange (69)
                  :     :  :     +- * Project (68)
                  :     :  :        +- * BroadcastHashJoin LeftSemi BuildRight (67)
                  :     :  :           :- * Filter (65)
                  :     :  :           :  +- * ColumnarToRow (64)
                  :     :  :           :     +- Scan parquet spark_catalog.default.web_sales (63)
                  :     :  :           +- ReusedExchange (66)
                  :     :  +- * Sort (75)
                  :     :     +- * Project (74)
                  :     :        +- * Filter (73)
                  :     :           +- * HashAggregate (72)
                  :     :              +- ReusedExchange (71)
                  :     +- ReusedExchange (77)
                  +- ReusedExchange (80)


(1) Scan parquet spark_catalog.default.catalog_sales
Output [5]: [cs_bill_customer_sk#1, cs_item_sk#2, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#5), dynamicpruningexpression(cs_sold_date_sk#5 IN dynamicpruning#6)]
PushedFilters: [IsNotNull(cs_bill_customer_sk)]
ReadSchema: struct<cs_bill_customer_sk:int,cs_item_sk:int,cs_quantity:int,cs_list_price:decimal(7,2)>

(2) ColumnarToRow [codegen id : 5]
Input [5]: [cs_bill_customer_sk#1, cs_item_sk#2, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]

(3) Filter [codegen id : 5]
Input [5]: [cs_bill_customer_sk#1, cs_item_sk#2, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Condition : isnotnull(cs_bill_customer_sk#1)

(4) Scan parquet spark_catalog.default.store_sales
Output [2]: [ss_item_sk#7, ss_sold_date_sk#8]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#8), dynamicpruningexpression(ss_sold_date_sk#8 IN dynamicpruning#9)]
PushedFilters: [IsNotNull(ss_item_sk)]
ReadSchema: struct<ss_item_sk:int>

(5) ColumnarToRow [codegen id : 3]
Input [2]: [ss_item_sk#7, ss_sold_date_sk#8]

(6) Filter [codegen id : 3]
Input [2]: [ss_item_sk#7, ss_sold_date_sk#8]
Condition : isnotnull(ss_item_sk#7)

(7) ReusedExchange [Reuses operator id: 97]
Output [2]: [d_date_sk#10, d_date#11]

(8) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_sold_date_sk#8]
Right keys [1]: [d_date_sk#10]
Join type: Inner
Join condition: None

(9) Project [codegen id : 3]
Output [2]: [ss_item_sk#7, d_date#11]
Input [4]: [ss_item_sk#7, ss_sold_date_sk#8, d_date_sk#10, d_date#11]

(10) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#12, i_item_desc#13]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_item_desc:string>

(11) ColumnarToRow [codegen id : 2]
Input [2]: [i_item_sk#12, i_item_desc#13]

(12) Filter [codegen id : 2]
Input [2]: [i_item_sk#12, i_item_desc#13]
Condition : isnotnull(i_item_sk#12)

(13) BroadcastExchange
Input [2]: [i_item_sk#12, i_item_desc#13]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1]

(14) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_item_sk#7]
Right keys [1]: [i_item_sk#12]
Join type: Inner
Join condition: None

(15) Project [codegen id : 3]
Output [3]: [d_date#11, i_item_sk#12, substr(i_item_desc#13, 1, 30) AS _groupingexpression#14]
Input [4]: [ss_item_sk#7, d_date#11, i_item_sk#12, i_item_desc#13]

(16) HashAggregate [codegen id : 3]
Input [3]: [d_date#11, i_item_sk#12, _groupingexpression#14]
Keys [3]: [_groupingexpression#14, i_item_sk#12, d_date#11]
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#15]
Results [4]: [_groupingexpression#14, i_item_sk#12, d_date#11, count#16]

(17) Exchange
Input [4]: [_groupingexpression#14, i_item_sk#12, d_date#11, count#16]
Arguments: hashpartitioning(_groupingexpression#14, i_item_sk#12, d_date#11, 5), ENSURE_REQUIREMENTS, [plan_id=2]

(18) HashAggregate [codegen id : 4]
Input [4]: [_groupingexpression#14, i_item_sk#12, d_date#11, count#16]
Keys [3]: [_groupingexpression#14, i_item_sk#12, d_date#11]
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#17]
Results [2]: [i_item_sk#12 AS item_sk#18, count(1)#17 AS cnt#19]

(19) Filter [codegen id : 4]
Input [2]: [item_sk#18, cnt#19]
Condition : (cnt#19 > 4)

(20) Project [codegen id : 4]
Output [1]: [item_sk#18]
Input [2]: [item_sk#18, cnt#19]

(21) BroadcastExchange
Input [1]: [item_sk#18]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(22) BroadcastHashJoin [codegen id : 5]
Left keys [1]: [cs_item_sk#2]
Right keys [1]: [item_sk#18]
Join type: LeftSemi
Join condition: None

(23) Project [codegen id : 5]
Output [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Input [5]: [cs_bill_customer_sk#1, cs_item_sk#2, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]

(24) Exchange
Input [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Arguments: hashpartitioning(cs_bill_customer_sk#1, 5), ENSURE_REQUIREMENTS, [plan_id=4]

(25) Sort [codegen id : 6]
Input [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Arguments: [cs_bill_customer_sk#1 ASC NULLS FIRST], false, 0

(26) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22, ss_sold_date_sk#23]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_customer_sk)]
ReadSchema: struct<ss_customer_sk:int,ss_quantity:int,ss_sales_price:decimal(7,2)>

(27) ColumnarToRow [codegen id : 8]
Input [4]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22, ss_sold_date_sk#23]

(28) Filter [codegen id : 8]
Input [4]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22, ss_sold_date_sk#23]
Condition : isnotnull(ss_customer_sk#20)

(29) Project [codegen id : 8]
Output [3]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22]
Input [4]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22, ss_sold_date_sk#23]

(30) Scan parquet spark_catalog.default.customer
Output [1]: [c_customer_sk#24]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer]
PushedFilters: [IsNotNull(c_customer_sk)]
ReadSchema: struct<c_customer_sk:int>

(31) ColumnarToRow [codegen id : 7]
Input [1]: [c_customer_sk#24]

(32) Filter [codegen id : 7]
Input [1]: [c_customer_sk#24]
Condition : isnotnull(c_customer_sk#24)

(33) BroadcastExchange
Input [1]: [c_customer_sk#24]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=5]

(34) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ss_customer_sk#20]
Right keys [1]: [c_customer_sk#24]
Join type: Inner
Join condition: None

(35) Project [codegen id : 8]
Output [3]: [ss_quantity#21, ss_sales_price#22, c_customer_sk#24]
Input [4]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22, c_customer_sk#24]

(36) HashAggregate [codegen id : 8]
Input [3]: [ss_quantity#21, ss_sales_price#22, c_customer_sk#24]
Keys [1]: [c_customer_sk#24]
Functions [1]: [partial_sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))]
Aggregate Attributes [2]: [sum#25, isEmpty#26]
Results [3]: [c_customer_sk#24, sum#27, isEmpty#28]

(37) Exchange
Input [3]: [c_customer_sk#24, sum#27, isEmpty#28]
Arguments: hashpartitioning(c_customer_sk#24, 5), ENSURE_REQUIREMENTS, [plan_id=6]

(38) HashAggregate [codegen id : 9]
Input [3]: [c_customer_sk#24, sum#27, isEmpty#28]
Keys [1]: [c_customer_sk#24]
Functions [1]: [sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))]
Aggregate Attributes [1]: [sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))#29]
Results [2]: [c_customer_sk#24, sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))#29 AS ssales#30]

(39) Filter [codegen id : 9]
Input [2]: [c_customer_sk#24, ssales#30]
Condition : (isnotnull(ssales#30) AND (cast(ssales#30 as decimal(38,8)) > (0.500000 * Subquery scalar-subquery#31, [id=#7])))

(40) Project [codegen id : 9]
Output [1]: [c_customer_sk#24]
Input [2]: [c_customer_sk#24, ssales#30]

(41) Sort [codegen id : 9]
Input [1]: [c_customer_sk#24]
Arguments: [c_customer_sk#24 ASC NULLS FIRST], false, 0

(42) SortMergeJoin [codegen id : 17]
Left keys [1]: [cs_bill_customer_sk#1]
Right keys [1]: [c_customer_sk#24]
Join type: LeftSemi
Join condition: None

(43) Scan parquet spark_catalog.default.customer
Output [3]: [c_customer_sk#32, c_first_name#33, c_last_name#34]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer]
PushedFilters: [IsNotNull(c_customer_sk)]
ReadSchema: struct<c_customer_sk:int,c_first_name:string,c_last_name:string>

(44) ColumnarToRow [codegen id : 10]
Input [3]: [c_customer_sk#32, c_first_name#33, c_last_name#34]

(45) Filter [codegen id : 10]
Input [3]: [c_customer_sk#32, c_first_name#33, c_last_name#34]
Condition : isnotnull(c_customer_sk#32)

(46) Exchange
Input [3]: [c_customer_sk#32, c_first_name#33, c_last_name#34]
Arguments: hashpartitioning(c_customer_sk#32, 5), ENSURE_REQUIREMENTS, [plan_id=8]

(47) Sort [codegen id : 11]
Input [3]: [c_customer_sk#32, c_first_name#33, c_last_name#34]
Arguments: [c_customer_sk#32 ASC NULLS FIRST], false, 0

(48) ReusedExchange [Reuses operator id: 37]
Output [3]: [c_customer_sk#24, sum#27, isEmpty#28]

(49) HashAggregate [codegen id : 14]
Input [3]: [c_customer_sk#24, sum#27, isEmpty#28]
Keys [1]: [c_customer_sk#24]
Functions [1]: [sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))]
Aggregate Attributes [1]: [sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))#29]
Results [2]: [c_customer_sk#24, sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))#29 AS ssales#30]

(50) Filter [codegen id : 14]
Input [2]: [c_customer_sk#24, ssales#30]
Condition : (isnotnull(ssales#30) AND (cast(ssales#30 as decimal(38,8)) > (0.500000 * ReusedSubquery Subquery scalar-subquery#31, [id=#7])))

(51) Project [codegen id : 14]
Output [1]: [c_customer_sk#24]
Input [2]: [c_customer_sk#24, ssales#30]

(52) Sort [codegen id : 14]
Input [1]: [c_customer_sk#24]
Arguments: [c_customer_sk#24 ASC NULLS FIRST], false, 0

(53) SortMergeJoin [codegen id : 15]
Left keys [1]: [c_customer_sk#32]
Right keys [1]: [c_customer_sk#24]
Join type: LeftSemi
Join condition: None

(54) BroadcastExchange
Input [3]: [c_customer_sk#32, c_first_name#33, c_last_name#34]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=9]

(55) BroadcastHashJoin [codegen id : 17]
Left keys [1]: [cs_bill_customer_sk#1]
Right keys [1]: [c_customer_sk#32]
Join type: Inner
Join condition: None

(56) Project [codegen id : 17]
Output [5]: [cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5, c_first_name#33, c_last_name#34]
Input [7]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5, c_customer_sk#32, c_first_name#33, c_last_name#34]

(57) ReusedExchange [Reuses operator id: 92]
Output [1]: [d_date_sk#35]

(58) BroadcastHashJoin [codegen id : 17]
Left keys [1]: [cs_sold_date_sk#5]
Right keys [1]: [d_date_sk#35]
Join type: Inner
Join condition: None

(59) Project [codegen id : 17]
Output [4]: [cs_quantity#3, cs_list_price#4, c_first_name#33, c_last_name#34]
Input [6]: [cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5, c_first_name#33, c_last_name#34, d_date_sk#35]

(60) HashAggregate [codegen id : 17]
Input [4]: [cs_quantity#3, cs_list_price#4, c_first_name#33, c_last_name#34]
Keys [2]: [c_last_name#34, c_first_name#33]
Functions [1]: [partial_sum((cast(cs_quantity#3 as decimal(10,0)) * cs_list_price#4))]
Aggregate Attributes [2]: [sum#36, isEmpty#37]
Results [4]: [c_last_name#34, c_first_name#33, sum#38, isEmpty#39]

(61) Exchange
Input [4]: [c_last_name#34, c_first_name#33, sum#38, isEmpty#39]
Arguments: hashpartitioning(c_last_name#34, c_first_name#33, 5), ENSURE_REQUIREMENTS, [plan_id=10]

(62) HashAggregate [codegen id : 18]
Input [4]: [c_last_name#34, c_first_name#33, sum#38, isEmpty#39]
Keys [2]: [c_last_name#34, c_first_name#33]
Functions [1]: [sum((cast(cs_quantity#3 as decimal(10,0)) * cs_list_price#4))]
Aggregate Attributes [1]: [sum((cast(cs_quantity#3 as decimal(10,0)) * cs_list_price#4))#40]
Results [3]: [c_last_name#34, c_first_name#33, sum((cast(cs_quantity#3 as decimal(10,0)) * cs_list_price#4))#40 AS sales#41]

(63) Scan parquet spark_catalog.default.web_sales
Output [5]: [ws_item_sk#42, ws_bill_customer_sk#43, ws_quantity#44, ws_list_price#45, ws_sold_date_sk#46]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#46), dynamicpruningexpression(ws_sold_date_sk#46 IN dynamicpruning#6)]
PushedFilters: [IsNotNull(ws_bill_customer_sk)]
ReadSchema: struct<ws_item_sk:int,ws_bill_customer_sk:int,ws_quantity:int,ws_list_price:decimal(7,2)>

(64) ColumnarToRow [codegen id : 23]
Input [5]: [ws_item_sk#42, ws_bill_customer_sk#43, ws_quantity#44, ws_list_price#45, ws_sold_date_sk#46]

(65) Filter [codegen id : 23]
Input [5]: [ws_item_sk#42, ws_bill_customer_sk#43, ws_quantity#44, ws_list_price#45, ws_sold_date_sk#46]
Condition : isnotnull(ws_bill_customer_sk#43)

(66) ReusedExchange [Reuses operator id: 21]
Output [1]: [item_sk#47]

(67) BroadcastHashJoin [codegen id : 23]
Left keys [1]: [ws_item_sk#42]
Right keys [1]: [item_sk#47]
Join type: LeftSemi
Join condition: None

(68) Project [codegen id : 23]
Output [4]: [ws_bill_customer_sk#43, ws_quantity#44, ws_list_price#45, ws_sold_date_sk#46]
Input [5]: [ws_item_sk#42, ws_bill_customer_sk#43, ws_quantity#44, ws_list_price#45, ws_sold_date_sk#46]

(69) Exchange
Input [4]: [ws_bill_customer_sk#43, ws_quantity#44, ws_list_price#45, ws_sold_date_sk#46]
Arguments: hashpartitioning(ws_bill_customer_sk#43, 5), ENSURE_REQUIREMENTS, [plan_id=11]

(70) Sort [codegen id : 24]
Input [4]: [ws_bill_customer_sk#43, ws_quantity#44, ws_list_price#45, ws_sold_date_sk#46]
Arguments: [ws_bill_customer_sk#43 ASC NULLS FIRST], false, 0

(71) ReusedExchange [Reuses operator id: 37]
Output [3]: [c_customer_sk#48, sum#49, isEmpty#50]

(72) HashAggregate [codegen id : 27]
Input [3]: [c_customer_sk#48, sum#49, isEmpty#50]
Keys [1]: [c_customer_sk#48]
Functions [1]: [sum((cast(ss_quantity#51 as decimal(10,0)) * ss_sales_price#52))]
Aggregate Attributes [1]: [sum((cast(ss_quantity#51 as decimal(10,0)) * ss_sales_price#52))#29]
Results [2]: [c_customer_sk#48, sum((cast(ss_quantity#51 as decimal(10,0)) * ss_sales_price#52))#29 AS ssales#53]

(73) Filter [codegen id : 27]
Input [2]: [c_customer_sk#48, ssales#53]
Condition : (isnotnull(ssales#53) AND (cast(ssales#53 as decimal(38,8)) > (0.500000 * ReusedSubquery Subquery scalar-subquery#31, [id=#7])))

(74) Project [codegen id : 27]
Output [1]: [c_customer_sk#48]
Input [2]: [c_customer_sk#48, ssales#53]

(75) Sort [codegen id : 27]
Input [1]: [c_customer_sk#48]
Arguments: [c_customer_sk#48 ASC NULLS FIRST], false, 0

(76) SortMergeJoin [codegen id : 35]
Left keys [1]: [ws_bill_customer_sk#43]
Right keys [1]: [c_customer_sk#48]
Join type: LeftSemi
Join condition: None

(77) ReusedExchange [Reuses operator id: 54]
Output [3]: [c_customer_sk#54, c_first_name#55, c_last_name#56]

(78) BroadcastHashJoin [codegen id : 35]
Left keys [1]: [ws_bill_customer_sk#43]
Right keys [1]: [c_customer_sk#54]
Join type: Inner
Join condition: None

(79) Project [codegen id : 35]
Output [5]: [ws_quantity#44, ws_list_price#45, ws_sold_date_sk#46, c_first_name#55, c_last_name#56]
Input [7]: [ws_bill_customer_sk#43, ws_quantity#44, ws_list_price#45, ws_sold_date_sk#46, c_customer_sk#54, c_first_name#55, c_last_name#56]

(80) ReusedExchange [Reuses operator id: 92]
Output [1]: [d_date_sk#57]

(81) BroadcastHashJoin [codegen id : 35]
Left keys [1]: [ws_sold_date_sk#46]
Right keys [1]: [d_date_sk#57]
Join type: Inner
Join condition: None

(82) Project [codegen id : 35]
Output [4]: [ws_quantity#44, ws_list_price#45, c_first_name#55, c_last_name#56]
Input [6]: [ws_quantity#44, ws_list_price#45, ws_sold_date_sk#46, c_first_name#55, c_last_name#56, d_date_sk#57]

(83) HashAggregate [codegen id : 35]
Input [4]: [ws_quantity#44, ws_list_price#45, c_first_name#55, c_last_name#56]
Keys [2]: [c_last_name#56, c_first_name#55]
Functions [1]: [partial_sum((cast(ws_quantity#44 as decimal(10,0)) * ws_list_price#45))]
Aggregate Attributes [2]: [sum#58, isEmpty#59]
Results [4]: [c_last_name#56, c_first_name#55, sum#60, isEmpty#61]

(84) Exchange
Input [4]: [c_last_name#56, c_first_name#55, sum#60, isEmpty#61]
Arguments: hashpartitioning(c_last_name#56, c_first_name#55, 5), ENSURE_REQUIREMENTS, [plan_id=12]

(85) HashAggregate [codegen id : 36]
Input [4]: [c_last_name#56, c_first_name#55, sum#60, isEmpty#61]
Keys [2]: [c_last_name#56, c_first_name#55]
Functions [1]: [sum((cast(ws_quantity#44 as decimal(10,0)) * ws_list_price#45))]
Aggregate Attributes [1]: [sum((cast(ws_quantity#44 as decimal(10,0)) * ws_list_price#45))#62]
Results [3]: [c_last_name#56, c_first_name#55, sum((cast(ws_quantity#44 as decimal(10,0)) * ws_list_price#45))#62 AS sales#63]

(86) Union

(87) TakeOrderedAndProject
Input [3]: [c_last_name#34, c_first_name#33, sales#41]
Arguments: 100, [c_last_name#34 ASC NULLS FIRST, c_first_name#33 ASC NULLS FIRST, sales#41 ASC NULLS FIRST], [c_last_name#34, c_first_name#33, sales#41]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = cs_sold_date_sk#5 IN dynamicpruning#6
BroadcastExchange (92)
+- * Project (91)
   +- * Filter (90)
      +- * ColumnarToRow (89)
         +- Scan parquet spark_catalog.default.date_dim (88)


(88) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#35, d_year#64, d_moy#65]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), EqualTo(d_year,2000), EqualTo(d_moy,2), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>

(89) ColumnarToRow [codegen id : 1]
Input [3]: [d_date_sk#35, d_year#64, d_moy#65]

(90) Filter [codegen id : 1]
Input [3]: [d_date_sk#35, d_year#64, d_moy#65]
Condition : ((((isnotnull(d_year#64) AND isnotnull(d_moy#65)) AND (d_year#64 = 2000)) AND (d_moy#65 = 2)) AND isnotnull(d_date_sk#35))

(91) Project [codegen id : 1]
Output [1]: [d_date_sk#35]
Input [3]: [d_date_sk#35, d_year#64, d_moy#65]

(92) BroadcastExchange
Input [1]: [d_date_sk#35]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=13]

Subquery:2 Hosting operator id = 4 Hosting Expression = ss_sold_date_sk#8 IN dynamicpruning#9
BroadcastExchange (97)
+- * Project (96)
   +- * Filter (95)
      +- * ColumnarToRow (94)
         +- Scan parquet spark_catalog.default.date_dim (93)


(93) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#10, d_date#11, d_year#66]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [In(d_year, [2000,2001,2002,2003]), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date,d_year:int>

(94) ColumnarToRow [codegen id : 1]
Input [3]: [d_date_sk#10, d_date#11, d_year#66]

(95) Filter [codegen id : 1]
Input [3]: [d_date_sk#10, d_date#11, d_year#66]
Condition : (d_year#66 IN (2000,2001,2002,2003) AND isnotnull(d_date_sk#10))

(96) Project [codegen id : 1]
Output [2]: [d_date_sk#10, d_date#11]
Input [3]: [d_date_sk#10, d_date#11, d_year#66]

(97) BroadcastExchange
Input [2]: [d_date_sk#10, d_date#11]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=14]

Subquery:3 Hosting operator id = 39 Hosting Expression = Subquery scalar-subquery#31, [id=#7]
* HashAggregate (112)
+- Exchange (111)
   +- * HashAggregate (110)
      +- * HashAggregate (109)
         +- Exchange (108)
            +- * HashAggregate (107)
               +- * Project (106)
                  +- * BroadcastHashJoin Inner BuildRight (105)
                     :- * Project (103)
                     :  +- * BroadcastHashJoin Inner BuildRight (102)
                     :     :- * Filter (100)
                     :     :  +- * ColumnarToRow (99)
                     :     :     +- Scan parquet spark_catalog.default.store_sales (98)
                     :     +- ReusedExchange (101)
                     +- ReusedExchange (104)


(98) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_customer_sk#67, ss_quantity#68, ss_sales_price#69, ss_sold_date_sk#70]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#70), dynamicpruningexpression(ss_sold_date_sk#70 IN dynamicpruning#71)]
PushedFilters: [IsNotNull(ss_customer_sk)]
ReadSchema: struct<ss_customer_sk:int,ss_quantity:int,ss_sales_price:decimal(7,2)>

(99) ColumnarToRow [codegen id : 3]
Input [4]: [ss_customer_sk#67, ss_quantity#68, ss_sales_price#69, ss_sold_date_sk#70]

(100) Filter [codegen id : 3]
Input [4]: [ss_customer_sk#67, ss_quantity#68, ss_sales_price#69, ss_sold_date_sk#70]
Condition : isnotnull(ss_customer_sk#67)

(101) ReusedExchange [Reuses operator id: 33]
Output [1]: [c_customer_sk#72]

(102) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_customer_sk#67]
Right keys [1]: [c_customer_sk#72]
Join type: Inner
Join condition: None

(103) Project [codegen id : 3]
Output [4]: [ss_quantity#68, ss_sales_price#69, ss_sold_date_sk#70, c_customer_sk#72]
Input [5]: [ss_customer_sk#67, ss_quantity#68, ss_sales_price#69, ss_sold_date_sk#70, c_customer_sk#72]

(104) ReusedExchange [Reuses operator id: 117]
Output [1]: [d_date_sk#73]

(105) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_sold_date_sk#70]
Right keys [1]: [d_date_sk#73]
Join type: Inner
Join condition: None

(106) Project [codegen id : 3]
Output [3]: [ss_quantity#68, ss_sales_price#69, c_customer_sk#72]
Input [5]: [ss_quantity#68, ss_sales_price#69, ss_sold_date_sk#70, c_customer_sk#72, d_date_sk#73]

(107) HashAggregate [codegen id : 3]
Input [3]: [ss_quantity#68, ss_sales_price#69, c_customer_sk#72]
Keys [1]: [c_customer_sk#72]
Functions [1]: [partial_sum((cast(ss_quantity#68 as decimal(10,0)) * ss_sales_price#69))]
Aggregate Attributes [2]: [sum#74, isEmpty#75]
Results [3]: [c_customer_sk#72, sum#76, isEmpty#77]

(108) Exchange
Input [3]: [c_customer_sk#72, sum#76, isEmpty#77]
Arguments: hashpartitioning(c_customer_sk#72, 5), ENSURE_REQUIREMENTS, [plan_id=15]

(109) HashAggregate [codegen id : 4]
Input [3]: [c_customer_sk#72, sum#76, isEmpty#77]
Keys [1]: [c_customer_sk#72]
Functions [1]: [sum((cast(ss_quantity#68 as decimal(10,0)) * ss_sales_price#69))]
Aggregate Attributes [1]: [sum((cast(ss_quantity#68 as decimal(10,0)) * ss_sales_price#69))#78]
Results [1]: [sum((cast(ss_quantity#68 as decimal(10,0)) * ss_sales_price#69))#78 AS csales#79]

(110) HashAggregate [codegen id : 4]
Input [1]: [csales#79]
Keys: []
Functions [1]: [partial_max(csales#79)]
Aggregate Attributes [1]: [max#80]
Results [1]: [max#81]

(111) Exchange
Input [1]: [max#81]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=16]

(112) HashAggregate [codegen id : 5]
Input [1]: [max#81]
Keys: []
Functions [1]: [max(csales#79)]
Aggregate Attributes [1]: [max(csales#79)#82]
Results [1]: [max(csales#79)#82 AS tpcds_cmax#83]

Subquery:4 Hosting operator id = 98 Hosting Expression = ss_sold_date_sk#70 IN dynamicpruning#71
BroadcastExchange (117)
+- * Project (116)
   +- * Filter (115)
      +- * ColumnarToRow (114)
         +- Scan parquet spark_catalog.default.date_dim (113)


(113) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#73, d_year#84]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [In(d_year, [2000,2001,2002,2003]), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int>

(114) ColumnarToRow [codegen id : 1]
Input [2]: [d_date_sk#73, d_year#84]

(115) Filter [codegen id : 1]
Input [2]: [d_date_sk#73, d_year#84]
Condition : (d_year#84 IN (2000,2001,2002,2003) AND isnotnull(d_date_sk#73))

(116) Project [codegen id : 1]
Output [1]: [d_date_sk#73]
Input [2]: [d_date_sk#73, d_year#84]

(117) BroadcastExchange
Input [1]: [d_date_sk#73]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=17]

Subquery:5 Hosting operator id = 50 Hosting Expression = ReusedSubquery Subquery scalar-subquery#31, [id=#7]

Subquery:6 Hosting operator id = 63 Hosting Expression = ws_sold_date_sk#46 IN dynamicpruning#6

Subquery:7 Hosting operator id = 73 Hosting Expression = ReusedSubquery Subquery scalar-subquery#31, [id=#7]


