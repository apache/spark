== Physical Plan ==
* HashAggregate (66)
+- Exchange (65)
   +- * HashAggregate (64)
      +- Union (63)
         :- * Project (45)
         :  +- * BroadcastHashJoin Inner BuildRight (44)
         :     :- * Project (42)
         :     :  +- * SortMergeJoin LeftSemi (41)
         :     :     :- * Sort (24)
         :     :     :  +- Exchange (23)
         :     :     :     +- * Project (22)
         :     :     :        +- * BroadcastHashJoin LeftSemi BuildRight (21)
         :     :     :           :- * ColumnarToRow (2)
         :     :     :           :  +- Scan parquet spark_catalog.default.catalog_sales (1)
         :     :     :           +- BroadcastExchange (20)
         :     :     :              +- * Project (19)
         :     :     :                 +- * Filter (18)
         :     :     :                    +- * HashAggregate (17)
         :     :     :                       +- Exchange (16)
         :     :     :                          +- * HashAggregate (15)
         :     :     :                             +- * Project (14)
         :     :     :                                +- * BroadcastHashJoin Inner BuildRight (13)
         :     :     :                                   :- * Project (8)
         :     :     :                                   :  +- * BroadcastHashJoin Inner BuildRight (7)
         :     :     :                                   :     :- * Filter (5)
         :     :     :                                   :     :  +- * ColumnarToRow (4)
         :     :     :                                   :     :     +- Scan parquet spark_catalog.default.store_sales (3)
         :     :     :                                   :     +- ReusedExchange (6)
         :     :     :                                   +- BroadcastExchange (12)
         :     :     :                                      +- * Filter (11)
         :     :     :                                         +- * ColumnarToRow (10)
         :     :     :                                            +- Scan parquet spark_catalog.default.item (9)
         :     :     +- * Sort (40)
         :     :        +- * Project (39)
         :     :           +- * Filter (38)
         :     :              +- * HashAggregate (37)
         :     :                 +- Exchange (36)
         :     :                    +- * HashAggregate (35)
         :     :                       +- * Project (34)
         :     :                          +- * BroadcastHashJoin Inner BuildRight (33)
         :     :                             :- * Project (28)
         :     :                             :  +- * Filter (27)
         :     :                             :     +- * ColumnarToRow (26)
         :     :                             :        +- Scan parquet spark_catalog.default.store_sales (25)
         :     :                             +- BroadcastExchange (32)
         :     :                                +- * Filter (31)
         :     :                                   +- * ColumnarToRow (30)
         :     :                                      +- Scan parquet spark_catalog.default.customer (29)
         :     +- ReusedExchange (43)
         +- * Project (62)
            +- * BroadcastHashJoin Inner BuildRight (61)
               :- * Project (59)
               :  +- * SortMergeJoin LeftSemi (58)
               :     :- * Sort (52)
               :     :  +- Exchange (51)
               :     :     +- * Project (50)
               :     :        +- * BroadcastHashJoin LeftSemi BuildRight (49)
               :     :           :- * ColumnarToRow (47)
               :     :           :  +- Scan parquet spark_catalog.default.web_sales (46)
               :     :           +- ReusedExchange (48)
               :     +- * Sort (57)
               :        +- * Project (56)
               :           +- * Filter (55)
               :              +- * HashAggregate (54)
               :                 +- ReusedExchange (53)
               +- ReusedExchange (60)


(1) Scan parquet spark_catalog.default.catalog_sales
Output [5]: [cs_bill_customer_sk#1, cs_item_sk#2, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#5), dynamicpruningexpression(cs_sold_date_sk#5 IN dynamicpruning#6)]
ReadSchema: struct<cs_bill_customer_sk:int,cs_item_sk:int,cs_quantity:int,cs_list_price:decimal(7,2)>

(2) ColumnarToRow [codegen id : 5]
Input [5]: [cs_bill_customer_sk#1, cs_item_sk#2, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]

(3) Scan parquet spark_catalog.default.store_sales
Output [2]: [ss_item_sk#7, ss_sold_date_sk#8]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#8), dynamicpruningexpression(ss_sold_date_sk#8 IN dynamicpruning#9)]
PushedFilters: [IsNotNull(ss_item_sk)]
ReadSchema: struct<ss_item_sk:int>

(4) ColumnarToRow [codegen id : 3]
Input [2]: [ss_item_sk#7, ss_sold_date_sk#8]

(5) Filter [codegen id : 3]
Input [2]: [ss_item_sk#7, ss_sold_date_sk#8]
Condition : isnotnull(ss_item_sk#7)

(6) ReusedExchange [Reuses operator id: 76]
Output [2]: [d_date_sk#10, d_date#11]

(7) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_sold_date_sk#8]
Right keys [1]: [d_date_sk#10]
Join type: Inner
Join condition: None

(8) Project [codegen id : 3]
Output [2]: [ss_item_sk#7, d_date#11]
Input [4]: [ss_item_sk#7, ss_sold_date_sk#8, d_date_sk#10, d_date#11]

(9) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#12, i_item_desc#13]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_item_desc:string>

(10) ColumnarToRow [codegen id : 2]
Input [2]: [i_item_sk#12, i_item_desc#13]

(11) Filter [codegen id : 2]
Input [2]: [i_item_sk#12, i_item_desc#13]
Condition : isnotnull(i_item_sk#12)

(12) BroadcastExchange
Input [2]: [i_item_sk#12, i_item_desc#13]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1]

(13) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_item_sk#7]
Right keys [1]: [i_item_sk#12]
Join type: Inner
Join condition: None

(14) Project [codegen id : 3]
Output [3]: [d_date#11, i_item_sk#12, substr(i_item_desc#13, 1, 30) AS _groupingexpression#14]
Input [4]: [ss_item_sk#7, d_date#11, i_item_sk#12, i_item_desc#13]

(15) HashAggregate [codegen id : 3]
Input [3]: [d_date#11, i_item_sk#12, _groupingexpression#14]
Keys [3]: [_groupingexpression#14, i_item_sk#12, d_date#11]
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#15]
Results [4]: [_groupingexpression#14, i_item_sk#12, d_date#11, count#16]

(16) Exchange
Input [4]: [_groupingexpression#14, i_item_sk#12, d_date#11, count#16]
Arguments: hashpartitioning(_groupingexpression#14, i_item_sk#12, d_date#11, 5), ENSURE_REQUIREMENTS, [plan_id=2]

(17) HashAggregate [codegen id : 4]
Input [4]: [_groupingexpression#14, i_item_sk#12, d_date#11, count#16]
Keys [3]: [_groupingexpression#14, i_item_sk#12, d_date#11]
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#17]
Results [2]: [i_item_sk#12 AS item_sk#18, count(1)#17 AS cnt#19]

(18) Filter [codegen id : 4]
Input [2]: [item_sk#18, cnt#19]
Condition : (cnt#19 > 4)

(19) Project [codegen id : 4]
Output [1]: [item_sk#18]
Input [2]: [item_sk#18, cnt#19]

(20) BroadcastExchange
Input [1]: [item_sk#18]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(21) BroadcastHashJoin [codegen id : 5]
Left keys [1]: [cs_item_sk#2]
Right keys [1]: [item_sk#18]
Join type: LeftSemi
Join condition: None

(22) Project [codegen id : 5]
Output [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Input [5]: [cs_bill_customer_sk#1, cs_item_sk#2, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]

(23) Exchange
Input [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Arguments: hashpartitioning(cs_bill_customer_sk#1, 5), ENSURE_REQUIREMENTS, [plan_id=4]

(24) Sort [codegen id : 6]
Input [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Arguments: [cs_bill_customer_sk#1 ASC NULLS FIRST], false, 0

(25) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22, ss_sold_date_sk#23]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_customer_sk)]
ReadSchema: struct<ss_customer_sk:int,ss_quantity:int,ss_sales_price:decimal(7,2)>

(26) ColumnarToRow [codegen id : 8]
Input [4]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22, ss_sold_date_sk#23]

(27) Filter [codegen id : 8]
Input [4]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22, ss_sold_date_sk#23]
Condition : isnotnull(ss_customer_sk#20)

(28) Project [codegen id : 8]
Output [3]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22]
Input [4]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22, ss_sold_date_sk#23]

(29) Scan parquet spark_catalog.default.customer
Output [1]: [c_customer_sk#24]
Batched: true
Location [not included in comparison]/{warehouse_dir}/customer]
PushedFilters: [IsNotNull(c_customer_sk)]
ReadSchema: struct<c_customer_sk:int>

(30) ColumnarToRow [codegen id : 7]
Input [1]: [c_customer_sk#24]

(31) Filter [codegen id : 7]
Input [1]: [c_customer_sk#24]
Condition : isnotnull(c_customer_sk#24)

(32) BroadcastExchange
Input [1]: [c_customer_sk#24]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=5]

(33) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ss_customer_sk#20]
Right keys [1]: [c_customer_sk#24]
Join type: Inner
Join condition: None

(34) Project [codegen id : 8]
Output [3]: [ss_quantity#21, ss_sales_price#22, c_customer_sk#24]
Input [4]: [ss_customer_sk#20, ss_quantity#21, ss_sales_price#22, c_customer_sk#24]

(35) HashAggregate [codegen id : 8]
Input [3]: [ss_quantity#21, ss_sales_price#22, c_customer_sk#24]
Keys [1]: [c_customer_sk#24]
Functions [1]: [partial_sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))]
Aggregate Attributes [2]: [sum#25, isEmpty#26]
Results [3]: [c_customer_sk#24, sum#27, isEmpty#28]

(36) Exchange
Input [3]: [c_customer_sk#24, sum#27, isEmpty#28]
Arguments: hashpartitioning(c_customer_sk#24, 5), ENSURE_REQUIREMENTS, [plan_id=6]

(37) HashAggregate [codegen id : 9]
Input [3]: [c_customer_sk#24, sum#27, isEmpty#28]
Keys [1]: [c_customer_sk#24]
Functions [1]: [sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))]
Aggregate Attributes [1]: [sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))#29]
Results [2]: [c_customer_sk#24, sum((cast(ss_quantity#21 as decimal(10,0)) * ss_sales_price#22))#29 AS ssales#30]

(38) Filter [codegen id : 9]
Input [2]: [c_customer_sk#24, ssales#30]
Condition : (isnotnull(ssales#30) AND (cast(ssales#30 as decimal(38,8)) > (0.500000 * Subquery scalar-subquery#31, [id=#32])))

(39) Project [codegen id : 9]
Output [1]: [c_customer_sk#24]
Input [2]: [c_customer_sk#24, ssales#30]

(40) Sort [codegen id : 9]
Input [1]: [c_customer_sk#24]
Arguments: [c_customer_sk#24 ASC NULLS FIRST], false, 0

(41) SortMergeJoin [codegen id : 11]
Left keys [1]: [cs_bill_customer_sk#1]
Right keys [1]: [c_customer_sk#24]
Join type: LeftSemi
Join condition: None

(42) Project [codegen id : 11]
Output [3]: [cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]
Input [4]: [cs_bill_customer_sk#1, cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5]

(43) ReusedExchange [Reuses operator id: 71]
Output [1]: [d_date_sk#33]

(44) BroadcastHashJoin [codegen id : 11]
Left keys [1]: [cs_sold_date_sk#5]
Right keys [1]: [d_date_sk#33]
Join type: Inner
Join condition: None

(45) Project [codegen id : 11]
Output [1]: [(cast(cs_quantity#3 as decimal(10,0)) * cs_list_price#4) AS sales#34]
Input [4]: [cs_quantity#3, cs_list_price#4, cs_sold_date_sk#5, d_date_sk#33]

(46) Scan parquet spark_catalog.default.web_sales
Output [5]: [ws_item_sk#35, ws_bill_customer_sk#36, ws_quantity#37, ws_list_price#38, ws_sold_date_sk#39]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#39), dynamicpruningexpression(ws_sold_date_sk#39 IN dynamicpruning#6)]
ReadSchema: struct<ws_item_sk:int,ws_bill_customer_sk:int,ws_quantity:int,ws_list_price:decimal(7,2)>

(47) ColumnarToRow [codegen id : 16]
Input [5]: [ws_item_sk#35, ws_bill_customer_sk#36, ws_quantity#37, ws_list_price#38, ws_sold_date_sk#39]

(48) ReusedExchange [Reuses operator id: 20]
Output [1]: [item_sk#40]

(49) BroadcastHashJoin [codegen id : 16]
Left keys [1]: [ws_item_sk#35]
Right keys [1]: [item_sk#40]
Join type: LeftSemi
Join condition: None

(50) Project [codegen id : 16]
Output [4]: [ws_bill_customer_sk#36, ws_quantity#37, ws_list_price#38, ws_sold_date_sk#39]
Input [5]: [ws_item_sk#35, ws_bill_customer_sk#36, ws_quantity#37, ws_list_price#38, ws_sold_date_sk#39]

(51) Exchange
Input [4]: [ws_bill_customer_sk#36, ws_quantity#37, ws_list_price#38, ws_sold_date_sk#39]
Arguments: hashpartitioning(ws_bill_customer_sk#36, 5), ENSURE_REQUIREMENTS, [plan_id=7]

(52) Sort [codegen id : 17]
Input [4]: [ws_bill_customer_sk#36, ws_quantity#37, ws_list_price#38, ws_sold_date_sk#39]
Arguments: [ws_bill_customer_sk#36 ASC NULLS FIRST], false, 0

(53) ReusedExchange [Reuses operator id: 36]
Output [3]: [c_customer_sk#41, sum#42, isEmpty#43]

(54) HashAggregate [codegen id : 20]
Input [3]: [c_customer_sk#41, sum#42, isEmpty#43]
Keys [1]: [c_customer_sk#41]
Functions [1]: [sum((cast(ss_quantity#44 as decimal(10,0)) * ss_sales_price#45))]
Aggregate Attributes [1]: [sum((cast(ss_quantity#44 as decimal(10,0)) * ss_sales_price#45))#29]
Results [2]: [c_customer_sk#41, sum((cast(ss_quantity#44 as decimal(10,0)) * ss_sales_price#45))#29 AS ssales#46]

(55) Filter [codegen id : 20]
Input [2]: [c_customer_sk#41, ssales#46]
Condition : (isnotnull(ssales#46) AND (cast(ssales#46 as decimal(38,8)) > (0.500000 * ReusedSubquery Subquery scalar-subquery#31, [id=#32])))

(56) Project [codegen id : 20]
Output [1]: [c_customer_sk#41]
Input [2]: [c_customer_sk#41, ssales#46]

(57) Sort [codegen id : 20]
Input [1]: [c_customer_sk#41]
Arguments: [c_customer_sk#41 ASC NULLS FIRST], false, 0

(58) SortMergeJoin [codegen id : 22]
Left keys [1]: [ws_bill_customer_sk#36]
Right keys [1]: [c_customer_sk#41]
Join type: LeftSemi
Join condition: None

(59) Project [codegen id : 22]
Output [3]: [ws_quantity#37, ws_list_price#38, ws_sold_date_sk#39]
Input [4]: [ws_bill_customer_sk#36, ws_quantity#37, ws_list_price#38, ws_sold_date_sk#39]

(60) ReusedExchange [Reuses operator id: 71]
Output [1]: [d_date_sk#47]

(61) BroadcastHashJoin [codegen id : 22]
Left keys [1]: [ws_sold_date_sk#39]
Right keys [1]: [d_date_sk#47]
Join type: Inner
Join condition: None

(62) Project [codegen id : 22]
Output [1]: [(cast(ws_quantity#37 as decimal(10,0)) * ws_list_price#38) AS sales#48]
Input [4]: [ws_quantity#37, ws_list_price#38, ws_sold_date_sk#39, d_date_sk#47]

(63) Union

(64) HashAggregate [codegen id : 23]
Input [1]: [sales#34]
Keys: []
Functions [1]: [partial_sum(sales#34)]
Aggregate Attributes [2]: [sum#49, isEmpty#50]
Results [2]: [sum#51, isEmpty#52]

(65) Exchange
Input [2]: [sum#51, isEmpty#52]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=8]

(66) HashAggregate [codegen id : 24]
Input [2]: [sum#51, isEmpty#52]
Keys: []
Functions [1]: [sum(sales#34)]
Aggregate Attributes [1]: [sum(sales#34)#53]
Results [1]: [sum(sales#34)#53 AS sum(sales)#54]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = cs_sold_date_sk#5 IN dynamicpruning#6
BroadcastExchange (71)
+- * Project (70)
   +- * Filter (69)
      +- * ColumnarToRow (68)
         +- Scan parquet spark_catalog.default.date_dim (67)


(67) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#33, d_year#55, d_moy#56]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_year), IsNotNull(d_moy), EqualTo(d_year,2000), EqualTo(d_moy,2), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>

(68) ColumnarToRow [codegen id : 1]
Input [3]: [d_date_sk#33, d_year#55, d_moy#56]

(69) Filter [codegen id : 1]
Input [3]: [d_date_sk#33, d_year#55, d_moy#56]
Condition : ((((isnotnull(d_year#55) AND isnotnull(d_moy#56)) AND (d_year#55 = 2000)) AND (d_moy#56 = 2)) AND isnotnull(d_date_sk#33))

(70) Project [codegen id : 1]
Output [1]: [d_date_sk#33]
Input [3]: [d_date_sk#33, d_year#55, d_moy#56]

(71) BroadcastExchange
Input [1]: [d_date_sk#33]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=9]

Subquery:2 Hosting operator id = 3 Hosting Expression = ss_sold_date_sk#8 IN dynamicpruning#9
BroadcastExchange (76)
+- * Project (75)
   +- * Filter (74)
      +- * ColumnarToRow (73)
         +- Scan parquet spark_catalog.default.date_dim (72)


(72) Scan parquet spark_catalog.default.date_dim
Output [3]: [d_date_sk#10, d_date#11, d_year#57]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [In(d_year, [2000,2001,2002,2003]), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date,d_year:int>

(73) ColumnarToRow [codegen id : 1]
Input [3]: [d_date_sk#10, d_date#11, d_year#57]

(74) Filter [codegen id : 1]
Input [3]: [d_date_sk#10, d_date#11, d_year#57]
Condition : (d_year#57 IN (2000,2001,2002,2003) AND isnotnull(d_date_sk#10))

(75) Project [codegen id : 1]
Output [2]: [d_date_sk#10, d_date#11]
Input [3]: [d_date_sk#10, d_date#11, d_year#57]

(76) BroadcastExchange
Input [2]: [d_date_sk#10, d_date#11]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=10]

Subquery:3 Hosting operator id = 38 Hosting Expression = Subquery scalar-subquery#31, [id=#32]
* HashAggregate (91)
+- Exchange (90)
   +- * HashAggregate (89)
      +- * HashAggregate (88)
         +- Exchange (87)
            +- * HashAggregate (86)
               +- * Project (85)
                  +- * BroadcastHashJoin Inner BuildRight (84)
                     :- * Project (82)
                     :  +- * BroadcastHashJoin Inner BuildRight (81)
                     :     :- * Filter (79)
                     :     :  +- * ColumnarToRow (78)
                     :     :     +- Scan parquet spark_catalog.default.store_sales (77)
                     :     +- ReusedExchange (80)
                     +- ReusedExchange (83)


(77) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_customer_sk#58, ss_quantity#59, ss_sales_price#60, ss_sold_date_sk#61]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#61), dynamicpruningexpression(ss_sold_date_sk#61 IN dynamicpruning#62)]
PushedFilters: [IsNotNull(ss_customer_sk)]
ReadSchema: struct<ss_customer_sk:int,ss_quantity:int,ss_sales_price:decimal(7,2)>

(78) ColumnarToRow [codegen id : 3]
Input [4]: [ss_customer_sk#58, ss_quantity#59, ss_sales_price#60, ss_sold_date_sk#61]

(79) Filter [codegen id : 3]
Input [4]: [ss_customer_sk#58, ss_quantity#59, ss_sales_price#60, ss_sold_date_sk#61]
Condition : isnotnull(ss_customer_sk#58)

(80) ReusedExchange [Reuses operator id: 32]
Output [1]: [c_customer_sk#63]

(81) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_customer_sk#58]
Right keys [1]: [c_customer_sk#63]
Join type: Inner
Join condition: None

(82) Project [codegen id : 3]
Output [4]: [ss_quantity#59, ss_sales_price#60, ss_sold_date_sk#61, c_customer_sk#63]
Input [5]: [ss_customer_sk#58, ss_quantity#59, ss_sales_price#60, ss_sold_date_sk#61, c_customer_sk#63]

(83) ReusedExchange [Reuses operator id: 96]
Output [1]: [d_date_sk#64]

(84) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_sold_date_sk#61]
Right keys [1]: [d_date_sk#64]
Join type: Inner
Join condition: None

(85) Project [codegen id : 3]
Output [3]: [ss_quantity#59, ss_sales_price#60, c_customer_sk#63]
Input [5]: [ss_quantity#59, ss_sales_price#60, ss_sold_date_sk#61, c_customer_sk#63, d_date_sk#64]

(86) HashAggregate [codegen id : 3]
Input [3]: [ss_quantity#59, ss_sales_price#60, c_customer_sk#63]
Keys [1]: [c_customer_sk#63]
Functions [1]: [partial_sum((cast(ss_quantity#59 as decimal(10,0)) * ss_sales_price#60))]
Aggregate Attributes [2]: [sum#65, isEmpty#66]
Results [3]: [c_customer_sk#63, sum#67, isEmpty#68]

(87) Exchange
Input [3]: [c_customer_sk#63, sum#67, isEmpty#68]
Arguments: hashpartitioning(c_customer_sk#63, 5), ENSURE_REQUIREMENTS, [plan_id=11]

(88) HashAggregate [codegen id : 4]
Input [3]: [c_customer_sk#63, sum#67, isEmpty#68]
Keys [1]: [c_customer_sk#63]
Functions [1]: [sum((cast(ss_quantity#59 as decimal(10,0)) * ss_sales_price#60))]
Aggregate Attributes [1]: [sum((cast(ss_quantity#59 as decimal(10,0)) * ss_sales_price#60))#69]
Results [1]: [sum((cast(ss_quantity#59 as decimal(10,0)) * ss_sales_price#60))#69 AS csales#70]

(89) HashAggregate [codegen id : 4]
Input [1]: [csales#70]
Keys: []
Functions [1]: [partial_max(csales#70)]
Aggregate Attributes [1]: [max#71]
Results [1]: [max#72]

(90) Exchange
Input [1]: [max#72]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=12]

(91) HashAggregate [codegen id : 5]
Input [1]: [max#72]
Keys: []
Functions [1]: [max(csales#70)]
Aggregate Attributes [1]: [max(csales#70)#73]
Results [1]: [max(csales#70)#73 AS tpcds_cmax#74]

Subquery:4 Hosting operator id = 77 Hosting Expression = ss_sold_date_sk#61 IN dynamicpruning#62
BroadcastExchange (96)
+- * Project (95)
   +- * Filter (94)
      +- * ColumnarToRow (93)
         +- Scan parquet spark_catalog.default.date_dim (92)


(92) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#64, d_year#75]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [In(d_year, [2000,2001,2002,2003]), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_year:int>

(93) ColumnarToRow [codegen id : 1]
Input [2]: [d_date_sk#64, d_year#75]

(94) Filter [codegen id : 1]
Input [2]: [d_date_sk#64, d_year#75]
Condition : (d_year#75 IN (2000,2001,2002,2003) AND isnotnull(d_date_sk#64))

(95) Project [codegen id : 1]
Output [1]: [d_date_sk#64]
Input [2]: [d_date_sk#64, d_year#75]

(96) BroadcastExchange
Input [1]: [d_date_sk#64]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=13]

Subquery:5 Hosting operator id = 46 Hosting Expression = ws_sold_date_sk#39 IN dynamicpruning#6

Subquery:6 Hosting operator id = 55 Hosting Expression = ReusedSubquery Subquery scalar-subquery#31, [id=#32]


