== Physical Plan ==
TakeOrderedAndProject (49)
+- * Project (48)
   +- * BroadcastHashJoin Inner BuildRight (47)
      :- * Project (32)
      :  +- * BroadcastHashJoin Inner BuildRight (31)
      :     :- * Filter (16)
      :     :  +- * HashAggregate (15)
      :     :     +- Exchange (14)
      :     :        +- * HashAggregate (13)
      :     :           +- * Project (12)
      :     :              +- * BroadcastHashJoin Inner BuildRight (11)
      :     :                 :- * Project (6)
      :     :                 :  +- * BroadcastHashJoin Inner BuildRight (5)
      :     :                 :     :- * Filter (3)
      :     :                 :     :  +- * ColumnarToRow (2)
      :     :                 :     :     +- Scan parquet spark_catalog.default.store_sales (1)
      :     :                 :     +- ReusedExchange (4)
      :     :                 +- BroadcastExchange (10)
      :     :                    +- * Filter (9)
      :     :                       +- * ColumnarToRow (8)
      :     :                          +- Scan parquet spark_catalog.default.item (7)
      :     +- BroadcastExchange (30)
      :        +- * Filter (29)
      :           +- * HashAggregate (28)
      :              +- Exchange (27)
      :                 +- * HashAggregate (26)
      :                    +- * Project (25)
      :                       +- * BroadcastHashJoin Inner BuildRight (24)
      :                          :- * Project (22)
      :                          :  +- * BroadcastHashJoin Inner BuildRight (21)
      :                          :     :- * Filter (19)
      :                          :     :  +- * ColumnarToRow (18)
      :                          :     :     +- Scan parquet spark_catalog.default.catalog_sales (17)
      :                          :     +- ReusedExchange (20)
      :                          +- ReusedExchange (23)
      +- BroadcastExchange (46)
         +- * Filter (45)
            +- * HashAggregate (44)
               +- Exchange (43)
                  +- * HashAggregate (42)
                     +- * Project (41)
                        +- * BroadcastHashJoin Inner BuildRight (40)
                           :- * Project (38)
                           :  +- * BroadcastHashJoin Inner BuildRight (37)
                           :     :- * Filter (35)
                           :     :  +- * ColumnarToRow (34)
                           :     :     +- Scan parquet spark_catalog.default.web_sales (33)
                           :     +- ReusedExchange (36)
                           +- ReusedExchange (39)


(1) Scan parquet spark_catalog.default.store_sales
Output [3]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#3), dynamicpruningexpression(ss_sold_date_sk#3 IN dynamicpruning#4)]
PushedFilters: [IsNotNull(ss_item_sk)]
ReadSchema: struct<ss_item_sk:int,ss_ext_sales_price:decimal(7,2)>

(2) ColumnarToRow [codegen id : 4]
Input [3]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3]

(3) Filter [codegen id : 4]
Input [3]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3]
Condition : isnotnull(ss_item_sk#1)

(4) ReusedExchange [Reuses operator id: 60]
Output [1]: [d_date_sk#5]

(5) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_sold_date_sk#3]
Right keys [1]: [d_date_sk#5]
Join type: Inner
Join condition: None

(6) Project [codegen id : 4]
Output [2]: [ss_item_sk#1, ss_ext_sales_price#2]
Input [4]: [ss_item_sk#1, ss_ext_sales_price#2, ss_sold_date_sk#3, d_date_sk#5]

(7) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#6, i_item_id#7]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_item_sk), IsNotNull(i_item_id)]
ReadSchema: struct<i_item_sk:int,i_item_id:string>

(8) ColumnarToRow [codegen id : 3]
Input [2]: [i_item_sk#6, i_item_id#7]

(9) Filter [codegen id : 3]
Input [2]: [i_item_sk#6, i_item_id#7]
Condition : (isnotnull(i_item_sk#6) AND isnotnull(i_item_id#7))

(10) BroadcastExchange
Input [2]: [i_item_sk#6, i_item_id#7]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1]

(11) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_item_sk#1]
Right keys [1]: [i_item_sk#6]
Join type: Inner
Join condition: None

(12) Project [codegen id : 4]
Output [2]: [ss_ext_sales_price#2, i_item_id#7]
Input [4]: [ss_item_sk#1, ss_ext_sales_price#2, i_item_sk#6, i_item_id#7]

(13) HashAggregate [codegen id : 4]
Input [2]: [ss_ext_sales_price#2, i_item_id#7]
Keys [1]: [i_item_id#7]
Functions [1]: [partial_sum(UnscaledValue(ss_ext_sales_price#2))]
Aggregate Attributes [1]: [sum#8]
Results [2]: [i_item_id#7, sum#9]

(14) Exchange
Input [2]: [i_item_id#7, sum#9]
Arguments: hashpartitioning(i_item_id#7, 5), ENSURE_REQUIREMENTS, [plan_id=2]

(15) HashAggregate [codegen id : 15]
Input [2]: [i_item_id#7, sum#9]
Keys [1]: [i_item_id#7]
Functions [1]: [sum(UnscaledValue(ss_ext_sales_price#2))]
Aggregate Attributes [1]: [sum(UnscaledValue(ss_ext_sales_price#2))#10]
Results [2]: [i_item_id#7 AS item_id#11, MakeDecimal(sum(UnscaledValue(ss_ext_sales_price#2))#10,17,2) AS ss_item_rev#12]

(16) Filter [codegen id : 15]
Input [2]: [item_id#11, ss_item_rev#12]
Condition : isnotnull(ss_item_rev#12)

(17) Scan parquet spark_catalog.default.catalog_sales
Output [3]: [cs_item_sk#13, cs_ext_sales_price#14, cs_sold_date_sk#15]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#15), dynamicpruningexpression(cs_sold_date_sk#15 IN dynamicpruning#4)]
PushedFilters: [IsNotNull(cs_item_sk)]
ReadSchema: struct<cs_item_sk:int,cs_ext_sales_price:decimal(7,2)>

(18) ColumnarToRow [codegen id : 8]
Input [3]: [cs_item_sk#13, cs_ext_sales_price#14, cs_sold_date_sk#15]

(19) Filter [codegen id : 8]
Input [3]: [cs_item_sk#13, cs_ext_sales_price#14, cs_sold_date_sk#15]
Condition : isnotnull(cs_item_sk#13)

(20) ReusedExchange [Reuses operator id: 60]
Output [1]: [d_date_sk#16]

(21) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [cs_sold_date_sk#15]
Right keys [1]: [d_date_sk#16]
Join type: Inner
Join condition: None

(22) Project [codegen id : 8]
Output [2]: [cs_item_sk#13, cs_ext_sales_price#14]
Input [4]: [cs_item_sk#13, cs_ext_sales_price#14, cs_sold_date_sk#15, d_date_sk#16]

(23) ReusedExchange [Reuses operator id: 10]
Output [2]: [i_item_sk#17, i_item_id#18]

(24) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [cs_item_sk#13]
Right keys [1]: [i_item_sk#17]
Join type: Inner
Join condition: None

(25) Project [codegen id : 8]
Output [2]: [cs_ext_sales_price#14, i_item_id#18]
Input [4]: [cs_item_sk#13, cs_ext_sales_price#14, i_item_sk#17, i_item_id#18]

(26) HashAggregate [codegen id : 8]
Input [2]: [cs_ext_sales_price#14, i_item_id#18]
Keys [1]: [i_item_id#18]
Functions [1]: [partial_sum(UnscaledValue(cs_ext_sales_price#14))]
Aggregate Attributes [1]: [sum#19]
Results [2]: [i_item_id#18, sum#20]

(27) Exchange
Input [2]: [i_item_id#18, sum#20]
Arguments: hashpartitioning(i_item_id#18, 5), ENSURE_REQUIREMENTS, [plan_id=3]

(28) HashAggregate [codegen id : 9]
Input [2]: [i_item_id#18, sum#20]
Keys [1]: [i_item_id#18]
Functions [1]: [sum(UnscaledValue(cs_ext_sales_price#14))]
Aggregate Attributes [1]: [sum(UnscaledValue(cs_ext_sales_price#14))#21]
Results [2]: [i_item_id#18 AS item_id#22, MakeDecimal(sum(UnscaledValue(cs_ext_sales_price#14))#21,17,2) AS cs_item_rev#23]

(29) Filter [codegen id : 9]
Input [2]: [item_id#22, cs_item_rev#23]
Condition : isnotnull(cs_item_rev#23)

(30) BroadcastExchange
Input [2]: [item_id#22, cs_item_rev#23]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=4]

(31) BroadcastHashJoin [codegen id : 15]
Left keys [1]: [item_id#11]
Right keys [1]: [item_id#22]
Join type: Inner
Join condition: ((((cast(ss_item_rev#12 as decimal(19,3)) >= (0.9 * cs_item_rev#23)) AND (cast(ss_item_rev#12 as decimal(20,3)) <= (1.1 * cs_item_rev#23))) AND (cast(cs_item_rev#23 as decimal(19,3)) >= (0.9 * ss_item_rev#12))) AND (cast(cs_item_rev#23 as decimal(20,3)) <= (1.1 * ss_item_rev#12)))

(32) Project [codegen id : 15]
Output [3]: [item_id#11, ss_item_rev#12, cs_item_rev#23]
Input [4]: [item_id#11, ss_item_rev#12, item_id#22, cs_item_rev#23]

(33) Scan parquet spark_catalog.default.web_sales
Output [3]: [ws_item_sk#24, ws_ext_sales_price#25, ws_sold_date_sk#26]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#26), dynamicpruningexpression(ws_sold_date_sk#26 IN dynamicpruning#4)]
PushedFilters: [IsNotNull(ws_item_sk)]
ReadSchema: struct<ws_item_sk:int,ws_ext_sales_price:decimal(7,2)>

(34) ColumnarToRow [codegen id : 13]
Input [3]: [ws_item_sk#24, ws_ext_sales_price#25, ws_sold_date_sk#26]

(35) Filter [codegen id : 13]
Input [3]: [ws_item_sk#24, ws_ext_sales_price#25, ws_sold_date_sk#26]
Condition : isnotnull(ws_item_sk#24)

(36) ReusedExchange [Reuses operator id: 60]
Output [1]: [d_date_sk#27]

(37) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ws_sold_date_sk#26]
Right keys [1]: [d_date_sk#27]
Join type: Inner
Join condition: None

(38) Project [codegen id : 13]
Output [2]: [ws_item_sk#24, ws_ext_sales_price#25]
Input [4]: [ws_item_sk#24, ws_ext_sales_price#25, ws_sold_date_sk#26, d_date_sk#27]

(39) ReusedExchange [Reuses operator id: 10]
Output [2]: [i_item_sk#28, i_item_id#29]

(40) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ws_item_sk#24]
Right keys [1]: [i_item_sk#28]
Join type: Inner
Join condition: None

(41) Project [codegen id : 13]
Output [2]: [ws_ext_sales_price#25, i_item_id#29]
Input [4]: [ws_item_sk#24, ws_ext_sales_price#25, i_item_sk#28, i_item_id#29]

(42) HashAggregate [codegen id : 13]
Input [2]: [ws_ext_sales_price#25, i_item_id#29]
Keys [1]: [i_item_id#29]
Functions [1]: [partial_sum(UnscaledValue(ws_ext_sales_price#25))]
Aggregate Attributes [1]: [sum#30]
Results [2]: [i_item_id#29, sum#31]

(43) Exchange
Input [2]: [i_item_id#29, sum#31]
Arguments: hashpartitioning(i_item_id#29, 5), ENSURE_REQUIREMENTS, [plan_id=5]

(44) HashAggregate [codegen id : 14]
Input [2]: [i_item_id#29, sum#31]
Keys [1]: [i_item_id#29]
Functions [1]: [sum(UnscaledValue(ws_ext_sales_price#25))]
Aggregate Attributes [1]: [sum(UnscaledValue(ws_ext_sales_price#25))#32]
Results [2]: [i_item_id#29 AS item_id#33, MakeDecimal(sum(UnscaledValue(ws_ext_sales_price#25))#32,17,2) AS ws_item_rev#34]

(45) Filter [codegen id : 14]
Input [2]: [item_id#33, ws_item_rev#34]
Condition : isnotnull(ws_item_rev#34)

(46) BroadcastExchange
Input [2]: [item_id#33, ws_item_rev#34]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=6]

(47) BroadcastHashJoin [codegen id : 15]
Left keys [1]: [item_id#11]
Right keys [1]: [item_id#33]
Join type: Inner
Join condition: ((((((((cast(ss_item_rev#12 as decimal(19,3)) >= (0.9 * ws_item_rev#34)) AND (cast(ss_item_rev#12 as decimal(20,3)) <= (1.1 * ws_item_rev#34))) AND (cast(cs_item_rev#23 as decimal(19,3)) >= (0.9 * ws_item_rev#34))) AND (cast(cs_item_rev#23 as decimal(20,3)) <= (1.1 * ws_item_rev#34))) AND (cast(ws_item_rev#34 as decimal(19,3)) >= (0.9 * ss_item_rev#12))) AND (cast(ws_item_rev#34 as decimal(20,3)) <= (1.1 * ss_item_rev#12))) AND (cast(ws_item_rev#34 as decimal(19,3)) >= (0.9 * cs_item_rev#23))) AND (cast(ws_item_rev#34 as decimal(20,3)) <= (1.1 * cs_item_rev#23)))

(48) Project [codegen id : 15]
Output [8]: [item_id#11, ss_item_rev#12, (((ss_item_rev#12 / ((ss_item_rev#12 + cs_item_rev#23) + ws_item_rev#34)) / 3) * 100) AS ss_dev#35, cs_item_rev#23, (((cs_item_rev#23 / ((ss_item_rev#12 + cs_item_rev#23) + ws_item_rev#34)) / 3) * 100) AS cs_dev#36, ws_item_rev#34, (((ws_item_rev#34 / ((ss_item_rev#12 + cs_item_rev#23) + ws_item_rev#34)) / 3) * 100) AS ws_dev#37, (((ss_item_rev#12 + cs_item_rev#23) + ws_item_rev#34) / 3) AS average#38]
Input [5]: [item_id#11, ss_item_rev#12, cs_item_rev#23, item_id#33, ws_item_rev#34]

(49) TakeOrderedAndProject
Input [8]: [item_id#11, ss_item_rev#12, ss_dev#35, cs_item_rev#23, cs_dev#36, ws_item_rev#34, ws_dev#37, average#38]
Arguments: 100, [item_id#11 ASC NULLS FIRST, ss_item_rev#12 ASC NULLS FIRST], [item_id#11, ss_item_rev#12, ss_dev#35, cs_item_rev#23, cs_dev#36, ws_item_rev#34, ws_dev#37, average#38]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#3 IN dynamicpruning#4
BroadcastExchange (60)
+- * Project (59)
   +- * BroadcastHashJoin LeftSemi BuildRight (58)
      :- * Filter (52)
      :  +- * ColumnarToRow (51)
      :     +- Scan parquet spark_catalog.default.date_dim (50)
      +- BroadcastExchange (57)
         +- * Project (56)
            +- * Filter (55)
               +- * ColumnarToRow (54)
                  +- Scan parquet spark_catalog.default.date_dim (53)


(50) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#5, d_date#39]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(51) ColumnarToRow [codegen id : 2]
Input [2]: [d_date_sk#5, d_date#39]

(52) Filter [codegen id : 2]
Input [2]: [d_date_sk#5, d_date#39]
Condition : isnotnull(d_date_sk#5)

(53) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date#40, d_week_seq#41]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_week_seq), EqualTo(d_week_seq,ScalarSubquery#42)]
ReadSchema: struct<d_date:date,d_week_seq:int>

(54) ColumnarToRow [codegen id : 1]
Input [2]: [d_date#40, d_week_seq#41]

(55) Filter [codegen id : 1]
Input [2]: [d_date#40, d_week_seq#41]
Condition : (isnotnull(d_week_seq#41) AND (d_week_seq#41 = ReusedSubquery Subquery scalar-subquery#42, [id=#43]))

(56) Project [codegen id : 1]
Output [1]: [d_date#40]
Input [2]: [d_date#40, d_week_seq#41]

(57) BroadcastExchange
Input [1]: [d_date#40]
Arguments: HashedRelationBroadcastMode(List(input[0, date, true]),false), [plan_id=7]

(58) BroadcastHashJoin [codegen id : 2]
Left keys [1]: [d_date#39]
Right keys [1]: [d_date#40]
Join type: LeftSemi
Join condition: None

(59) Project [codegen id : 2]
Output [1]: [d_date_sk#5]
Input [2]: [d_date_sk#5, d_date#39]

(60) BroadcastExchange
Input [1]: [d_date_sk#5]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=8]

Subquery:2 Hosting operator id = 55 Hosting Expression = ReusedSubquery Subquery scalar-subquery#42, [id=#43]

Subquery:3 Hosting operator id = 53 Hosting Expression = Subquery scalar-subquery#42, [id=#43]
* Project (64)
+- * Filter (63)
   +- * ColumnarToRow (62)
      +- Scan parquet spark_catalog.default.date_dim (61)


(61) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date#44, d_week_seq#45]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), EqualTo(d_date,2000-01-03)]
ReadSchema: struct<d_date:date,d_week_seq:int>

(62) ColumnarToRow [codegen id : 1]
Input [2]: [d_date#44, d_week_seq#45]

(63) Filter [codegen id : 1]
Input [2]: [d_date#44, d_week_seq#45]
Condition : (isnotnull(d_date#44) AND (d_date#44 = 2000-01-03))

(64) Project [codegen id : 1]
Output [1]: [d_week_seq#45]
Input [2]: [d_date#44, d_week_seq#45]

Subquery:4 Hosting operator id = 17 Hosting Expression = cs_sold_date_sk#15 IN dynamicpruning#4

Subquery:5 Hosting operator id = 33 Hosting Expression = ws_sold_date_sk#26 IN dynamicpruning#4


