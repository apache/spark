== Physical Plan ==
TakeOrderedAndProject (107)
+- * HashAggregate (106)
   +- Exchange (105)
      +- * HashAggregate (104)
         +- * Expand (103)
            +- Union (102)
               :- * HashAggregate (39)
               :  +- Exchange (38)
               :     +- * HashAggregate (37)
               :        +- * Project (36)
               :           +- * BroadcastHashJoin Inner BuildRight (35)
               :              :- * Project (30)
               :              :  +- * BroadcastHashJoin Inner BuildRight (29)
               :              :     :- * Project (27)
               :              :     :  +- * BroadcastHashJoin Inner BuildRight (26)
               :              :     :     :- * Project (20)
               :              :     :     :  +- * BroadcastHashJoin Inner BuildRight (19)
               :              :     :     :     :- * Project (13)
               :              :     :     :     :  +- * SortMergeJoin LeftOuter (12)
               :              :     :     :     :     :- * Sort (5)
               :              :     :     :     :     :  +- Exchange (4)
               :              :     :     :     :     :     +- * Filter (3)
               :              :     :     :     :     :        +- * ColumnarToRow (2)
               :              :     :     :     :     :           +- Scan parquet spark_catalog.default.store_sales (1)
               :              :     :     :     :     +- * Sort (11)
               :              :     :     :     :        +- Exchange (10)
               :              :     :     :     :           +- * Project (9)
               :              :     :     :     :              +- * Filter (8)
               :              :     :     :     :                 +- * ColumnarToRow (7)
               :              :     :     :     :                    +- Scan parquet spark_catalog.default.store_returns (6)
               :              :     :     :     +- BroadcastExchange (18)
               :              :     :     :        +- * Project (17)
               :              :     :     :           +- * Filter (16)
               :              :     :     :              +- * ColumnarToRow (15)
               :              :     :     :                 +- Scan parquet spark_catalog.default.item (14)
               :              :     :     +- BroadcastExchange (25)
               :              :     :        +- * Project (24)
               :              :     :           +- * Filter (23)
               :              :     :              +- * ColumnarToRow (22)
               :              :     :                 +- Scan parquet spark_catalog.default.promotion (21)
               :              :     +- ReusedExchange (28)
               :              +- BroadcastExchange (34)
               :                 +- * Filter (33)
               :                    +- * ColumnarToRow (32)
               :                       +- Scan parquet spark_catalog.default.store (31)
               :- * HashAggregate (70)
               :  +- Exchange (69)
               :     +- * HashAggregate (68)
               :        +- * Project (67)
               :           +- * BroadcastHashJoin Inner BuildRight (66)
               :              :- * Project (61)
               :              :  +- * BroadcastHashJoin Inner BuildRight (60)
               :              :     :- * Project (58)
               :              :     :  +- * BroadcastHashJoin Inner BuildRight (57)
               :              :     :     :- * Project (55)
               :              :     :     :  +- * BroadcastHashJoin Inner BuildRight (54)
               :              :     :     :     :- * Project (52)
               :              :     :     :     :  +- * SortMergeJoin LeftOuter (51)
               :              :     :     :     :     :- * Sort (44)
               :              :     :     :     :     :  +- Exchange (43)
               :              :     :     :     :     :     +- * Filter (42)
               :              :     :     :     :     :        +- * ColumnarToRow (41)
               :              :     :     :     :     :           +- Scan parquet spark_catalog.default.catalog_sales (40)
               :              :     :     :     :     +- * Sort (50)
               :              :     :     :     :        +- Exchange (49)
               :              :     :     :     :           +- * Project (48)
               :              :     :     :     :              +- * Filter (47)
               :              :     :     :     :                 +- * ColumnarToRow (46)
               :              :     :     :     :                    +- Scan parquet spark_catalog.default.catalog_returns (45)
               :              :     :     :     +- ReusedExchange (53)
               :              :     :     +- ReusedExchange (56)
               :              :     +- ReusedExchange (59)
               :              +- BroadcastExchange (65)
               :                 +- * Filter (64)
               :                    +- * ColumnarToRow (63)
               :                       +- Scan parquet spark_catalog.default.catalog_page (62)
               +- * HashAggregate (101)
                  +- Exchange (100)
                     +- * HashAggregate (99)
                        +- * Project (98)
                           +- * BroadcastHashJoin Inner BuildRight (97)
                              :- * Project (92)
                              :  +- * BroadcastHashJoin Inner BuildRight (91)
                              :     :- * Project (89)
                              :     :  +- * BroadcastHashJoin Inner BuildRight (88)
                              :     :     :- * Project (86)
                              :     :     :  +- * BroadcastHashJoin Inner BuildRight (85)
                              :     :     :     :- * Project (83)
                              :     :     :     :  +- * SortMergeJoin LeftOuter (82)
                              :     :     :     :     :- * Sort (75)
                              :     :     :     :     :  +- Exchange (74)
                              :     :     :     :     :     +- * Filter (73)
                              :     :     :     :     :        +- * ColumnarToRow (72)
                              :     :     :     :     :           +- Scan parquet spark_catalog.default.web_sales (71)
                              :     :     :     :     +- * Sort (81)
                              :     :     :     :        +- Exchange (80)
                              :     :     :     :           +- * Project (79)
                              :     :     :     :              +- * Filter (78)
                              :     :     :     :                 +- * ColumnarToRow (77)
                              :     :     :     :                    +- Scan parquet spark_catalog.default.web_returns (76)
                              :     :     :     +- ReusedExchange (84)
                              :     :     +- ReusedExchange (87)
                              :     +- ReusedExchange (90)
                              +- BroadcastExchange (96)
                                 +- * Filter (95)
                                    +- * ColumnarToRow (94)
                                       +- Scan parquet spark_catalog.default.web_site (93)


(1) Scan parquet spark_catalog.default.store_sales
Output [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#7), dynamicpruningexpression(ss_sold_date_sk#7 IN dynamicpruning#8)]
PushedFilters: [IsNotNull(ss_store_sk), IsNotNull(ss_item_sk), IsNotNull(ss_promo_sk)]
ReadSchema: struct<ss_item_sk:int,ss_store_sk:int,ss_promo_sk:int,ss_ticket_number:int,ss_ext_sales_price:decimal(7,2),ss_net_profit:decimal(7,2)>

(2) ColumnarToRow [codegen id : 1]
Input [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]

(3) Filter [codegen id : 1]
Input [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]
Condition : ((((isnotnull(ss_store_sk#2) AND isnotnull(ss_item_sk#1)) AND isnotnull(ss_promo_sk#3)) AND might_contain(Subquery scalar-subquery#9, [id=#10], xxhash64(ss_item_sk#1, 42))) AND might_contain(Subquery scalar-subquery#11, [id=#12], xxhash64(ss_promo_sk#3, 42)))

(4) Exchange
Input [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]
Arguments: hashpartitioning(ss_item_sk#1, ss_ticket_number#4, 5), ENSURE_REQUIREMENTS, [plan_id=1]

(5) Sort [codegen id : 2]
Input [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]
Arguments: [ss_item_sk#1 ASC NULLS FIRST, ss_ticket_number#4 ASC NULLS FIRST], false, 0

(6) Scan parquet spark_catalog.default.store_returns
Output [5]: [sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16, sr_returned_date_sk#17]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_returns]
PushedFilters: [IsNotNull(sr_item_sk), IsNotNull(sr_ticket_number)]
ReadSchema: struct<sr_item_sk:int,sr_ticket_number:int,sr_return_amt:decimal(7,2),sr_net_loss:decimal(7,2)>

(7) ColumnarToRow [codegen id : 3]
Input [5]: [sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16, sr_returned_date_sk#17]

(8) Filter [codegen id : 3]
Input [5]: [sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16, sr_returned_date_sk#17]
Condition : (isnotnull(sr_item_sk#13) AND isnotnull(sr_ticket_number#14))

(9) Project [codegen id : 3]
Output [4]: [sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16]
Input [5]: [sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16, sr_returned_date_sk#17]

(10) Exchange
Input [4]: [sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16]
Arguments: hashpartitioning(sr_item_sk#13, sr_ticket_number#14, 5), ENSURE_REQUIREMENTS, [plan_id=2]

(11) Sort [codegen id : 4]
Input [4]: [sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16]
Arguments: [sr_item_sk#13 ASC NULLS FIRST, sr_ticket_number#14 ASC NULLS FIRST], false, 0

(12) SortMergeJoin [codegen id : 9]
Left keys [2]: [ss_item_sk#1, ss_ticket_number#4]
Right keys [2]: [sr_item_sk#13, sr_ticket_number#14]
Join type: LeftOuter
Join condition: None

(13) Project [codegen id : 9]
Output [8]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#15, sr_net_loss#16]
Input [11]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_item_sk#13, sr_ticket_number#14, sr_return_amt#15, sr_net_loss#16]

(14) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#18, i_current_price#19]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_current_price), GreaterThan(i_current_price,50.00), IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_current_price:decimal(7,2)>

(15) ColumnarToRow [codegen id : 5]
Input [2]: [i_item_sk#18, i_current_price#19]

(16) Filter [codegen id : 5]
Input [2]: [i_item_sk#18, i_current_price#19]
Condition : ((isnotnull(i_current_price#19) AND (i_current_price#19 > 50.00)) AND isnotnull(i_item_sk#18))

(17) Project [codegen id : 5]
Output [1]: [i_item_sk#18]
Input [2]: [i_item_sk#18, i_current_price#19]

(18) BroadcastExchange
Input [1]: [i_item_sk#18]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(19) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ss_item_sk#1]
Right keys [1]: [i_item_sk#18]
Join type: Inner
Join condition: None

(20) Project [codegen id : 9]
Output [7]: [ss_store_sk#2, ss_promo_sk#3, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#15, sr_net_loss#16]
Input [9]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#15, sr_net_loss#16, i_item_sk#18]

(21) Scan parquet spark_catalog.default.promotion
Output [2]: [p_promo_sk#20, p_channel_tv#21]
Batched: true
Location [not included in comparison]/{warehouse_dir}/promotion]
PushedFilters: [IsNotNull(p_channel_tv), EqualTo(p_channel_tv,N), IsNotNull(p_promo_sk)]
ReadSchema: struct<p_promo_sk:int,p_channel_tv:string>

(22) ColumnarToRow [codegen id : 6]
Input [2]: [p_promo_sk#20, p_channel_tv#21]

(23) Filter [codegen id : 6]
Input [2]: [p_promo_sk#20, p_channel_tv#21]
Condition : ((isnotnull(p_channel_tv#21) AND (p_channel_tv#21 = N)) AND isnotnull(p_promo_sk#20))

(24) Project [codegen id : 6]
Output [1]: [p_promo_sk#20]
Input [2]: [p_promo_sk#20, p_channel_tv#21]

(25) BroadcastExchange
Input [1]: [p_promo_sk#20]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=4]

(26) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ss_promo_sk#3]
Right keys [1]: [p_promo_sk#20]
Join type: Inner
Join condition: None

(27) Project [codegen id : 9]
Output [6]: [ss_store_sk#2, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#15, sr_net_loss#16]
Input [8]: [ss_store_sk#2, ss_promo_sk#3, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#15, sr_net_loss#16, p_promo_sk#20]

(28) ReusedExchange [Reuses operator id: 126]
Output [1]: [d_date_sk#22]

(29) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ss_sold_date_sk#7]
Right keys [1]: [d_date_sk#22]
Join type: Inner
Join condition: None

(30) Project [codegen id : 9]
Output [5]: [ss_store_sk#2, ss_ext_sales_price#5, ss_net_profit#6, sr_return_amt#15, sr_net_loss#16]
Input [7]: [ss_store_sk#2, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#15, sr_net_loss#16, d_date_sk#22]

(31) Scan parquet spark_catalog.default.store
Output [2]: [s_store_sk#23, s_store_id#24]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int,s_store_id:string>

(32) ColumnarToRow [codegen id : 8]
Input [2]: [s_store_sk#23, s_store_id#24]

(33) Filter [codegen id : 8]
Input [2]: [s_store_sk#23, s_store_id#24]
Condition : isnotnull(s_store_sk#23)

(34) BroadcastExchange
Input [2]: [s_store_sk#23, s_store_id#24]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=5]

(35) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ss_store_sk#2]
Right keys [1]: [s_store_sk#23]
Join type: Inner
Join condition: None

(36) Project [codegen id : 9]
Output [5]: [ss_ext_sales_price#5, ss_net_profit#6, sr_return_amt#15, sr_net_loss#16, s_store_id#24]
Input [7]: [ss_store_sk#2, ss_ext_sales_price#5, ss_net_profit#6, sr_return_amt#15, sr_net_loss#16, s_store_sk#23, s_store_id#24]

(37) HashAggregate [codegen id : 9]
Input [5]: [ss_ext_sales_price#5, ss_net_profit#6, sr_return_amt#15, sr_net_loss#16, s_store_id#24]
Keys [1]: [s_store_id#24]
Functions [3]: [partial_sum(UnscaledValue(ss_ext_sales_price#5)), partial_sum(coalesce(cast(sr_return_amt#15 as decimal(12,2)), 0.00)), partial_sum((ss_net_profit#6 - coalesce(cast(sr_net_loss#16 as decimal(12,2)), 0.00)))]
Aggregate Attributes [5]: [sum#25, sum#26, isEmpty#27, sum#28, isEmpty#29]
Results [6]: [s_store_id#24, sum#30, sum#31, isEmpty#32, sum#33, isEmpty#34]

(38) Exchange
Input [6]: [s_store_id#24, sum#30, sum#31, isEmpty#32, sum#33, isEmpty#34]
Arguments: hashpartitioning(s_store_id#24, 5), ENSURE_REQUIREMENTS, [plan_id=6]

(39) HashAggregate [codegen id : 10]
Input [6]: [s_store_id#24, sum#30, sum#31, isEmpty#32, sum#33, isEmpty#34]
Keys [1]: [s_store_id#24]
Functions [3]: [sum(UnscaledValue(ss_ext_sales_price#5)), sum(coalesce(cast(sr_return_amt#15 as decimal(12,2)), 0.00)), sum((ss_net_profit#6 - coalesce(cast(sr_net_loss#16 as decimal(12,2)), 0.00)))]
Aggregate Attributes [3]: [sum(UnscaledValue(ss_ext_sales_price#5))#35, sum(coalesce(cast(sr_return_amt#15 as decimal(12,2)), 0.00))#36, sum((ss_net_profit#6 - coalesce(cast(sr_net_loss#16 as decimal(12,2)), 0.00)))#37]
Results [5]: [MakeDecimal(sum(UnscaledValue(ss_ext_sales_price#5))#35,17,2) AS sales#38, sum(coalesce(cast(sr_return_amt#15 as decimal(12,2)), 0.00))#36 AS returns#39, sum((ss_net_profit#6 - coalesce(cast(sr_net_loss#16 as decimal(12,2)), 0.00)))#37 AS profit#40, store channel AS channel#41, concat(store, s_store_id#24) AS id#42]

(40) Scan parquet spark_catalog.default.catalog_sales
Output [7]: [cs_catalog_page_sk#43, cs_item_sk#44, cs_promo_sk#45, cs_order_number#46, cs_ext_sales_price#47, cs_net_profit#48, cs_sold_date_sk#49]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#49), dynamicpruningexpression(cs_sold_date_sk#49 IN dynamicpruning#8)]
PushedFilters: [IsNotNull(cs_catalog_page_sk), IsNotNull(cs_item_sk), IsNotNull(cs_promo_sk)]
ReadSchema: struct<cs_catalog_page_sk:int,cs_item_sk:int,cs_promo_sk:int,cs_order_number:int,cs_ext_sales_price:decimal(7,2),cs_net_profit:decimal(7,2)>

(41) ColumnarToRow [codegen id : 11]
Input [7]: [cs_catalog_page_sk#43, cs_item_sk#44, cs_promo_sk#45, cs_order_number#46, cs_ext_sales_price#47, cs_net_profit#48, cs_sold_date_sk#49]

(42) Filter [codegen id : 11]
Input [7]: [cs_catalog_page_sk#43, cs_item_sk#44, cs_promo_sk#45, cs_order_number#46, cs_ext_sales_price#47, cs_net_profit#48, cs_sold_date_sk#49]
Condition : ((((isnotnull(cs_catalog_page_sk#43) AND isnotnull(cs_item_sk#44)) AND isnotnull(cs_promo_sk#45)) AND might_contain(ReusedSubquery Subquery scalar-subquery#9, [id=#10], xxhash64(cs_item_sk#44, 42))) AND might_contain(ReusedSubquery Subquery scalar-subquery#11, [id=#12], xxhash64(cs_promo_sk#45, 42)))

(43) Exchange
Input [7]: [cs_catalog_page_sk#43, cs_item_sk#44, cs_promo_sk#45, cs_order_number#46, cs_ext_sales_price#47, cs_net_profit#48, cs_sold_date_sk#49]
Arguments: hashpartitioning(cs_item_sk#44, cs_order_number#46, 5), ENSURE_REQUIREMENTS, [plan_id=7]

(44) Sort [codegen id : 12]
Input [7]: [cs_catalog_page_sk#43, cs_item_sk#44, cs_promo_sk#45, cs_order_number#46, cs_ext_sales_price#47, cs_net_profit#48, cs_sold_date_sk#49]
Arguments: [cs_item_sk#44 ASC NULLS FIRST, cs_order_number#46 ASC NULLS FIRST], false, 0

(45) Scan parquet spark_catalog.default.catalog_returns
Output [5]: [cr_item_sk#50, cr_order_number#51, cr_return_amount#52, cr_net_loss#53, cr_returned_date_sk#54]
Batched: true
Location [not included in comparison]/{warehouse_dir}/catalog_returns]
PushedFilters: [IsNotNull(cr_item_sk), IsNotNull(cr_order_number)]
ReadSchema: struct<cr_item_sk:int,cr_order_number:int,cr_return_amount:decimal(7,2),cr_net_loss:decimal(7,2)>

(46) ColumnarToRow [codegen id : 13]
Input [5]: [cr_item_sk#50, cr_order_number#51, cr_return_amount#52, cr_net_loss#53, cr_returned_date_sk#54]

(47) Filter [codegen id : 13]
Input [5]: [cr_item_sk#50, cr_order_number#51, cr_return_amount#52, cr_net_loss#53, cr_returned_date_sk#54]
Condition : (isnotnull(cr_item_sk#50) AND isnotnull(cr_order_number#51))

(48) Project [codegen id : 13]
Output [4]: [cr_item_sk#50, cr_order_number#51, cr_return_amount#52, cr_net_loss#53]
Input [5]: [cr_item_sk#50, cr_order_number#51, cr_return_amount#52, cr_net_loss#53, cr_returned_date_sk#54]

(49) Exchange
Input [4]: [cr_item_sk#50, cr_order_number#51, cr_return_amount#52, cr_net_loss#53]
Arguments: hashpartitioning(cr_item_sk#50, cr_order_number#51, 5), ENSURE_REQUIREMENTS, [plan_id=8]

(50) Sort [codegen id : 14]
Input [4]: [cr_item_sk#50, cr_order_number#51, cr_return_amount#52, cr_net_loss#53]
Arguments: [cr_item_sk#50 ASC NULLS FIRST, cr_order_number#51 ASC NULLS FIRST], false, 0

(51) SortMergeJoin [codegen id : 19]
Left keys [2]: [cs_item_sk#44, cs_order_number#46]
Right keys [2]: [cr_item_sk#50, cr_order_number#51]
Join type: LeftOuter
Join condition: None

(52) Project [codegen id : 19]
Output [8]: [cs_catalog_page_sk#43, cs_item_sk#44, cs_promo_sk#45, cs_ext_sales_price#47, cs_net_profit#48, cs_sold_date_sk#49, cr_return_amount#52, cr_net_loss#53]
Input [11]: [cs_catalog_page_sk#43, cs_item_sk#44, cs_promo_sk#45, cs_order_number#46, cs_ext_sales_price#47, cs_net_profit#48, cs_sold_date_sk#49, cr_item_sk#50, cr_order_number#51, cr_return_amount#52, cr_net_loss#53]

(53) ReusedExchange [Reuses operator id: 18]
Output [1]: [i_item_sk#55]

(54) BroadcastHashJoin [codegen id : 19]
Left keys [1]: [cs_item_sk#44]
Right keys [1]: [i_item_sk#55]
Join type: Inner
Join condition: None

(55) Project [codegen id : 19]
Output [7]: [cs_catalog_page_sk#43, cs_promo_sk#45, cs_ext_sales_price#47, cs_net_profit#48, cs_sold_date_sk#49, cr_return_amount#52, cr_net_loss#53]
Input [9]: [cs_catalog_page_sk#43, cs_item_sk#44, cs_promo_sk#45, cs_ext_sales_price#47, cs_net_profit#48, cs_sold_date_sk#49, cr_return_amount#52, cr_net_loss#53, i_item_sk#55]

(56) ReusedExchange [Reuses operator id: 25]
Output [1]: [p_promo_sk#56]

(57) BroadcastHashJoin [codegen id : 19]
Left keys [1]: [cs_promo_sk#45]
Right keys [1]: [p_promo_sk#56]
Join type: Inner
Join condition: None

(58) Project [codegen id : 19]
Output [6]: [cs_catalog_page_sk#43, cs_ext_sales_price#47, cs_net_profit#48, cs_sold_date_sk#49, cr_return_amount#52, cr_net_loss#53]
Input [8]: [cs_catalog_page_sk#43, cs_promo_sk#45, cs_ext_sales_price#47, cs_net_profit#48, cs_sold_date_sk#49, cr_return_amount#52, cr_net_loss#53, p_promo_sk#56]

(59) ReusedExchange [Reuses operator id: 126]
Output [1]: [d_date_sk#57]

(60) BroadcastHashJoin [codegen id : 19]
Left keys [1]: [cs_sold_date_sk#49]
Right keys [1]: [d_date_sk#57]
Join type: Inner
Join condition: None

(61) Project [codegen id : 19]
Output [5]: [cs_catalog_page_sk#43, cs_ext_sales_price#47, cs_net_profit#48, cr_return_amount#52, cr_net_loss#53]
Input [7]: [cs_catalog_page_sk#43, cs_ext_sales_price#47, cs_net_profit#48, cs_sold_date_sk#49, cr_return_amount#52, cr_net_loss#53, d_date_sk#57]

(62) Scan parquet spark_catalog.default.catalog_page
Output [2]: [cp_catalog_page_sk#58, cp_catalog_page_id#59]
Batched: true
Location [not included in comparison]/{warehouse_dir}/catalog_page]
PushedFilters: [IsNotNull(cp_catalog_page_sk)]
ReadSchema: struct<cp_catalog_page_sk:int,cp_catalog_page_id:string>

(63) ColumnarToRow [codegen id : 18]
Input [2]: [cp_catalog_page_sk#58, cp_catalog_page_id#59]

(64) Filter [codegen id : 18]
Input [2]: [cp_catalog_page_sk#58, cp_catalog_page_id#59]
Condition : isnotnull(cp_catalog_page_sk#58)

(65) BroadcastExchange
Input [2]: [cp_catalog_page_sk#58, cp_catalog_page_id#59]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=9]

(66) BroadcastHashJoin [codegen id : 19]
Left keys [1]: [cs_catalog_page_sk#43]
Right keys [1]: [cp_catalog_page_sk#58]
Join type: Inner
Join condition: None

(67) Project [codegen id : 19]
Output [5]: [cs_ext_sales_price#47, cs_net_profit#48, cr_return_amount#52, cr_net_loss#53, cp_catalog_page_id#59]
Input [7]: [cs_catalog_page_sk#43, cs_ext_sales_price#47, cs_net_profit#48, cr_return_amount#52, cr_net_loss#53, cp_catalog_page_sk#58, cp_catalog_page_id#59]

(68) HashAggregate [codegen id : 19]
Input [5]: [cs_ext_sales_price#47, cs_net_profit#48, cr_return_amount#52, cr_net_loss#53, cp_catalog_page_id#59]
Keys [1]: [cp_catalog_page_id#59]
Functions [3]: [partial_sum(UnscaledValue(cs_ext_sales_price#47)), partial_sum(coalesce(cast(cr_return_amount#52 as decimal(12,2)), 0.00)), partial_sum((cs_net_profit#48 - coalesce(cast(cr_net_loss#53 as decimal(12,2)), 0.00)))]
Aggregate Attributes [5]: [sum#60, sum#61, isEmpty#62, sum#63, isEmpty#64]
Results [6]: [cp_catalog_page_id#59, sum#65, sum#66, isEmpty#67, sum#68, isEmpty#69]

(69) Exchange
Input [6]: [cp_catalog_page_id#59, sum#65, sum#66, isEmpty#67, sum#68, isEmpty#69]
Arguments: hashpartitioning(cp_catalog_page_id#59, 5), ENSURE_REQUIREMENTS, [plan_id=10]

(70) HashAggregate [codegen id : 20]
Input [6]: [cp_catalog_page_id#59, sum#65, sum#66, isEmpty#67, sum#68, isEmpty#69]
Keys [1]: [cp_catalog_page_id#59]
Functions [3]: [sum(UnscaledValue(cs_ext_sales_price#47)), sum(coalesce(cast(cr_return_amount#52 as decimal(12,2)), 0.00)), sum((cs_net_profit#48 - coalesce(cast(cr_net_loss#53 as decimal(12,2)), 0.00)))]
Aggregate Attributes [3]: [sum(UnscaledValue(cs_ext_sales_price#47))#70, sum(coalesce(cast(cr_return_amount#52 as decimal(12,2)), 0.00))#71, sum((cs_net_profit#48 - coalesce(cast(cr_net_loss#53 as decimal(12,2)), 0.00)))#72]
Results [5]: [MakeDecimal(sum(UnscaledValue(cs_ext_sales_price#47))#70,17,2) AS sales#73, sum(coalesce(cast(cr_return_amount#52 as decimal(12,2)), 0.00))#71 AS returns#74, sum((cs_net_profit#48 - coalesce(cast(cr_net_loss#53 as decimal(12,2)), 0.00)))#72 AS profit#75, catalog channel AS channel#76, concat(catalog_page, cp_catalog_page_id#59) AS id#77]

(71) Scan parquet spark_catalog.default.web_sales
Output [7]: [ws_item_sk#78, ws_web_site_sk#79, ws_promo_sk#80, ws_order_number#81, ws_ext_sales_price#82, ws_net_profit#83, ws_sold_date_sk#84]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#84), dynamicpruningexpression(ws_sold_date_sk#84 IN dynamicpruning#8)]
PushedFilters: [IsNotNull(ws_web_site_sk), IsNotNull(ws_item_sk), IsNotNull(ws_promo_sk)]
ReadSchema: struct<ws_item_sk:int,ws_web_site_sk:int,ws_promo_sk:int,ws_order_number:int,ws_ext_sales_price:decimal(7,2),ws_net_profit:decimal(7,2)>

(72) ColumnarToRow [codegen id : 21]
Input [7]: [ws_item_sk#78, ws_web_site_sk#79, ws_promo_sk#80, ws_order_number#81, ws_ext_sales_price#82, ws_net_profit#83, ws_sold_date_sk#84]

(73) Filter [codegen id : 21]
Input [7]: [ws_item_sk#78, ws_web_site_sk#79, ws_promo_sk#80, ws_order_number#81, ws_ext_sales_price#82, ws_net_profit#83, ws_sold_date_sk#84]
Condition : ((((isnotnull(ws_web_site_sk#79) AND isnotnull(ws_item_sk#78)) AND isnotnull(ws_promo_sk#80)) AND might_contain(ReusedSubquery Subquery scalar-subquery#9, [id=#10], xxhash64(ws_item_sk#78, 42))) AND might_contain(ReusedSubquery Subquery scalar-subquery#11, [id=#12], xxhash64(ws_promo_sk#80, 42)))

(74) Exchange
Input [7]: [ws_item_sk#78, ws_web_site_sk#79, ws_promo_sk#80, ws_order_number#81, ws_ext_sales_price#82, ws_net_profit#83, ws_sold_date_sk#84]
Arguments: hashpartitioning(ws_item_sk#78, ws_order_number#81, 5), ENSURE_REQUIREMENTS, [plan_id=11]

(75) Sort [codegen id : 22]
Input [7]: [ws_item_sk#78, ws_web_site_sk#79, ws_promo_sk#80, ws_order_number#81, ws_ext_sales_price#82, ws_net_profit#83, ws_sold_date_sk#84]
Arguments: [ws_item_sk#78 ASC NULLS FIRST, ws_order_number#81 ASC NULLS FIRST], false, 0

(76) Scan parquet spark_catalog.default.web_returns
Output [5]: [wr_item_sk#85, wr_order_number#86, wr_return_amt#87, wr_net_loss#88, wr_returned_date_sk#89]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_returns]
PushedFilters: [IsNotNull(wr_item_sk), IsNotNull(wr_order_number)]
ReadSchema: struct<wr_item_sk:int,wr_order_number:int,wr_return_amt:decimal(7,2),wr_net_loss:decimal(7,2)>

(77) ColumnarToRow [codegen id : 23]
Input [5]: [wr_item_sk#85, wr_order_number#86, wr_return_amt#87, wr_net_loss#88, wr_returned_date_sk#89]

(78) Filter [codegen id : 23]
Input [5]: [wr_item_sk#85, wr_order_number#86, wr_return_amt#87, wr_net_loss#88, wr_returned_date_sk#89]
Condition : (isnotnull(wr_item_sk#85) AND isnotnull(wr_order_number#86))

(79) Project [codegen id : 23]
Output [4]: [wr_item_sk#85, wr_order_number#86, wr_return_amt#87, wr_net_loss#88]
Input [5]: [wr_item_sk#85, wr_order_number#86, wr_return_amt#87, wr_net_loss#88, wr_returned_date_sk#89]

(80) Exchange
Input [4]: [wr_item_sk#85, wr_order_number#86, wr_return_amt#87, wr_net_loss#88]
Arguments: hashpartitioning(wr_item_sk#85, wr_order_number#86, 5), ENSURE_REQUIREMENTS, [plan_id=12]

(81) Sort [codegen id : 24]
Input [4]: [wr_item_sk#85, wr_order_number#86, wr_return_amt#87, wr_net_loss#88]
Arguments: [wr_item_sk#85 ASC NULLS FIRST, wr_order_number#86 ASC NULLS FIRST], false, 0

(82) SortMergeJoin [codegen id : 29]
Left keys [2]: [ws_item_sk#78, ws_order_number#81]
Right keys [2]: [wr_item_sk#85, wr_order_number#86]
Join type: LeftOuter
Join condition: None

(83) Project [codegen id : 29]
Output [8]: [ws_item_sk#78, ws_web_site_sk#79, ws_promo_sk#80, ws_ext_sales_price#82, ws_net_profit#83, ws_sold_date_sk#84, wr_return_amt#87, wr_net_loss#88]
Input [11]: [ws_item_sk#78, ws_web_site_sk#79, ws_promo_sk#80, ws_order_number#81, ws_ext_sales_price#82, ws_net_profit#83, ws_sold_date_sk#84, wr_item_sk#85, wr_order_number#86, wr_return_amt#87, wr_net_loss#88]

(84) ReusedExchange [Reuses operator id: 18]
Output [1]: [i_item_sk#90]

(85) BroadcastHashJoin [codegen id : 29]
Left keys [1]: [ws_item_sk#78]
Right keys [1]: [i_item_sk#90]
Join type: Inner
Join condition: None

(86) Project [codegen id : 29]
Output [7]: [ws_web_site_sk#79, ws_promo_sk#80, ws_ext_sales_price#82, ws_net_profit#83, ws_sold_date_sk#84, wr_return_amt#87, wr_net_loss#88]
Input [9]: [ws_item_sk#78, ws_web_site_sk#79, ws_promo_sk#80, ws_ext_sales_price#82, ws_net_profit#83, ws_sold_date_sk#84, wr_return_amt#87, wr_net_loss#88, i_item_sk#90]

(87) ReusedExchange [Reuses operator id: 25]
Output [1]: [p_promo_sk#91]

(88) BroadcastHashJoin [codegen id : 29]
Left keys [1]: [ws_promo_sk#80]
Right keys [1]: [p_promo_sk#91]
Join type: Inner
Join condition: None

(89) Project [codegen id : 29]
Output [6]: [ws_web_site_sk#79, ws_ext_sales_price#82, ws_net_profit#83, ws_sold_date_sk#84, wr_return_amt#87, wr_net_loss#88]
Input [8]: [ws_web_site_sk#79, ws_promo_sk#80, ws_ext_sales_price#82, ws_net_profit#83, ws_sold_date_sk#84, wr_return_amt#87, wr_net_loss#88, p_promo_sk#91]

(90) ReusedExchange [Reuses operator id: 126]
Output [1]: [d_date_sk#92]

(91) BroadcastHashJoin [codegen id : 29]
Left keys [1]: [ws_sold_date_sk#84]
Right keys [1]: [d_date_sk#92]
Join type: Inner
Join condition: None

(92) Project [codegen id : 29]
Output [5]: [ws_web_site_sk#79, ws_ext_sales_price#82, ws_net_profit#83, wr_return_amt#87, wr_net_loss#88]
Input [7]: [ws_web_site_sk#79, ws_ext_sales_price#82, ws_net_profit#83, ws_sold_date_sk#84, wr_return_amt#87, wr_net_loss#88, d_date_sk#92]

(93) Scan parquet spark_catalog.default.web_site
Output [2]: [web_site_sk#93, web_site_id#94]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_site]
PushedFilters: [IsNotNull(web_site_sk)]
ReadSchema: struct<web_site_sk:int,web_site_id:string>

(94) ColumnarToRow [codegen id : 28]
Input [2]: [web_site_sk#93, web_site_id#94]

(95) Filter [codegen id : 28]
Input [2]: [web_site_sk#93, web_site_id#94]
Condition : isnotnull(web_site_sk#93)

(96) BroadcastExchange
Input [2]: [web_site_sk#93, web_site_id#94]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=13]

(97) BroadcastHashJoin [codegen id : 29]
Left keys [1]: [ws_web_site_sk#79]
Right keys [1]: [web_site_sk#93]
Join type: Inner
Join condition: None

(98) Project [codegen id : 29]
Output [5]: [ws_ext_sales_price#82, ws_net_profit#83, wr_return_amt#87, wr_net_loss#88, web_site_id#94]
Input [7]: [ws_web_site_sk#79, ws_ext_sales_price#82, ws_net_profit#83, wr_return_amt#87, wr_net_loss#88, web_site_sk#93, web_site_id#94]

(99) HashAggregate [codegen id : 29]
Input [5]: [ws_ext_sales_price#82, ws_net_profit#83, wr_return_amt#87, wr_net_loss#88, web_site_id#94]
Keys [1]: [web_site_id#94]
Functions [3]: [partial_sum(UnscaledValue(ws_ext_sales_price#82)), partial_sum(coalesce(cast(wr_return_amt#87 as decimal(12,2)), 0.00)), partial_sum((ws_net_profit#83 - coalesce(cast(wr_net_loss#88 as decimal(12,2)), 0.00)))]
Aggregate Attributes [5]: [sum#95, sum#96, isEmpty#97, sum#98, isEmpty#99]
Results [6]: [web_site_id#94, sum#100, sum#101, isEmpty#102, sum#103, isEmpty#104]

(100) Exchange
Input [6]: [web_site_id#94, sum#100, sum#101, isEmpty#102, sum#103, isEmpty#104]
Arguments: hashpartitioning(web_site_id#94, 5), ENSURE_REQUIREMENTS, [plan_id=14]

(101) HashAggregate [codegen id : 30]
Input [6]: [web_site_id#94, sum#100, sum#101, isEmpty#102, sum#103, isEmpty#104]
Keys [1]: [web_site_id#94]
Functions [3]: [sum(UnscaledValue(ws_ext_sales_price#82)), sum(coalesce(cast(wr_return_amt#87 as decimal(12,2)), 0.00)), sum((ws_net_profit#83 - coalesce(cast(wr_net_loss#88 as decimal(12,2)), 0.00)))]
Aggregate Attributes [3]: [sum(UnscaledValue(ws_ext_sales_price#82))#105, sum(coalesce(cast(wr_return_amt#87 as decimal(12,2)), 0.00))#106, sum((ws_net_profit#83 - coalesce(cast(wr_net_loss#88 as decimal(12,2)), 0.00)))#107]
Results [5]: [MakeDecimal(sum(UnscaledValue(ws_ext_sales_price#82))#105,17,2) AS sales#108, sum(coalesce(cast(wr_return_amt#87 as decimal(12,2)), 0.00))#106 AS returns#109, sum((ws_net_profit#83 - coalesce(cast(wr_net_loss#88 as decimal(12,2)), 0.00)))#107 AS profit#110, web channel AS channel#111, concat(web_site, web_site_id#94) AS id#112]

(102) Union

(103) Expand [codegen id : 31]
Input [5]: [sales#38, returns#39, profit#40, channel#41, id#42]
Arguments: [[sales#38, returns#39, profit#40, channel#41, id#42, 0], [sales#38, returns#39, profit#40, channel#41, null, 1], [sales#38, returns#39, profit#40, null, null, 3]], [sales#38, returns#39, profit#40, channel#113, id#114, spark_grouping_id#115]

(104) HashAggregate [codegen id : 31]
Input [6]: [sales#38, returns#39, profit#40, channel#113, id#114, spark_grouping_id#115]
Keys [3]: [channel#113, id#114, spark_grouping_id#115]
Functions [3]: [partial_sum(sales#38), partial_sum(returns#39), partial_sum(profit#40)]
Aggregate Attributes [6]: [sum#116, isEmpty#117, sum#118, isEmpty#119, sum#120, isEmpty#121]
Results [9]: [channel#113, id#114, spark_grouping_id#115, sum#122, isEmpty#123, sum#124, isEmpty#125, sum#126, isEmpty#127]

(105) Exchange
Input [9]: [channel#113, id#114, spark_grouping_id#115, sum#122, isEmpty#123, sum#124, isEmpty#125, sum#126, isEmpty#127]
Arguments: hashpartitioning(channel#113, id#114, spark_grouping_id#115, 5), ENSURE_REQUIREMENTS, [plan_id=15]

(106) HashAggregate [codegen id : 32]
Input [9]: [channel#113, id#114, spark_grouping_id#115, sum#122, isEmpty#123, sum#124, isEmpty#125, sum#126, isEmpty#127]
Keys [3]: [channel#113, id#114, spark_grouping_id#115]
Functions [3]: [sum(sales#38), sum(returns#39), sum(profit#40)]
Aggregate Attributes [3]: [sum(sales#38)#128, sum(returns#39)#129, sum(profit#40)#130]
Results [5]: [channel#113, id#114, sum(sales#38)#128 AS sales#131, sum(returns#39)#129 AS returns#132, sum(profit#40)#130 AS profit#133]

(107) TakeOrderedAndProject
Input [5]: [channel#113, id#114, sales#131, returns#132, profit#133]
Arguments: 100, [channel#113 ASC NULLS FIRST, id#114 ASC NULLS FIRST], [channel#113, id#114, sales#131, returns#132, profit#133]

===== Subqueries =====

Subquery:1 Hosting operator id = 3 Hosting Expression = Subquery scalar-subquery#9, [id=#10]
ObjectHashAggregate (114)
+- Exchange (113)
   +- ObjectHashAggregate (112)
      +- * Project (111)
         +- * Filter (110)
            +- * ColumnarToRow (109)
               +- Scan parquet spark_catalog.default.item (108)


(108) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#18, i_current_price#19]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_current_price), GreaterThan(i_current_price,50.00), IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_current_price:decimal(7,2)>

(109) ColumnarToRow [codegen id : 1]
Input [2]: [i_item_sk#18, i_current_price#19]

(110) Filter [codegen id : 1]
Input [2]: [i_item_sk#18, i_current_price#19]
Condition : ((isnotnull(i_current_price#19) AND (i_current_price#19 > 50.00)) AND isnotnull(i_item_sk#18))

(111) Project [codegen id : 1]
Output [1]: [i_item_sk#18]
Input [2]: [i_item_sk#18, i_current_price#19]

(112) ObjectHashAggregate
Input [1]: [i_item_sk#18]
Keys: []
Functions [1]: [partial_bloom_filter_agg(xxhash64(i_item_sk#18, 42), 101823, 1521109, 0, 0)]
Aggregate Attributes [1]: [buf#134]
Results [1]: [buf#135]

(113) Exchange
Input [1]: [buf#135]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=16]

(114) ObjectHashAggregate
Input [1]: [buf#135]
Keys: []
Functions [1]: [bloom_filter_agg(xxhash64(i_item_sk#18, 42), 101823, 1521109, 0, 0)]
Aggregate Attributes [1]: [bloom_filter_agg(xxhash64(i_item_sk#18, 42), 101823, 1521109, 0, 0)#136]
Results [1]: [bloom_filter_agg(xxhash64(i_item_sk#18, 42), 101823, 1521109, 0, 0)#136 AS bloomFilter#137]

Subquery:2 Hosting operator id = 3 Hosting Expression = Subquery scalar-subquery#11, [id=#12]
ObjectHashAggregate (121)
+- Exchange (120)
   +- ObjectHashAggregate (119)
      +- * Project (118)
         +- * Filter (117)
            +- * ColumnarToRow (116)
               +- Scan parquet spark_catalog.default.promotion (115)


(115) Scan parquet spark_catalog.default.promotion
Output [2]: [p_promo_sk#20, p_channel_tv#21]
Batched: true
Location [not included in comparison]/{warehouse_dir}/promotion]
PushedFilters: [IsNotNull(p_channel_tv), EqualTo(p_channel_tv,N), IsNotNull(p_promo_sk)]
ReadSchema: struct<p_promo_sk:int,p_channel_tv:string>

(116) ColumnarToRow [codegen id : 1]
Input [2]: [p_promo_sk#20, p_channel_tv#21]

(117) Filter [codegen id : 1]
Input [2]: [p_promo_sk#20, p_channel_tv#21]
Condition : ((isnotnull(p_channel_tv#21) AND (p_channel_tv#21 = N)) AND isnotnull(p_promo_sk#20))

(118) Project [codegen id : 1]
Output [1]: [p_promo_sk#20]
Input [2]: [p_promo_sk#20, p_channel_tv#21]

(119) ObjectHashAggregate
Input [1]: [p_promo_sk#20]
Keys: []
Functions [1]: [partial_bloom_filter_agg(xxhash64(p_promo_sk#20, 42), 986, 24246, 0, 0)]
Aggregate Attributes [1]: [buf#138]
Results [1]: [buf#139]

(120) Exchange
Input [1]: [buf#139]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=17]

(121) ObjectHashAggregate
Input [1]: [buf#139]
Keys: []
Functions [1]: [bloom_filter_agg(xxhash64(p_promo_sk#20, 42), 986, 24246, 0, 0)]
Aggregate Attributes [1]: [bloom_filter_agg(xxhash64(p_promo_sk#20, 42), 986, 24246, 0, 0)#140]
Results [1]: [bloom_filter_agg(xxhash64(p_promo_sk#20, 42), 986, 24246, 0, 0)#140 AS bloomFilter#141]

Subquery:3 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#7 IN dynamicpruning#8
BroadcastExchange (126)
+- * Project (125)
   +- * Filter (124)
      +- * ColumnarToRow (123)
         +- Scan parquet spark_catalog.default.date_dim (122)


(122) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#22, d_date#142]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), GreaterThanOrEqual(d_date,2000-08-23), LessThanOrEqual(d_date,2000-09-22), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(123) ColumnarToRow [codegen id : 1]
Input [2]: [d_date_sk#22, d_date#142]

(124) Filter [codegen id : 1]
Input [2]: [d_date_sk#22, d_date#142]
Condition : (((isnotnull(d_date#142) AND (d_date#142 >= 2000-08-23)) AND (d_date#142 <= 2000-09-22)) AND isnotnull(d_date_sk#22))

(125) Project [codegen id : 1]
Output [1]: [d_date_sk#22]
Input [2]: [d_date_sk#22, d_date#142]

(126) BroadcastExchange
Input [1]: [d_date_sk#22]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=18]

Subquery:4 Hosting operator id = 42 Hosting Expression = ReusedSubquery Subquery scalar-subquery#9, [id=#10]

Subquery:5 Hosting operator id = 42 Hosting Expression = ReusedSubquery Subquery scalar-subquery#11, [id=#12]

Subquery:6 Hosting operator id = 40 Hosting Expression = cs_sold_date_sk#49 IN dynamicpruning#8

Subquery:7 Hosting operator id = 73 Hosting Expression = ReusedSubquery Subquery scalar-subquery#9, [id=#10]

Subquery:8 Hosting operator id = 73 Hosting Expression = ReusedSubquery Subquery scalar-subquery#11, [id=#12]

Subquery:9 Hosting operator id = 71 Hosting Expression = ws_sold_date_sk#84 IN dynamicpruning#8


