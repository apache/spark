== Physical Plan ==
TakeOrderedAndProject (107)
+- * HashAggregate (106)
   +- Exchange (105)
      +- * HashAggregate (104)
         +- * Expand (103)
            +- Union (102)
               :- * HashAggregate (39)
               :  +- Exchange (38)
               :     +- * HashAggregate (37)
               :        +- * Project (36)
               :           +- * BroadcastHashJoin Inner BuildRight (35)
               :              :- * Project (30)
               :              :  +- * BroadcastHashJoin Inner BuildRight (29)
               :              :     :- * Project (27)
               :              :     :  +- * BroadcastHashJoin Inner BuildRight (26)
               :              :     :     :- * Project (20)
               :              :     :     :  +- * BroadcastHashJoin Inner BuildRight (19)
               :              :     :     :     :- * Project (13)
               :              :     :     :     :  +- * SortMergeJoin LeftOuter (12)
               :              :     :     :     :     :- * Sort (5)
               :              :     :     :     :     :  +- Exchange (4)
               :              :     :     :     :     :     +- * Filter (3)
               :              :     :     :     :     :        +- * ColumnarToRow (2)
               :              :     :     :     :     :           +- Scan parquet spark_catalog.default.store_sales (1)
               :              :     :     :     :     +- * Sort (11)
               :              :     :     :     :        +- Exchange (10)
               :              :     :     :     :           +- * Project (9)
               :              :     :     :     :              +- * Filter (8)
               :              :     :     :     :                 +- * ColumnarToRow (7)
               :              :     :     :     :                    +- Scan parquet spark_catalog.default.store_returns (6)
               :              :     :     :     +- BroadcastExchange (18)
               :              :     :     :        +- * Project (17)
               :              :     :     :           +- * Filter (16)
               :              :     :     :              +- * ColumnarToRow (15)
               :              :     :     :                 +- Scan parquet spark_catalog.default.item (14)
               :              :     :     +- BroadcastExchange (25)
               :              :     :        +- * Project (24)
               :              :     :           +- * Filter (23)
               :              :     :              +- * ColumnarToRow (22)
               :              :     :                 +- Scan parquet spark_catalog.default.promotion (21)
               :              :     +- ReusedExchange (28)
               :              +- BroadcastExchange (34)
               :                 +- * Filter (33)
               :                    +- * ColumnarToRow (32)
               :                       +- Scan parquet spark_catalog.default.store (31)
               :- * HashAggregate (70)
               :  +- Exchange (69)
               :     +- * HashAggregate (68)
               :        +- * Project (67)
               :           +- * BroadcastHashJoin Inner BuildRight (66)
               :              :- * Project (61)
               :              :  +- * BroadcastHashJoin Inner BuildRight (60)
               :              :     :- * Project (58)
               :              :     :  +- * BroadcastHashJoin Inner BuildRight (57)
               :              :     :     :- * Project (55)
               :              :     :     :  +- * BroadcastHashJoin Inner BuildRight (54)
               :              :     :     :     :- * Project (52)
               :              :     :     :     :  +- * SortMergeJoin LeftOuter (51)
               :              :     :     :     :     :- * Sort (44)
               :              :     :     :     :     :  +- Exchange (43)
               :              :     :     :     :     :     +- * Filter (42)
               :              :     :     :     :     :        +- * ColumnarToRow (41)
               :              :     :     :     :     :           +- Scan parquet spark_catalog.default.catalog_sales (40)
               :              :     :     :     :     +- * Sort (50)
               :              :     :     :     :        +- Exchange (49)
               :              :     :     :     :           +- * Project (48)
               :              :     :     :     :              +- * Filter (47)
               :              :     :     :     :                 +- * ColumnarToRow (46)
               :              :     :     :     :                    +- Scan parquet spark_catalog.default.catalog_returns (45)
               :              :     :     :     +- ReusedExchange (53)
               :              :     :     +- ReusedExchange (56)
               :              :     +- ReusedExchange (59)
               :              +- BroadcastExchange (65)
               :                 +- * Filter (64)
               :                    +- * ColumnarToRow (63)
               :                       +- Scan parquet spark_catalog.default.catalog_page (62)
               +- * HashAggregate (101)
                  +- Exchange (100)
                     +- * HashAggregate (99)
                        +- * Project (98)
                           +- * BroadcastHashJoin Inner BuildRight (97)
                              :- * Project (92)
                              :  +- * BroadcastHashJoin Inner BuildRight (91)
                              :     :- * Project (89)
                              :     :  +- * BroadcastHashJoin Inner BuildRight (88)
                              :     :     :- * Project (86)
                              :     :     :  +- * BroadcastHashJoin Inner BuildRight (85)
                              :     :     :     :- * Project (83)
                              :     :     :     :  +- * SortMergeJoin LeftOuter (82)
                              :     :     :     :     :- * Sort (75)
                              :     :     :     :     :  +- Exchange (74)
                              :     :     :     :     :     +- * Filter (73)
                              :     :     :     :     :        +- * ColumnarToRow (72)
                              :     :     :     :     :           +- Scan parquet spark_catalog.default.web_sales (71)
                              :     :     :     :     +- * Sort (81)
                              :     :     :     :        +- Exchange (80)
                              :     :     :     :           +- * Project (79)
                              :     :     :     :              +- * Filter (78)
                              :     :     :     :                 +- * ColumnarToRow (77)
                              :     :     :     :                    +- Scan parquet spark_catalog.default.web_returns (76)
                              :     :     :     +- ReusedExchange (84)
                              :     :     +- ReusedExchange (87)
                              :     +- ReusedExchange (90)
                              +- BroadcastExchange (96)
                                 +- * Filter (95)
                                    +- * ColumnarToRow (94)
                                       +- Scan parquet spark_catalog.default.web_site (93)


(1) Scan parquet spark_catalog.default.store_sales
Output [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ss_sold_date_sk#7), dynamicpruningexpression(ss_sold_date_sk#7 IN dynamicpruning#8)]
PushedFilters: [IsNotNull(ss_store_sk), IsNotNull(ss_item_sk), IsNotNull(ss_promo_sk)]
ReadSchema: struct<ss_item_sk:int,ss_store_sk:int,ss_promo_sk:int,ss_ticket_number:int,ss_ext_sales_price:decimal(7,2),ss_net_profit:decimal(7,2)>

(2) ColumnarToRow [codegen id : 1]
Input [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]

(3) Filter [codegen id : 1]
Input [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]
Condition : ((((isnotnull(ss_store_sk#2) AND isnotnull(ss_item_sk#1)) AND isnotnull(ss_promo_sk#3)) AND might_contain(Subquery scalar-subquery#9, [id=#1], xxhash64(ss_item_sk#1, 42))) AND might_contain(Subquery scalar-subquery#10, [id=#2], xxhash64(ss_promo_sk#3, 42)))

(4) Exchange
Input [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]
Arguments: hashpartitioning(ss_item_sk#1, ss_ticket_number#4, 5), ENSURE_REQUIREMENTS, [plan_id=3]

(5) Sort [codegen id : 2]
Input [7]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7]
Arguments: [ss_item_sk#1 ASC NULLS FIRST, ss_ticket_number#4 ASC NULLS FIRST], false, 0

(6) Scan parquet spark_catalog.default.store_returns
Output [5]: [sr_item_sk#11, sr_ticket_number#12, sr_return_amt#13, sr_net_loss#14, sr_returned_date_sk#15]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_returns]
PushedFilters: [IsNotNull(sr_item_sk), IsNotNull(sr_ticket_number)]
ReadSchema: struct<sr_item_sk:int,sr_ticket_number:int,sr_return_amt:decimal(7,2),sr_net_loss:decimal(7,2)>

(7) ColumnarToRow [codegen id : 3]
Input [5]: [sr_item_sk#11, sr_ticket_number#12, sr_return_amt#13, sr_net_loss#14, sr_returned_date_sk#15]

(8) Filter [codegen id : 3]
Input [5]: [sr_item_sk#11, sr_ticket_number#12, sr_return_amt#13, sr_net_loss#14, sr_returned_date_sk#15]
Condition : (isnotnull(sr_item_sk#11) AND isnotnull(sr_ticket_number#12))

(9) Project [codegen id : 3]
Output [4]: [sr_item_sk#11, sr_ticket_number#12, sr_return_amt#13, sr_net_loss#14]
Input [5]: [sr_item_sk#11, sr_ticket_number#12, sr_return_amt#13, sr_net_loss#14, sr_returned_date_sk#15]

(10) Exchange
Input [4]: [sr_item_sk#11, sr_ticket_number#12, sr_return_amt#13, sr_net_loss#14]
Arguments: hashpartitioning(sr_item_sk#11, sr_ticket_number#12, 5), ENSURE_REQUIREMENTS, [plan_id=4]

(11) Sort [codegen id : 4]
Input [4]: [sr_item_sk#11, sr_ticket_number#12, sr_return_amt#13, sr_net_loss#14]
Arguments: [sr_item_sk#11 ASC NULLS FIRST, sr_ticket_number#12 ASC NULLS FIRST], false, 0

(12) SortMergeJoin [codegen id : 9]
Left keys [2]: [ss_item_sk#1, ss_ticket_number#4]
Right keys [2]: [sr_item_sk#11, sr_ticket_number#12]
Join type: LeftOuter
Join condition: None

(13) Project [codegen id : 9]
Output [8]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#13, sr_net_loss#14]
Input [11]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ticket_number#4, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_item_sk#11, sr_ticket_number#12, sr_return_amt#13, sr_net_loss#14]

(14) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#16, i_current_price#17]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_current_price), GreaterThan(i_current_price,50.00), IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_current_price:decimal(7,2)>

(15) ColumnarToRow [codegen id : 5]
Input [2]: [i_item_sk#16, i_current_price#17]

(16) Filter [codegen id : 5]
Input [2]: [i_item_sk#16, i_current_price#17]
Condition : ((isnotnull(i_current_price#17) AND (i_current_price#17 > 50.00)) AND isnotnull(i_item_sk#16))

(17) Project [codegen id : 5]
Output [1]: [i_item_sk#16]
Input [2]: [i_item_sk#16, i_current_price#17]

(18) BroadcastExchange
Input [1]: [i_item_sk#16]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=5]

(19) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ss_item_sk#1]
Right keys [1]: [i_item_sk#16]
Join type: Inner
Join condition: None

(20) Project [codegen id : 9]
Output [7]: [ss_store_sk#2, ss_promo_sk#3, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#13, sr_net_loss#14]
Input [9]: [ss_item_sk#1, ss_store_sk#2, ss_promo_sk#3, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#13, sr_net_loss#14, i_item_sk#16]

(21) Scan parquet spark_catalog.default.promotion
Output [2]: [p_promo_sk#18, p_channel_tv#19]
Batched: true
Location [not included in comparison]/{warehouse_dir}/promotion]
PushedFilters: [IsNotNull(p_channel_tv), EqualTo(p_channel_tv,N), IsNotNull(p_promo_sk)]
ReadSchema: struct<p_promo_sk:int,p_channel_tv:string>

(22) ColumnarToRow [codegen id : 6]
Input [2]: [p_promo_sk#18, p_channel_tv#19]

(23) Filter [codegen id : 6]
Input [2]: [p_promo_sk#18, p_channel_tv#19]
Condition : ((isnotnull(p_channel_tv#19) AND (p_channel_tv#19 = N)) AND isnotnull(p_promo_sk#18))

(24) Project [codegen id : 6]
Output [1]: [p_promo_sk#18]
Input [2]: [p_promo_sk#18, p_channel_tv#19]

(25) BroadcastExchange
Input [1]: [p_promo_sk#18]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=6]

(26) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ss_promo_sk#3]
Right keys [1]: [p_promo_sk#18]
Join type: Inner
Join condition: None

(27) Project [codegen id : 9]
Output [6]: [ss_store_sk#2, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#13, sr_net_loss#14]
Input [8]: [ss_store_sk#2, ss_promo_sk#3, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#13, sr_net_loss#14, p_promo_sk#18]

(28) ReusedExchange [Reuses operator id: 126]
Output [1]: [d_date_sk#20]

(29) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ss_sold_date_sk#7]
Right keys [1]: [d_date_sk#20]
Join type: Inner
Join condition: None

(30) Project [codegen id : 9]
Output [5]: [ss_store_sk#2, ss_ext_sales_price#5, ss_net_profit#6, sr_return_amt#13, sr_net_loss#14]
Input [7]: [ss_store_sk#2, ss_ext_sales_price#5, ss_net_profit#6, ss_sold_date_sk#7, sr_return_amt#13, sr_net_loss#14, d_date_sk#20]

(31) Scan parquet spark_catalog.default.store
Output [2]: [s_store_sk#21, s_store_id#22]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int,s_store_id:string>

(32) ColumnarToRow [codegen id : 8]
Input [2]: [s_store_sk#21, s_store_id#22]

(33) Filter [codegen id : 8]
Input [2]: [s_store_sk#21, s_store_id#22]
Condition : isnotnull(s_store_sk#21)

(34) BroadcastExchange
Input [2]: [s_store_sk#21, s_store_id#22]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=7]

(35) BroadcastHashJoin [codegen id : 9]
Left keys [1]: [ss_store_sk#2]
Right keys [1]: [s_store_sk#21]
Join type: Inner
Join condition: None

(36) Project [codegen id : 9]
Output [5]: [ss_ext_sales_price#5, ss_net_profit#6, sr_return_amt#13, sr_net_loss#14, s_store_id#22]
Input [7]: [ss_store_sk#2, ss_ext_sales_price#5, ss_net_profit#6, sr_return_amt#13, sr_net_loss#14, s_store_sk#21, s_store_id#22]

(37) HashAggregate [codegen id : 9]
Input [5]: [ss_ext_sales_price#5, ss_net_profit#6, sr_return_amt#13, sr_net_loss#14, s_store_id#22]
Keys [1]: [s_store_id#22]
Functions [3]: [partial_sum(UnscaledValue(ss_ext_sales_price#5)), partial_sum(coalesce(cast(sr_return_amt#13 as decimal(12,2)), 0.00)), partial_sum((ss_net_profit#6 - coalesce(cast(sr_net_loss#14 as decimal(12,2)), 0.00)))]
Aggregate Attributes [5]: [sum#23, sum#24, isEmpty#25, sum#26, isEmpty#27]
Results [6]: [s_store_id#22, sum#28, sum#29, isEmpty#30, sum#31, isEmpty#32]

(38) Exchange
Input [6]: [s_store_id#22, sum#28, sum#29, isEmpty#30, sum#31, isEmpty#32]
Arguments: hashpartitioning(s_store_id#22, 5), ENSURE_REQUIREMENTS, [plan_id=8]

(39) HashAggregate [codegen id : 10]
Input [6]: [s_store_id#22, sum#28, sum#29, isEmpty#30, sum#31, isEmpty#32]
Keys [1]: [s_store_id#22]
Functions [3]: [sum(UnscaledValue(ss_ext_sales_price#5)), sum(coalesce(cast(sr_return_amt#13 as decimal(12,2)), 0.00)), sum((ss_net_profit#6 - coalesce(cast(sr_net_loss#14 as decimal(12,2)), 0.00)))]
Aggregate Attributes [3]: [sum(UnscaledValue(ss_ext_sales_price#5))#33, sum(coalesce(cast(sr_return_amt#13 as decimal(12,2)), 0.00))#34, sum((ss_net_profit#6 - coalesce(cast(sr_net_loss#14 as decimal(12,2)), 0.00)))#35]
Results [5]: [MakeDecimal(sum(UnscaledValue(ss_ext_sales_price#5))#33,17,2) AS sales#36, sum(coalesce(cast(sr_return_amt#13 as decimal(12,2)), 0.00))#34 AS returns#37, sum((ss_net_profit#6 - coalesce(cast(sr_net_loss#14 as decimal(12,2)), 0.00)))#35 AS profit#38, store channel AS channel#39, concat(store, s_store_id#22) AS id#40]

(40) Scan parquet spark_catalog.default.catalog_sales
Output [7]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_order_number#44, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(cs_sold_date_sk#47), dynamicpruningexpression(cs_sold_date_sk#47 IN dynamicpruning#8)]
PushedFilters: [IsNotNull(cs_catalog_page_sk), IsNotNull(cs_item_sk), IsNotNull(cs_promo_sk)]
ReadSchema: struct<cs_catalog_page_sk:int,cs_item_sk:int,cs_promo_sk:int,cs_order_number:int,cs_ext_sales_price:decimal(7,2),cs_net_profit:decimal(7,2)>

(41) ColumnarToRow [codegen id : 11]
Input [7]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_order_number#44, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47]

(42) Filter [codegen id : 11]
Input [7]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_order_number#44, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47]
Condition : ((((isnotnull(cs_catalog_page_sk#41) AND isnotnull(cs_item_sk#42)) AND isnotnull(cs_promo_sk#43)) AND might_contain(ReusedSubquery Subquery scalar-subquery#9, [id=#1], xxhash64(cs_item_sk#42, 42))) AND might_contain(ReusedSubquery Subquery scalar-subquery#10, [id=#2], xxhash64(cs_promo_sk#43, 42)))

(43) Exchange
Input [7]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_order_number#44, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47]
Arguments: hashpartitioning(cs_item_sk#42, cs_order_number#44, 5), ENSURE_REQUIREMENTS, [plan_id=9]

(44) Sort [codegen id : 12]
Input [7]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_order_number#44, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47]
Arguments: [cs_item_sk#42 ASC NULLS FIRST, cs_order_number#44 ASC NULLS FIRST], false, 0

(45) Scan parquet spark_catalog.default.catalog_returns
Output [5]: [cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51, cr_returned_date_sk#52]
Batched: true
Location [not included in comparison]/{warehouse_dir}/catalog_returns]
PushedFilters: [IsNotNull(cr_item_sk), IsNotNull(cr_order_number)]
ReadSchema: struct<cr_item_sk:int,cr_order_number:int,cr_return_amount:decimal(7,2),cr_net_loss:decimal(7,2)>

(46) ColumnarToRow [codegen id : 13]
Input [5]: [cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51, cr_returned_date_sk#52]

(47) Filter [codegen id : 13]
Input [5]: [cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51, cr_returned_date_sk#52]
Condition : (isnotnull(cr_item_sk#48) AND isnotnull(cr_order_number#49))

(48) Project [codegen id : 13]
Output [4]: [cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51]
Input [5]: [cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51, cr_returned_date_sk#52]

(49) Exchange
Input [4]: [cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51]
Arguments: hashpartitioning(cr_item_sk#48, cr_order_number#49, 5), ENSURE_REQUIREMENTS, [plan_id=10]

(50) Sort [codegen id : 14]
Input [4]: [cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51]
Arguments: [cr_item_sk#48 ASC NULLS FIRST, cr_order_number#49 ASC NULLS FIRST], false, 0

(51) SortMergeJoin [codegen id : 19]
Left keys [2]: [cs_item_sk#42, cs_order_number#44]
Right keys [2]: [cr_item_sk#48, cr_order_number#49]
Join type: LeftOuter
Join condition: None

(52) Project [codegen id : 19]
Output [8]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47, cr_return_amount#50, cr_net_loss#51]
Input [11]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_order_number#44, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47, cr_item_sk#48, cr_order_number#49, cr_return_amount#50, cr_net_loss#51]

(53) ReusedExchange [Reuses operator id: 18]
Output [1]: [i_item_sk#53]

(54) BroadcastHashJoin [codegen id : 19]
Left keys [1]: [cs_item_sk#42]
Right keys [1]: [i_item_sk#53]
Join type: Inner
Join condition: None

(55) Project [codegen id : 19]
Output [7]: [cs_catalog_page_sk#41, cs_promo_sk#43, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47, cr_return_amount#50, cr_net_loss#51]
Input [9]: [cs_catalog_page_sk#41, cs_item_sk#42, cs_promo_sk#43, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47, cr_return_amount#50, cr_net_loss#51, i_item_sk#53]

(56) ReusedExchange [Reuses operator id: 25]
Output [1]: [p_promo_sk#54]

(57) BroadcastHashJoin [codegen id : 19]
Left keys [1]: [cs_promo_sk#43]
Right keys [1]: [p_promo_sk#54]
Join type: Inner
Join condition: None

(58) Project [codegen id : 19]
Output [6]: [cs_catalog_page_sk#41, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47, cr_return_amount#50, cr_net_loss#51]
Input [8]: [cs_catalog_page_sk#41, cs_promo_sk#43, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47, cr_return_amount#50, cr_net_loss#51, p_promo_sk#54]

(59) ReusedExchange [Reuses operator id: 126]
Output [1]: [d_date_sk#55]

(60) BroadcastHashJoin [codegen id : 19]
Left keys [1]: [cs_sold_date_sk#47]
Right keys [1]: [d_date_sk#55]
Join type: Inner
Join condition: None

(61) Project [codegen id : 19]
Output [5]: [cs_catalog_page_sk#41, cs_ext_sales_price#45, cs_net_profit#46, cr_return_amount#50, cr_net_loss#51]
Input [7]: [cs_catalog_page_sk#41, cs_ext_sales_price#45, cs_net_profit#46, cs_sold_date_sk#47, cr_return_amount#50, cr_net_loss#51, d_date_sk#55]

(62) Scan parquet spark_catalog.default.catalog_page
Output [2]: [cp_catalog_page_sk#56, cp_catalog_page_id#57]
Batched: true
Location [not included in comparison]/{warehouse_dir}/catalog_page]
PushedFilters: [IsNotNull(cp_catalog_page_sk)]
ReadSchema: struct<cp_catalog_page_sk:int,cp_catalog_page_id:string>

(63) ColumnarToRow [codegen id : 18]
Input [2]: [cp_catalog_page_sk#56, cp_catalog_page_id#57]

(64) Filter [codegen id : 18]
Input [2]: [cp_catalog_page_sk#56, cp_catalog_page_id#57]
Condition : isnotnull(cp_catalog_page_sk#56)

(65) BroadcastExchange
Input [2]: [cp_catalog_page_sk#56, cp_catalog_page_id#57]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=11]

(66) BroadcastHashJoin [codegen id : 19]
Left keys [1]: [cs_catalog_page_sk#41]
Right keys [1]: [cp_catalog_page_sk#56]
Join type: Inner
Join condition: None

(67) Project [codegen id : 19]
Output [5]: [cs_ext_sales_price#45, cs_net_profit#46, cr_return_amount#50, cr_net_loss#51, cp_catalog_page_id#57]
Input [7]: [cs_catalog_page_sk#41, cs_ext_sales_price#45, cs_net_profit#46, cr_return_amount#50, cr_net_loss#51, cp_catalog_page_sk#56, cp_catalog_page_id#57]

(68) HashAggregate [codegen id : 19]
Input [5]: [cs_ext_sales_price#45, cs_net_profit#46, cr_return_amount#50, cr_net_loss#51, cp_catalog_page_id#57]
Keys [1]: [cp_catalog_page_id#57]
Functions [3]: [partial_sum(UnscaledValue(cs_ext_sales_price#45)), partial_sum(coalesce(cast(cr_return_amount#50 as decimal(12,2)), 0.00)), partial_sum((cs_net_profit#46 - coalesce(cast(cr_net_loss#51 as decimal(12,2)), 0.00)))]
Aggregate Attributes [5]: [sum#58, sum#59, isEmpty#60, sum#61, isEmpty#62]
Results [6]: [cp_catalog_page_id#57, sum#63, sum#64, isEmpty#65, sum#66, isEmpty#67]

(69) Exchange
Input [6]: [cp_catalog_page_id#57, sum#63, sum#64, isEmpty#65, sum#66, isEmpty#67]
Arguments: hashpartitioning(cp_catalog_page_id#57, 5), ENSURE_REQUIREMENTS, [plan_id=12]

(70) HashAggregate [codegen id : 20]
Input [6]: [cp_catalog_page_id#57, sum#63, sum#64, isEmpty#65, sum#66, isEmpty#67]
Keys [1]: [cp_catalog_page_id#57]
Functions [3]: [sum(UnscaledValue(cs_ext_sales_price#45)), sum(coalesce(cast(cr_return_amount#50 as decimal(12,2)), 0.00)), sum((cs_net_profit#46 - coalesce(cast(cr_net_loss#51 as decimal(12,2)), 0.00)))]
Aggregate Attributes [3]: [sum(UnscaledValue(cs_ext_sales_price#45))#68, sum(coalesce(cast(cr_return_amount#50 as decimal(12,2)), 0.00))#69, sum((cs_net_profit#46 - coalesce(cast(cr_net_loss#51 as decimal(12,2)), 0.00)))#70]
Results [5]: [MakeDecimal(sum(UnscaledValue(cs_ext_sales_price#45))#68,17,2) AS sales#71, sum(coalesce(cast(cr_return_amount#50 as decimal(12,2)), 0.00))#69 AS returns#72, sum((cs_net_profit#46 - coalesce(cast(cr_net_loss#51 as decimal(12,2)), 0.00)))#70 AS profit#73, catalog channel AS channel#74, concat(catalog_page, cp_catalog_page_id#57) AS id#75]

(71) Scan parquet spark_catalog.default.web_sales
Output [7]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_order_number#79, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82]
Batched: true
Location: InMemoryFileIndex []
PartitionFilters: [isnotnull(ws_sold_date_sk#82), dynamicpruningexpression(ws_sold_date_sk#82 IN dynamicpruning#8)]
PushedFilters: [IsNotNull(ws_web_site_sk), IsNotNull(ws_item_sk), IsNotNull(ws_promo_sk)]
ReadSchema: struct<ws_item_sk:int,ws_web_site_sk:int,ws_promo_sk:int,ws_order_number:int,ws_ext_sales_price:decimal(7,2),ws_net_profit:decimal(7,2)>

(72) ColumnarToRow [codegen id : 21]
Input [7]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_order_number#79, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82]

(73) Filter [codegen id : 21]
Input [7]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_order_number#79, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82]
Condition : ((((isnotnull(ws_web_site_sk#77) AND isnotnull(ws_item_sk#76)) AND isnotnull(ws_promo_sk#78)) AND might_contain(ReusedSubquery Subquery scalar-subquery#9, [id=#1], xxhash64(ws_item_sk#76, 42))) AND might_contain(ReusedSubquery Subquery scalar-subquery#10, [id=#2], xxhash64(ws_promo_sk#78, 42)))

(74) Exchange
Input [7]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_order_number#79, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82]
Arguments: hashpartitioning(ws_item_sk#76, ws_order_number#79, 5), ENSURE_REQUIREMENTS, [plan_id=13]

(75) Sort [codegen id : 22]
Input [7]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_order_number#79, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82]
Arguments: [ws_item_sk#76 ASC NULLS FIRST, ws_order_number#79 ASC NULLS FIRST], false, 0

(76) Scan parquet spark_catalog.default.web_returns
Output [5]: [wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86, wr_returned_date_sk#87]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_returns]
PushedFilters: [IsNotNull(wr_item_sk), IsNotNull(wr_order_number)]
ReadSchema: struct<wr_item_sk:int,wr_order_number:int,wr_return_amt:decimal(7,2),wr_net_loss:decimal(7,2)>

(77) ColumnarToRow [codegen id : 23]
Input [5]: [wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86, wr_returned_date_sk#87]

(78) Filter [codegen id : 23]
Input [5]: [wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86, wr_returned_date_sk#87]
Condition : (isnotnull(wr_item_sk#83) AND isnotnull(wr_order_number#84))

(79) Project [codegen id : 23]
Output [4]: [wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86]
Input [5]: [wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86, wr_returned_date_sk#87]

(80) Exchange
Input [4]: [wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86]
Arguments: hashpartitioning(wr_item_sk#83, wr_order_number#84, 5), ENSURE_REQUIREMENTS, [plan_id=14]

(81) Sort [codegen id : 24]
Input [4]: [wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86]
Arguments: [wr_item_sk#83 ASC NULLS FIRST, wr_order_number#84 ASC NULLS FIRST], false, 0

(82) SortMergeJoin [codegen id : 29]
Left keys [2]: [ws_item_sk#76, ws_order_number#79]
Right keys [2]: [wr_item_sk#83, wr_order_number#84]
Join type: LeftOuter
Join condition: None

(83) Project [codegen id : 29]
Output [8]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82, wr_return_amt#85, wr_net_loss#86]
Input [11]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_order_number#79, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82, wr_item_sk#83, wr_order_number#84, wr_return_amt#85, wr_net_loss#86]

(84) ReusedExchange [Reuses operator id: 18]
Output [1]: [i_item_sk#88]

(85) BroadcastHashJoin [codegen id : 29]
Left keys [1]: [ws_item_sk#76]
Right keys [1]: [i_item_sk#88]
Join type: Inner
Join condition: None

(86) Project [codegen id : 29]
Output [7]: [ws_web_site_sk#77, ws_promo_sk#78, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82, wr_return_amt#85, wr_net_loss#86]
Input [9]: [ws_item_sk#76, ws_web_site_sk#77, ws_promo_sk#78, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82, wr_return_amt#85, wr_net_loss#86, i_item_sk#88]

(87) ReusedExchange [Reuses operator id: 25]
Output [1]: [p_promo_sk#89]

(88) BroadcastHashJoin [codegen id : 29]
Left keys [1]: [ws_promo_sk#78]
Right keys [1]: [p_promo_sk#89]
Join type: Inner
Join condition: None

(89) Project [codegen id : 29]
Output [6]: [ws_web_site_sk#77, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82, wr_return_amt#85, wr_net_loss#86]
Input [8]: [ws_web_site_sk#77, ws_promo_sk#78, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82, wr_return_amt#85, wr_net_loss#86, p_promo_sk#89]

(90) ReusedExchange [Reuses operator id: 126]
Output [1]: [d_date_sk#90]

(91) BroadcastHashJoin [codegen id : 29]
Left keys [1]: [ws_sold_date_sk#82]
Right keys [1]: [d_date_sk#90]
Join type: Inner
Join condition: None

(92) Project [codegen id : 29]
Output [5]: [ws_web_site_sk#77, ws_ext_sales_price#80, ws_net_profit#81, wr_return_amt#85, wr_net_loss#86]
Input [7]: [ws_web_site_sk#77, ws_ext_sales_price#80, ws_net_profit#81, ws_sold_date_sk#82, wr_return_amt#85, wr_net_loss#86, d_date_sk#90]

(93) Scan parquet spark_catalog.default.web_site
Output [2]: [web_site_sk#91, web_site_id#92]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_site]
PushedFilters: [IsNotNull(web_site_sk)]
ReadSchema: struct<web_site_sk:int,web_site_id:string>

(94) ColumnarToRow [codegen id : 28]
Input [2]: [web_site_sk#91, web_site_id#92]

(95) Filter [codegen id : 28]
Input [2]: [web_site_sk#91, web_site_id#92]
Condition : isnotnull(web_site_sk#91)

(96) BroadcastExchange
Input [2]: [web_site_sk#91, web_site_id#92]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=15]

(97) BroadcastHashJoin [codegen id : 29]
Left keys [1]: [ws_web_site_sk#77]
Right keys [1]: [web_site_sk#91]
Join type: Inner
Join condition: None

(98) Project [codegen id : 29]
Output [5]: [ws_ext_sales_price#80, ws_net_profit#81, wr_return_amt#85, wr_net_loss#86, web_site_id#92]
Input [7]: [ws_web_site_sk#77, ws_ext_sales_price#80, ws_net_profit#81, wr_return_amt#85, wr_net_loss#86, web_site_sk#91, web_site_id#92]

(99) HashAggregate [codegen id : 29]
Input [5]: [ws_ext_sales_price#80, ws_net_profit#81, wr_return_amt#85, wr_net_loss#86, web_site_id#92]
Keys [1]: [web_site_id#92]
Functions [3]: [partial_sum(UnscaledValue(ws_ext_sales_price#80)), partial_sum(coalesce(cast(wr_return_amt#85 as decimal(12,2)), 0.00)), partial_sum((ws_net_profit#81 - coalesce(cast(wr_net_loss#86 as decimal(12,2)), 0.00)))]
Aggregate Attributes [5]: [sum#93, sum#94, isEmpty#95, sum#96, isEmpty#97]
Results [6]: [web_site_id#92, sum#98, sum#99, isEmpty#100, sum#101, isEmpty#102]

(100) Exchange
Input [6]: [web_site_id#92, sum#98, sum#99, isEmpty#100, sum#101, isEmpty#102]
Arguments: hashpartitioning(web_site_id#92, 5), ENSURE_REQUIREMENTS, [plan_id=16]

(101) HashAggregate [codegen id : 30]
Input [6]: [web_site_id#92, sum#98, sum#99, isEmpty#100, sum#101, isEmpty#102]
Keys [1]: [web_site_id#92]
Functions [3]: [sum(UnscaledValue(ws_ext_sales_price#80)), sum(coalesce(cast(wr_return_amt#85 as decimal(12,2)), 0.00)), sum((ws_net_profit#81 - coalesce(cast(wr_net_loss#86 as decimal(12,2)), 0.00)))]
Aggregate Attributes [3]: [sum(UnscaledValue(ws_ext_sales_price#80))#103, sum(coalesce(cast(wr_return_amt#85 as decimal(12,2)), 0.00))#104, sum((ws_net_profit#81 - coalesce(cast(wr_net_loss#86 as decimal(12,2)), 0.00)))#105]
Results [5]: [MakeDecimal(sum(UnscaledValue(ws_ext_sales_price#80))#103,17,2) AS sales#106, sum(coalesce(cast(wr_return_amt#85 as decimal(12,2)), 0.00))#104 AS returns#107, sum((ws_net_profit#81 - coalesce(cast(wr_net_loss#86 as decimal(12,2)), 0.00)))#105 AS profit#108, web channel AS channel#109, concat(web_site, web_site_id#92) AS id#110]

(102) Union

(103) Expand [codegen id : 31]
Input [5]: [sales#36, returns#37, profit#38, channel#39, id#40]
Arguments: [[sales#36, returns#37, profit#38, channel#39, id#40, 0], [sales#36, returns#37, profit#38, channel#39, null, 1], [sales#36, returns#37, profit#38, null, null, 3]], [sales#36, returns#37, profit#38, channel#111, id#112, spark_grouping_id#113]

(104) HashAggregate [codegen id : 31]
Input [6]: [sales#36, returns#37, profit#38, channel#111, id#112, spark_grouping_id#113]
Keys [3]: [channel#111, id#112, spark_grouping_id#113]
Functions [3]: [partial_sum(sales#36), partial_sum(returns#37), partial_sum(profit#38)]
Aggregate Attributes [6]: [sum#114, isEmpty#115, sum#116, isEmpty#117, sum#118, isEmpty#119]
Results [9]: [channel#111, id#112, spark_grouping_id#113, sum#120, isEmpty#121, sum#122, isEmpty#123, sum#124, isEmpty#125]

(105) Exchange
Input [9]: [channel#111, id#112, spark_grouping_id#113, sum#120, isEmpty#121, sum#122, isEmpty#123, sum#124, isEmpty#125]
Arguments: hashpartitioning(channel#111, id#112, spark_grouping_id#113, 5), ENSURE_REQUIREMENTS, [plan_id=17]

(106) HashAggregate [codegen id : 32]
Input [9]: [channel#111, id#112, spark_grouping_id#113, sum#120, isEmpty#121, sum#122, isEmpty#123, sum#124, isEmpty#125]
Keys [3]: [channel#111, id#112, spark_grouping_id#113]
Functions [3]: [sum(sales#36), sum(returns#37), sum(profit#38)]
Aggregate Attributes [3]: [sum(sales#36)#126, sum(returns#37)#127, sum(profit#38)#128]
Results [5]: [channel#111, id#112, sum(sales#36)#126 AS sales#129, sum(returns#37)#127 AS returns#130, sum(profit#38)#128 AS profit#131]

(107) TakeOrderedAndProject
Input [5]: [channel#111, id#112, sales#129, returns#130, profit#131]
Arguments: 100, [channel#111 ASC NULLS FIRST, id#112 ASC NULLS FIRST], [channel#111, id#112, sales#129, returns#130, profit#131]

===== Subqueries =====

Subquery:1 Hosting operator id = 3 Hosting Expression = Subquery scalar-subquery#9, [id=#1]
ObjectHashAggregate (114)
+- Exchange (113)
   +- ObjectHashAggregate (112)
      +- * Project (111)
         +- * Filter (110)
            +- * ColumnarToRow (109)
               +- Scan parquet spark_catalog.default.item (108)


(108) Scan parquet spark_catalog.default.item
Output [2]: [i_item_sk#16, i_current_price#17]
Batched: true
Location [not included in comparison]/{warehouse_dir}/item]
PushedFilters: [IsNotNull(i_current_price), GreaterThan(i_current_price,50.00), IsNotNull(i_item_sk)]
ReadSchema: struct<i_item_sk:int,i_current_price:decimal(7,2)>

(109) ColumnarToRow [codegen id : 1]
Input [2]: [i_item_sk#16, i_current_price#17]

(110) Filter [codegen id : 1]
Input [2]: [i_item_sk#16, i_current_price#17]
Condition : ((isnotnull(i_current_price#17) AND (i_current_price#17 > 50.00)) AND isnotnull(i_item_sk#16))

(111) Project [codegen id : 1]
Output [1]: [i_item_sk#16]
Input [2]: [i_item_sk#16, i_current_price#17]

(112) ObjectHashAggregate
Input [1]: [i_item_sk#16]
Keys: []
Functions [1]: [partial_bloom_filter_agg(xxhash64(i_item_sk#16, 42), 101823, 1521109, 0, 0)]
Aggregate Attributes [1]: [buf#132]
Results [1]: [buf#133]

(113) Exchange
Input [1]: [buf#133]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=18]

(114) ObjectHashAggregate
Input [1]: [buf#133]
Keys: []
Functions [1]: [bloom_filter_agg(xxhash64(i_item_sk#16, 42), 101823, 1521109, 0, 0)]
Aggregate Attributes [1]: [bloom_filter_agg(xxhash64(i_item_sk#16, 42), 101823, 1521109, 0, 0)#134]
Results [1]: [bloom_filter_agg(xxhash64(i_item_sk#16, 42), 101823, 1521109, 0, 0)#134 AS bloomFilter#135]

Subquery:2 Hosting operator id = 3 Hosting Expression = Subquery scalar-subquery#10, [id=#2]
ObjectHashAggregate (121)
+- Exchange (120)
   +- ObjectHashAggregate (119)
      +- * Project (118)
         +- * Filter (117)
            +- * ColumnarToRow (116)
               +- Scan parquet spark_catalog.default.promotion (115)


(115) Scan parquet spark_catalog.default.promotion
Output [2]: [p_promo_sk#18, p_channel_tv#19]
Batched: true
Location [not included in comparison]/{warehouse_dir}/promotion]
PushedFilters: [IsNotNull(p_channel_tv), EqualTo(p_channel_tv,N), IsNotNull(p_promo_sk)]
ReadSchema: struct<p_promo_sk:int,p_channel_tv:string>

(116) ColumnarToRow [codegen id : 1]
Input [2]: [p_promo_sk#18, p_channel_tv#19]

(117) Filter [codegen id : 1]
Input [2]: [p_promo_sk#18, p_channel_tv#19]
Condition : ((isnotnull(p_channel_tv#19) AND (p_channel_tv#19 = N)) AND isnotnull(p_promo_sk#18))

(118) Project [codegen id : 1]
Output [1]: [p_promo_sk#18]
Input [2]: [p_promo_sk#18, p_channel_tv#19]

(119) ObjectHashAggregate
Input [1]: [p_promo_sk#18]
Keys: []
Functions [1]: [partial_bloom_filter_agg(xxhash64(p_promo_sk#18, 42), 986, 24246, 0, 0)]
Aggregate Attributes [1]: [buf#136]
Results [1]: [buf#137]

(120) Exchange
Input [1]: [buf#137]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=19]

(121) ObjectHashAggregate
Input [1]: [buf#137]
Keys: []
Functions [1]: [bloom_filter_agg(xxhash64(p_promo_sk#18, 42), 986, 24246, 0, 0)]
Aggregate Attributes [1]: [bloom_filter_agg(xxhash64(p_promo_sk#18, 42), 986, 24246, 0, 0)#138]
Results [1]: [bloom_filter_agg(xxhash64(p_promo_sk#18, 42), 986, 24246, 0, 0)#138 AS bloomFilter#139]

Subquery:3 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#7 IN dynamicpruning#8
BroadcastExchange (126)
+- * Project (125)
   +- * Filter (124)
      +- * ColumnarToRow (123)
         +- Scan parquet spark_catalog.default.date_dim (122)


(122) Scan parquet spark_catalog.default.date_dim
Output [2]: [d_date_sk#20, d_date#140]
Batched: true
Location [not included in comparison]/{warehouse_dir}/date_dim]
PushedFilters: [IsNotNull(d_date), GreaterThanOrEqual(d_date,2000-08-23), LessThanOrEqual(d_date,2000-09-22), IsNotNull(d_date_sk)]
ReadSchema: struct<d_date_sk:int,d_date:date>

(123) ColumnarToRow [codegen id : 1]
Input [2]: [d_date_sk#20, d_date#140]

(124) Filter [codegen id : 1]
Input [2]: [d_date_sk#20, d_date#140]
Condition : (((isnotnull(d_date#140) AND (d_date#140 >= 2000-08-23)) AND (d_date#140 <= 2000-09-22)) AND isnotnull(d_date_sk#20))

(125) Project [codegen id : 1]
Output [1]: [d_date_sk#20]
Input [2]: [d_date_sk#20, d_date#140]

(126) BroadcastExchange
Input [1]: [d_date_sk#20]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=20]

Subquery:4 Hosting operator id = 42 Hosting Expression = ReusedSubquery Subquery scalar-subquery#9, [id=#1]

Subquery:5 Hosting operator id = 42 Hosting Expression = ReusedSubquery Subquery scalar-subquery#10, [id=#2]

Subquery:6 Hosting operator id = 40 Hosting Expression = cs_sold_date_sk#47 IN dynamicpruning#8

Subquery:7 Hosting operator id = 73 Hosting Expression = ReusedSubquery Subquery scalar-subquery#9, [id=#1]

Subquery:8 Hosting operator id = 73 Hosting Expression = ReusedSubquery Subquery scalar-subquery#10, [id=#2]

Subquery:9 Hosting operator id = 71 Hosting Expression = ws_sold_date_sk#82 IN dynamicpruning#8


