== Physical Plan ==
* Project (51)
+- * BroadcastNestedLoopJoin Inner BuildRight (50)
   :- * HashAggregate (28)
   :  +- Exchange (27)
   :     +- * HashAggregate (26)
   :        +- * Project (25)
   :           +- * BroadcastHashJoin Inner BuildRight (24)
   :              :- * Project (18)
   :              :  +- * BroadcastHashJoin Inner BuildRight (17)
   :              :     :- * Project (11)
   :              :     :  +- * BroadcastHashJoin Inner BuildRight (10)
   :              :     :     :- * Project (4)
   :              :     :     :  +- * Filter (3)
   :              :     :     :     +- * ColumnarToRow (2)
   :              :     :     :        +- Scan parquet spark_catalog.default.web_sales (1)
   :              :     :     +- BroadcastExchange (9)
   :              :     :        +- * Project (8)
   :              :     :           +- * Filter (7)
   :              :     :              +- * ColumnarToRow (6)
   :              :     :                 +- Scan parquet spark_catalog.default.household_demographics (5)
   :              :     +- BroadcastExchange (16)
   :              :        +- * Project (15)
   :              :           +- * Filter (14)
   :              :              +- * ColumnarToRow (13)
   :              :                 +- Scan parquet spark_catalog.default.time_dim (12)
   :              +- BroadcastExchange (23)
   :                 +- * Project (22)
   :                    +- * Filter (21)
   :                       +- * ColumnarToRow (20)
   :                          +- Scan parquet spark_catalog.default.web_page (19)
   +- BroadcastExchange (49)
      +- * HashAggregate (48)
         +- Exchange (47)
            +- * HashAggregate (46)
               +- * Project (45)
                  +- * BroadcastHashJoin Inner BuildRight (44)
                     :- * Project (42)
                     :  +- * BroadcastHashJoin Inner BuildRight (41)
                     :     :- * Project (35)
                     :     :  +- * BroadcastHashJoin Inner BuildRight (34)
                     :     :     :- * Project (32)
                     :     :     :  +- * Filter (31)
                     :     :     :     +- * ColumnarToRow (30)
                     :     :     :        +- Scan parquet spark_catalog.default.web_sales (29)
                     :     :     +- ReusedExchange (33)
                     :     +- BroadcastExchange (40)
                     :        +- * Project (39)
                     :           +- * Filter (38)
                     :              +- * ColumnarToRow (37)
                     :                 +- Scan parquet spark_catalog.default.time_dim (36)
                     +- ReusedExchange (43)


(1) Scan parquet spark_catalog.default.web_sales
Output [4]: [ws_sold_time_sk#1, ws_ship_hdemo_sk#2, ws_web_page_sk#3, ws_sold_date_sk#4]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_sales]
PushedFilters: [IsNotNull(ws_ship_hdemo_sk), IsNotNull(ws_sold_time_sk), IsNotNull(ws_web_page_sk)]
ReadSchema: struct<ws_sold_time_sk:int,ws_ship_hdemo_sk:int,ws_web_page_sk:int>

(2) ColumnarToRow [codegen id : 4]
Input [4]: [ws_sold_time_sk#1, ws_ship_hdemo_sk#2, ws_web_page_sk#3, ws_sold_date_sk#4]

(3) Filter [codegen id : 4]
Input [4]: [ws_sold_time_sk#1, ws_ship_hdemo_sk#2, ws_web_page_sk#3, ws_sold_date_sk#4]
Condition : ((isnotnull(ws_ship_hdemo_sk#2) AND isnotnull(ws_sold_time_sk#1)) AND isnotnull(ws_web_page_sk#3))

(4) Project [codegen id : 4]
Output [3]: [ws_sold_time_sk#1, ws_ship_hdemo_sk#2, ws_web_page_sk#3]
Input [4]: [ws_sold_time_sk#1, ws_ship_hdemo_sk#2, ws_web_page_sk#3, ws_sold_date_sk#4]

(5) Scan parquet spark_catalog.default.household_demographics
Output [2]: [hd_demo_sk#5, hd_dep_count#6]
Batched: true
Location [not included in comparison]/{warehouse_dir}/household_demographics]
PushedFilters: [IsNotNull(hd_dep_count), EqualTo(hd_dep_count,6), IsNotNull(hd_demo_sk)]
ReadSchema: struct<hd_demo_sk:int,hd_dep_count:int>

(6) ColumnarToRow [codegen id : 1]
Input [2]: [hd_demo_sk#5, hd_dep_count#6]

(7) Filter [codegen id : 1]
Input [2]: [hd_demo_sk#5, hd_dep_count#6]
Condition : ((isnotnull(hd_dep_count#6) AND (hd_dep_count#6 = 6)) AND isnotnull(hd_demo_sk#5))

(8) Project [codegen id : 1]
Output [1]: [hd_demo_sk#5]
Input [2]: [hd_demo_sk#5, hd_dep_count#6]

(9) BroadcastExchange
Input [1]: [hd_demo_sk#5]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=1]

(10) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ws_ship_hdemo_sk#2]
Right keys [1]: [hd_demo_sk#5]
Join type: Inner
Join condition: None

(11) Project [codegen id : 4]
Output [2]: [ws_sold_time_sk#1, ws_web_page_sk#3]
Input [4]: [ws_sold_time_sk#1, ws_ship_hdemo_sk#2, ws_web_page_sk#3, hd_demo_sk#5]

(12) Scan parquet spark_catalog.default.time_dim
Output [2]: [t_time_sk#7, t_hour#8]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), GreaterThanOrEqual(t_hour,8), LessThanOrEqual(t_hour,9), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int>

(13) ColumnarToRow [codegen id : 2]
Input [2]: [t_time_sk#7, t_hour#8]

(14) Filter [codegen id : 2]
Input [2]: [t_time_sk#7, t_hour#8]
Condition : (((isnotnull(t_hour#8) AND (t_hour#8 >= 8)) AND (t_hour#8 <= 9)) AND isnotnull(t_time_sk#7))

(15) Project [codegen id : 2]
Output [1]: [t_time_sk#7]
Input [2]: [t_time_sk#7, t_hour#8]

(16) BroadcastExchange
Input [1]: [t_time_sk#7]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=2]

(17) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ws_sold_time_sk#1]
Right keys [1]: [t_time_sk#7]
Join type: Inner
Join condition: None

(18) Project [codegen id : 4]
Output [1]: [ws_web_page_sk#3]
Input [3]: [ws_sold_time_sk#1, ws_web_page_sk#3, t_time_sk#7]

(19) Scan parquet spark_catalog.default.web_page
Output [2]: [wp_web_page_sk#9, wp_char_count#10]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_page]
PushedFilters: [IsNotNull(wp_char_count), GreaterThanOrEqual(wp_char_count,5000), LessThanOrEqual(wp_char_count,5200), IsNotNull(wp_web_page_sk)]
ReadSchema: struct<wp_web_page_sk:int,wp_char_count:int>

(20) ColumnarToRow [codegen id : 3]
Input [2]: [wp_web_page_sk#9, wp_char_count#10]

(21) Filter [codegen id : 3]
Input [2]: [wp_web_page_sk#9, wp_char_count#10]
Condition : (((isnotnull(wp_char_count#10) AND (wp_char_count#10 >= 5000)) AND (wp_char_count#10 <= 5200)) AND isnotnull(wp_web_page_sk#9))

(22) Project [codegen id : 3]
Output [1]: [wp_web_page_sk#9]
Input [2]: [wp_web_page_sk#9, wp_char_count#10]

(23) BroadcastExchange
Input [1]: [wp_web_page_sk#9]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(24) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ws_web_page_sk#3]
Right keys [1]: [wp_web_page_sk#9]
Join type: Inner
Join condition: None

(25) Project [codegen id : 4]
Output: []
Input [2]: [ws_web_page_sk#3, wp_web_page_sk#9]

(26) HashAggregate [codegen id : 4]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#11]
Results [1]: [count#12]

(27) Exchange
Input [1]: [count#12]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=4]

(28) HashAggregate [codegen id : 10]
Input [1]: [count#12]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#13]
Results [1]: [count(1)#13 AS amc#14]

(29) Scan parquet spark_catalog.default.web_sales
Output [4]: [ws_sold_time_sk#15, ws_ship_hdemo_sk#16, ws_web_page_sk#17, ws_sold_date_sk#18]
Batched: true
Location [not included in comparison]/{warehouse_dir}/web_sales]
PushedFilters: [IsNotNull(ws_ship_hdemo_sk), IsNotNull(ws_sold_time_sk), IsNotNull(ws_web_page_sk)]
ReadSchema: struct<ws_sold_time_sk:int,ws_ship_hdemo_sk:int,ws_web_page_sk:int>

(30) ColumnarToRow [codegen id : 8]
Input [4]: [ws_sold_time_sk#15, ws_ship_hdemo_sk#16, ws_web_page_sk#17, ws_sold_date_sk#18]

(31) Filter [codegen id : 8]
Input [4]: [ws_sold_time_sk#15, ws_ship_hdemo_sk#16, ws_web_page_sk#17, ws_sold_date_sk#18]
Condition : ((isnotnull(ws_ship_hdemo_sk#16) AND isnotnull(ws_sold_time_sk#15)) AND isnotnull(ws_web_page_sk#17))

(32) Project [codegen id : 8]
Output [3]: [ws_sold_time_sk#15, ws_ship_hdemo_sk#16, ws_web_page_sk#17]
Input [4]: [ws_sold_time_sk#15, ws_ship_hdemo_sk#16, ws_web_page_sk#17, ws_sold_date_sk#18]

(33) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#19]

(34) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ws_ship_hdemo_sk#16]
Right keys [1]: [hd_demo_sk#19]
Join type: Inner
Join condition: None

(35) Project [codegen id : 8]
Output [2]: [ws_sold_time_sk#15, ws_web_page_sk#17]
Input [4]: [ws_sold_time_sk#15, ws_ship_hdemo_sk#16, ws_web_page_sk#17, hd_demo_sk#19]

(36) Scan parquet spark_catalog.default.time_dim
Output [2]: [t_time_sk#20, t_hour#21]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), GreaterThanOrEqual(t_hour,19), LessThanOrEqual(t_hour,20), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int>

(37) ColumnarToRow [codegen id : 6]
Input [2]: [t_time_sk#20, t_hour#21]

(38) Filter [codegen id : 6]
Input [2]: [t_time_sk#20, t_hour#21]
Condition : (((isnotnull(t_hour#21) AND (t_hour#21 >= 19)) AND (t_hour#21 <= 20)) AND isnotnull(t_time_sk#20))

(39) Project [codegen id : 6]
Output [1]: [t_time_sk#20]
Input [2]: [t_time_sk#20, t_hour#21]

(40) BroadcastExchange
Input [1]: [t_time_sk#20]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=5]

(41) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ws_sold_time_sk#15]
Right keys [1]: [t_time_sk#20]
Join type: Inner
Join condition: None

(42) Project [codegen id : 8]
Output [1]: [ws_web_page_sk#17]
Input [3]: [ws_sold_time_sk#15, ws_web_page_sk#17, t_time_sk#20]

(43) ReusedExchange [Reuses operator id: 23]
Output [1]: [wp_web_page_sk#22]

(44) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ws_web_page_sk#17]
Right keys [1]: [wp_web_page_sk#22]
Join type: Inner
Join condition: None

(45) Project [codegen id : 8]
Output: []
Input [2]: [ws_web_page_sk#17, wp_web_page_sk#22]

(46) HashAggregate [codegen id : 8]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#23]
Results [1]: [count#24]

(47) Exchange
Input [1]: [count#24]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=6]

(48) HashAggregate [codegen id : 9]
Input [1]: [count#24]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#25]
Results [1]: [count(1)#25 AS pmc#26]

(49) BroadcastExchange
Input [1]: [pmc#26]
Arguments: IdentityBroadcastMode, [plan_id=7]

(50) BroadcastNestedLoopJoin [codegen id : 10]
Join type: Inner
Join condition: None

(51) Project [codegen id : 10]
Output [1]: [(cast(amc#14 as decimal(15,4)) / cast(pmc#26 as decimal(15,4))) AS am_pm_ratio#27]
Input [2]: [amc#14, pmc#26]

