== Physical Plan ==
* BroadcastNestedLoopJoin Inner BuildRight (182)
:- * BroadcastNestedLoopJoin Inner BuildRight (160)
:  :- * BroadcastNestedLoopJoin Inner BuildRight (138)
:  :  :- * BroadcastNestedLoopJoin Inner BuildRight (116)
:  :  :  :- * BroadcastNestedLoopJoin Inner BuildRight (94)
:  :  :  :  :- * BroadcastNestedLoopJoin Inner BuildRight (72)
:  :  :  :  :  :- * BroadcastNestedLoopJoin Inner BuildRight (50)
:  :  :  :  :  :  :- * HashAggregate (28)
:  :  :  :  :  :  :  +- Exchange (27)
:  :  :  :  :  :  :     +- * HashAggregate (26)
:  :  :  :  :  :  :        +- * Project (25)
:  :  :  :  :  :  :           +- * BroadcastHashJoin Inner BuildRight (24)
:  :  :  :  :  :  :              :- * Project (18)
:  :  :  :  :  :  :              :  +- * BroadcastHashJoin Inner BuildRight (17)
:  :  :  :  :  :  :              :     :- * Project (11)
:  :  :  :  :  :  :              :     :  +- * BroadcastHashJoin Inner BuildRight (10)
:  :  :  :  :  :  :              :     :     :- * Project (4)
:  :  :  :  :  :  :              :     :     :  +- * Filter (3)
:  :  :  :  :  :  :              :     :     :     +- * ColumnarToRow (2)
:  :  :  :  :  :  :              :     :     :        +- Scan parquet spark_catalog.default.store_sales (1)
:  :  :  :  :  :  :              :     :     +- BroadcastExchange (9)
:  :  :  :  :  :  :              :     :        +- * Project (8)
:  :  :  :  :  :  :              :     :           +- * Filter (7)
:  :  :  :  :  :  :              :     :              +- * ColumnarToRow (6)
:  :  :  :  :  :  :              :     :                 +- Scan parquet spark_catalog.default.household_demographics (5)
:  :  :  :  :  :  :              :     +- BroadcastExchange (16)
:  :  :  :  :  :  :              :        +- * Project (15)
:  :  :  :  :  :  :              :           +- * Filter (14)
:  :  :  :  :  :  :              :              +- * ColumnarToRow (13)
:  :  :  :  :  :  :              :                 +- Scan parquet spark_catalog.default.time_dim (12)
:  :  :  :  :  :  :              +- BroadcastExchange (23)
:  :  :  :  :  :  :                 +- * Project (22)
:  :  :  :  :  :  :                    +- * Filter (21)
:  :  :  :  :  :  :                       +- * ColumnarToRow (20)
:  :  :  :  :  :  :                          +- Scan parquet spark_catalog.default.store (19)
:  :  :  :  :  :  +- BroadcastExchange (49)
:  :  :  :  :  :     +- * HashAggregate (48)
:  :  :  :  :  :        +- Exchange (47)
:  :  :  :  :  :           +- * HashAggregate (46)
:  :  :  :  :  :              +- * Project (45)
:  :  :  :  :  :                 +- * BroadcastHashJoin Inner BuildRight (44)
:  :  :  :  :  :                    :- * Project (42)
:  :  :  :  :  :                    :  +- * BroadcastHashJoin Inner BuildRight (41)
:  :  :  :  :  :                    :     :- * Project (35)
:  :  :  :  :  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (34)
:  :  :  :  :  :                    :     :     :- * Project (32)
:  :  :  :  :  :                    :     :     :  +- * Filter (31)
:  :  :  :  :  :                    :     :     :     +- * ColumnarToRow (30)
:  :  :  :  :  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (29)
:  :  :  :  :  :                    :     :     +- ReusedExchange (33)
:  :  :  :  :  :                    :     +- BroadcastExchange (40)
:  :  :  :  :  :                    :        +- * Project (39)
:  :  :  :  :  :                    :           +- * Filter (38)
:  :  :  :  :  :                    :              +- * ColumnarToRow (37)
:  :  :  :  :  :                    :                 +- Scan parquet spark_catalog.default.time_dim (36)
:  :  :  :  :  :                    +- ReusedExchange (43)
:  :  :  :  :  +- BroadcastExchange (71)
:  :  :  :  :     +- * HashAggregate (70)
:  :  :  :  :        +- Exchange (69)
:  :  :  :  :           +- * HashAggregate (68)
:  :  :  :  :              +- * Project (67)
:  :  :  :  :                 +- * BroadcastHashJoin Inner BuildRight (66)
:  :  :  :  :                    :- * Project (64)
:  :  :  :  :                    :  +- * BroadcastHashJoin Inner BuildRight (63)
:  :  :  :  :                    :     :- * Project (57)
:  :  :  :  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (56)
:  :  :  :  :                    :     :     :- * Project (54)
:  :  :  :  :                    :     :     :  +- * Filter (53)
:  :  :  :  :                    :     :     :     +- * ColumnarToRow (52)
:  :  :  :  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (51)
:  :  :  :  :                    :     :     +- ReusedExchange (55)
:  :  :  :  :                    :     +- BroadcastExchange (62)
:  :  :  :  :                    :        +- * Project (61)
:  :  :  :  :                    :           +- * Filter (60)
:  :  :  :  :                    :              +- * ColumnarToRow (59)
:  :  :  :  :                    :                 +- Scan parquet spark_catalog.default.time_dim (58)
:  :  :  :  :                    +- ReusedExchange (65)
:  :  :  :  +- BroadcastExchange (93)
:  :  :  :     +- * HashAggregate (92)
:  :  :  :        +- Exchange (91)
:  :  :  :           +- * HashAggregate (90)
:  :  :  :              +- * Project (89)
:  :  :  :                 +- * BroadcastHashJoin Inner BuildRight (88)
:  :  :  :                    :- * Project (86)
:  :  :  :                    :  +- * BroadcastHashJoin Inner BuildRight (85)
:  :  :  :                    :     :- * Project (79)
:  :  :  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (78)
:  :  :  :                    :     :     :- * Project (76)
:  :  :  :                    :     :     :  +- * Filter (75)
:  :  :  :                    :     :     :     +- * ColumnarToRow (74)
:  :  :  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (73)
:  :  :  :                    :     :     +- ReusedExchange (77)
:  :  :  :                    :     +- BroadcastExchange (84)
:  :  :  :                    :        +- * Project (83)
:  :  :  :                    :           +- * Filter (82)
:  :  :  :                    :              +- * ColumnarToRow (81)
:  :  :  :                    :                 +- Scan parquet spark_catalog.default.time_dim (80)
:  :  :  :                    +- ReusedExchange (87)
:  :  :  +- BroadcastExchange (115)
:  :  :     +- * HashAggregate (114)
:  :  :        +- Exchange (113)
:  :  :           +- * HashAggregate (112)
:  :  :              +- * Project (111)
:  :  :                 +- * BroadcastHashJoin Inner BuildRight (110)
:  :  :                    :- * Project (108)
:  :  :                    :  +- * BroadcastHashJoin Inner BuildRight (107)
:  :  :                    :     :- * Project (101)
:  :  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (100)
:  :  :                    :     :     :- * Project (98)
:  :  :                    :     :     :  +- * Filter (97)
:  :  :                    :     :     :     +- * ColumnarToRow (96)
:  :  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (95)
:  :  :                    :     :     +- ReusedExchange (99)
:  :  :                    :     +- BroadcastExchange (106)
:  :  :                    :        +- * Project (105)
:  :  :                    :           +- * Filter (104)
:  :  :                    :              +- * ColumnarToRow (103)
:  :  :                    :                 +- Scan parquet spark_catalog.default.time_dim (102)
:  :  :                    +- ReusedExchange (109)
:  :  +- BroadcastExchange (137)
:  :     +- * HashAggregate (136)
:  :        +- Exchange (135)
:  :           +- * HashAggregate (134)
:  :              +- * Project (133)
:  :                 +- * BroadcastHashJoin Inner BuildRight (132)
:  :                    :- * Project (130)
:  :                    :  +- * BroadcastHashJoin Inner BuildRight (129)
:  :                    :     :- * Project (123)
:  :                    :     :  +- * BroadcastHashJoin Inner BuildRight (122)
:  :                    :     :     :- * Project (120)
:  :                    :     :     :  +- * Filter (119)
:  :                    :     :     :     +- * ColumnarToRow (118)
:  :                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (117)
:  :                    :     :     +- ReusedExchange (121)
:  :                    :     +- BroadcastExchange (128)
:  :                    :        +- * Project (127)
:  :                    :           +- * Filter (126)
:  :                    :              +- * ColumnarToRow (125)
:  :                    :                 +- Scan parquet spark_catalog.default.time_dim (124)
:  :                    +- ReusedExchange (131)
:  +- BroadcastExchange (159)
:     +- * HashAggregate (158)
:        +- Exchange (157)
:           +- * HashAggregate (156)
:              +- * Project (155)
:                 +- * BroadcastHashJoin Inner BuildRight (154)
:                    :- * Project (152)
:                    :  +- * BroadcastHashJoin Inner BuildRight (151)
:                    :     :- * Project (145)
:                    :     :  +- * BroadcastHashJoin Inner BuildRight (144)
:                    :     :     :- * Project (142)
:                    :     :     :  +- * Filter (141)
:                    :     :     :     +- * ColumnarToRow (140)
:                    :     :     :        +- Scan parquet spark_catalog.default.store_sales (139)
:                    :     :     +- ReusedExchange (143)
:                    :     +- BroadcastExchange (150)
:                    :        +- * Project (149)
:                    :           +- * Filter (148)
:                    :              +- * ColumnarToRow (147)
:                    :                 +- Scan parquet spark_catalog.default.time_dim (146)
:                    +- ReusedExchange (153)
+- BroadcastExchange (181)
   +- * HashAggregate (180)
      +- Exchange (179)
         +- * HashAggregate (178)
            +- * Project (177)
               +- * BroadcastHashJoin Inner BuildRight (176)
                  :- * Project (174)
                  :  +- * BroadcastHashJoin Inner BuildRight (173)
                  :     :- * Project (167)
                  :     :  +- * BroadcastHashJoin Inner BuildRight (166)
                  :     :     :- * Project (164)
                  :     :     :  +- * Filter (163)
                  :     :     :     +- * ColumnarToRow (162)
                  :     :     :        +- Scan parquet spark_catalog.default.store_sales (161)
                  :     :     +- ReusedExchange (165)
                  :     +- BroadcastExchange (172)
                  :        +- * Project (171)
                  :           +- * Filter (170)
                  :              +- * ColumnarToRow (169)
                  :                 +- Scan parquet spark_catalog.default.time_dim (168)
                  +- ReusedExchange (175)


(1) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(2) ColumnarToRow [codegen id : 4]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(3) Filter [codegen id : 4]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]
Condition : ((isnotnull(ss_hdemo_sk#2) AND isnotnull(ss_sold_time_sk#1)) AND isnotnull(ss_store_sk#3))

(4) Project [codegen id : 4]
Output [3]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, ss_sold_date_sk#4]

(5) Scan parquet spark_catalog.default.household_demographics
Output [3]: [hd_demo_sk#5, hd_dep_count#6, hd_vehicle_count#7]
Batched: true
Location [not included in comparison]/{warehouse_dir}/household_demographics]
PushedFilters: [Or(Or(And(EqualTo(hd_dep_count,4),LessThanOrEqual(hd_vehicle_count,6)),And(EqualTo(hd_dep_count,2),LessThanOrEqual(hd_vehicle_count,4))),And(EqualTo(hd_dep_count,0),LessThanOrEqual(hd_vehicle_count,2))), IsNotNull(hd_demo_sk)]
ReadSchema: struct<hd_demo_sk:int,hd_dep_count:int,hd_vehicle_count:int>

(6) ColumnarToRow [codegen id : 1]
Input [3]: [hd_demo_sk#5, hd_dep_count#6, hd_vehicle_count#7]

(7) Filter [codegen id : 1]
Input [3]: [hd_demo_sk#5, hd_dep_count#6, hd_vehicle_count#7]
Condition : (((((hd_dep_count#6 = 4) AND (hd_vehicle_count#7 <= 6)) OR ((hd_dep_count#6 = 2) AND (hd_vehicle_count#7 <= 4))) OR ((hd_dep_count#6 = 0) AND (hd_vehicle_count#7 <= 2))) AND isnotnull(hd_demo_sk#5))

(8) Project [codegen id : 1]
Output [1]: [hd_demo_sk#5]
Input [3]: [hd_demo_sk#5, hd_dep_count#6, hd_vehicle_count#7]

(9) BroadcastExchange
Input [1]: [hd_demo_sk#5]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=1]

(10) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_hdemo_sk#2]
Right keys [1]: [hd_demo_sk#5]
Join condition: None

(11) Project [codegen id : 4]
Output [2]: [ss_sold_time_sk#1, ss_store_sk#3]
Input [4]: [ss_sold_time_sk#1, ss_hdemo_sk#2, ss_store_sk#3, hd_demo_sk#5]

(12) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,8), GreaterThanOrEqual(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(13) ColumnarToRow [codegen id : 2]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(14) Filter [codegen id : 2]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]
Condition : ((((isnotnull(t_hour#9) AND isnotnull(t_minute#10)) AND (t_hour#9 = 8)) AND (t_minute#10 >= 30)) AND isnotnull(t_time_sk#8))

(15) Project [codegen id : 2]
Output [1]: [t_time_sk#8]
Input [3]: [t_time_sk#8, t_hour#9, t_minute#10]

(16) BroadcastExchange
Input [1]: [t_time_sk#8]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=2]

(17) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_sold_time_sk#1]
Right keys [1]: [t_time_sk#8]
Join condition: None

(18) Project [codegen id : 4]
Output [1]: [ss_store_sk#3]
Input [3]: [ss_sold_time_sk#1, ss_store_sk#3, t_time_sk#8]

(19) Scan parquet spark_catalog.default.store
Output [2]: [s_store_sk#11, s_store_name#12]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store]
PushedFilters: [IsNotNull(s_store_name), EqualTo(s_store_name,ese), IsNotNull(s_store_sk)]
ReadSchema: struct<s_store_sk:int,s_store_name:string>

(20) ColumnarToRow [codegen id : 3]
Input [2]: [s_store_sk#11, s_store_name#12]

(21) Filter [codegen id : 3]
Input [2]: [s_store_sk#11, s_store_name#12]
Condition : ((isnotnull(s_store_name#12) AND (s_store_name#12 = ese)) AND isnotnull(s_store_sk#11))

(22) Project [codegen id : 3]
Output [1]: [s_store_sk#11]
Input [2]: [s_store_sk#11, s_store_name#12]

(23) BroadcastExchange
Input [1]: [s_store_sk#11]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=3]

(24) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_store_sk#3]
Right keys [1]: [s_store_sk#11]
Join condition: None

(25) Project [codegen id : 4]
Output: []
Input [2]: [ss_store_sk#3, s_store_sk#11]

(26) HashAggregate [codegen id : 4]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#13]
Results [1]: [count#14]

(27) Exchange
Input [1]: [count#14]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=4]

(28) HashAggregate [codegen id : 40]
Input [1]: [count#14]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#15]
Results [1]: [count(1)#15 AS h8_30_to_9#16]

(29) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#17, ss_hdemo_sk#18, ss_store_sk#19, ss_sold_date_sk#20]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(30) ColumnarToRow [codegen id : 8]
Input [4]: [ss_sold_time_sk#17, ss_hdemo_sk#18, ss_store_sk#19, ss_sold_date_sk#20]

(31) Filter [codegen id : 8]
Input [4]: [ss_sold_time_sk#17, ss_hdemo_sk#18, ss_store_sk#19, ss_sold_date_sk#20]
Condition : ((isnotnull(ss_hdemo_sk#18) AND isnotnull(ss_sold_time_sk#17)) AND isnotnull(ss_store_sk#19))

(32) Project [codegen id : 8]
Output [3]: [ss_sold_time_sk#17, ss_hdemo_sk#18, ss_store_sk#19]
Input [4]: [ss_sold_time_sk#17, ss_hdemo_sk#18, ss_store_sk#19, ss_sold_date_sk#20]

(33) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#21]

(34) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ss_hdemo_sk#18]
Right keys [1]: [hd_demo_sk#21]
Join condition: None

(35) Project [codegen id : 8]
Output [2]: [ss_sold_time_sk#17, ss_store_sk#19]
Input [4]: [ss_sold_time_sk#17, ss_hdemo_sk#18, ss_store_sk#19, hd_demo_sk#21]

(36) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#22, t_hour#23, t_minute#24]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,9), LessThan(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(37) ColumnarToRow [codegen id : 6]
Input [3]: [t_time_sk#22, t_hour#23, t_minute#24]

(38) Filter [codegen id : 6]
Input [3]: [t_time_sk#22, t_hour#23, t_minute#24]
Condition : ((((isnotnull(t_hour#23) AND isnotnull(t_minute#24)) AND (t_hour#23 = 9)) AND (t_minute#24 < 30)) AND isnotnull(t_time_sk#22))

(39) Project [codegen id : 6]
Output [1]: [t_time_sk#22]
Input [3]: [t_time_sk#22, t_hour#23, t_minute#24]

(40) BroadcastExchange
Input [1]: [t_time_sk#22]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=5]

(41) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ss_sold_time_sk#17]
Right keys [1]: [t_time_sk#22]
Join condition: None

(42) Project [codegen id : 8]
Output [1]: [ss_store_sk#19]
Input [3]: [ss_sold_time_sk#17, ss_store_sk#19, t_time_sk#22]

(43) ReusedExchange [Reuses operator id: 23]
Output [1]: [s_store_sk#25]

(44) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [ss_store_sk#19]
Right keys [1]: [s_store_sk#25]
Join condition: None

(45) Project [codegen id : 8]
Output: []
Input [2]: [ss_store_sk#19, s_store_sk#25]

(46) HashAggregate [codegen id : 8]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#26]
Results [1]: [count#27]

(47) Exchange
Input [1]: [count#27]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=6]

(48) HashAggregate [codegen id : 9]
Input [1]: [count#27]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#28]
Results [1]: [count(1)#28 AS h9_to_9_30#29]

(49) BroadcastExchange
Input [1]: [h9_to_9_30#29]
Arguments: IdentityBroadcastMode, [plan_id=7]

(50) BroadcastNestedLoopJoin [codegen id : 40]
Join condition: None

(51) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#30, ss_hdemo_sk#31, ss_store_sk#32, ss_sold_date_sk#33]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(52) ColumnarToRow [codegen id : 13]
Input [4]: [ss_sold_time_sk#30, ss_hdemo_sk#31, ss_store_sk#32, ss_sold_date_sk#33]

(53) Filter [codegen id : 13]
Input [4]: [ss_sold_time_sk#30, ss_hdemo_sk#31, ss_store_sk#32, ss_sold_date_sk#33]
Condition : ((isnotnull(ss_hdemo_sk#31) AND isnotnull(ss_sold_time_sk#30)) AND isnotnull(ss_store_sk#32))

(54) Project [codegen id : 13]
Output [3]: [ss_sold_time_sk#30, ss_hdemo_sk#31, ss_store_sk#32]
Input [4]: [ss_sold_time_sk#30, ss_hdemo_sk#31, ss_store_sk#32, ss_sold_date_sk#33]

(55) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#34]

(56) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ss_hdemo_sk#31]
Right keys [1]: [hd_demo_sk#34]
Join condition: None

(57) Project [codegen id : 13]
Output [2]: [ss_sold_time_sk#30, ss_store_sk#32]
Input [4]: [ss_sold_time_sk#30, ss_hdemo_sk#31, ss_store_sk#32, hd_demo_sk#34]

(58) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#35, t_hour#36, t_minute#37]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,9), GreaterThanOrEqual(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(59) ColumnarToRow [codegen id : 11]
Input [3]: [t_time_sk#35, t_hour#36, t_minute#37]

(60) Filter [codegen id : 11]
Input [3]: [t_time_sk#35, t_hour#36, t_minute#37]
Condition : ((((isnotnull(t_hour#36) AND isnotnull(t_minute#37)) AND (t_hour#36 = 9)) AND (t_minute#37 >= 30)) AND isnotnull(t_time_sk#35))

(61) Project [codegen id : 11]
Output [1]: [t_time_sk#35]
Input [3]: [t_time_sk#35, t_hour#36, t_minute#37]

(62) BroadcastExchange
Input [1]: [t_time_sk#35]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=8]

(63) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ss_sold_time_sk#30]
Right keys [1]: [t_time_sk#35]
Join condition: None

(64) Project [codegen id : 13]
Output [1]: [ss_store_sk#32]
Input [3]: [ss_sold_time_sk#30, ss_store_sk#32, t_time_sk#35]

(65) ReusedExchange [Reuses operator id: 23]
Output [1]: [s_store_sk#38]

(66) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ss_store_sk#32]
Right keys [1]: [s_store_sk#38]
Join condition: None

(67) Project [codegen id : 13]
Output: []
Input [2]: [ss_store_sk#32, s_store_sk#38]

(68) HashAggregate [codegen id : 13]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#39]
Results [1]: [count#40]

(69) Exchange
Input [1]: [count#40]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=9]

(70) HashAggregate [codegen id : 14]
Input [1]: [count#40]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#41]
Results [1]: [count(1)#41 AS h9_30_to_10#42]

(71) BroadcastExchange
Input [1]: [h9_30_to_10#42]
Arguments: IdentityBroadcastMode, [plan_id=10]

(72) BroadcastNestedLoopJoin [codegen id : 40]
Join condition: None

(73) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#43, ss_hdemo_sk#44, ss_store_sk#45, ss_sold_date_sk#46]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(74) ColumnarToRow [codegen id : 18]
Input [4]: [ss_sold_time_sk#43, ss_hdemo_sk#44, ss_store_sk#45, ss_sold_date_sk#46]

(75) Filter [codegen id : 18]
Input [4]: [ss_sold_time_sk#43, ss_hdemo_sk#44, ss_store_sk#45, ss_sold_date_sk#46]
Condition : ((isnotnull(ss_hdemo_sk#44) AND isnotnull(ss_sold_time_sk#43)) AND isnotnull(ss_store_sk#45))

(76) Project [codegen id : 18]
Output [3]: [ss_sold_time_sk#43, ss_hdemo_sk#44, ss_store_sk#45]
Input [4]: [ss_sold_time_sk#43, ss_hdemo_sk#44, ss_store_sk#45, ss_sold_date_sk#46]

(77) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#47]

(78) BroadcastHashJoin [codegen id : 18]
Left keys [1]: [ss_hdemo_sk#44]
Right keys [1]: [hd_demo_sk#47]
Join condition: None

(79) Project [codegen id : 18]
Output [2]: [ss_sold_time_sk#43, ss_store_sk#45]
Input [4]: [ss_sold_time_sk#43, ss_hdemo_sk#44, ss_store_sk#45, hd_demo_sk#47]

(80) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#48, t_hour#49, t_minute#50]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,10), LessThan(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(81) ColumnarToRow [codegen id : 16]
Input [3]: [t_time_sk#48, t_hour#49, t_minute#50]

(82) Filter [codegen id : 16]
Input [3]: [t_time_sk#48, t_hour#49, t_minute#50]
Condition : ((((isnotnull(t_hour#49) AND isnotnull(t_minute#50)) AND (t_hour#49 = 10)) AND (t_minute#50 < 30)) AND isnotnull(t_time_sk#48))

(83) Project [codegen id : 16]
Output [1]: [t_time_sk#48]
Input [3]: [t_time_sk#48, t_hour#49, t_minute#50]

(84) BroadcastExchange
Input [1]: [t_time_sk#48]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=11]

(85) BroadcastHashJoin [codegen id : 18]
Left keys [1]: [ss_sold_time_sk#43]
Right keys [1]: [t_time_sk#48]
Join condition: None

(86) Project [codegen id : 18]
Output [1]: [ss_store_sk#45]
Input [3]: [ss_sold_time_sk#43, ss_store_sk#45, t_time_sk#48]

(87) ReusedExchange [Reuses operator id: 23]
Output [1]: [s_store_sk#51]

(88) BroadcastHashJoin [codegen id : 18]
Left keys [1]: [ss_store_sk#45]
Right keys [1]: [s_store_sk#51]
Join condition: None

(89) Project [codegen id : 18]
Output: []
Input [2]: [ss_store_sk#45, s_store_sk#51]

(90) HashAggregate [codegen id : 18]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#52]
Results [1]: [count#53]

(91) Exchange
Input [1]: [count#53]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=12]

(92) HashAggregate [codegen id : 19]
Input [1]: [count#53]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#54]
Results [1]: [count(1)#54 AS h10_to_10_30#55]

(93) BroadcastExchange
Input [1]: [h10_to_10_30#55]
Arguments: IdentityBroadcastMode, [plan_id=13]

(94) BroadcastNestedLoopJoin [codegen id : 40]
Join condition: None

(95) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#56, ss_hdemo_sk#57, ss_store_sk#58, ss_sold_date_sk#59]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(96) ColumnarToRow [codegen id : 23]
Input [4]: [ss_sold_time_sk#56, ss_hdemo_sk#57, ss_store_sk#58, ss_sold_date_sk#59]

(97) Filter [codegen id : 23]
Input [4]: [ss_sold_time_sk#56, ss_hdemo_sk#57, ss_store_sk#58, ss_sold_date_sk#59]
Condition : ((isnotnull(ss_hdemo_sk#57) AND isnotnull(ss_sold_time_sk#56)) AND isnotnull(ss_store_sk#58))

(98) Project [codegen id : 23]
Output [3]: [ss_sold_time_sk#56, ss_hdemo_sk#57, ss_store_sk#58]
Input [4]: [ss_sold_time_sk#56, ss_hdemo_sk#57, ss_store_sk#58, ss_sold_date_sk#59]

(99) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#60]

(100) BroadcastHashJoin [codegen id : 23]
Left keys [1]: [ss_hdemo_sk#57]
Right keys [1]: [hd_demo_sk#60]
Join condition: None

(101) Project [codegen id : 23]
Output [2]: [ss_sold_time_sk#56, ss_store_sk#58]
Input [4]: [ss_sold_time_sk#56, ss_hdemo_sk#57, ss_store_sk#58, hd_demo_sk#60]

(102) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#61, t_hour#62, t_minute#63]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,10), GreaterThanOrEqual(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(103) ColumnarToRow [codegen id : 21]
Input [3]: [t_time_sk#61, t_hour#62, t_minute#63]

(104) Filter [codegen id : 21]
Input [3]: [t_time_sk#61, t_hour#62, t_minute#63]
Condition : ((((isnotnull(t_hour#62) AND isnotnull(t_minute#63)) AND (t_hour#62 = 10)) AND (t_minute#63 >= 30)) AND isnotnull(t_time_sk#61))

(105) Project [codegen id : 21]
Output [1]: [t_time_sk#61]
Input [3]: [t_time_sk#61, t_hour#62, t_minute#63]

(106) BroadcastExchange
Input [1]: [t_time_sk#61]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=14]

(107) BroadcastHashJoin [codegen id : 23]
Left keys [1]: [ss_sold_time_sk#56]
Right keys [1]: [t_time_sk#61]
Join condition: None

(108) Project [codegen id : 23]
Output [1]: [ss_store_sk#58]
Input [3]: [ss_sold_time_sk#56, ss_store_sk#58, t_time_sk#61]

(109) ReusedExchange [Reuses operator id: 23]
Output [1]: [s_store_sk#64]

(110) BroadcastHashJoin [codegen id : 23]
Left keys [1]: [ss_store_sk#58]
Right keys [1]: [s_store_sk#64]
Join condition: None

(111) Project [codegen id : 23]
Output: []
Input [2]: [ss_store_sk#58, s_store_sk#64]

(112) HashAggregate [codegen id : 23]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#65]
Results [1]: [count#66]

(113) Exchange
Input [1]: [count#66]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=15]

(114) HashAggregate [codegen id : 24]
Input [1]: [count#66]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#67]
Results [1]: [count(1)#67 AS h10_30_to_11#68]

(115) BroadcastExchange
Input [1]: [h10_30_to_11#68]
Arguments: IdentityBroadcastMode, [plan_id=16]

(116) BroadcastNestedLoopJoin [codegen id : 40]
Join condition: None

(117) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#69, ss_hdemo_sk#70, ss_store_sk#71, ss_sold_date_sk#72]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(118) ColumnarToRow [codegen id : 28]
Input [4]: [ss_sold_time_sk#69, ss_hdemo_sk#70, ss_store_sk#71, ss_sold_date_sk#72]

(119) Filter [codegen id : 28]
Input [4]: [ss_sold_time_sk#69, ss_hdemo_sk#70, ss_store_sk#71, ss_sold_date_sk#72]
Condition : ((isnotnull(ss_hdemo_sk#70) AND isnotnull(ss_sold_time_sk#69)) AND isnotnull(ss_store_sk#71))

(120) Project [codegen id : 28]
Output [3]: [ss_sold_time_sk#69, ss_hdemo_sk#70, ss_store_sk#71]
Input [4]: [ss_sold_time_sk#69, ss_hdemo_sk#70, ss_store_sk#71, ss_sold_date_sk#72]

(121) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#73]

(122) BroadcastHashJoin [codegen id : 28]
Left keys [1]: [ss_hdemo_sk#70]
Right keys [1]: [hd_demo_sk#73]
Join condition: None

(123) Project [codegen id : 28]
Output [2]: [ss_sold_time_sk#69, ss_store_sk#71]
Input [4]: [ss_sold_time_sk#69, ss_hdemo_sk#70, ss_store_sk#71, hd_demo_sk#73]

(124) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#74, t_hour#75, t_minute#76]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,11), LessThan(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(125) ColumnarToRow [codegen id : 26]
Input [3]: [t_time_sk#74, t_hour#75, t_minute#76]

(126) Filter [codegen id : 26]
Input [3]: [t_time_sk#74, t_hour#75, t_minute#76]
Condition : ((((isnotnull(t_hour#75) AND isnotnull(t_minute#76)) AND (t_hour#75 = 11)) AND (t_minute#76 < 30)) AND isnotnull(t_time_sk#74))

(127) Project [codegen id : 26]
Output [1]: [t_time_sk#74]
Input [3]: [t_time_sk#74, t_hour#75, t_minute#76]

(128) BroadcastExchange
Input [1]: [t_time_sk#74]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=17]

(129) BroadcastHashJoin [codegen id : 28]
Left keys [1]: [ss_sold_time_sk#69]
Right keys [1]: [t_time_sk#74]
Join condition: None

(130) Project [codegen id : 28]
Output [1]: [ss_store_sk#71]
Input [3]: [ss_sold_time_sk#69, ss_store_sk#71, t_time_sk#74]

(131) ReusedExchange [Reuses operator id: 23]
Output [1]: [s_store_sk#77]

(132) BroadcastHashJoin [codegen id : 28]
Left keys [1]: [ss_store_sk#71]
Right keys [1]: [s_store_sk#77]
Join condition: None

(133) Project [codegen id : 28]
Output: []
Input [2]: [ss_store_sk#71, s_store_sk#77]

(134) HashAggregate [codegen id : 28]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#78]
Results [1]: [count#79]

(135) Exchange
Input [1]: [count#79]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=18]

(136) HashAggregate [codegen id : 29]
Input [1]: [count#79]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#80]
Results [1]: [count(1)#80 AS h11_to_11_30#81]

(137) BroadcastExchange
Input [1]: [h11_to_11_30#81]
Arguments: IdentityBroadcastMode, [plan_id=19]

(138) BroadcastNestedLoopJoin [codegen id : 40]
Join condition: None

(139) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#82, ss_hdemo_sk#83, ss_store_sk#84, ss_sold_date_sk#85]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(140) ColumnarToRow [codegen id : 33]
Input [4]: [ss_sold_time_sk#82, ss_hdemo_sk#83, ss_store_sk#84, ss_sold_date_sk#85]

(141) Filter [codegen id : 33]
Input [4]: [ss_sold_time_sk#82, ss_hdemo_sk#83, ss_store_sk#84, ss_sold_date_sk#85]
Condition : ((isnotnull(ss_hdemo_sk#83) AND isnotnull(ss_sold_time_sk#82)) AND isnotnull(ss_store_sk#84))

(142) Project [codegen id : 33]
Output [3]: [ss_sold_time_sk#82, ss_hdemo_sk#83, ss_store_sk#84]
Input [4]: [ss_sold_time_sk#82, ss_hdemo_sk#83, ss_store_sk#84, ss_sold_date_sk#85]

(143) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#86]

(144) BroadcastHashJoin [codegen id : 33]
Left keys [1]: [ss_hdemo_sk#83]
Right keys [1]: [hd_demo_sk#86]
Join condition: None

(145) Project [codegen id : 33]
Output [2]: [ss_sold_time_sk#82, ss_store_sk#84]
Input [4]: [ss_sold_time_sk#82, ss_hdemo_sk#83, ss_store_sk#84, hd_demo_sk#86]

(146) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#87, t_hour#88, t_minute#89]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,11), GreaterThanOrEqual(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(147) ColumnarToRow [codegen id : 31]
Input [3]: [t_time_sk#87, t_hour#88, t_minute#89]

(148) Filter [codegen id : 31]
Input [3]: [t_time_sk#87, t_hour#88, t_minute#89]
Condition : ((((isnotnull(t_hour#88) AND isnotnull(t_minute#89)) AND (t_hour#88 = 11)) AND (t_minute#89 >= 30)) AND isnotnull(t_time_sk#87))

(149) Project [codegen id : 31]
Output [1]: [t_time_sk#87]
Input [3]: [t_time_sk#87, t_hour#88, t_minute#89]

(150) BroadcastExchange
Input [1]: [t_time_sk#87]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=20]

(151) BroadcastHashJoin [codegen id : 33]
Left keys [1]: [ss_sold_time_sk#82]
Right keys [1]: [t_time_sk#87]
Join condition: None

(152) Project [codegen id : 33]
Output [1]: [ss_store_sk#84]
Input [3]: [ss_sold_time_sk#82, ss_store_sk#84, t_time_sk#87]

(153) ReusedExchange [Reuses operator id: 23]
Output [1]: [s_store_sk#90]

(154) BroadcastHashJoin [codegen id : 33]
Left keys [1]: [ss_store_sk#84]
Right keys [1]: [s_store_sk#90]
Join condition: None

(155) Project [codegen id : 33]
Output: []
Input [2]: [ss_store_sk#84, s_store_sk#90]

(156) HashAggregate [codegen id : 33]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#91]
Results [1]: [count#92]

(157) Exchange
Input [1]: [count#92]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=21]

(158) HashAggregate [codegen id : 34]
Input [1]: [count#92]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#93]
Results [1]: [count(1)#93 AS h11_30_to_12#94]

(159) BroadcastExchange
Input [1]: [h11_30_to_12#94]
Arguments: IdentityBroadcastMode, [plan_id=22]

(160) BroadcastNestedLoopJoin [codegen id : 40]
Join condition: None

(161) Scan parquet spark_catalog.default.store_sales
Output [4]: [ss_sold_time_sk#95, ss_hdemo_sk#96, ss_store_sk#97, ss_sold_date_sk#98]
Batched: true
Location [not included in comparison]/{warehouse_dir}/store_sales]
PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)]
ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>

(162) ColumnarToRow [codegen id : 38]
Input [4]: [ss_sold_time_sk#95, ss_hdemo_sk#96, ss_store_sk#97, ss_sold_date_sk#98]

(163) Filter [codegen id : 38]
Input [4]: [ss_sold_time_sk#95, ss_hdemo_sk#96, ss_store_sk#97, ss_sold_date_sk#98]
Condition : ((isnotnull(ss_hdemo_sk#96) AND isnotnull(ss_sold_time_sk#95)) AND isnotnull(ss_store_sk#97))

(164) Project [codegen id : 38]
Output [3]: [ss_sold_time_sk#95, ss_hdemo_sk#96, ss_store_sk#97]
Input [4]: [ss_sold_time_sk#95, ss_hdemo_sk#96, ss_store_sk#97, ss_sold_date_sk#98]

(165) ReusedExchange [Reuses operator id: 9]
Output [1]: [hd_demo_sk#99]

(166) BroadcastHashJoin [codegen id : 38]
Left keys [1]: [ss_hdemo_sk#96]
Right keys [1]: [hd_demo_sk#99]
Join condition: None

(167) Project [codegen id : 38]
Output [2]: [ss_sold_time_sk#95, ss_store_sk#97]
Input [4]: [ss_sold_time_sk#95, ss_hdemo_sk#96, ss_store_sk#97, hd_demo_sk#99]

(168) Scan parquet spark_catalog.default.time_dim
Output [3]: [t_time_sk#100, t_hour#101, t_minute#102]
Batched: true
Location [not included in comparison]/{warehouse_dir}/time_dim]
PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,12), LessThan(t_minute,30), IsNotNull(t_time_sk)]
ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>

(169) ColumnarToRow [codegen id : 36]
Input [3]: [t_time_sk#100, t_hour#101, t_minute#102]

(170) Filter [codegen id : 36]
Input [3]: [t_time_sk#100, t_hour#101, t_minute#102]
Condition : ((((isnotnull(t_hour#101) AND isnotnull(t_minute#102)) AND (t_hour#101 = 12)) AND (t_minute#102 < 30)) AND isnotnull(t_time_sk#100))

(171) Project [codegen id : 36]
Output [1]: [t_time_sk#100]
Input [3]: [t_time_sk#100, t_hour#101, t_minute#102]

(172) BroadcastExchange
Input [1]: [t_time_sk#100]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=23]

(173) BroadcastHashJoin [codegen id : 38]
Left keys [1]: [ss_sold_time_sk#95]
Right keys [1]: [t_time_sk#100]
Join condition: None

(174) Project [codegen id : 38]
Output [1]: [ss_store_sk#97]
Input [3]: [ss_sold_time_sk#95, ss_store_sk#97, t_time_sk#100]

(175) ReusedExchange [Reuses operator id: 23]
Output [1]: [s_store_sk#103]

(176) BroadcastHashJoin [codegen id : 38]
Left keys [1]: [ss_store_sk#97]
Right keys [1]: [s_store_sk#103]
Join condition: None

(177) Project [codegen id : 38]
Output: []
Input [2]: [ss_store_sk#97, s_store_sk#103]

(178) HashAggregate [codegen id : 38]
Input: []
Keys: []
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#104]
Results [1]: [count#105]

(179) Exchange
Input [1]: [count#105]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=24]

(180) HashAggregate [codegen id : 39]
Input [1]: [count#105]
Keys: []
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#106]
Results [1]: [count(1)#106 AS h12_to_12_30#107]

(181) BroadcastExchange
Input [1]: [h12_to_12_30#107]
Arguments: IdentityBroadcastMode, [plan_id=25]

(182) BroadcastNestedLoopJoin [codegen id : 40]
Join condition: None

