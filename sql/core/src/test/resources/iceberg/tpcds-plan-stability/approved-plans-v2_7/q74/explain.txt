== Physical Plan ==
TakeOrderedAndProject (71)
+- * Project (70)
   +- * BroadcastHashJoin Inner BuildRight (69)
      :- * Project (52)
      :  +- * BroadcastHashJoin Inner BuildRight (51)
      :     :- * BroadcastHashJoin Inner BuildRight (33)
      :     :  :- * Filter (16)
      :     :  :  +- * HashAggregate (15)
      :     :  :     +- Exchange (14)
      :     :  :        +- * HashAggregate (13)
      :     :  :           +- * Project (12)
      :     :  :              +- * BroadcastHashJoin Inner BuildRight (11)
      :     :  :                 :- * Project (9)
      :     :  :                 :  +- * BroadcastHashJoin Inner BuildRight (8)
      :     :  :                 :     :- * Project (3)
      :     :  :                 :     :  +- * Filter (2)
      :     :  :                 :     :     +- BatchScan spark_catalog.default.customer (1)
      :     :  :                 :     +- BroadcastExchange (7)
      :     :  :                 :        +- * Project (6)
      :     :  :                 :           +- * Filter (5)
      :     :  :                 :              +- BatchScan spark_catalog.default.store_sales (4)
      :     :  :                 +- ReusedExchange (10)
      :     :  +- BroadcastExchange (32)
      :     :     +- * HashAggregate (31)
      :     :        +- Exchange (30)
      :     :           +- * HashAggregate (29)
      :     :              +- * Project (28)
      :     :                 +- * BroadcastHashJoin Inner BuildRight (27)
      :     :                    :- * Project (25)
      :     :                    :  +- * BroadcastHashJoin Inner BuildRight (24)
      :     :                    :     :- * Project (19)
      :     :                    :     :  +- * Filter (18)
      :     :                    :     :     +- BatchScan spark_catalog.default.customer (17)
      :     :                    :     +- BroadcastExchange (23)
      :     :                    :        +- * Project (22)
      :     :                    :           +- * Filter (21)
      :     :                    :              +- BatchScan spark_catalog.default.store_sales (20)
      :     :                    +- ReusedExchange (26)
      :     +- BroadcastExchange (50)
      :        +- * Filter (49)
      :           +- * HashAggregate (48)
      :              +- Exchange (47)
      :                 +- * HashAggregate (46)
      :                    +- * Project (45)
      :                       +- * BroadcastHashJoin Inner BuildRight (44)
      :                          :- * Project (42)
      :                          :  +- * BroadcastHashJoin Inner BuildRight (41)
      :                          :     :- * Project (36)
      :                          :     :  +- * Filter (35)
      :                          :     :     +- BatchScan spark_catalog.default.customer (34)
      :                          :     +- BroadcastExchange (40)
      :                          :        +- * Project (39)
      :                          :           +- * Filter (38)
      :                          :              +- BatchScan spark_catalog.default.web_sales (37)
      :                          +- ReusedExchange (43)
      +- BroadcastExchange (68)
         +- * HashAggregate (67)
            +- Exchange (66)
               +- * HashAggregate (65)
                  +- * Project (64)
                     +- * BroadcastHashJoin Inner BuildRight (63)
                        :- * Project (61)
                        :  +- * BroadcastHashJoin Inner BuildRight (60)
                        :     :- * Project (55)
                        :     :  +- * Filter (54)
                        :     :     +- BatchScan spark_catalog.default.customer (53)
                        :     +- BroadcastExchange (59)
                        :        +- * Project (58)
                        :           +- * Filter (57)
                        :              +- BatchScan spark_catalog.default.web_sales (56)
                        +- ReusedExchange (62)


(1) BatchScan spark_catalog.default.customer
Output [4]: [c_customer_sk#1, c_customer_id#2, c_first_name#3, c_last_name#4]
spark_catalog.default.customer [scan class = SparkBatchQueryScan] [filters=c_customer_sk IS NOT NULL, c_customer_id IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(2) Filter [codegen id : 3]
Input [4]: [c_customer_sk#1, c_customer_id#2, c_first_name#3, c_last_name#4]
Condition : (isnotnull(c_customer_sk#1) AND isnotnull(c_customer_id#2))

(3) Project [codegen id : 3]
Output [4]: [c_customer_sk#1, c_customer_id#2, c_first_name#3, c_last_name#4]
Input [4]: [c_customer_sk#1, c_customer_id#2, c_first_name#3, c_last_name#4]

(4) BatchScan spark_catalog.default.store_sales
Output [3]: [ss_sold_date_sk#5, ss_customer_sk#6, ss_net_paid#7]
spark_catalog.default.store_sales [scan class = SparkBatchQueryScan] [filters=ss_customer_sk IS NOT NULL, ss_sold_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(5) Filter [codegen id : 1]
Input [3]: [ss_sold_date_sk#5, ss_customer_sk#6, ss_net_paid#7]
Condition : (isnotnull(ss_customer_sk#6) AND isnotnull(ss_sold_date_sk#5))

(6) Project [codegen id : 1]
Output [3]: [ss_sold_date_sk#5, ss_customer_sk#6, ss_net_paid#7]
Input [3]: [ss_sold_date_sk#5, ss_customer_sk#6, ss_net_paid#7]

(7) BroadcastExchange
Input [3]: [ss_sold_date_sk#5, ss_customer_sk#6, ss_net_paid#7]
Arguments: HashedRelationBroadcastMode(List(cast(input[1, int, true] as bigint)),false), [plan_id=1]

(8) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [c_customer_sk#1]
Right keys [1]: [ss_customer_sk#6]
Join condition: None

(9) Project [codegen id : 3]
Output [5]: [c_customer_id#2, c_first_name#3, c_last_name#4, ss_sold_date_sk#5, ss_net_paid#7]
Input [7]: [c_customer_sk#1, c_customer_id#2, c_first_name#3, c_last_name#4, ss_sold_date_sk#5, ss_customer_sk#6, ss_net_paid#7]

(10) ReusedExchange [Reuses operator id: 75]
Output [2]: [d_date_sk#8, d_year#9]

(11) BroadcastHashJoin [codegen id : 3]
Left keys [1]: [ss_sold_date_sk#5]
Right keys [1]: [d_date_sk#8]
Join condition: None

(12) Project [codegen id : 3]
Output [5]: [c_customer_id#2, c_first_name#3, c_last_name#4, ss_net_paid#7, d_year#9]
Input [7]: [c_customer_id#2, c_first_name#3, c_last_name#4, ss_sold_date_sk#5, ss_net_paid#7, d_date_sk#8, d_year#9]

(13) HashAggregate [codegen id : 3]
Input [5]: [c_customer_id#2, c_first_name#3, c_last_name#4, ss_net_paid#7, d_year#9]
Keys [4]: [c_customer_id#2, c_first_name#3, c_last_name#4, d_year#9]
Functions [1]: [partial_sum(UnscaledValue(ss_net_paid#7))]
Aggregate Attributes [1]: [sum#10]
Results [5]: [c_customer_id#2, c_first_name#3, c_last_name#4, d_year#9, sum#11]

(14) Exchange
Input [5]: [c_customer_id#2, c_first_name#3, c_last_name#4, d_year#9, sum#11]
Arguments: hashpartitioning(c_customer_id#2, c_first_name#3, c_last_name#4, d_year#9, 1), ENSURE_REQUIREMENTS, [plan_id=2]

(15) HashAggregate [codegen id : 16]
Input [5]: [c_customer_id#2, c_first_name#3, c_last_name#4, d_year#9, sum#11]
Keys [4]: [c_customer_id#2, c_first_name#3, c_last_name#4, d_year#9]
Functions [1]: [sum(UnscaledValue(ss_net_paid#7))]
Aggregate Attributes [1]: [sum(UnscaledValue(ss_net_paid#7))#12]
Results [2]: [c_customer_id#2 AS customer_id#13, MakeDecimal(sum(UnscaledValue(ss_net_paid#7))#12,17,2) AS year_total#14]

(16) Filter [codegen id : 16]
Input [2]: [customer_id#13, year_total#14]
Condition : (isnotnull(year_total#14) AND (year_total#14 > 0.00))

(17) BatchScan spark_catalog.default.customer
Output [4]: [c_customer_sk#15, c_customer_id#16, c_first_name#17, c_last_name#18]
spark_catalog.default.customer [scan class = SparkBatchQueryScan] [filters=c_customer_sk IS NOT NULL, c_customer_id IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(18) Filter [codegen id : 6]
Input [4]: [c_customer_sk#15, c_customer_id#16, c_first_name#17, c_last_name#18]
Condition : (isnotnull(c_customer_sk#15) AND isnotnull(c_customer_id#16))

(19) Project [codegen id : 6]
Output [4]: [c_customer_sk#15, c_customer_id#16, c_first_name#17, c_last_name#18]
Input [4]: [c_customer_sk#15, c_customer_id#16, c_first_name#17, c_last_name#18]

(20) BatchScan spark_catalog.default.store_sales
Output [3]: [ss_sold_date_sk#19, ss_customer_sk#20, ss_net_paid#21]
spark_catalog.default.store_sales [scan class = SparkBatchQueryScan] [filters=ss_customer_sk IS NOT NULL, ss_sold_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(21) Filter [codegen id : 4]
Input [3]: [ss_sold_date_sk#19, ss_customer_sk#20, ss_net_paid#21]
Condition : (isnotnull(ss_customer_sk#20) AND isnotnull(ss_sold_date_sk#19))

(22) Project [codegen id : 4]
Output [3]: [ss_sold_date_sk#19, ss_customer_sk#20, ss_net_paid#21]
Input [3]: [ss_sold_date_sk#19, ss_customer_sk#20, ss_net_paid#21]

(23) BroadcastExchange
Input [3]: [ss_sold_date_sk#19, ss_customer_sk#20, ss_net_paid#21]
Arguments: HashedRelationBroadcastMode(List(cast(input[1, int, true] as bigint)),false), [plan_id=3]

(24) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [c_customer_sk#15]
Right keys [1]: [ss_customer_sk#20]
Join condition: None

(25) Project [codegen id : 6]
Output [5]: [c_customer_id#16, c_first_name#17, c_last_name#18, ss_sold_date_sk#19, ss_net_paid#21]
Input [7]: [c_customer_sk#15, c_customer_id#16, c_first_name#17, c_last_name#18, ss_sold_date_sk#19, ss_customer_sk#20, ss_net_paid#21]

(26) ReusedExchange [Reuses operator id: 79]
Output [2]: [d_date_sk#22, d_year#23]

(27) BroadcastHashJoin [codegen id : 6]
Left keys [1]: [ss_sold_date_sk#19]
Right keys [1]: [d_date_sk#22]
Join condition: None

(28) Project [codegen id : 6]
Output [5]: [c_customer_id#16, c_first_name#17, c_last_name#18, ss_net_paid#21, d_year#23]
Input [7]: [c_customer_id#16, c_first_name#17, c_last_name#18, ss_sold_date_sk#19, ss_net_paid#21, d_date_sk#22, d_year#23]

(29) HashAggregate [codegen id : 6]
Input [5]: [c_customer_id#16, c_first_name#17, c_last_name#18, ss_net_paid#21, d_year#23]
Keys [4]: [c_customer_id#16, c_first_name#17, c_last_name#18, d_year#23]
Functions [1]: [partial_sum(UnscaledValue(ss_net_paid#21))]
Aggregate Attributes [1]: [sum#24]
Results [5]: [c_customer_id#16, c_first_name#17, c_last_name#18, d_year#23, sum#25]

(30) Exchange
Input [5]: [c_customer_id#16, c_first_name#17, c_last_name#18, d_year#23, sum#25]
Arguments: hashpartitioning(c_customer_id#16, c_first_name#17, c_last_name#18, d_year#23, 1), ENSURE_REQUIREMENTS, [plan_id=4]

(31) HashAggregate [codegen id : 7]
Input [5]: [c_customer_id#16, c_first_name#17, c_last_name#18, d_year#23, sum#25]
Keys [4]: [c_customer_id#16, c_first_name#17, c_last_name#18, d_year#23]
Functions [1]: [sum(UnscaledValue(ss_net_paid#21))]
Aggregate Attributes [1]: [sum(UnscaledValue(ss_net_paid#21))#12]
Results [4]: [c_customer_id#16 AS customer_id#26, c_first_name#17 AS customer_first_name#27, c_last_name#18 AS customer_last_name#28, MakeDecimal(sum(UnscaledValue(ss_net_paid#21))#12,17,2) AS year_total#29]

(32) BroadcastExchange
Input [4]: [customer_id#26, customer_first_name#27, customer_last_name#28, year_total#29]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=5]

(33) BroadcastHashJoin [codegen id : 16]
Left keys [1]: [customer_id#13]
Right keys [1]: [customer_id#26]
Join condition: None

(34) BatchScan spark_catalog.default.customer
Output [4]: [c_customer_sk#30, c_customer_id#31, c_first_name#32, c_last_name#33]
spark_catalog.default.customer [scan class = SparkBatchQueryScan] [filters=c_customer_sk IS NOT NULL, c_customer_id IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(35) Filter [codegen id : 10]
Input [4]: [c_customer_sk#30, c_customer_id#31, c_first_name#32, c_last_name#33]
Condition : (isnotnull(c_customer_sk#30) AND isnotnull(c_customer_id#31))

(36) Project [codegen id : 10]
Output [4]: [c_customer_sk#30, c_customer_id#31, c_first_name#32, c_last_name#33]
Input [4]: [c_customer_sk#30, c_customer_id#31, c_first_name#32, c_last_name#33]

(37) BatchScan spark_catalog.default.web_sales
Output [3]: [ws_sold_date_sk#34, ws_bill_customer_sk#35, ws_net_paid#36]
spark_catalog.default.web_sales [scan class = SparkBatchQueryScan] [filters=ws_bill_customer_sk IS NOT NULL, ws_sold_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(38) Filter [codegen id : 8]
Input [3]: [ws_sold_date_sk#34, ws_bill_customer_sk#35, ws_net_paid#36]
Condition : (isnotnull(ws_bill_customer_sk#35) AND isnotnull(ws_sold_date_sk#34))

(39) Project [codegen id : 8]
Output [3]: [ws_sold_date_sk#34, ws_bill_customer_sk#35, ws_net_paid#36]
Input [3]: [ws_sold_date_sk#34, ws_bill_customer_sk#35, ws_net_paid#36]

(40) BroadcastExchange
Input [3]: [ws_sold_date_sk#34, ws_bill_customer_sk#35, ws_net_paid#36]
Arguments: HashedRelationBroadcastMode(List(cast(input[1, int, true] as bigint)),false), [plan_id=6]

(41) BroadcastHashJoin [codegen id : 10]
Left keys [1]: [c_customer_sk#30]
Right keys [1]: [ws_bill_customer_sk#35]
Join condition: None

(42) Project [codegen id : 10]
Output [5]: [c_customer_id#31, c_first_name#32, c_last_name#33, ws_sold_date_sk#34, ws_net_paid#36]
Input [7]: [c_customer_sk#30, c_customer_id#31, c_first_name#32, c_last_name#33, ws_sold_date_sk#34, ws_bill_customer_sk#35, ws_net_paid#36]

(43) ReusedExchange [Reuses operator id: 75]
Output [2]: [d_date_sk#37, d_year#38]

(44) BroadcastHashJoin [codegen id : 10]
Left keys [1]: [ws_sold_date_sk#34]
Right keys [1]: [d_date_sk#37]
Join condition: None

(45) Project [codegen id : 10]
Output [5]: [c_customer_id#31, c_first_name#32, c_last_name#33, ws_net_paid#36, d_year#38]
Input [7]: [c_customer_id#31, c_first_name#32, c_last_name#33, ws_sold_date_sk#34, ws_net_paid#36, d_date_sk#37, d_year#38]

(46) HashAggregate [codegen id : 10]
Input [5]: [c_customer_id#31, c_first_name#32, c_last_name#33, ws_net_paid#36, d_year#38]
Keys [4]: [c_customer_id#31, c_first_name#32, c_last_name#33, d_year#38]
Functions [1]: [partial_sum(UnscaledValue(ws_net_paid#36))]
Aggregate Attributes [1]: [sum#39]
Results [5]: [c_customer_id#31, c_first_name#32, c_last_name#33, d_year#38, sum#40]

(47) Exchange
Input [5]: [c_customer_id#31, c_first_name#32, c_last_name#33, d_year#38, sum#40]
Arguments: hashpartitioning(c_customer_id#31, c_first_name#32, c_last_name#33, d_year#38, 1), ENSURE_REQUIREMENTS, [plan_id=7]

(48) HashAggregate [codegen id : 11]
Input [5]: [c_customer_id#31, c_first_name#32, c_last_name#33, d_year#38, sum#40]
Keys [4]: [c_customer_id#31, c_first_name#32, c_last_name#33, d_year#38]
Functions [1]: [sum(UnscaledValue(ws_net_paid#36))]
Aggregate Attributes [1]: [sum(UnscaledValue(ws_net_paid#36))#41]
Results [2]: [c_customer_id#31 AS customer_id#42, MakeDecimal(sum(UnscaledValue(ws_net_paid#36))#41,17,2) AS year_total#43]

(49) Filter [codegen id : 11]
Input [2]: [customer_id#42, year_total#43]
Condition : (isnotnull(year_total#43) AND (year_total#43 > 0.00))

(50) BroadcastExchange
Input [2]: [customer_id#42, year_total#43]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=8]

(51) BroadcastHashJoin [codegen id : 16]
Left keys [1]: [customer_id#13]
Right keys [1]: [customer_id#42]
Join condition: None

(52) Project [codegen id : 16]
Output [7]: [customer_id#13, year_total#14, customer_id#26, customer_first_name#27, customer_last_name#28, year_total#29, year_total#43]
Input [8]: [customer_id#13, year_total#14, customer_id#26, customer_first_name#27, customer_last_name#28, year_total#29, customer_id#42, year_total#43]

(53) BatchScan spark_catalog.default.customer
Output [4]: [c_customer_sk#44, c_customer_id#45, c_first_name#46, c_last_name#47]
spark_catalog.default.customer [scan class = SparkBatchQueryScan] [filters=c_customer_sk IS NOT NULL, c_customer_id IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(54) Filter [codegen id : 14]
Input [4]: [c_customer_sk#44, c_customer_id#45, c_first_name#46, c_last_name#47]
Condition : (isnotnull(c_customer_sk#44) AND isnotnull(c_customer_id#45))

(55) Project [codegen id : 14]
Output [4]: [c_customer_sk#44, c_customer_id#45, c_first_name#46, c_last_name#47]
Input [4]: [c_customer_sk#44, c_customer_id#45, c_first_name#46, c_last_name#47]

(56) BatchScan spark_catalog.default.web_sales
Output [3]: [ws_sold_date_sk#48, ws_bill_customer_sk#49, ws_net_paid#50]
spark_catalog.default.web_sales [scan class = SparkBatchQueryScan] [filters=ws_bill_customer_sk IS NOT NULL, ws_sold_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(57) Filter [codegen id : 12]
Input [3]: [ws_sold_date_sk#48, ws_bill_customer_sk#49, ws_net_paid#50]
Condition : (isnotnull(ws_bill_customer_sk#49) AND isnotnull(ws_sold_date_sk#48))

(58) Project [codegen id : 12]
Output [3]: [ws_sold_date_sk#48, ws_bill_customer_sk#49, ws_net_paid#50]
Input [3]: [ws_sold_date_sk#48, ws_bill_customer_sk#49, ws_net_paid#50]

(59) BroadcastExchange
Input [3]: [ws_sold_date_sk#48, ws_bill_customer_sk#49, ws_net_paid#50]
Arguments: HashedRelationBroadcastMode(List(cast(input[1, int, true] as bigint)),false), [plan_id=9]

(60) BroadcastHashJoin [codegen id : 14]
Left keys [1]: [c_customer_sk#44]
Right keys [1]: [ws_bill_customer_sk#49]
Join condition: None

(61) Project [codegen id : 14]
Output [5]: [c_customer_id#45, c_first_name#46, c_last_name#47, ws_sold_date_sk#48, ws_net_paid#50]
Input [7]: [c_customer_sk#44, c_customer_id#45, c_first_name#46, c_last_name#47, ws_sold_date_sk#48, ws_bill_customer_sk#49, ws_net_paid#50]

(62) ReusedExchange [Reuses operator id: 79]
Output [2]: [d_date_sk#51, d_year#52]

(63) BroadcastHashJoin [codegen id : 14]
Left keys [1]: [ws_sold_date_sk#48]
Right keys [1]: [d_date_sk#51]
Join condition: None

(64) Project [codegen id : 14]
Output [5]: [c_customer_id#45, c_first_name#46, c_last_name#47, ws_net_paid#50, d_year#52]
Input [7]: [c_customer_id#45, c_first_name#46, c_last_name#47, ws_sold_date_sk#48, ws_net_paid#50, d_date_sk#51, d_year#52]

(65) HashAggregate [codegen id : 14]
Input [5]: [c_customer_id#45, c_first_name#46, c_last_name#47, ws_net_paid#50, d_year#52]
Keys [4]: [c_customer_id#45, c_first_name#46, c_last_name#47, d_year#52]
Functions [1]: [partial_sum(UnscaledValue(ws_net_paid#50))]
Aggregate Attributes [1]: [sum#53]
Results [5]: [c_customer_id#45, c_first_name#46, c_last_name#47, d_year#52, sum#54]

(66) Exchange
Input [5]: [c_customer_id#45, c_first_name#46, c_last_name#47, d_year#52, sum#54]
Arguments: hashpartitioning(c_customer_id#45, c_first_name#46, c_last_name#47, d_year#52, 1), ENSURE_REQUIREMENTS, [plan_id=10]

(67) HashAggregate [codegen id : 15]
Input [5]: [c_customer_id#45, c_first_name#46, c_last_name#47, d_year#52, sum#54]
Keys [4]: [c_customer_id#45, c_first_name#46, c_last_name#47, d_year#52]
Functions [1]: [sum(UnscaledValue(ws_net_paid#50))]
Aggregate Attributes [1]: [sum(UnscaledValue(ws_net_paid#50))#41]
Results [2]: [c_customer_id#45 AS customer_id#55, MakeDecimal(sum(UnscaledValue(ws_net_paid#50))#41,17,2) AS year_total#56]

(68) BroadcastExchange
Input [2]: [customer_id#55, year_total#56]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=11]

(69) BroadcastHashJoin [codegen id : 16]
Left keys [1]: [customer_id#13]
Right keys [1]: [customer_id#55]
Join condition: (CASE WHEN (year_total#43 > 0.00) THEN CheckOverflow((promote_precision(year_total#56) / promote_precision(year_total#43)), DecimalType(37,20)) END > CASE WHEN (year_total#14 > 0.00) THEN CheckOverflow((promote_precision(year_total#29) / promote_precision(year_total#14)), DecimalType(37,20)) END)

(70) Project [codegen id : 16]
Output [3]: [customer_id#26, customer_first_name#27, customer_last_name#28]
Input [9]: [customer_id#13, year_total#14, customer_id#26, customer_first_name#27, customer_last_name#28, year_total#29, year_total#43, customer_id#55, year_total#56]

(71) TakeOrderedAndProject
Input [3]: [customer_id#26, customer_first_name#27, customer_last_name#28]
Arguments: 100, [customer_first_name#27 ASC NULLS FIRST, customer_id#26 ASC NULLS FIRST, customer_last_name#28 ASC NULLS FIRST], [customer_id#26, customer_first_name#27, customer_last_name#28]

===== Subqueries =====

Subquery:1 Hosting operator id = 4 Hosting Expression = ss_sold_date_sk#5 IN dynamicpruning#57
BroadcastExchange (75)
+- * Project (74)
   +- * Filter (73)
      +- BatchScan spark_catalog.default.date_dim (72)


(72) BatchScan spark_catalog.default.date_dim
Output [2]: [d_date_sk#8, d_year#9]
spark_catalog.default.date_dim [scan class = SparkBatchQueryScan] [filters=d_year IS NOT NULL, d_year = 2001, d_year IN (2001, 2002), d_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(73) Filter [codegen id : 1]
Input [2]: [d_date_sk#8, d_year#9]
Condition : (((isnotnull(d_year#9) AND (d_year#9 = 2001)) AND d_year#9 IN (2001,2002)) AND isnotnull(d_date_sk#8))

(74) Project [codegen id : 1]
Output [2]: [d_date_sk#8, d_year#9]
Input [2]: [d_date_sk#8, d_year#9]

(75) BroadcastExchange
Input [2]: [d_date_sk#8, d_year#9]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=12]

Subquery:2 Hosting operator id = 20 Hosting Expression = ss_sold_date_sk#19 IN dynamicpruning#58
BroadcastExchange (79)
+- * Project (78)
   +- * Filter (77)
      +- BatchScan spark_catalog.default.date_dim (76)


(76) BatchScan spark_catalog.default.date_dim
Output [2]: [d_date_sk#22, d_year#23]
spark_catalog.default.date_dim [scan class = SparkBatchQueryScan] [filters=d_year IS NOT NULL, d_year = 2002, d_year IN (2001, 2002), d_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(77) Filter [codegen id : 1]
Input [2]: [d_date_sk#22, d_year#23]
Condition : (((isnotnull(d_year#23) AND (d_year#23 = 2002)) AND d_year#23 IN (2001,2002)) AND isnotnull(d_date_sk#22))

(78) Project [codegen id : 1]
Output [2]: [d_date_sk#22, d_year#23]
Input [2]: [d_date_sk#22, d_year#23]

(79) BroadcastExchange
Input [2]: [d_date_sk#22, d_year#23]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=13]

Subquery:3 Hosting operator id = 37 Hosting Expression = ws_sold_date_sk#34 IN dynamicpruning#57

Subquery:4 Hosting operator id = 56 Hosting Expression = ws_sold_date_sk#48 IN dynamicpruning#58


