== Physical Plan ==
TakeOrderedAndProject (49)
+- * Project (48)
   +- * BroadcastHashJoin Inner BuildRight (47)
      :- * Project (32)
      :  +- * BroadcastHashJoin Inner BuildRight (31)
      :     :- * Filter (16)
      :     :  +- * HashAggregate (15)
      :     :     +- Exchange (14)
      :     :        +- * HashAggregate (13)
      :     :           +- * Project (12)
      :     :              +- * BroadcastHashJoin Inner BuildRight (11)
      :     :                 :- * Project (9)
      :     :                 :  +- * BroadcastHashJoin Inner BuildRight (8)
      :     :                 :     :- * Project (3)
      :     :                 :     :  +- * Filter (2)
      :     :                 :     :     +- BatchScan spark_catalog.default.store_sales (1)
      :     :                 :     +- BroadcastExchange (7)
      :     :                 :        +- * Project (6)
      :     :                 :           +- * Filter (5)
      :     :                 :              +- BatchScan spark_catalog.default.item (4)
      :     :                 +- ReusedExchange (10)
      :     +- BroadcastExchange (30)
      :        +- * Filter (29)
      :           +- * HashAggregate (28)
      :              +- Exchange (27)
      :                 +- * HashAggregate (26)
      :                    +- * Project (25)
      :                       +- * BroadcastHashJoin Inner BuildRight (24)
      :                          :- * Project (22)
      :                          :  +- * BroadcastHashJoin Inner BuildRight (21)
      :                          :     :- * Project (19)
      :                          :     :  +- * Filter (18)
      :                          :     :     +- BatchScan spark_catalog.default.catalog_sales (17)
      :                          :     +- ReusedExchange (20)
      :                          +- ReusedExchange (23)
      +- BroadcastExchange (46)
         +- * Filter (45)
            +- * HashAggregate (44)
               +- Exchange (43)
                  +- * HashAggregate (42)
                     +- * Project (41)
                        +- * BroadcastHashJoin Inner BuildRight (40)
                           :- * Project (38)
                           :  +- * BroadcastHashJoin Inner BuildRight (37)
                           :     :- * Project (35)
                           :     :  +- * Filter (34)
                           :     :     +- BatchScan spark_catalog.default.web_sales (33)
                           :     +- ReusedExchange (36)
                           +- ReusedExchange (39)


(1) BatchScan spark_catalog.default.store_sales
Output [3]: [ss_sold_date_sk#1, ss_item_sk#2, ss_ext_sales_price#3]
spark_catalog.default.store_sales [scan class = SparkBatchQueryScan] [filters=ss_item_sk IS NOT NULL, ss_sold_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(2) Filter [codegen id : 4]
Input [3]: [ss_sold_date_sk#1, ss_item_sk#2, ss_ext_sales_price#3]
Condition : (isnotnull(ss_item_sk#2) AND isnotnull(ss_sold_date_sk#1))

(3) Project [codegen id : 4]
Output [3]: [ss_sold_date_sk#1, ss_item_sk#2, ss_ext_sales_price#3]
Input [3]: [ss_sold_date_sk#1, ss_item_sk#2, ss_ext_sales_price#3]

(4) BatchScan spark_catalog.default.item
Output [2]: [i_item_sk#4, i_item_id#5]
spark_catalog.default.item [scan class = SparkBatchQueryScan] [filters=i_item_sk IS NOT NULL, i_item_id IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(5) Filter [codegen id : 1]
Input [2]: [i_item_sk#4, i_item_id#5]
Condition : (isnotnull(i_item_sk#4) AND isnotnull(i_item_id#5))

(6) Project [codegen id : 1]
Output [2]: [i_item_sk#4, i_item_id#5]
Input [2]: [i_item_sk#4, i_item_id#5]

(7) BroadcastExchange
Input [2]: [i_item_sk#4, i_item_id#5]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=1]

(8) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_item_sk#2]
Right keys [1]: [i_item_sk#4]
Join condition: None

(9) Project [codegen id : 4]
Output [3]: [ss_sold_date_sk#1, ss_ext_sales_price#3, i_item_id#5]
Input [5]: [ss_sold_date_sk#1, ss_item_sk#2, ss_ext_sales_price#3, i_item_sk#4, i_item_id#5]

(10) ReusedExchange [Reuses operator id: 59]
Output [1]: [d_date_sk#6]

(11) BroadcastHashJoin [codegen id : 4]
Left keys [1]: [ss_sold_date_sk#1]
Right keys [1]: [d_date_sk#6]
Join condition: None

(12) Project [codegen id : 4]
Output [2]: [ss_ext_sales_price#3, i_item_id#5]
Input [4]: [ss_sold_date_sk#1, ss_ext_sales_price#3, i_item_id#5, d_date_sk#6]

(13) HashAggregate [codegen id : 4]
Input [2]: [ss_ext_sales_price#3, i_item_id#5]
Keys [1]: [i_item_id#5]
Functions [1]: [partial_sum(UnscaledValue(ss_ext_sales_price#3))]
Aggregate Attributes [1]: [sum#7]
Results [2]: [i_item_id#5, sum#8]

(14) Exchange
Input [2]: [i_item_id#5, sum#8]
Arguments: hashpartitioning(i_item_id#5, 1), ENSURE_REQUIREMENTS, [plan_id=2]

(15) HashAggregate [codegen id : 15]
Input [2]: [i_item_id#5, sum#8]
Keys [1]: [i_item_id#5]
Functions [1]: [sum(UnscaledValue(ss_ext_sales_price#3))]
Aggregate Attributes [1]: [sum(UnscaledValue(ss_ext_sales_price#3))#9]
Results [2]: [i_item_id#5 AS item_id#10, MakeDecimal(sum(UnscaledValue(ss_ext_sales_price#3))#9,17,2) AS ss_item_rev#11]

(16) Filter [codegen id : 15]
Input [2]: [item_id#10, ss_item_rev#11]
Condition : isnotnull(ss_item_rev#11)

(17) BatchScan spark_catalog.default.catalog_sales
Output [3]: [cs_sold_date_sk#12, cs_item_sk#13, cs_ext_sales_price#14]
spark_catalog.default.catalog_sales [scan class = SparkBatchQueryScan] [filters=cs_item_sk IS NOT NULL, cs_sold_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(18) Filter [codegen id : 8]
Input [3]: [cs_sold_date_sk#12, cs_item_sk#13, cs_ext_sales_price#14]
Condition : (isnotnull(cs_item_sk#13) AND isnotnull(cs_sold_date_sk#12))

(19) Project [codegen id : 8]
Output [3]: [cs_sold_date_sk#12, cs_item_sk#13, cs_ext_sales_price#14]
Input [3]: [cs_sold_date_sk#12, cs_item_sk#13, cs_ext_sales_price#14]

(20) ReusedExchange [Reuses operator id: 7]
Output [2]: [i_item_sk#15, i_item_id#16]

(21) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [cs_item_sk#13]
Right keys [1]: [i_item_sk#15]
Join condition: None

(22) Project [codegen id : 8]
Output [3]: [cs_sold_date_sk#12, cs_ext_sales_price#14, i_item_id#16]
Input [5]: [cs_sold_date_sk#12, cs_item_sk#13, cs_ext_sales_price#14, i_item_sk#15, i_item_id#16]

(23) ReusedExchange [Reuses operator id: 59]
Output [1]: [d_date_sk#17]

(24) BroadcastHashJoin [codegen id : 8]
Left keys [1]: [cs_sold_date_sk#12]
Right keys [1]: [d_date_sk#17]
Join condition: None

(25) Project [codegen id : 8]
Output [2]: [cs_ext_sales_price#14, i_item_id#16]
Input [4]: [cs_sold_date_sk#12, cs_ext_sales_price#14, i_item_id#16, d_date_sk#17]

(26) HashAggregate [codegen id : 8]
Input [2]: [cs_ext_sales_price#14, i_item_id#16]
Keys [1]: [i_item_id#16]
Functions [1]: [partial_sum(UnscaledValue(cs_ext_sales_price#14))]
Aggregate Attributes [1]: [sum#18]
Results [2]: [i_item_id#16, sum#19]

(27) Exchange
Input [2]: [i_item_id#16, sum#19]
Arguments: hashpartitioning(i_item_id#16, 1), ENSURE_REQUIREMENTS, [plan_id=3]

(28) HashAggregate [codegen id : 9]
Input [2]: [i_item_id#16, sum#19]
Keys [1]: [i_item_id#16]
Functions [1]: [sum(UnscaledValue(cs_ext_sales_price#14))]
Aggregate Attributes [1]: [sum(UnscaledValue(cs_ext_sales_price#14))#20]
Results [2]: [i_item_id#16 AS item_id#21, MakeDecimal(sum(UnscaledValue(cs_ext_sales_price#14))#20,17,2) AS cs_item_rev#22]

(29) Filter [codegen id : 9]
Input [2]: [item_id#21, cs_item_rev#22]
Condition : isnotnull(cs_item_rev#22)

(30) BroadcastExchange
Input [2]: [item_id#21, cs_item_rev#22]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=4]

(31) BroadcastHashJoin [codegen id : 15]
Left keys [1]: [item_id#10]
Right keys [1]: [item_id#21]
Join condition: ((((cast(ss_item_rev#11 as decimal(19,3)) >= CheckOverflow((0.90 * promote_precision(cs_item_rev#22)), DecimalType(19,3))) AND (cast(ss_item_rev#11 as decimal(20,3)) <= CheckOverflow((1.10 * promote_precision(cs_item_rev#22)), DecimalType(20,3)))) AND (cast(cs_item_rev#22 as decimal(19,3)) >= CheckOverflow((0.90 * promote_precision(ss_item_rev#11)), DecimalType(19,3)))) AND (cast(cs_item_rev#22 as decimal(20,3)) <= CheckOverflow((1.10 * promote_precision(ss_item_rev#11)), DecimalType(20,3))))

(32) Project [codegen id : 15]
Output [3]: [item_id#10, ss_item_rev#11, cs_item_rev#22]
Input [4]: [item_id#10, ss_item_rev#11, item_id#21, cs_item_rev#22]

(33) BatchScan spark_catalog.default.web_sales
Output [3]: [ws_sold_date_sk#23, ws_item_sk#24, ws_ext_sales_price#25]
spark_catalog.default.web_sales [scan class = SparkBatchQueryScan] [filters=ws_item_sk IS NOT NULL, ws_sold_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(34) Filter [codegen id : 13]
Input [3]: [ws_sold_date_sk#23, ws_item_sk#24, ws_ext_sales_price#25]
Condition : (isnotnull(ws_item_sk#24) AND isnotnull(ws_sold_date_sk#23))

(35) Project [codegen id : 13]
Output [3]: [ws_sold_date_sk#23, ws_item_sk#24, ws_ext_sales_price#25]
Input [3]: [ws_sold_date_sk#23, ws_item_sk#24, ws_ext_sales_price#25]

(36) ReusedExchange [Reuses operator id: 7]
Output [2]: [i_item_sk#26, i_item_id#27]

(37) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ws_item_sk#24]
Right keys [1]: [i_item_sk#26]
Join condition: None

(38) Project [codegen id : 13]
Output [3]: [ws_sold_date_sk#23, ws_ext_sales_price#25, i_item_id#27]
Input [5]: [ws_sold_date_sk#23, ws_item_sk#24, ws_ext_sales_price#25, i_item_sk#26, i_item_id#27]

(39) ReusedExchange [Reuses operator id: 59]
Output [1]: [d_date_sk#28]

(40) BroadcastHashJoin [codegen id : 13]
Left keys [1]: [ws_sold_date_sk#23]
Right keys [1]: [d_date_sk#28]
Join condition: None

(41) Project [codegen id : 13]
Output [2]: [ws_ext_sales_price#25, i_item_id#27]
Input [4]: [ws_sold_date_sk#23, ws_ext_sales_price#25, i_item_id#27, d_date_sk#28]

(42) HashAggregate [codegen id : 13]
Input [2]: [ws_ext_sales_price#25, i_item_id#27]
Keys [1]: [i_item_id#27]
Functions [1]: [partial_sum(UnscaledValue(ws_ext_sales_price#25))]
Aggregate Attributes [1]: [sum#29]
Results [2]: [i_item_id#27, sum#30]

(43) Exchange
Input [2]: [i_item_id#27, sum#30]
Arguments: hashpartitioning(i_item_id#27, 1), ENSURE_REQUIREMENTS, [plan_id=5]

(44) HashAggregate [codegen id : 14]
Input [2]: [i_item_id#27, sum#30]
Keys [1]: [i_item_id#27]
Functions [1]: [sum(UnscaledValue(ws_ext_sales_price#25))]
Aggregate Attributes [1]: [sum(UnscaledValue(ws_ext_sales_price#25))#31]
Results [2]: [i_item_id#27 AS item_id#32, MakeDecimal(sum(UnscaledValue(ws_ext_sales_price#25))#31,17,2) AS ws_item_rev#33]

(45) Filter [codegen id : 14]
Input [2]: [item_id#32, ws_item_rev#33]
Condition : isnotnull(ws_item_rev#33)

(46) BroadcastExchange
Input [2]: [item_id#32, ws_item_rev#33]
Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=6]

(47) BroadcastHashJoin [codegen id : 15]
Left keys [1]: [item_id#10]
Right keys [1]: [item_id#32]
Join condition: ((((((((cast(ss_item_rev#11 as decimal(19,3)) >= CheckOverflow((0.90 * promote_precision(ws_item_rev#33)), DecimalType(19,3))) AND (cast(ss_item_rev#11 as decimal(20,3)) <= CheckOverflow((1.10 * promote_precision(ws_item_rev#33)), DecimalType(20,3)))) AND (cast(cs_item_rev#22 as decimal(19,3)) >= CheckOverflow((0.90 * promote_precision(ws_item_rev#33)), DecimalType(19,3)))) AND (cast(cs_item_rev#22 as decimal(20,3)) <= CheckOverflow((1.10 * promote_precision(ws_item_rev#33)), DecimalType(20,3)))) AND (cast(ws_item_rev#33 as decimal(19,3)) >= CheckOverflow((0.90 * promote_precision(ss_item_rev#11)), DecimalType(19,3)))) AND (cast(ws_item_rev#33 as decimal(20,3)) <= CheckOverflow((1.10 * promote_precision(ss_item_rev#11)), DecimalType(20,3)))) AND (cast(ws_item_rev#33 as decimal(19,3)) >= CheckOverflow((0.90 * promote_precision(cs_item_rev#22)), DecimalType(19,3)))) AND (cast(ws_item_rev#33 as decimal(20,3)) <= CheckOverflow((1.10 * promote_precision(cs_item_rev#22)), DecimalType(20,3))))

(48) Project [codegen id : 15]
Output [8]: [item_id#10, ss_item_rev#11, CheckOverflow((promote_precision(CheckOverflow((promote_precision(CheckOverflow((promote_precision(cast(ss_item_rev#11 as decimal(19,2))) / promote_precision(CheckOverflow((promote_precision(cast(CheckOverflow((promote_precision(cast(ss_item_rev#11 as decimal(18,2))) + promote_precision(cast(cs_item_rev#22 as decimal(18,2)))), DecimalType(18,2)) as decimal(19,2))) + promote_precision(cast(ws_item_rev#33 as decimal(19,2)))), DecimalType(19,2)))), DecimalType(38,21))) / 3.000000000000000000000), DecimalType(38,21))) * 100.000000000000000000000), DecimalType(38,17)) AS ss_dev#34, cs_item_rev#22, CheckOverflow((promote_precision(CheckOverflow((promote_precision(CheckOverflow((promote_precision(cast(cs_item_rev#22 as decimal(19,2))) / promote_precision(CheckOverflow((promote_precision(cast(CheckOverflow((promote_precision(cast(ss_item_rev#11 as decimal(18,2))) + promote_precision(cast(cs_item_rev#22 as decimal(18,2)))), DecimalType(18,2)) as decimal(19,2))) + promote_precision(cast(ws_item_rev#33 as decimal(19,2)))), DecimalType(19,2)))), DecimalType(38,21))) / 3.000000000000000000000), DecimalType(38,21))) * 100.000000000000000000000), DecimalType(38,17)) AS cs_dev#35, ws_item_rev#33, CheckOverflow((promote_precision(CheckOverflow((promote_precision(CheckOverflow((promote_precision(cast(ws_item_rev#33 as decimal(19,2))) / promote_precision(CheckOverflow((promote_precision(cast(CheckOverflow((promote_precision(cast(ss_item_rev#11 as decimal(18,2))) + promote_precision(cast(cs_item_rev#22 as decimal(18,2)))), DecimalType(18,2)) as decimal(19,2))) + promote_precision(cast(ws_item_rev#33 as decimal(19,2)))), DecimalType(19,2)))), DecimalType(38,21))) / 3.000000000000000000000), DecimalType(38,21))) * 100.000000000000000000000), DecimalType(38,17)) AS ws_dev#36, CheckOverflow((promote_precision(CheckOverflow((promote_precision(cast(CheckOverflow((promote_precision(cast(ss_item_rev#11 as decimal(18,2))) + promote_precision(cast(cs_item_rev#22 as decimal(18,2)))), DecimalType(18,2)) as decimal(19,2))) + promote_precision(cast(ws_item_rev#33 as decimal(19,2)))), DecimalType(19,2))) / 3.00), DecimalType(23,6)) AS average#37]
Input [5]: [item_id#10, ss_item_rev#11, cs_item_rev#22, item_id#32, ws_item_rev#33]

(49) TakeOrderedAndProject
Input [8]: [item_id#10, ss_item_rev#11, ss_dev#34, cs_item_rev#22, cs_dev#35, ws_item_rev#33, ws_dev#36, average#37]
Arguments: 100, [item_id#10 ASC NULLS FIRST, ss_item_rev#11 ASC NULLS FIRST], [item_id#10, ss_item_rev#11, ss_dev#34, cs_item_rev#22, cs_dev#35, ws_item_rev#33, ws_dev#36, average#37]

===== Subqueries =====

Subquery:1 Hosting operator id = 1 Hosting Expression = ss_sold_date_sk#1 IN dynamicpruning#38
BroadcastExchange (59)
+- * Project (58)
   +- * BroadcastHashJoin LeftSemi BuildRight (57)
      :- * Project (52)
      :  +- * Filter (51)
      :     +- BatchScan spark_catalog.default.date_dim (50)
      +- BroadcastExchange (56)
         +- * Project (55)
            +- * Filter (54)
               +- BatchScan spark_catalog.default.date_dim (53)


(50) BatchScan spark_catalog.default.date_dim
Output [2]: [d_date_sk#6, d_date#39]
spark_catalog.default.date_dim [scan class = SparkBatchQueryScan] [filters=d_date_sk IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(51) Filter [codegen id : 2]
Input [2]: [d_date_sk#6, d_date#39]
Condition : isnotnull(d_date_sk#6)

(52) Project [codegen id : 2]
Output [2]: [d_date_sk#6, d_date#39]
Input [2]: [d_date_sk#6, d_date#39]

(53) BatchScan spark_catalog.default.date_dim
Output [2]: [d_date#40, d_week_seq#41]
spark_catalog.default.date_dim [scan class = SparkBatchQueryScan] [filters=d_week_seq IS NOT NULL], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(54) Filter [codegen id : 1]
Input [2]: [d_date#40, d_week_seq#41]
Condition : (isnotnull(d_week_seq#41) AND (d_week_seq#41 = Subquery scalar-subquery#42, [id=#43]))

(55) Project [codegen id : 1]
Output [1]: [d_date#40]
Input [2]: [d_date#40, d_week_seq#41]

(56) BroadcastExchange
Input [1]: [d_date#40]
Arguments: HashedRelationBroadcastMode(List(input[0, date, true]),false), [plan_id=7]

(57) BroadcastHashJoin [codegen id : 2]
Left keys [1]: [d_date#39]
Right keys [1]: [d_date#40]
Join condition: None

(58) Project [codegen id : 2]
Output [1]: [d_date_sk#6]
Input [2]: [d_date_sk#6, d_date#39]

(59) BroadcastExchange
Input [1]: [d_date_sk#6]
Arguments: HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=8]

Subquery:2 Hosting operator id = 54 Hosting Expression = Subquery scalar-subquery#42, [id=#43]
* Project (62)
+- * Filter (61)
   +- BatchScan spark_catalog.default.date_dim (60)


(60) BatchScan spark_catalog.default.date_dim
Output [2]: [d_date#44, d_week_seq#45]
spark_catalog.default.date_dim [scan class = SparkBatchQueryScan] [filters=d_date IS NOT NULL, d_date = 10959], [runtimeFilters=[]], caseSensitive=false,[ Broadcast Var UNUSED =]

(61) Filter [codegen id : 1]
Input [2]: [d_date#44, d_week_seq#45]
Condition : (isnotnull(d_date#44) AND (d_date#44 = 2000-01-03))

(62) Project [codegen id : 1]
Output [1]: [d_week_seq#45]
Input [2]: [d_date#44, d_week_seq#45]

Subquery:3 Hosting operator id = 17 Hosting Expression = cs_sold_date_sk#12 IN dynamicpruning#38

Subquery:4 Hosting operator id = 33 Hosting Expression = ws_sold_date_sk#23 IN dynamicpruning#38


