/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.spark.sql.connect.client.jdbc

import java.sql.{Array => _, _}

import org.apache.spark.sql.connect.SparkSession

class SparkConnectStatement(spark: SparkSession) extends Statement {

  private var operationId: String = _
  private var resultSet: SparkConnectQueryResultSet = _

  override def executeQuery(sql: String): ResultSet = {
    val sparkResult = spark.sql(sql).collectResult()
    operationId = sparkResult.operationId
    resultSet = new SparkConnectQueryResultSet(this, sparkResult)
    resultSet
  }

  override def executeUpdate(sql: String): Int = {
    val sparkResult = spark.sql(sql).collectResult()
    operationId = sparkResult.operationId
    resultSet = null
    0
  }

  override def execute(sql: String): Boolean = {
    executeQuery(sql)
    true
  }

  override def getResultSet: ResultSet = resultSet

  var closed: Boolean = false

  override def isClosed: Boolean = closed

  override def close(): Unit = if (!closed) {
    if (operationId != null) {
      spark.interruptOperation(operationId)
      operationId = null
    }
    if (resultSet != null) {
      resultSet.close()
      resultSet = null
    }
    closed = false
  }

  override def getMaxFieldSize: Int = ???

  override def setMaxFieldSize(max: Int): Unit = ???

  override def getMaxRows: Int = ???

  override def setMaxRows(max: Int): Unit = ???

  override def setEscapeProcessing(enable: Boolean): Unit = ???

  override def getQueryTimeout: Int = ???

  override def setQueryTimeout(seconds: Int): Unit = ???

  override def cancel(): Unit = if (operationId != null) {
    spark.interruptOperation(operationId)
  }

  override def getWarnings: SQLWarning = ???

  override def clearWarnings(): Unit = ???

  override def setCursorName(name: String): Unit = ???

  override def getUpdateCount: Int = ???

  override def getMoreResults: Boolean = ???

  override def setFetchDirection(direction: Int): Unit = ???

  override def getFetchDirection: Int = ???

  override def setFetchSize(rows: Int): Unit = ???

  override def getFetchSize: Int = ???

  override def getResultSetConcurrency: Int = ???

  override def getResultSetType: Int = ???

  override def addBatch(sql: String): Unit = ???

  override def clearBatch(): Unit = ???

  override def executeBatch(): Array[Int] = ???

  override def getConnection: Connection = ???

  override def getMoreResults(current: Int): Boolean = ???

  override def getGeneratedKeys: ResultSet =
    throw new SQLFeatureNotSupportedException

  override def executeUpdate(sql: String, autoGeneratedKeys: Int): Int =
    throw new SQLFeatureNotSupportedException

  override def executeUpdate(sql: String, columnIndexes: Array[Int]): Int =
    throw new SQLFeatureNotSupportedException

  override def executeUpdate(sql: String, columnNames: Array[String]): Int =
    throw new SQLFeatureNotSupportedException

  override def execute(sql: String, autoGeneratedKeys: Int): Boolean =
    throw new SQLFeatureNotSupportedException

  override def execute(sql: String, columnIndexes: Array[Int]): Boolean =
    throw new SQLFeatureNotSupportedException

  override def execute(sql: String, columnNames: Array[String]): Boolean =
    throw new SQLFeatureNotSupportedException

  override def getResultSetHoldability: Int = ???

  override def setPoolable(poolable: Boolean): Unit = {}

  override def isPoolable: Boolean = false

  override def closeOnCompletion(): Unit = ???

  override def isCloseOnCompletion: Boolean = ???

  override def unwrap[T](iface: Class[T]): T = if (isWrapperFor(iface)) {
    iface.asInstanceOf[T]
  } else {
    throw new SQLException(s"${this.getClass.getName} not unwrappable from ${iface.getName}")
  }

  override def isWrapperFor(iface: Class[_]): Boolean = iface.isInstance(this)
}
