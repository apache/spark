<?xml version="1.0" encoding="UTF-8"?>
<!--
  ~ Licensed to the Apache Software Foundation (ASF) under one or more
  ~ contributor license agreements.  See the NOTICE file distributed with
  ~ this work for additional information regarding copyright ownership.
  ~ The ASF licenses this file to You under the Apache License, Version 2.0
  ~ (the "License"); you may not use this file except in compliance with
  ~ the License.  You may obtain a copy of the License at
  ~
  ~    http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an "AS IS" BASIS,
  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~ See the License for the specific language governing permissions and
  ~ limitations under the License.
  -->

<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <parent>
    <groupId>org.apache.spark</groupId>
    <artifactId>spark-parent_2.13</artifactId>
    <version>4.0.0-SNAPSHOT</version>
    <relativePath>../../../pom.xml</relativePath>
  </parent>

  <artifactId>spark-connect_2.13</artifactId>
  <packaging>jar</packaging>
  <name>Spark Project Connect Server</name>
  <url>https://spark.apache.org/</url>
  <properties>
    <sbt.project.name>connect</sbt.project.name>
  </properties>

  <dependencies>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
      <scope>provided</scope>
      <exclusions>
        <exclusion>
          <groupId>com.google.guava</groupId>
          <artifactId>guava</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-connect-common_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
      <exclusions>
        <exclusion>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-connect-shims_${scala.binary.version}</artifactId>
        </exclusion>
        <exclusion>
          <groupId>com.google.guava</groupId>
          <artifactId>guava</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
      <type>test-jar</type>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-catalyst_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
      <scope>provided</scope>
      <exclusions>
        <exclusion>
          <groupId>com.google.guava</groupId>
          <artifactId>guava</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-sql_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
      <scope>provided</scope>
      <exclusions>
        <exclusion>
          <groupId>com.google.guava</groupId>
          <artifactId>guava</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-mllib_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
      <scope>provided</scope>
      <exclusions>
        <exclusion>
          <groupId>com.google.guava</groupId>
          <artifactId>guava</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-avro_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-protobuf_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-catalyst_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
      <type>test-jar</type>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-sql_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
      <type>test-jar</type>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-connect-common_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
      <type>test-jar</type>
      <scope>test</scope>
      <exclusions>
        <exclusion>
          <groupId>com.google.guava</groupId>
          <artifactId>guava</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-tags_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
      <scope>provided</scope>
      <exclusions>
        <exclusion>
          <groupId>com.google.guava</groupId>
          <artifactId>guava</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>org.scala-lang.modules</groupId>
      <artifactId>scala-parallel-collections_${scala.binary.version}</artifactId>
    </dependency>
    <dependency>
      <groupId>jakarta.servlet</groupId>
      <artifactId>jakarta.servlet-api</artifactId>
    </dependency>
    <dependency>
      <groupId>javax.servlet</groupId>
      <artifactId>javax.servlet-api</artifactId>
    </dependency>
    <dependency>
      <groupId>com.google.guava</groupId>
      <artifactId>guava</artifactId>
      <version>${connect.guava.version}</version>
      <scope>compile</scope>
    </dependency>
    <dependency>
      <groupId>com.google.guava</groupId>
      <artifactId>failureaccess</artifactId>
      <version>${guava.failureaccess.version}</version>
      <scope>compile</scope>
    </dependency>
    <dependency>
      <groupId>com.google.protobuf</groupId>
      <artifactId>protobuf-java</artifactId>
      <scope>compile</scope>
    </dependency>
    <dependency>
      <groupId>com.google.protobuf</groupId>
      <artifactId>protobuf-java-util</artifactId>
      <scope>compile</scope>
    </dependency>
    <dependency>
      <groupId>io.grpc</groupId>
      <artifactId>grpc-netty</artifactId>
      <version>${io.grpc.version}</version>
    </dependency>
    <dependency>
      <groupId>io.grpc</groupId>
      <artifactId>grpc-protobuf</artifactId>
      <version>${io.grpc.version}</version>
    </dependency>
    <dependency>
      <groupId>io.grpc</groupId>
      <artifactId>grpc-services</artifactId>
      <version>${io.grpc.version}</version>
    </dependency>
    <dependency>
      <groupId>io.grpc</groupId>
      <artifactId>grpc-stub</artifactId>
      <version>${io.grpc.version}</version>
    </dependency>
    <dependency>
      <groupId>io.netty</groupId>
      <artifactId>netty-codec-http2</artifactId>
      <version>${netty.version}</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>io.netty</groupId>
      <artifactId>netty-handler-proxy</artifactId>
      <version>${netty.version}</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>io.netty</groupId>
      <artifactId>netty-transport-native-unix-common</artifactId>
      <version>${netty.version}</version>
      <scope>provided</scope>
    </dependency>
    <dependency> <!-- necessary for Java 9+ -->
      <groupId>org.apache.tomcat</groupId>
      <artifactId>annotations-api</artifactId>
      <version>${tomcat.annotations.api.version}</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>org.scalacheck</groupId>
      <artifactId>scalacheck_${scala.binary.version}</artifactId>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.mockito</groupId>
      <artifactId>mockito-core</artifactId>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>net.bytebuddy</groupId>
      <artifactId>byte-buddy</artifactId>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>net.bytebuddy</groupId>
      <artifactId>byte-buddy-agent</artifactId>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>com.h2database</groupId>
      <artifactId>h2</artifactId>
      <version>2.3.232</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-repl_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
      <type>test-jar</type>
      <scope>test</scope>
    </dependency>
  </dependencies>
  <build>
    <outputDirectory>target/scala-${scala.binary.version}/classes</outputDirectory>
    <testOutputDirectory>target/scala-${scala.binary.version}/test-classes</testOutputDirectory>
    <plugins>
      <plugin>
        <groupId>org.codehaus.mojo</groupId>
        <artifactId>build-helper-maven-plugin</artifactId>
        <executions>
          <execution>
            <id>add-sources</id>
            <phase>generate-sources</phase>
            <goals>
              <goal>add-source</goal>
            </goals>
            <configuration>
              <sources>
                <source>src/main/scala-${scala.binary.version}</source>
              </sources>
            </configuration>
          </execution>
          <execution>
            <id>add-scala-test-sources</id>
            <phase>generate-test-sources</phase>
            <goals>
              <goal>add-test-source</goal>
            </goals>
            <configuration>
              <sources>
                <source>src/test/gen-java</source>
              </sources>
            </configuration>
          </execution>
        </executions>
      </plugin>
      <!-- Shade all GRPC / Guava / Protobuf dependencies of this build -->
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-shade-plugin</artifactId>
        <configuration>
          <shadedArtifactAttached>false</shadedArtifactAttached>
          <artifactSet>
            <includes>
              <include>com.google.guava:*</include>
              <include>io.grpc:*:</include>
              <include>com.google.protobuf:*</include>

              <!--
                The dependencies below are not added in SBT because SBT add them all
                as assembly build.
              -->
              <include>com.google.android:annotations</include>
              <include>com.google.api.grpc:proto-google-common-protos</include>
              <include>io.perfmark:perfmark-api</include>
              <include>org.codehaus.mojo:animal-sniffer-annotations</include>
              <include>com.google.errorprone:error_prone_annotations</include>
              <include>com.google.j2objc:j2objc-annotations</include>
              <include>org.checkerframework:checker-qual</include>
              <include>com.google.code.gson:gson</include>
              <include>org.apache.spark:spark-connect-common_${scala.binary.version}</include>
            </includes>
          </artifactSet>
          <relocations>
            <relocation>
              <pattern>com.google.common</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.guava</shadedPattern>
              <includes>
                <include>com.google.common.**</include>
              </includes>
            </relocation>
            <relocation>
              <pattern>com.google.thirdparty</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.guava</shadedPattern>
              <includes>
                <include>com.google.thirdparty.**</include>
              </includes>
            </relocation>
            <relocation>
              <pattern>com.google.protobuf</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.protobuf</shadedPattern>
              <includes>
                <include>com.google.protobuf.**</include>
              </includes>
            </relocation>
            <relocation>
              <pattern>io.grpc</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.grpc</shadedPattern>
            </relocation>

            <relocation>
              <pattern>android.annotation</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.android_annotation</shadedPattern>
            </relocation>
            <relocation>
              <pattern>io.perfmark</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.io_perfmark</shadedPattern>
            </relocation>
            <relocation>
              <pattern>org.codehaus.mojo.animal_sniffer</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.animal_sniffer</shadedPattern>
            </relocation>
            <relocation>
              <pattern>com.google.j2objc.annotations</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.j2objc_annotations</shadedPattern>
            </relocation>
            <relocation>
              <pattern>com.google.errorprone.annotations</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.errorprone_annotations</shadedPattern>
            </relocation>
            <relocation>
              <pattern>org.checkerframework</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.checkerframework</shadedPattern>
            </relocation>
            <relocation>
              <pattern>com.google.gson</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.gson</shadedPattern>
            </relocation>

            <!--
              For `com.google.api.grpc:proto-google-common-protos`, do not directly define pattern
              as `common.google`, otherwise, otherwise, the relocation result may be uncertain due
              to the change of rule order.
            -->
            <relocation>
              <pattern>com.google.api</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.google_protos.api</shadedPattern>
            </relocation>
            <relocation>
              <pattern>com.google.cloud</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.google_protos.cloud</shadedPattern>
            </relocation>
            <relocation>
              <pattern>com.google.geo</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.google_protos.geo</shadedPattern>
            </relocation>
            <relocation>
              <pattern>com.google.logging</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.google_protos.logging</shadedPattern>
            </relocation>
            <relocation>
              <pattern>com.google.longrunning</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.google_protos.longrunning</shadedPattern>
            </relocation>
            <relocation>
              <pattern>com.google.rpc</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.google_protos.rpc</shadedPattern>
            </relocation>
            <relocation>
              <pattern>com.google.type</pattern>
              <shadedPattern>${spark.shade.packageName}.connect.google_protos.type</shadedPattern>
            </relocation>
          </relocations>
          <transformers>
            <transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/>
          </transformers>
        </configuration>
      </plugin>
    </plugins>
  </build>
</project>
