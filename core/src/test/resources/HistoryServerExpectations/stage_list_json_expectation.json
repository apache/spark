[ {
  "status" : "COMPLETE",
  "stageId" : 3,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2015-02-03T16:43:07.191GMT",
  "firstTaskLaunchedTime" : "2015-02-03T16:43:07.191GMT",
  "completionTime" : "2015-02-03T16:43:07.226GMT",
  "executorDeserializeTime" : 36,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 162,
  "executorCpuTime" : 0,
  "resultSize" : 14496,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 1,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 160,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "count at <console>:17",
  "details" : "org.apache.spark.rdd.RDD.count(RDD.scala:910)\n$line19.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:17)\n$line19.$read$$iwC$$iwC$$iwC.<init>(<console>:22)\n$line19.$read$$iwC$$iwC.<init>(<console>:24)\n$line19.$read$$iwC.<init>(<console>:26)\n$line19.$read.<init>(<console>:28)\n$line19.$read$.<init>(<console>:32)\n$line19.$read$.<clinit>(<console>)\n$line19.$eval$.<init>(<console>:7)\n$line19.$eval$.<clinit>(<console>)\n$line19.$eval.$print(<console>)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)\norg.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)\norg.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)\norg.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)\norg.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)",
  "schedulingPool" : "default",
  "rddIds" : [ 6, 5 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0
  }
}, {
  "status" : "FAILED",
  "stageId" : 2,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 7,
  "numFailedTasks" : 1,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 7,
  "submissionTime" : "2015-02-03T16:43:06.296GMT",
  "firstTaskLaunchedTime" : "2015-02-03T16:43:06.296GMT",
  "completionTime" : "2015-02-03T16:43:06.347GMT",
  "failureReason" : "Job aborted due to stage failure: Task 3 in stage 2.0 failed 1 times, most recent failure: Lost task 3.0 in stage 2.0 (TID 19, localhost): java.lang.RuntimeException: got a 3, failing\n\tat $line11.$read$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:18)\n\tat $line11.$read$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(<console>:17)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n\tat org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1311)\n\tat org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:910)\n\tat org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:910)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1314)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1314)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:56)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:",
  "executorDeserializeTime" : 10,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 278,
  "executorCpuTime" : 0,
  "resultSize" : 6034,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 0,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 64,
  "shuffleFetchWaitTime" : 1,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "count at <console>:20",
  "details" : "org.apache.spark.rdd.RDD.count(RDD.scala:910)\n$line11.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:20)\n$line11.$read$$iwC$$iwC$$iwC.<init>(<console>:25)\n$line11.$read$$iwC$$iwC.<init>(<console>:27)\n$line11.$read$$iwC.<init>(<console>:29)\n$line11.$read.<init>(<console>:31)\n$line11.$read$.<init>(<console>:35)\n$line11.$read$.<clinit>(<console>)\n$line11.$eval$.<init>(<console>:7)\n$line11.$eval$.<clinit>(<console>)\n$line11.$eval.$print(<console>)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)\norg.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)\norg.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)\norg.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)\norg.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)",
  "schedulingPool" : "default",
  "rddIds" : [ 3, 2 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 1,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2015-02-03T16:43:05.829GMT",
  "firstTaskLaunchedTime" : "2015-02-03T16:43:05.829GMT",
  "completionTime" : "2015-02-03T16:43:06.286GMT",
  "executorDeserializeTime" : 13,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 3476,
  "executorCpuTime" : 0,
  "resultSize" : 15216,
  "jvmGcTime" : 152,
  "resultSerializationTime" : 9,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 28000128,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 13180,
  "shuffleWriteTime" : 692000,
  "shuffleWriteRecords" : 0,
  "name" : "map at <console>:14",
  "details" : "org.apache.spark.rdd.RDD.map(RDD.scala:271)\n$line10.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:14)\n$line10.$read$$iwC$$iwC$$iwC.<init>(<console>:19)\n$line10.$read$$iwC$$iwC.<init>(<console>:21)\n$line10.$read$$iwC.<init>(<console>:23)\n$line10.$read.<init>(<console>:25)\n$line10.$read$.<init>(<console>:29)\n$line10.$read$.<clinit>(<console>)\n$line10.$eval$.<init>(<console>:7)\n$line10.$eval$.<clinit>(<console>)\n$line10.$eval.$print(<console>)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)\norg.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)\norg.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)\norg.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)\norg.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)",
  "schedulingPool" : "default",
  "rddIds" : [ 1, 0 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0
  }
}, {
  "status" : "COMPLETE",
  "stageId" : 0,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2015-02-03T16:43:04.228GMT",
  "firstTaskLaunchedTime" : "2015-02-03T16:43:04.234GMT",
  "completionTime" : "2015-02-03T16:43:04.819GMT",
  "executorDeserializeTime" : 91,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 4338,
  "executorCpuTime" : 0,
  "resultSize" : 10144,
  "jvmGcTime" : 200,
  "resultSerializationTime" : 5,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "count at <console>:15",
  "details" : "org.apache.spark.rdd.RDD.count(RDD.scala:910)\n$line9.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:15)\n$line9.$read$$iwC$$iwC$$iwC.<init>(<console>:20)\n$line9.$read$$iwC$$iwC.<init>(<console>:22)\n$line9.$read$$iwC.<init>(<console>:24)\n$line9.$read.<init>(<console>:26)\n$line9.$read$.<init>(<console>:30)\n$line9.$read$.<clinit>(<console>)\n$line9.$eval$.<init>(<console>:7)\n$line9.$eval$.<clinit>(<console>)\n$line9.$eval.$print(<console>)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)\norg.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)\norg.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)\norg.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)\norg.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)",
  "schedulingPool" : "default",
  "rddIds" : [ 0 ],
  "accumulatorUpdates" : [ ],
  "killedTasksSummary" : { },
  "resourceProfileId" : 0,
  "peakExecutorMetrics" : {
    "JVMHeapMemory" : 0,
    "JVMOffHeapMemory" : 0,
    "OnHeapExecutionMemory" : 0,
    "OffHeapExecutionMemory" : 0,
    "OnHeapStorageMemory" : 0,
    "OffHeapStorageMemory" : 0,
    "OnHeapUnifiedMemory" : 0,
    "OffHeapUnifiedMemory" : 0,
    "DirectPoolMemory" : 0,
    "MappedPoolMemory" : 0,
    "ProcessTreeJVMVMemory" : 0,
    "ProcessTreeJVMRSSMemory" : 0,
    "ProcessTreePythonVMemory" : 0,
    "ProcessTreePythonRSSMemory" : 0,
    "ProcessTreeOtherVMemory" : 0,
    "ProcessTreeOtherRSSMemory" : 0,
    "MinorGCCount" : 0,
    "MinorGCTime" : 0,
    "MajorGCCount" : 0,
    "MajorGCTime" : 0
  }
} ]
