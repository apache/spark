{
  "AMBIGUOUS_FIELD_NAME" : {
    "message" : [ "Field name <fieldName> is ambiguous and has <n> matching fields in the struct." ],
    "sqlState" : "42000"
  },
  "ARITHMETIC_OVERFLOW" : {
    "message" : [ "<message>.<alternative> If necessary set <config> to false (except for ANSI interval type) to bypass this error.<context>" ],
    "sqlState" : "22003"
  },
  "CANNOT_CAST_DATATYPE" : {
    "message" : [ "Cannot cast <sourceType> to <targetType>." ],
    "sqlState" : "22005"
  },
  "CANNOT_CHANGE_DECIMAL_PRECISION" : {
    "message" : [ "<value> cannot be represented as Decimal(<precision>, <scale>). If necessary set <config> to false to bypass this error.<details>" ],
    "sqlState" : "22005"
  },
  "CANNOT_PARSE_DECIMAL" : {
    "message" : [ "Cannot parse decimal" ],
    "sqlState" : "42000"
  },
  "CANNOT_UP_CAST_DATATYPE" : {
    "message" : [ "Cannot up cast <value> from <sourceType> to <targetType>.\n<details>" ]
  },
  "CAST_CAUSES_OVERFLOW" : {
    "message" : [ "Casting <value> to <type> causes overflow. To return NULL instead, use 'try_cast'. If necessary set <config> to false to bypass this error." ],
    "sqlState" : "22005"
  },
  "CONCURRENT_QUERY" : {
    "message" : [ "Another instance of this query was just started by a concurrent session." ]
  },
  "DATETIME_OVERFLOW" : {
    "message" : [ "Datetime operation overflow: <operation>." ],
    "sqlState" : "22008"
  },
  "DIVIDE_BY_ZERO" : {
    "message" : [ "divide by zero. To return NULL instead, use 'try_divide'. If necessary set <config> to false (except for ANSI interval type) to bypass this error.<details>" ],
    "sqlState" : "22012"
  },
  "DUPLICATE_KEY" : {
    "message" : [ "Found duplicate keys <keyColumn>" ],
    "sqlState" : "23000"
  },
  "FAILED_EXECUTE_UDF" : {
    "message" : [ "Failed to execute user defined function (<functionName>: (<signature>) => <result>)" ]
  },
  "FAILED_RENAME_PATH" : {
    "message" : [ "Failed to rename <sourcePath> to <targetPath> as destination already exists" ],
    "sqlState" : "22023"
  },
  "FAILED_SET_ORIGINAL_PERMISSION_BACK" : {
    "message" : [ "Failed to set original permission <permission> back to the created path: <path>. Exception: <message>" ]
  },
  "FORBIDDEN_OPERATION" : {
    "message" : [ "The operation <statement> is not allowed on <objectType>: <objectName>" ]
  },
  "GRAPHITE_SINK_INVALID_PROTOCOL" : {
    "message" : [ "Invalid Graphite protocol: <protocol>" ]
  },
  "GRAPHITE_SINK_PROPERTY_MISSING" : {
    "message" : [ "Graphite sink requires '<property>' property." ]
  },
  "GROUPING_COLUMN_MISMATCH" : {
    "message" : [ "Column of grouping (<grouping>) can't be found in grouping columns <groupingColumns>" ],
    "sqlState" : "42000"
  },
  "GROUPING_ID_COLUMN_MISMATCH" : {
    "message" : [ "Columns of grouping_id (<groupingIdColumn>) does not match grouping columns (<groupByColumns>)" ],
    "sqlState" : "42000"
  },
  "GROUPING_SIZE_LIMIT_EXCEEDED" : {
    "message" : [ "Grouping sets size cannot be greater than <maxSize>" ]
  },
  "INCOMPARABLE_PIVOT_COLUMN" : {
    "message" : [ "Invalid pivot column '<columnName>'. Pivot columns must be comparable." ],
    "sqlState" : "42000"
  },
  "INCOMPATIBLE_DATASOURCE_REGISTER" : {
    "message" : [ "Detected an incompatible DataSourceRegister. Please remove the incompatible library from classpath or upgrade it. Error: <message>" ]
  },
  "INCONSISTENT_BEHAVIOR_CROSS_VERSION" : {
    "message" : [ "You may get a different result due to the upgrading to Spark >= <sparkVersion>: <details>" ]
  },
  "INDEX_OUT_OF_BOUNDS" : {
    "message" : [ "Index <indexValue> must be between 0 and the length of the ArrayData." ],
    "sqlState" : "22023"
  },
  "INTERNAL_ERROR" : {
    "message" : [ "<message>" ]
  },
  "INVALID_ARRAY_INDEX" : {
    "message" : [ "Invalid index: <indexValue>, numElements: <arraySize>. If necessary set <config> to false to bypass this error." ]
  },
  "INVALID_ARRAY_INDEX_IN_ELEMENT_AT" : {
    "message" : [ "Invalid index: <indexValue>, numElements: <arraySize>. To return NULL instead, use 'try_element_at'. If necessary set <config> to false to bypass this error." ]
  },
  "INVALID_FIELD_NAME" : {
    "message" : [ "Field name <fieldName> is invalid: <path> is not a struct." ],
    "sqlState" : "42000"
  },
  "INVALID_FRACTION_OF_SECOND" : {
    "message" : [ "The fraction of sec must be zero. Valid range is [0, 60]. If necessary set <config> to false to bypass this error. " ],
    "sqlState" : "22023"
  },
  "INVALID_JSON_SCHEMA_MAPTYPE" : {
    "message" : [ "Input schema <dataType> can only contain StringType as a key type for a MapType." ]
  },
  "INVALID_PANDAS_UDF_PLACEMENT" : {
    "message" : [ "The group aggregate pandas UDF <functionName> cannot be invoked together with as other, non-pandas aggregate functions." ]
  },
  "INVALID_PARAMETER_VALUE" : {
    "message" : [ "The value of parameter(s) '<parameter>' in <functionName> is invalid: <expected>" ],
    "sqlState" : "22023"
  },
  "INVALID_SQL_SYNTAX" : {
    "message" : [ "Invalid SQL syntax: <inputString>" ],
    "sqlState" : "42000"
  },
  "INVALID_SYNTAX_FOR_CAST" : {
    "message" : [ "Invalid input syntax for type <typeName>: <value>. To return NULL instead, use 'try_cast'. If necessary set <config> to false to bypass this error.<details>" ],
    "sqlState" : "42000"
  },
  "MAP_KEY_DOES_NOT_EXIST" : {
    "message" : [ "Key <keyValue> does not exist. To return NULL instead, use 'try_element_at'. If necessary set <config> to false to bypass this error.<details>" ]
  },
  "MISSING_COLUMN" : {
    "message" : [ "Column '<columnName>' does not exist. Did you mean one of the following? [<proposal>]" ],
    "sqlState" : "42000"
  },
  "MISSING_STATIC_PARTITION_COLUMN" : {
    "message" : [ "Unknown static partition column: <columnName>" ],
    "sqlState" : "42000"
  },
  "MULTI_UDF_INTERFACE_ERROR" : {
    "message" : [ "Not allowed to implement multiple UDF interfaces, UDF class <class>" ]
  },
  "NON_LITERAL_PIVOT_VALUES" : {
    "message" : [ "Literal expressions required for pivot values, found '<expression>'" ],
    "sqlState" : "42000"
  },
  "NON_PARTITION_COLUMN" : {
    "message" : [ "PARTITION clause cannot contain a non-partition column name: <columnName>" ],
    "sqlState" : "42000"
  },
  "NO_HANDLER_FOR_UDAF" : {
    "message" : [ "No handler for UDAF '<functionName>'. Use sparkSession.udf.register(...) instead." ]
  },
  "NO_UDF_INTERFACE_ERROR" : {
    "message" : [ "UDF class <class> doesn't implement any UDF interface" ]
  },
  "PARSE_CHAR_MISSING_LENGTH" : {
    "message" : [ "DataType <type> requires a length parameter, for example <type>(10). Please specify the length." ],
    "sqlState" : "42000"
  },
  "PARSE_EMPTY_STATEMENT" : {
    "message" : [ "Syntax error, unexpected empty statement" ],
    "sqlState" : "42000"
  },
  "PARSE_SYNTAX_ERROR" : {
    "message" : [ "Syntax error at or near <error><hint>" ],
    "sqlState" : "42000"
  },
  "PIVOT_VALUE_DATA_TYPE_MISMATCH" : {
    "message" : [ "Invalid pivot value '<value>': value data type <valueType> does not match pivot column data type <pivotType>" ],
    "sqlState" : "42000"
  },
  "RENAME_SRC_PATH_NOT_FOUND" : {
    "message" : [ "Failed to rename as <sourcePath> was not found" ],
    "sqlState" : "22023"
  },
  "SECOND_FUNCTION_ARGUMENT_NOT_INTEGER" : {
    "message" : [ "The second argument of '<functionName>' function needs to be an integer." ],
    "sqlState" : "22023"
  },
  "UNABLE_TO_ACQUIRE_MEMORY" : {
    "message" : [ "Unable to acquire <requestedBytes> bytes of memory, got <receivedBytes>" ]
  },
  "UNRECOGNIZED_SQL_TYPE" : {
    "message" : [ "Unrecognized SQL type <typeName>" ],
    "sqlState" : "42000"
  },
  "UNSUPPORTED_DATATYPE" : {
    "message" : [ "Unsupported data type <typeName>" ],
    "sqlState" : "0A000"
  },
  "UNSUPPORTED_FEATURE" : {
    "message" : [ "The feature is not supported: " ],
    "subClass" : {
      "AES_MODE" : {
        "message" : [ "AES-<mode> with the padding <padding> by the <functionName> function." ]
      },
      "DISTRIBUTE_BY" : {
        "message" : [ "DISTRIBUTE BY clause." ]
      },
      "INSERT_PARTITION_SPEC_IF_NOT_EXISTS" : {
        "message" : [ "INSERT INTO <tableName> IF NOT EXISTS in the PARTITION spec." ]
      },
      "JDBC_TRANSACTION" : {
        "message" : [ "The target JDBC server does not support transactions and can only support ALTER TABLE with a single action." ]
      },
      "LATERAL_JOIN_OF_TYPE" : {
        "message" : [ "<joinType> JOIN with LATERAL correlation." ]
      },
      "LATERAL_JOIN_USING" : {
        "message" : [ "JOIN USING with LATERAL correlation." ]
      },
      "LATERAL_NATURAL_JOIN" : {
        "message" : [ "NATURAL join with LATERAL correlation." ]
      },
      "LITERAL_TYPE" : {
        "message" : [ "Literal for '<value>' of <type>." ]
      },
      "NATURAL_CROSS_JOIN" : {
        "message" : [ "NATURAL CROSS JOIN." ]
      },
      "ORC_TYPE_CAST" : {
        "message" : [ "Unable to convert <orcType> of Orc to data type <toType>." ]
      },
      "PANDAS_UDAF_IN_PIVOT" : {
        "message" : [ "Pandas user defined aggregate function in the PIVOT clause." ]
      },
      "PIVOT_AFTER_GROUP_BY" : {
        "message" : [ "PIVOT clause following a GROUP BY clause." ]
      },
      "PIVOT_TYPE" : {
        "message" : [ "Pivoting by the value '<value>' of the column data type <type>." ]
      },
      "PYTHON_UDF_IN_ON_CLAUSE" : {
        "message" : [ "Python UDF in the ON clause of a <joinType> JOIN." ]
      },
      "REPEATED_PIVOT" : {
        "message" : [ "Repeated PIVOT operation." ]
      },
      "TOO_MANY_TYPE_ARGUMENTS_FOR_UDF_CLASS" : {
        "message" : [ "UDF class with <n> type arguments." ]
      },
      "TRANSFORM_DISTINCT_ALL" : {
        "message" : [ "TRANSFORM with the DISTINCT/ALL clause." ]
      },
      "TRANSFORM_NON_HIVE" : {
        "message" : [ "TRANSFORM with SERDE is only supported in hive mode." ]
      }
    },
    "sqlState" : "0A000"
  },
  "UNSUPPORTED_GROUPING_EXPRESSION" : {
    "message" : [ "grouping()/grouping_id() can only be used with GroupingSets/Cube/Rollup" ]
  },
  "UNTYPED_SCALA_UDF" : {
    "message" : [ "You're using untyped Scala UDF, which does not have the input type information. Spark may blindly pass null to the Scala closure with primitive-type argument, and the closure will see the default value of the Java type for the null argument, e.g. `udf((x: Int) => x, IntegerType)`, the result is 0 for null input. To get rid of this error, you could:\n1. use typed Scala UDF APIs(without return type parameter), e.g. `udf((x: Int) => x)`\n2. use Java UDF APIs, e.g. `udf(new UDF1[String, Integer] { override def call(s: String): Integer = s.length() }, IntegerType)`, if input types are all non primitive\n3. set \"spark.sql.legacy.allowUntypedScalaUDF\" to true and use this API with caution" ]
  },
  "WRITING_JOB_ABORTED" : {
    "message" : [ "Writing job aborted" ],
    "sqlState" : "40000"
  }
}
