{
  "AMBIGUOUS_FIELD_NAME" : {
    "message" : [ "Field name <fieldName> is ambiguous and has <n> matching fields in the struct." ],
    "sqlState" : "42000"
  },
  "ARITHMETIC_OVERFLOW" : {
    "message" : [ "<message>.<alternative> If necessary set <config> to \"false\" (except for ANSI interval type) to bypass this error." ],
    "sqlState" : "22003"
  },
  "CANNOT_CAST_DATATYPE" : {
    "message" : [ "Cannot cast <sourceType> to <targetType>." ],
    "sqlState" : "22005"
  },
  "CANNOT_CHANGE_DECIMAL_PRECISION" : {
    "message" : [ "<value> cannot be represented as Decimal(<precision>, <scale>). If necessary set <config> to \"false\" to bypass this error." ],
    "sqlState" : "22005"
  },
  "CANNOT_PARSE_DECIMAL" : {
    "message" : [ "Cannot parse decimal" ],
    "sqlState" : "42000"
  },
  "CANNOT_UP_CAST_DATATYPE" : {
    "message" : [ "Cannot up cast <value> from <sourceType> to <targetType>.\n<details>" ]
  },
  "CANNOT_USE_MIXTURE" : {
    "message" : [ "Cannot use a mixture of aggregate function and group aggregate pandas UDF" ]
  },
  "CAST_INVALID_INPUT" : {
    "message" : [ "The value <value> of the type <sourceType> cannot be cast to <targetType> because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. If necessary set <config> to \"false\" to bypass this error." ],
    "sqlState" : "42000"
  },
  "CAST_OVERFLOW" : {
    "message" : [ "The value <value> of the type <sourceType> cannot be cast to <targetType> due to an overflow. Use `try_cast` to tolerate overflow and return NULL instead. If necessary set <config> to \"false\" to bypass this error." ],
    "sqlState" : "22005"
  },
  "CAST_OVERFLOW_IN_TABLE_INSERT" : {
    "message" : [ "Fail to insert a value of <sourceType> type into the <targetType> type column <columnName> due to an overflow. Use `try_cast` on the input value to tolerate overflow and return NULL instead." ],
    "sqlState" : "22005"
  },
  "CONCURRENT_QUERY" : {
    "message" : [ "Another instance of this query was just started by a concurrent session." ]
  },
  "DATETIME_OVERFLOW" : {
    "message" : [ "Datetime operation overflow: <operation>." ],
    "sqlState" : "22008"
  },
  "DIVIDE_BY_ZERO" : {
    "message" : [ "Division by zero. Use `try_divide` to tolerate divisor being 0 and return NULL instead. If necessary set <config> to \"false\" (except for ANSI interval type) to bypass this error." ],
    "sqlState" : "22012"
  },
  "DUPLICATE_KEY" : {
    "message" : [ "Found duplicate keys <keyColumn>" ],
    "sqlState" : "23000"
  },
  "FAILED_EXECUTE_UDF" : {
    "message" : [ "Failed to execute user defined function (<functionName>: (<signature>) => <result>)" ]
  },
  "FAILED_RENAME_PATH" : {
    "message" : [ "Failed to rename <sourcePath> to <targetPath> as destination already exists" ],
    "sqlState" : "22023"
  },
  "GRAPHITE_SINK_INVALID_PROTOCOL" : {
    "message" : [ "Invalid Graphite protocol: <protocol>" ]
  },
  "GRAPHITE_SINK_PROPERTY_MISSING" : {
    "message" : [ "Graphite sink requires '<property>' property." ]
  },
  "GROUPING_COLUMN_MISMATCH" : {
    "message" : [ "Column of grouping (<grouping>) can't be found in grouping columns <groupingColumns>" ],
    "sqlState" : "42000"
  },
  "GROUPING_ID_COLUMN_MISMATCH" : {
    "message" : [ "Columns of grouping_id (<groupingIdColumn>) does not match grouping columns (<groupByColumns>)" ],
    "sqlState" : "42000"
  },
  "GROUPING_SIZE_LIMIT_EXCEEDED" : {
    "message" : [ "Grouping sets size cannot be greater than <maxSize>" ]
  },
  "INCOMPARABLE_PIVOT_COLUMN" : {
    "message" : [ "Invalid pivot column <columnName>. Pivot columns must be comparable." ],
    "sqlState" : "42000"
  },
  "INCOMPATIBLE_DATASOURCE_REGISTER" : {
    "message" : [ "Detected an incompatible DataSourceRegister. Please remove the incompatible library from classpath or upgrade it. Error: <message>" ]
  },
  "INCONSISTENT_BEHAVIOR_CROSS_VERSION" : {
    "message" : [ "You may get a different result due to the upgrading to Spark >= <sparkVersion>: <details>" ]
  },
  "INDEX_OUT_OF_BOUNDS" : {
    "message" : [ "Index <indexValue> must be between 0 and the length of the ArrayData." ],
    "sqlState" : "22023"
  },
  "INTERNAL_ERROR" : {
    "message" : [ "<message>" ]
  },
  "INVALID_ARRAY_INDEX" : {
    "message" : [ "The index <indexValue> is out of bounds. The array has <arraySize> elements. If necessary set <config> to \"false\" to bypass this error." ]
  },
  "INVALID_ARRAY_INDEX_IN_ELEMENT_AT" : {
    "message" : [ "The index <indexValue> is out of bounds. The array has <arraySize> elements. Use `try_element_at` to tolerate accessing element at invalid index and return NULL instead. If necessary set <config> to \"false\" to bypass this error." ]
  },
  "INVALID_BUCKET_FILE" : {
    "message" : [ "Invalid bucket file: <path>" ]
  },
  "INVALID_FIELD_NAME" : {
    "message" : [ "Field name <fieldName> is invalid: <path> is not a struct." ],
    "sqlState" : "42000"
  },
  "INVALID_FRACTION_OF_SECOND" : {
    "message" : [ "The fraction of sec must be zero. Valid range is [0, 60]. If necessary set <config> to \"false\" to bypass this error. " ],
    "sqlState" : "22023"
  },
  "INVALID_JSON_SCHEMA_MAP_TYPE" : {
    "message" : [ "Input schema <jsonSchema> can only contain STRING as a key type for a MAP." ]
  },
  "INVALID_PARAMETER_VALUE" : {
    "message" : [ "The value of parameter(s) '<parameter>' in <functionName> is invalid: <expected>" ],
    "sqlState" : "22023"
  },
  "INVALID_PROPERTY_KEY" : {
    "message" : [ "<key> is an invalid property key, please use quotes, e.g. SET <key>=<value>" ]
  },
  "INVALID_PROPERTY_VALUE" : {
    "message" : [ "<value> is an invalid property value, please use quotes, e.g. SET <key>=<value>" ]
  },
  "INVALID_SQL_SYNTAX" : {
    "message" : [ "Invalid SQL syntax: <inputString>" ],
    "sqlState" : "42000"
  },
  "MAP_KEY_DOES_NOT_EXIST" : {
    "message" : [ "Key <keyValue> does not exist. Use `try_element_at` to tolerate non-existent key and return NULL instead. If necessary set <config> to \"false\" to bypass this error." ]
  },
  "MISSING_COLUMN" : {
    "message" : [ "Column '<columnName>' does not exist. Did you mean one of the following? [<proposal>]" ],
    "sqlState" : "42000"
  },
  "MISSING_STATIC_PARTITION_COLUMN" : {
    "message" : [ "Unknown static partition column: <columnName>" ],
    "sqlState" : "42000"
  },
  "NON_LITERAL_PIVOT_VALUES" : {
    "message" : [ "Literal expressions required for pivot values, found <expression>." ],
    "sqlState" : "42000"
  },
  "NON_PARTITION_COLUMN" : {
    "message" : [ "PARTITION clause cannot contain the non-partition column: <columnName>." ],
    "sqlState" : "42000"
  },
  "NULL_COMPARISON_RESULT" : {
    "message" : [ "The comparison result is null. If you want to handle null as 0 (equal), you can set \"spark.sql.legacy.allowNullComparisonResultInArraySort\" to \"true\"." ]
  },
  "PARSE_CHAR_MISSING_LENGTH" : {
    "message" : [ "DataType <type> requires a length parameter, for example <type>(10). Please specify the length." ],
    "sqlState" : "42000"
  },
  "PARSE_EMPTY_STATEMENT" : {
    "message" : [ "Syntax error, unexpected empty statement" ],
    "sqlState" : "42000"
  },
  "PARSE_SYNTAX_ERROR" : {
    "message" : [ "Syntax error at or near <error><hint>" ],
    "sqlState" : "42000"
  },
  "PIVOT_VALUE_DATA_TYPE_MISMATCH" : {
    "message" : [ "Invalid pivot value '<value>': value data type <valueType> does not match pivot column data type <pivotType>" ],
    "sqlState" : "42000"
  },
  "RENAME_SRC_PATH_NOT_FOUND" : {
    "message" : [ "Failed to rename as <sourcePath> was not found" ],
    "sqlState" : "22023"
  },
  "RESET_PERMISSION_TO_ORIGINAL" : {
    "message" : [ "Failed to set original permission <permission> back to the created path: <path>. Exception: <message>" ]
  },
  "SECOND_FUNCTION_ARGUMENT_NOT_INTEGER" : {
    "message" : [ "The second argument of '<functionName>' function needs to be an integer." ],
    "sqlState" : "22023"
  },
  "UNABLE_TO_ACQUIRE_MEMORY" : {
    "message" : [ "Unable to acquire <requestedBytes> bytes of memory, got <receivedBytes>" ]
  },
  "UNRECOGNIZED_SQL_TYPE" : {
    "message" : [ "Unrecognized SQL type <typeName>" ],
    "sqlState" : "42000"
  },
  "UNSUPPORTED_DATATYPE" : {
    "message" : [ "Unsupported data type <typeName>" ],
    "sqlState" : "0A000"
  },
  "UNSUPPORTED_DESERIALIZER" : {
    "message" : [ "The deserializer is not supported: " ],
    "subClass" : {
      "DATA_TYPE_MISMATCH" : {
        "message" : [ "need a(n) <desiredType> field but got <dataType>." ]
      },
      "FIELD_NUMBER_MISMATCH" : {
        "message" : [ "try to map <schema> to Tuple<ordinal>, but failed as the number of fields does not line up." ]
      }
    }
  },
  "UNSUPPORTED_FEATURE" : {
    "message" : [ "The feature is not supported: <feature>" ],
    "sqlState" : "0A000"
  },
  "UNSUPPORTED_GENERATOR" : {
    "message" : [ "The generator is not supported: " ],
    "subClass" : {
      "MULTI_GENERATOR" : {
        "message" : [ "only one generator allowed per <clause> clause but found <num>: <generators>" ]
      },
      "NESTED_IN_EXPRESSIONS" : {
        "message" : [ "nested in expressions <expression>" ]
      },
      "NOT_GENERATOR" : {
        "message" : [ "<functionName> is expected to be a generator. However, its class is <classCanonicalName>, which is not a generator." ]
      },
      "OUTSIDE_SELECT" : {
        "message" : [ "outside the SELECT clause, found: <plan>" ]
      }
    }
  },
  "UNSUPPORTED_GROUPING_EXPRESSION" : {
    "message" : [ "grouping()/grouping_id() can only be used with GroupingSets/Cube/Rollup" ]
  },
  "UNSUPPORTED_OPERATION" : {
    "message" : [ "The operation is not supported: <operation>" ]
  },
  "UNSUPPORTED_SAVE_MODE" : {
    "message" : [ "The save mode <saveMode> is not supported for: " ],
    "subClass" : {
      "EXISTENT_PATH" : {
        "message" : [ "an existent path." ]
      },
      "NON_EXISTENT_PATH" : {
        "message" : [ "a non-existent path." ]
      }
    }
  },
  "WRITING_JOB_ABORTED" : {
    "message" : [ "Writing job aborted" ],
    "sqlState" : "40000"
  }
}
