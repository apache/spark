% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/RDD.R
\docType{methods}
\name{collect,DataFrame-method}
\alias{collect}
\alias{collect,DataFrame-method}
\alias{collect,RDD-method}
\alias{collectAsMap}
\alias{collectAsMap,RDD-method}
\alias{collectPartition}
\alias{collectPartition,RDD,integer-method}
\alias{collectPartition,integer,RDD-method}
\title{Collect elements of a DataFrame}
\usage{
\S4method{collect}{DataFrame}(rdd)

collect(rdd, ...)

\S4method{collect}{RDD}(rdd, flatten = TRUE)

collectPartition(rdd, partitionId)

\S4method{collectPartition}{RDD,integer}(rdd, partitionId)

collectAsMap(rdd)

\S4method{collectAsMap}{RDD}(rdd)
}
\arguments{
\item{rdd}{The RDD to collect}

\item{...}{Other optional arguments to collect}

\item{flatten}{FALSE if the list should not flattened}

\item{partitionId}{the partition to collect (starts from 0)}

\item{df}{A SparkSQL DataFrame}
}
\value{
a list containing elements in the RDD
}
\description{
Returns a list of Row objects from a DataFrame

\code{collect} returns a list that contains all of the elements in this RDD.

\code{collectPartition} returns a list that contains all of the elements
in the specified partition of the RDD.

\code{collectAsMap} returns a named list as a map that contains all of the elements
in a key-value pair RDD.
}
\examples{
\dontrun{
sc <- sparkR.init()
rdd <- parallelize(sc, 1:10, 2L)
collect(rdd) # list from 1 to 10
collectPartition(rdd, 0L) # list from 1 to 5
}
\dontrun{
sc <- sparkR.init()
rdd <- parallelize(sc, list(list(1, 2), list(3, 4)), 2L)
collectAsMap(rdd) # list(`1` = 2, `3` = 4)
}
}

