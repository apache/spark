<?xml version="1.0" encoding="UTF-8"?>
<!--
  ~ Licensed to the Apache Software Foundation (ASF) under one or more
  ~ contributor license agreements.  See the NOTICE file distributed with
  ~ this work for additional information regarding copyright ownership.
  ~ The ASF licenses this file to You under the Apache License, Version 2.0
  ~ (the "License"); you may not use this file except in compliance with
  ~ the License.  You may obtain a copy of the License at
  ~
  ~    http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an "AS IS" BASIS,
  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~ See the License for the specific language governing permissions and
  ~ limitations under the License.
  -->
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <parent>
    <groupId>org.apache.spark</groupId>
    <artifactId>spark-parent_2.11</artifactId>
    <version>2.1.0-SNAPSHOT</version>
    <relativePath>../pom.xml</relativePath>
  </parent>

  <artifactId>spark-cloud_2.11</artifactId>
  <packaging>jar</packaging>
  <name>Spark Project Cloud Integration</name>
  <description>
    Contains support for cloud infrastructures, specifically the Hadoop JARs and
    transitive dependencies needed to interact with the infrastructures.

    Any project which explicitly depends upon the spark-cloud artifact will get the dependencies;
    the exact versions of which will depend upon the hadoop version Spark was compiled against.

    Hadoop 2.7:
      hadoop-aws
      aws-java-sdk-s3
      hadoop-azure
      azure-storage
      hadoop-openstack

    WARNING: the signatures of methods in aws-java-sdk/aws-java-sdk-s3 can change between versions:
    use the same version against which Hadoop was compiled.

  </description>
  <properties>
    <sbt.project.name>cloud</sbt.project.name>
  </properties>

  <dependencies>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
    </dependency>

    <!--Used for test classes -->
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_${scala.binary.version}</artifactId>
      <version>${project.version}</version>
      <type>test-jar</type>
      <scope>test</scope>
    </dependency>


    <!-- Jets3t is needed for s3n and s3 classic to work-->
    <dependency>
      <groupId>net.java.dev.jets3t</groupId>
      <artifactId>jets3t</artifactId>
    </dependency>

    <!-- Explicit listing of transitive deps that are shaded. Otherwise, odd compiler crashes. -->
    <dependency>
      <groupId>com.google.guava</groupId>
      <artifactId>guava</artifactId>
    </dependency>
    <!-- End of shaded deps. -->
  </dependencies>

  <build>
    <outputDirectory>target/scala-${scala.binary.version}/classes</outputDirectory>
    <testOutputDirectory>target/scala-${scala.binary.version}/test-classes</testOutputDirectory>
  </build>

  <profiles>

    <!--
      This profile is enabled automatically by the sbt build. It changes the scope for the guava
      dependency, since we don't shade it in the artifacts generated by the sbt build.
    -->
    <profile>
      <id>sbt</id>
      <dependencies>
        <dependency>
          <groupId>com.google.guava</groupId>
          <artifactId>guava</artifactId>
          <scope>compile</scope>
        </dependency>
      </dependencies>
    </profile>

    <profile>
      <id>hadoop-2.7</id>
        <dependencies>
          <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-aws</artifactId>
            <scope>${hadoop.deps.scope}</scope>
          </dependency>
          <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-azure</artifactId>
            <scope>${hadoop.deps.scope}</scope>
          </dependency>
          <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-openstack</artifactId>
            <scope>${hadoop.deps.scope}</scope>
          </dependency>
          <!-- explicitly declare the jackson artifacts desired -->
          <dependency>
            <groupId>com.fasterxml.jackson.core</groupId>
            <artifactId>jackson-databind</artifactId>
            <scope>${hadoop.deps.scope}</scope>
          </dependency>
          <dependency>
            <groupId>com.fasterxml.jackson.core</groupId>
            <artifactId>jackson-annotations</artifactId>
            <scope>${hadoop.deps.scope}</scope>
          </dependency>
          <!-- When Hadoop switches to AWS SDK 10.77+ this JAR
           will need be referenced in in sync with Spark's Jackson 2 version. -->
          <!--
          <dependency>
            <groupId>com.fasterxml.jackson.dataformat</groupId>
            <artifactId>jackson-dataformat-cbor</artifactId>
            <scope>${hadoop.deps.scope}</scope>
          </dependency>
          -->
          <!--Explicit declaration to force in Spark version into transitive dependencies -->
          <dependency>
            <groupId>org.apache.httpcomponents</groupId>
            <artifactId>httpclient</artifactId>
          </dependency>
          <!--Explicit declaration to force in Spark version into transitive dependencies -->
          <dependency>
            <groupId>org.apache.httpcomponents</groupId>
            <artifactId>httpcore</artifactId>
          </dependency>
        </dependencies>
    </profile>

  </profiles>

</project>
