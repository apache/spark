#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
from google.protobuf.any_pb2 import (
    Any as google___protobuf___any_pb2___Any,
)

from google.protobuf.descriptor import (
    Descriptor as google___protobuf___descriptor___Descriptor,
    EnumDescriptor as google___protobuf___descriptor___EnumDescriptor,
    FileDescriptor as google___protobuf___descriptor___FileDescriptor,
)

from google.protobuf.internal.containers import (
    MessageMap as google___protobuf___internal___containers___MessageMap,
    RepeatedCompositeFieldContainer as google___protobuf___internal___containers___RepeatedCompositeFieldContainer,
    RepeatedScalarFieldContainer as google___protobuf___internal___containers___RepeatedScalarFieldContainer,
    ScalarMap as google___protobuf___internal___containers___ScalarMap,
)

from google.protobuf.internal.enum_type_wrapper import (
    _EnumTypeWrapper as google___protobuf___internal___enum_type_wrapper____EnumTypeWrapper,
)

from google.protobuf.message import (
    Message as google___protobuf___message___Message,
)

from pyspark.sql.connect.proto.catalog_pb2 import (
    Catalog as spark___connect___catalog_pb2___Catalog,
)

from pyspark.sql.connect.proto.expressions_pb2 import (
    CommonInlineUserDefinedFunction as spark___connect___expressions_pb2___CommonInlineUserDefinedFunction,
    Expression as spark___connect___expressions_pb2___Expression,
)

from pyspark.sql.connect.proto.types_pb2 import (
    DataType as spark___connect___types_pb2___DataType,
)

from typing import (
    Iterable as typing___Iterable,
    Mapping as typing___Mapping,
    NewType as typing___NewType,
    Optional as typing___Optional,
    Text as typing___Text,
    cast as typing___cast,
    overload as typing___overload,
)

from typing_extensions import (
    Literal as typing_extensions___Literal,
)

builtin___bool = bool
builtin___bytes = bytes
builtin___float = float
builtin___int = int

DESCRIPTOR: google___protobuf___descriptor___FileDescriptor = ...

class Relation(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

    @property
    def common(self) -> type___RelationCommon: ...
    @property
    def read(self) -> type___Read: ...
    @property
    def project(self) -> type___Project: ...
    @property
    def filter(self) -> type___Filter: ...
    @property
    def join(self) -> type___Join: ...
    @property
    def set_op(self) -> type___SetOperation: ...
    @property
    def sort(self) -> type___Sort: ...
    @property
    def limit(self) -> type___Limit: ...
    @property
    def aggregate(self) -> type___Aggregate: ...
    @property
    def sql(self) -> type___SQL: ...
    @property
    def local_relation(self) -> type___LocalRelation: ...
    @property
    def sample(self) -> type___Sample: ...
    @property
    def offset(self) -> type___Offset: ...
    @property
    def deduplicate(self) -> type___Deduplicate: ...
    @property
    def range(self) -> type___Range: ...
    @property
    def subquery_alias(self) -> type___SubqueryAlias: ...
    @property
    def repartition(self) -> type___Repartition: ...
    @property
    def to_df(self) -> type___ToDF: ...
    @property
    def with_columns_renamed(self) -> type___WithColumnsRenamed: ...
    @property
    def show_string(self) -> type___ShowString: ...
    @property
    def drop(self) -> type___Drop: ...
    @property
    def tail(self) -> type___Tail: ...
    @property
    def with_columns(self) -> type___WithColumns: ...
    @property
    def hint(self) -> type___Hint: ...
    @property
    def unpivot(self) -> type___Unpivot: ...
    @property
    def to_schema(self) -> type___ToSchema: ...
    @property
    def repartition_by_expression(self) -> type___RepartitionByExpression: ...
    @property
    def map_partitions(self) -> type___MapPartitions: ...
    @property
    def collect_metrics(self) -> type___CollectMetrics: ...
    @property
    def parse(self) -> type___Parse: ...
    @property
    def group_map(self) -> type___GroupMap: ...
    @property
    def co_group_map(self) -> type___CoGroupMap: ...
    @property
    def with_watermark(self) -> type___WithWatermark: ...
    @property
    def apply_in_pandas_with_state(self) -> type___ApplyInPandasWithState: ...
    @property
    def html_string(self) -> type___HtmlString: ...
    @property
    def cached_local_relation(self) -> type___CachedLocalRelation: ...
    @property
    def fill_na(self) -> type___NAFill: ...
    @property
    def drop_na(self) -> type___NADrop: ...
    @property
    def replace(self) -> type___NAReplace: ...
    @property
    def summary(self) -> type___StatSummary: ...
    @property
    def crosstab(self) -> type___StatCrosstab: ...
    @property
    def describe(self) -> type___StatDescribe: ...
    @property
    def cov(self) -> type___StatCov: ...
    @property
    def corr(self) -> type___StatCorr: ...
    @property
    def approx_quantile(self) -> type___StatApproxQuantile: ...
    @property
    def freq_items(self) -> type___StatFreqItems: ...
    @property
    def sample_by(self) -> type___StatSampleBy: ...
    @property
    def catalog(self) -> spark___connect___catalog_pb2___Catalog: ...
    @property
    def extension(self) -> google___protobuf___any_pb2___Any: ...
    @property
    def unknown(self) -> type___Unknown: ...
    def __init__(
        self,
        *,
        common: typing___Optional[type___RelationCommon] = None,
        read: typing___Optional[type___Read] = None,
        project: typing___Optional[type___Project] = None,
        filter: typing___Optional[type___Filter] = None,
        join: typing___Optional[type___Join] = None,
        set_op: typing___Optional[type___SetOperation] = None,
        sort: typing___Optional[type___Sort] = None,
        limit: typing___Optional[type___Limit] = None,
        aggregate: typing___Optional[type___Aggregate] = None,
        sql: typing___Optional[type___SQL] = None,
        local_relation: typing___Optional[type___LocalRelation] = None,
        sample: typing___Optional[type___Sample] = None,
        offset: typing___Optional[type___Offset] = None,
        deduplicate: typing___Optional[type___Deduplicate] = None,
        range: typing___Optional[type___Range] = None,
        subquery_alias: typing___Optional[type___SubqueryAlias] = None,
        repartition: typing___Optional[type___Repartition] = None,
        to_df: typing___Optional[type___ToDF] = None,
        with_columns_renamed: typing___Optional[type___WithColumnsRenamed] = None,
        show_string: typing___Optional[type___ShowString] = None,
        drop: typing___Optional[type___Drop] = None,
        tail: typing___Optional[type___Tail] = None,
        with_columns: typing___Optional[type___WithColumns] = None,
        hint: typing___Optional[type___Hint] = None,
        unpivot: typing___Optional[type___Unpivot] = None,
        to_schema: typing___Optional[type___ToSchema] = None,
        repartition_by_expression: typing___Optional[type___RepartitionByExpression] = None,
        map_partitions: typing___Optional[type___MapPartitions] = None,
        collect_metrics: typing___Optional[type___CollectMetrics] = None,
        parse: typing___Optional[type___Parse] = None,
        group_map: typing___Optional[type___GroupMap] = None,
        co_group_map: typing___Optional[type___CoGroupMap] = None,
        with_watermark: typing___Optional[type___WithWatermark] = None,
        apply_in_pandas_with_state: typing___Optional[type___ApplyInPandasWithState] = None,
        html_string: typing___Optional[type___HtmlString] = None,
        cached_local_relation: typing___Optional[type___CachedLocalRelation] = None,
        fill_na: typing___Optional[type___NAFill] = None,
        drop_na: typing___Optional[type___NADrop] = None,
        replace: typing___Optional[type___NAReplace] = None,
        summary: typing___Optional[type___StatSummary] = None,
        crosstab: typing___Optional[type___StatCrosstab] = None,
        describe: typing___Optional[type___StatDescribe] = None,
        cov: typing___Optional[type___StatCov] = None,
        corr: typing___Optional[type___StatCorr] = None,
        approx_quantile: typing___Optional[type___StatApproxQuantile] = None,
        freq_items: typing___Optional[type___StatFreqItems] = None,
        sample_by: typing___Optional[type___StatSampleBy] = None,
        catalog: typing___Optional[spark___connect___catalog_pb2___Catalog] = None,
        extension: typing___Optional[google___protobuf___any_pb2___Any] = None,
        unknown: typing___Optional[type___Unknown] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "aggregate",
            b"aggregate",
            "apply_in_pandas_with_state",
            b"apply_in_pandas_with_state",
            "approx_quantile",
            b"approx_quantile",
            "cached_local_relation",
            b"cached_local_relation",
            "catalog",
            b"catalog",
            "co_group_map",
            b"co_group_map",
            "collect_metrics",
            b"collect_metrics",
            "common",
            b"common",
            "corr",
            b"corr",
            "cov",
            b"cov",
            "crosstab",
            b"crosstab",
            "deduplicate",
            b"deduplicate",
            "describe",
            b"describe",
            "drop",
            b"drop",
            "drop_na",
            b"drop_na",
            "extension",
            b"extension",
            "fill_na",
            b"fill_na",
            "filter",
            b"filter",
            "freq_items",
            b"freq_items",
            "group_map",
            b"group_map",
            "hint",
            b"hint",
            "html_string",
            b"html_string",
            "join",
            b"join",
            "limit",
            b"limit",
            "local_relation",
            b"local_relation",
            "map_partitions",
            b"map_partitions",
            "offset",
            b"offset",
            "parse",
            b"parse",
            "project",
            b"project",
            "range",
            b"range",
            "read",
            b"read",
            "rel_type",
            b"rel_type",
            "repartition",
            b"repartition",
            "repartition_by_expression",
            b"repartition_by_expression",
            "replace",
            b"replace",
            "sample",
            b"sample",
            "sample_by",
            b"sample_by",
            "set_op",
            b"set_op",
            "show_string",
            b"show_string",
            "sort",
            b"sort",
            "sql",
            b"sql",
            "subquery_alias",
            b"subquery_alias",
            "summary",
            b"summary",
            "tail",
            b"tail",
            "to_df",
            b"to_df",
            "to_schema",
            b"to_schema",
            "unknown",
            b"unknown",
            "unpivot",
            b"unpivot",
            "with_columns",
            b"with_columns",
            "with_columns_renamed",
            b"with_columns_renamed",
            "with_watermark",
            b"with_watermark",
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "aggregate",
            b"aggregate",
            "apply_in_pandas_with_state",
            b"apply_in_pandas_with_state",
            "approx_quantile",
            b"approx_quantile",
            "cached_local_relation",
            b"cached_local_relation",
            "catalog",
            b"catalog",
            "co_group_map",
            b"co_group_map",
            "collect_metrics",
            b"collect_metrics",
            "common",
            b"common",
            "corr",
            b"corr",
            "cov",
            b"cov",
            "crosstab",
            b"crosstab",
            "deduplicate",
            b"deduplicate",
            "describe",
            b"describe",
            "drop",
            b"drop",
            "drop_na",
            b"drop_na",
            "extension",
            b"extension",
            "fill_na",
            b"fill_na",
            "filter",
            b"filter",
            "freq_items",
            b"freq_items",
            "group_map",
            b"group_map",
            "hint",
            b"hint",
            "html_string",
            b"html_string",
            "join",
            b"join",
            "limit",
            b"limit",
            "local_relation",
            b"local_relation",
            "map_partitions",
            b"map_partitions",
            "offset",
            b"offset",
            "parse",
            b"parse",
            "project",
            b"project",
            "range",
            b"range",
            "read",
            b"read",
            "rel_type",
            b"rel_type",
            "repartition",
            b"repartition",
            "repartition_by_expression",
            b"repartition_by_expression",
            "replace",
            b"replace",
            "sample",
            b"sample",
            "sample_by",
            b"sample_by",
            "set_op",
            b"set_op",
            "show_string",
            b"show_string",
            "sort",
            b"sort",
            "sql",
            b"sql",
            "subquery_alias",
            b"subquery_alias",
            "summary",
            b"summary",
            "tail",
            b"tail",
            "to_df",
            b"to_df",
            "to_schema",
            b"to_schema",
            "unknown",
            b"unknown",
            "unpivot",
            b"unpivot",
            "with_columns",
            b"with_columns",
            "with_columns_renamed",
            b"with_columns_renamed",
            "with_watermark",
            b"with_watermark",
        ],
    ) -> None: ...
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["rel_type", b"rel_type"]
    ) -> typing_extensions___Literal[
        "read",
        "project",
        "filter",
        "join",
        "set_op",
        "sort",
        "limit",
        "aggregate",
        "sql",
        "local_relation",
        "sample",
        "offset",
        "deduplicate",
        "range",
        "subquery_alias",
        "repartition",
        "to_df",
        "with_columns_renamed",
        "show_string",
        "drop",
        "tail",
        "with_columns",
        "hint",
        "unpivot",
        "to_schema",
        "repartition_by_expression",
        "map_partitions",
        "collect_metrics",
        "parse",
        "group_map",
        "co_group_map",
        "with_watermark",
        "apply_in_pandas_with_state",
        "html_string",
        "cached_local_relation",
        "fill_na",
        "drop_na",
        "replace",
        "summary",
        "crosstab",
        "describe",
        "cov",
        "corr",
        "approx_quantile",
        "freq_items",
        "sample_by",
        "catalog",
        "extension",
        "unknown",
    ]: ...

type___Relation = Relation

class Unknown(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

    def __init__(
        self,
    ) -> None: ...

type___Unknown = Unknown

class RelationCommon(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    source_info: typing___Text = ...
    plan_id: builtin___int = ...

    def __init__(
        self,
        *,
        source_info: typing___Optional[typing___Text] = None,
        plan_id: typing___Optional[builtin___int] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal["_plan_id", b"_plan_id", "plan_id", b"plan_id"],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_plan_id", b"_plan_id", "plan_id", b"plan_id", "source_info", b"source_info"
        ],
    ) -> None: ...
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_plan_id", b"_plan_id"]
    ) -> typing_extensions___Literal["plan_id"]: ...

type___RelationCommon = RelationCommon

class SQL(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

    class ArgsEntry(google___protobuf___message___Message):
        DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
        key: typing___Text = ...

        @property
        def value(self) -> spark___connect___expressions_pb2___Expression.Literal: ...
        def __init__(
            self,
            *,
            key: typing___Optional[typing___Text] = None,
            value: typing___Optional[spark___connect___expressions_pb2___Expression.Literal] = None,
        ) -> None: ...
        def HasField(
            self, field_name: typing_extensions___Literal["value", b"value"]
        ) -> builtin___bool: ...
        def ClearField(
            self, field_name: typing_extensions___Literal["key", b"key", "value", b"value"]
        ) -> None: ...
    type___ArgsEntry = ArgsEntry

    query: typing___Text = ...

    @property
    def args(
        self,
    ) -> google___protobuf___internal___containers___MessageMap[
        typing___Text, spark___connect___expressions_pb2___Expression.Literal
    ]: ...
    def __init__(
        self,
        *,
        query: typing___Optional[typing___Text] = None,
        args: typing___Optional[
            typing___Mapping[typing___Text, spark___connect___expressions_pb2___Expression.Literal]
        ] = None,
    ) -> None: ...
    def ClearField(
        self, field_name: typing_extensions___Literal["args", b"args", "query", b"query"]
    ) -> None: ...

type___SQL = SQL

class Read(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

    class NamedTable(google___protobuf___message___Message):
        DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

        class OptionsEntry(google___protobuf___message___Message):
            DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
            key: typing___Text = ...
            value: typing___Text = ...

            def __init__(
                self,
                *,
                key: typing___Optional[typing___Text] = None,
                value: typing___Optional[typing___Text] = None,
            ) -> None: ...
            def ClearField(
                self, field_name: typing_extensions___Literal["key", b"key", "value", b"value"]
            ) -> None: ...
        type___OptionsEntry = OptionsEntry

        unparsed_identifier: typing___Text = ...

        @property
        def options(
            self,
        ) -> google___protobuf___internal___containers___ScalarMap[
            typing___Text, typing___Text
        ]: ...
        def __init__(
            self,
            *,
            unparsed_identifier: typing___Optional[typing___Text] = None,
            options: typing___Optional[typing___Mapping[typing___Text, typing___Text]] = None,
        ) -> None: ...
        def ClearField(
            self,
            field_name: typing_extensions___Literal[
                "options", b"options", "unparsed_identifier", b"unparsed_identifier"
            ],
        ) -> None: ...
    type___NamedTable = NamedTable

    class DataSource(google___protobuf___message___Message):
        DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

        class OptionsEntry(google___protobuf___message___Message):
            DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
            key: typing___Text = ...
            value: typing___Text = ...

            def __init__(
                self,
                *,
                key: typing___Optional[typing___Text] = None,
                value: typing___Optional[typing___Text] = None,
            ) -> None: ...
            def ClearField(
                self, field_name: typing_extensions___Literal["key", b"key", "value", b"value"]
            ) -> None: ...
        type___OptionsEntry = OptionsEntry

        format: typing___Text = ...
        schema: typing___Text = ...
        paths: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
            typing___Text
        ] = ...
        predicates: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
            typing___Text
        ] = ...

        @property
        def options(
            self,
        ) -> google___protobuf___internal___containers___ScalarMap[
            typing___Text, typing___Text
        ]: ...
        def __init__(
            self,
            *,
            format: typing___Optional[typing___Text] = None,
            schema: typing___Optional[typing___Text] = None,
            options: typing___Optional[typing___Mapping[typing___Text, typing___Text]] = None,
            paths: typing___Optional[typing___Iterable[typing___Text]] = None,
            predicates: typing___Optional[typing___Iterable[typing___Text]] = None,
        ) -> None: ...
        def HasField(
            self,
            field_name: typing_extensions___Literal[
                "_format",
                b"_format",
                "_schema",
                b"_schema",
                "format",
                b"format",
                "schema",
                b"schema",
            ],
        ) -> builtin___bool: ...
        def ClearField(
            self,
            field_name: typing_extensions___Literal[
                "_format",
                b"_format",
                "_schema",
                b"_schema",
                "format",
                b"format",
                "options",
                b"options",
                "paths",
                b"paths",
                "predicates",
                b"predicates",
                "schema",
                b"schema",
            ],
        ) -> None: ...
        @typing___overload
        def WhichOneof(
            self, oneof_group: typing_extensions___Literal["_format", b"_format"]
        ) -> typing_extensions___Literal["format"]: ...
        @typing___overload
        def WhichOneof(
            self, oneof_group: typing_extensions___Literal["_schema", b"_schema"]
        ) -> typing_extensions___Literal["schema"]: ...
    type___DataSource = DataSource

    is_streaming: builtin___bool = ...

    @property
    def named_table(self) -> type___Read.NamedTable: ...
    @property
    def data_source(self) -> type___Read.DataSource: ...
    def __init__(
        self,
        *,
        named_table: typing___Optional[type___Read.NamedTable] = None,
        data_source: typing___Optional[type___Read.DataSource] = None,
        is_streaming: typing___Optional[builtin___bool] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "data_source", b"data_source", "named_table", b"named_table", "read_type", b"read_type"
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "data_source",
            b"data_source",
            "is_streaming",
            b"is_streaming",
            "named_table",
            b"named_table",
            "read_type",
            b"read_type",
        ],
    ) -> None: ...
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["read_type", b"read_type"]
    ) -> typing_extensions___Literal["named_table", "data_source"]: ...

type___Read = Read

class Project(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def expressions(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        expressions: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal["expressions", b"expressions", "input", b"input"],
    ) -> None: ...

type___Project = Project

class Filter(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def condition(self) -> spark___connect___expressions_pb2___Expression: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        condition: typing___Optional[spark___connect___expressions_pb2___Expression] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["condition", b"condition", "input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self, field_name: typing_extensions___Literal["condition", b"condition", "input", b"input"]
    ) -> None: ...

type___Filter = Filter

class Join(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    JoinTypeValue = typing___NewType("JoinTypeValue", builtin___int)
    type___JoinTypeValue = JoinTypeValue
    JoinType: _JoinType

    class _JoinType(
        google___protobuf___internal___enum_type_wrapper____EnumTypeWrapper[Join.JoinTypeValue]
    ):
        DESCRIPTOR: google___protobuf___descriptor___EnumDescriptor = ...
        JOIN_TYPE_UNSPECIFIED = typing___cast(Join.JoinTypeValue, 0)
        JOIN_TYPE_INNER = typing___cast(Join.JoinTypeValue, 1)
        JOIN_TYPE_FULL_OUTER = typing___cast(Join.JoinTypeValue, 2)
        JOIN_TYPE_LEFT_OUTER = typing___cast(Join.JoinTypeValue, 3)
        JOIN_TYPE_RIGHT_OUTER = typing___cast(Join.JoinTypeValue, 4)
        JOIN_TYPE_LEFT_ANTI = typing___cast(Join.JoinTypeValue, 5)
        JOIN_TYPE_LEFT_SEMI = typing___cast(Join.JoinTypeValue, 6)
        JOIN_TYPE_CROSS = typing___cast(Join.JoinTypeValue, 7)
    JOIN_TYPE_UNSPECIFIED = typing___cast(Join.JoinTypeValue, 0)
    JOIN_TYPE_INNER = typing___cast(Join.JoinTypeValue, 1)
    JOIN_TYPE_FULL_OUTER = typing___cast(Join.JoinTypeValue, 2)
    JOIN_TYPE_LEFT_OUTER = typing___cast(Join.JoinTypeValue, 3)
    JOIN_TYPE_RIGHT_OUTER = typing___cast(Join.JoinTypeValue, 4)
    JOIN_TYPE_LEFT_ANTI = typing___cast(Join.JoinTypeValue, 5)
    JOIN_TYPE_LEFT_SEMI = typing___cast(Join.JoinTypeValue, 6)
    JOIN_TYPE_CROSS = typing___cast(Join.JoinTypeValue, 7)

    join_type: type___Join.JoinTypeValue = ...
    using_columns: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
        typing___Text
    ] = ...

    @property
    def left(self) -> type___Relation: ...
    @property
    def right(self) -> type___Relation: ...
    @property
    def join_condition(self) -> spark___connect___expressions_pb2___Expression: ...
    def __init__(
        self,
        *,
        left: typing___Optional[type___Relation] = None,
        right: typing___Optional[type___Relation] = None,
        join_condition: typing___Optional[spark___connect___expressions_pb2___Expression] = None,
        join_type: typing___Optional[type___Join.JoinTypeValue] = None,
        using_columns: typing___Optional[typing___Iterable[typing___Text]] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "join_condition", b"join_condition", "left", b"left", "right", b"right"
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "join_condition",
            b"join_condition",
            "join_type",
            b"join_type",
            "left",
            b"left",
            "right",
            b"right",
            "using_columns",
            b"using_columns",
        ],
    ) -> None: ...

type___Join = Join

class SetOperation(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    SetOpTypeValue = typing___NewType("SetOpTypeValue", builtin___int)
    type___SetOpTypeValue = SetOpTypeValue
    SetOpType: _SetOpType

    class _SetOpType(
        google___protobuf___internal___enum_type_wrapper____EnumTypeWrapper[
            SetOperation.SetOpTypeValue
        ]
    ):
        DESCRIPTOR: google___protobuf___descriptor___EnumDescriptor = ...
        SET_OP_TYPE_UNSPECIFIED = typing___cast(SetOperation.SetOpTypeValue, 0)
        SET_OP_TYPE_INTERSECT = typing___cast(SetOperation.SetOpTypeValue, 1)
        SET_OP_TYPE_UNION = typing___cast(SetOperation.SetOpTypeValue, 2)
        SET_OP_TYPE_EXCEPT = typing___cast(SetOperation.SetOpTypeValue, 3)
    SET_OP_TYPE_UNSPECIFIED = typing___cast(SetOperation.SetOpTypeValue, 0)
    SET_OP_TYPE_INTERSECT = typing___cast(SetOperation.SetOpTypeValue, 1)
    SET_OP_TYPE_UNION = typing___cast(SetOperation.SetOpTypeValue, 2)
    SET_OP_TYPE_EXCEPT = typing___cast(SetOperation.SetOpTypeValue, 3)

    set_op_type: type___SetOperation.SetOpTypeValue = ...
    is_all: builtin___bool = ...
    by_name: builtin___bool = ...
    allow_missing_columns: builtin___bool = ...

    @property
    def left_input(self) -> type___Relation: ...
    @property
    def right_input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        left_input: typing___Optional[type___Relation] = None,
        right_input: typing___Optional[type___Relation] = None,
        set_op_type: typing___Optional[type___SetOperation.SetOpTypeValue] = None,
        is_all: typing___Optional[builtin___bool] = None,
        by_name: typing___Optional[builtin___bool] = None,
        allow_missing_columns: typing___Optional[builtin___bool] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_allow_missing_columns",
            b"_allow_missing_columns",
            "_by_name",
            b"_by_name",
            "_is_all",
            b"_is_all",
            "allow_missing_columns",
            b"allow_missing_columns",
            "by_name",
            b"by_name",
            "is_all",
            b"is_all",
            "left_input",
            b"left_input",
            "right_input",
            b"right_input",
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_allow_missing_columns",
            b"_allow_missing_columns",
            "_by_name",
            b"_by_name",
            "_is_all",
            b"_is_all",
            "allow_missing_columns",
            b"allow_missing_columns",
            "by_name",
            b"by_name",
            "is_all",
            b"is_all",
            "left_input",
            b"left_input",
            "right_input",
            b"right_input",
            "set_op_type",
            b"set_op_type",
        ],
    ) -> None: ...
    @typing___overload
    def WhichOneof(
        self,
        oneof_group: typing_extensions___Literal[
            "_allow_missing_columns", b"_allow_missing_columns"
        ],
    ) -> typing_extensions___Literal["allow_missing_columns"]: ...
    @typing___overload
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_by_name", b"_by_name"]
    ) -> typing_extensions___Literal["by_name"]: ...
    @typing___overload
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_is_all", b"_is_all"]
    ) -> typing_extensions___Literal["is_all"]: ...

type___SetOperation = SetOperation

class Limit(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    limit: builtin___int = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        limit: typing___Optional[builtin___int] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self, field_name: typing_extensions___Literal["input", b"input", "limit", b"limit"]
    ) -> None: ...

type___Limit = Limit

class Offset(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    offset: builtin___int = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        offset: typing___Optional[builtin___int] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self, field_name: typing_extensions___Literal["input", b"input", "offset", b"offset"]
    ) -> None: ...

type___Offset = Offset

class Tail(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    limit: builtin___int = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        limit: typing___Optional[builtin___int] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self, field_name: typing_extensions___Literal["input", b"input", "limit", b"limit"]
    ) -> None: ...

type___Tail = Tail

class Aggregate(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    GroupTypeValue = typing___NewType("GroupTypeValue", builtin___int)
    type___GroupTypeValue = GroupTypeValue
    GroupType: _GroupType

    class _GroupType(
        google___protobuf___internal___enum_type_wrapper____EnumTypeWrapper[
            Aggregate.GroupTypeValue
        ]
    ):
        DESCRIPTOR: google___protobuf___descriptor___EnumDescriptor = ...
        GROUP_TYPE_UNSPECIFIED = typing___cast(Aggregate.GroupTypeValue, 0)
        GROUP_TYPE_GROUPBY = typing___cast(Aggregate.GroupTypeValue, 1)
        GROUP_TYPE_ROLLUP = typing___cast(Aggregate.GroupTypeValue, 2)
        GROUP_TYPE_CUBE = typing___cast(Aggregate.GroupTypeValue, 3)
        GROUP_TYPE_PIVOT = typing___cast(Aggregate.GroupTypeValue, 4)
    GROUP_TYPE_UNSPECIFIED = typing___cast(Aggregate.GroupTypeValue, 0)
    GROUP_TYPE_GROUPBY = typing___cast(Aggregate.GroupTypeValue, 1)
    GROUP_TYPE_ROLLUP = typing___cast(Aggregate.GroupTypeValue, 2)
    GROUP_TYPE_CUBE = typing___cast(Aggregate.GroupTypeValue, 3)
    GROUP_TYPE_PIVOT = typing___cast(Aggregate.GroupTypeValue, 4)

    class Pivot(google___protobuf___message___Message):
        DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

        @property
        def col(self) -> spark___connect___expressions_pb2___Expression: ...
        @property
        def values(
            self,
        ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
            spark___connect___expressions_pb2___Expression.Literal
        ]: ...
        def __init__(
            self,
            *,
            col: typing___Optional[spark___connect___expressions_pb2___Expression] = None,
            values: typing___Optional[
                typing___Iterable[spark___connect___expressions_pb2___Expression.Literal]
            ] = None,
        ) -> None: ...
        def HasField(
            self, field_name: typing_extensions___Literal["col", b"col"]
        ) -> builtin___bool: ...
        def ClearField(
            self, field_name: typing_extensions___Literal["col", b"col", "values", b"values"]
        ) -> None: ...
    type___Pivot = Pivot

    group_type: type___Aggregate.GroupTypeValue = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def grouping_expressions(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    @property
    def aggregate_expressions(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    @property
    def pivot(self) -> type___Aggregate.Pivot: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        group_type: typing___Optional[type___Aggregate.GroupTypeValue] = None,
        grouping_expressions: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
        aggregate_expressions: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
        pivot: typing___Optional[type___Aggregate.Pivot] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input", "pivot", b"pivot"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "aggregate_expressions",
            b"aggregate_expressions",
            "group_type",
            b"group_type",
            "grouping_expressions",
            b"grouping_expressions",
            "input",
            b"input",
            "pivot",
            b"pivot",
        ],
    ) -> None: ...

type___Aggregate = Aggregate

class Sort(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    is_global: builtin___bool = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def order(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression.SortOrder
    ]: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        order: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression.SortOrder]
        ] = None,
        is_global: typing___Optional[builtin___bool] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_is_global", b"_is_global", "input", b"input", "is_global", b"is_global"
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_is_global",
            b"_is_global",
            "input",
            b"input",
            "is_global",
            b"is_global",
            "order",
            b"order",
        ],
    ) -> None: ...
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_is_global", b"_is_global"]
    ) -> typing_extensions___Literal["is_global"]: ...

type___Sort = Sort

class Drop(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    column_names: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
        typing___Text
    ] = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def columns(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        columns: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
        column_names: typing___Optional[typing___Iterable[typing___Text]] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "column_names", b"column_names", "columns", b"columns", "input", b"input"
        ],
    ) -> None: ...

type___Drop = Drop

class Deduplicate(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    column_names: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
        typing___Text
    ] = ...
    all_columns_as_keys: builtin___bool = ...
    within_watermark: builtin___bool = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        column_names: typing___Optional[typing___Iterable[typing___Text]] = None,
        all_columns_as_keys: typing___Optional[builtin___bool] = None,
        within_watermark: typing___Optional[builtin___bool] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_all_columns_as_keys",
            b"_all_columns_as_keys",
            "_within_watermark",
            b"_within_watermark",
            "all_columns_as_keys",
            b"all_columns_as_keys",
            "input",
            b"input",
            "within_watermark",
            b"within_watermark",
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_all_columns_as_keys",
            b"_all_columns_as_keys",
            "_within_watermark",
            b"_within_watermark",
            "all_columns_as_keys",
            b"all_columns_as_keys",
            "column_names",
            b"column_names",
            "input",
            b"input",
            "within_watermark",
            b"within_watermark",
        ],
    ) -> None: ...
    @typing___overload
    def WhichOneof(
        self,
        oneof_group: typing_extensions___Literal["_all_columns_as_keys", b"_all_columns_as_keys"],
    ) -> typing_extensions___Literal["all_columns_as_keys"]: ...
    @typing___overload
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_within_watermark", b"_within_watermark"]
    ) -> typing_extensions___Literal["within_watermark"]: ...

type___Deduplicate = Deduplicate

class LocalRelation(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    data: builtin___bytes = ...
    schema: typing___Text = ...

    def __init__(
        self,
        *,
        data: typing___Optional[builtin___bytes] = None,
        schema: typing___Optional[typing___Text] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_data", b"_data", "_schema", b"_schema", "data", b"data", "schema", b"schema"
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_data", b"_data", "_schema", b"_schema", "data", b"data", "schema", b"schema"
        ],
    ) -> None: ...
    @typing___overload
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_data", b"_data"]
    ) -> typing_extensions___Literal["data"]: ...
    @typing___overload
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_schema", b"_schema"]
    ) -> typing_extensions___Literal["schema"]: ...

type___LocalRelation = LocalRelation

class CachedLocalRelation(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    userId: typing___Text = ...
    sessionId: typing___Text = ...
    hash: typing___Text = ...

    USERID_FIELD_NUMBER: builtins.int
    SESSIONID_FIELD_NUMBER: builtins.int
    HASH_FIELD_NUMBER: builtins.int
    userId: builtins.str
    """(Required) An identifier of the user which created the local relation"""
    sessionId: builtins.str
    """(Required) An identifier of the Spark SQL session in which the user created the local relation."""
    hash: builtins.str
    """(Required) A sha-256 hash of the serialized local relation in proto, see LocalRelation."""
    def __init__(
        self,
        *,
        userId: typing___Optional[typing___Text] = None,
        sessionId: typing___Optional[typing___Text] = None,
        hash: typing___Optional[typing___Text] = None,
    ) -> None: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "hash", b"hash", "sessionId", b"sessionId", "userId", b"userId"
        ],
    ) -> None: ...

type___CachedLocalRelation = CachedLocalRelation

class Sample(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    lower_bound: builtin___float = ...
    upper_bound: builtin___float = ...
    with_replacement: builtin___bool = ...
    seed: builtin___int = ...
    deterministic_order: builtin___bool = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        lower_bound: typing___Optional[builtin___float] = None,
        upper_bound: typing___Optional[builtin___float] = None,
        with_replacement: typing___Optional[builtin___bool] = None,
        seed: typing___Optional[builtin___int] = None,
        deterministic_order: typing___Optional[builtin___bool] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_seed",
            b"_seed",
            "_with_replacement",
            b"_with_replacement",
            "input",
            b"input",
            "seed",
            b"seed",
            "with_replacement",
            b"with_replacement",
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_seed",
            b"_seed",
            "_with_replacement",
            b"_with_replacement",
            "deterministic_order",
            b"deterministic_order",
            "input",
            b"input",
            "lower_bound",
            b"lower_bound",
            "seed",
            b"seed",
            "upper_bound",
            b"upper_bound",
            "with_replacement",
            b"with_replacement",
        ],
    ) -> None: ...
    @typing___overload
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_seed", b"_seed"]
    ) -> typing_extensions___Literal["seed"]: ...
    @typing___overload
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_with_replacement", b"_with_replacement"]
    ) -> typing_extensions___Literal["with_replacement"]: ...

type___Sample = Sample

class Range(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    start: builtin___int = ...
    end: builtin___int = ...
    step: builtin___int = ...
    num_partitions: builtin___int = ...

    def __init__(
        self,
        *,
        start: typing___Optional[builtin___int] = None,
        end: typing___Optional[builtin___int] = None,
        step: typing___Optional[builtin___int] = None,
        num_partitions: typing___Optional[builtin___int] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_num_partitions",
            b"_num_partitions",
            "_start",
            b"_start",
            "num_partitions",
            b"num_partitions",
            "start",
            b"start",
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_num_partitions",
            b"_num_partitions",
            "_start",
            b"_start",
            "end",
            b"end",
            "num_partitions",
            b"num_partitions",
            "start",
            b"start",
            "step",
            b"step",
        ],
    ) -> None: ...
    @typing___overload
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_num_partitions", b"_num_partitions"]
    ) -> typing_extensions___Literal["num_partitions"]: ...
    @typing___overload
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_start", b"_start"]
    ) -> typing_extensions___Literal["start"]: ...

type___Range = Range

class SubqueryAlias(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    alias: typing___Text = ...
    qualifier: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
        typing___Text
    ] = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        alias: typing___Optional[typing___Text] = None,
        qualifier: typing___Optional[typing___Iterable[typing___Text]] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "alias", b"alias", "input", b"input", "qualifier", b"qualifier"
        ],
    ) -> None: ...

type___SubqueryAlias = SubqueryAlias

class Repartition(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    num_partitions: builtin___int = ...
    shuffle: builtin___bool = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        num_partitions: typing___Optional[builtin___int] = None,
        shuffle: typing___Optional[builtin___bool] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_shuffle", b"_shuffle", "input", b"input", "shuffle", b"shuffle"
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_shuffle",
            b"_shuffle",
            "input",
            b"input",
            "num_partitions",
            b"num_partitions",
            "shuffle",
            b"shuffle",
        ],
    ) -> None: ...
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_shuffle", b"_shuffle"]
    ) -> typing_extensions___Literal["shuffle"]: ...

type___Repartition = Repartition

class ShowString(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    num_rows: builtin___int = ...
    truncate: builtin___int = ...
    vertical: builtin___bool = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        num_rows: typing___Optional[builtin___int] = None,
        truncate: typing___Optional[builtin___int] = None,
        vertical: typing___Optional[builtin___bool] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "input",
            b"input",
            "num_rows",
            b"num_rows",
            "truncate",
            b"truncate",
            "vertical",
            b"vertical",
        ],
    ) -> None: ...

type___ShowString = ShowString

class HtmlString(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    num_rows: builtin___int = ...
    truncate: builtin___int = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        num_rows: typing___Optional[builtin___int] = None,
        truncate: typing___Optional[builtin___int] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "input", b"input", "num_rows", b"num_rows", "truncate", b"truncate"
        ],
    ) -> None: ...

type___HtmlString = HtmlString

class StatSummary(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    statistics: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
        typing___Text
    ] = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        statistics: typing___Optional[typing___Iterable[typing___Text]] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal["input", b"input", "statistics", b"statistics"],
    ) -> None: ...

type___StatSummary = StatSummary

class StatDescribe(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    cols: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
        typing___Text
    ] = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        cols: typing___Optional[typing___Iterable[typing___Text]] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self, field_name: typing_extensions___Literal["cols", b"cols", "input", b"input"]
    ) -> None: ...

type___StatDescribe = StatDescribe

class StatCrosstab(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    col1: typing___Text = ...
    col2: typing___Text = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        col1: typing___Optional[typing___Text] = None,
        col2: typing___Optional[typing___Text] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "col1", b"col1", "col2", b"col2", "input", b"input"
        ],
    ) -> None: ...

type___StatCrosstab = StatCrosstab

class StatCov(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    col1: typing___Text = ...
    col2: typing___Text = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        col1: typing___Optional[typing___Text] = None,
        col2: typing___Optional[typing___Text] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "col1", b"col1", "col2", b"col2", "input", b"input"
        ],
    ) -> None: ...

type___StatCov = StatCov

class StatCorr(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    col1: typing___Text = ...
    col2: typing___Text = ...
    method: typing___Text = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        col1: typing___Optional[typing___Text] = None,
        col2: typing___Optional[typing___Text] = None,
        method: typing___Optional[typing___Text] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_method", b"_method", "input", b"input", "method", b"method"
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_method",
            b"_method",
            "col1",
            b"col1",
            "col2",
            b"col2",
            "input",
            b"input",
            "method",
            b"method",
        ],
    ) -> None: ...
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_method", b"_method"]
    ) -> typing_extensions___Literal["method"]: ...

type___StatCorr = StatCorr

class StatApproxQuantile(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    cols: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
        typing___Text
    ] = ...
    probabilities: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
        builtin___float
    ] = ...
    relative_error: builtin___float = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        cols: typing___Optional[typing___Iterable[typing___Text]] = None,
        probabilities: typing___Optional[typing___Iterable[builtin___float]] = None,
        relative_error: typing___Optional[builtin___float] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "cols",
            b"cols",
            "input",
            b"input",
            "probabilities",
            b"probabilities",
            "relative_error",
            b"relative_error",
        ],
    ) -> None: ...

type___StatApproxQuantile = StatApproxQuantile

class StatFreqItems(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    cols: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
        typing___Text
    ] = ...
    support: builtin___float = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        cols: typing___Optional[typing___Iterable[typing___Text]] = None,
        support: typing___Optional[builtin___float] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_support", b"_support", "input", b"input", "support", b"support"
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_support", b"_support", "cols", b"cols", "input", b"input", "support", b"support"
        ],
    ) -> None: ...
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_support", b"_support"]
    ) -> typing_extensions___Literal["support"]: ...

type___StatFreqItems = StatFreqItems

class StatSampleBy(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

    class Fraction(google___protobuf___message___Message):
        DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
        fraction: builtin___float = ...

        @property
        def stratum(self) -> spark___connect___expressions_pb2___Expression.Literal: ...
        def __init__(
            self,
            *,
            stratum: typing___Optional[
                spark___connect___expressions_pb2___Expression.Literal
            ] = None,
            fraction: typing___Optional[builtin___float] = None,
        ) -> None: ...
        def HasField(
            self, field_name: typing_extensions___Literal["stratum", b"stratum"]
        ) -> builtin___bool: ...
        def ClearField(
            self,
            field_name: typing_extensions___Literal["fraction", b"fraction", "stratum", b"stratum"],
        ) -> None: ...
    type___Fraction = Fraction

    seed: builtin___int = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def col(self) -> spark___connect___expressions_pb2___Expression: ...
    @property
    def fractions(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        type___StatSampleBy.Fraction
    ]: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        col: typing___Optional[spark___connect___expressions_pb2___Expression] = None,
        fractions: typing___Optional[typing___Iterable[type___StatSampleBy.Fraction]] = None,
        seed: typing___Optional[builtin___int] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_seed", b"_seed", "col", b"col", "input", b"input", "seed", b"seed"
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_seed",
            b"_seed",
            "col",
            b"col",
            "fractions",
            b"fractions",
            "input",
            b"input",
            "seed",
            b"seed",
        ],
    ) -> None: ...
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_seed", b"_seed"]
    ) -> typing_extensions___Literal["seed"]: ...

type___StatSampleBy = StatSampleBy

class NAFill(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    cols: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
        typing___Text
    ] = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def values(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression.Literal
    ]: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        cols: typing___Optional[typing___Iterable[typing___Text]] = None,
        values: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression.Literal]
        ] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "cols", b"cols", "input", b"input", "values", b"values"
        ],
    ) -> None: ...

type___NAFill = NAFill

class NADrop(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    cols: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
        typing___Text
    ] = ...
    min_non_nulls: builtin___int = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        cols: typing___Optional[typing___Iterable[typing___Text]] = None,
        min_non_nulls: typing___Optional[builtin___int] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_min_non_nulls",
            b"_min_non_nulls",
            "input",
            b"input",
            "min_non_nulls",
            b"min_non_nulls",
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_min_non_nulls",
            b"_min_non_nulls",
            "cols",
            b"cols",
            "input",
            b"input",
            "min_non_nulls",
            b"min_non_nulls",
        ],
    ) -> None: ...
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_min_non_nulls", b"_min_non_nulls"]
    ) -> typing_extensions___Literal["min_non_nulls"]: ...

type___NADrop = NADrop

class NAReplace(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

    class Replacement(google___protobuf___message___Message):
        DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

        @property
        def old_value(self) -> spark___connect___expressions_pb2___Expression.Literal: ...
        @property
        def new_value(self) -> spark___connect___expressions_pb2___Expression.Literal: ...
        def __init__(
            self,
            *,
            old_value: typing___Optional[
                spark___connect___expressions_pb2___Expression.Literal
            ] = None,
            new_value: typing___Optional[
                spark___connect___expressions_pb2___Expression.Literal
            ] = None,
        ) -> None: ...
        def HasField(
            self,
            field_name: typing_extensions___Literal[
                "new_value", b"new_value", "old_value", b"old_value"
            ],
        ) -> builtin___bool: ...
        def ClearField(
            self,
            field_name: typing_extensions___Literal[
                "new_value", b"new_value", "old_value", b"old_value"
            ],
        ) -> None: ...
    type___Replacement = Replacement

    cols: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
        typing___Text
    ] = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def replacements(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        type___NAReplace.Replacement
    ]: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        cols: typing___Optional[typing___Iterable[typing___Text]] = None,
        replacements: typing___Optional[typing___Iterable[type___NAReplace.Replacement]] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "cols", b"cols", "input", b"input", "replacements", b"replacements"
        ],
    ) -> None: ...

type___NAReplace = NAReplace

class ToDF(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    column_names: google___protobuf___internal___containers___RepeatedScalarFieldContainer[
        typing___Text
    ] = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        column_names: typing___Optional[typing___Iterable[typing___Text]] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal["column_names", b"column_names", "input", b"input"],
    ) -> None: ...

type___ToDF = ToDF

class WithColumnsRenamed(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

    class RenameColumnsMapEntry(google___protobuf___message___Message):
        DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
        key: typing___Text = ...
        value: typing___Text = ...

        def __init__(
            self,
            *,
            key: typing___Optional[typing___Text] = None,
            value: typing___Optional[typing___Text] = None,
        ) -> None: ...
        def ClearField(
            self, field_name: typing_extensions___Literal["key", b"key", "value", b"value"]
        ) -> None: ...
    type___RenameColumnsMapEntry = RenameColumnsMapEntry

    @property
    def input(self) -> type___Relation: ...
    @property
    def rename_columns_map(
        self,
    ) -> google___protobuf___internal___containers___ScalarMap[typing___Text, typing___Text]: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        rename_columns_map: typing___Optional[
            typing___Mapping[typing___Text, typing___Text]
        ] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "input", b"input", "rename_columns_map", b"rename_columns_map"
        ],
    ) -> None: ...

type___WithColumnsRenamed = WithColumnsRenamed

class WithColumns(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def aliases(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression.Alias
    ]: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        aliases: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression.Alias]
        ] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self, field_name: typing_extensions___Literal["aliases", b"aliases", "input", b"input"]
    ) -> None: ...

type___WithColumns = WithColumns

class WithWatermark(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    event_time: typing___Text = ...
    delay_threshold: typing___Text = ...

    @property
    def input(self) -> type___Relation: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        event_time: typing___Optional[typing___Text] = None,
        delay_threshold: typing___Optional[typing___Text] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "delay_threshold", b"delay_threshold", "event_time", b"event_time", "input", b"input"
        ],
    ) -> None: ...

type___WithWatermark = WithWatermark

class Hint(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    name: typing___Text = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def parameters(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        name: typing___Optional[typing___Text] = None,
        parameters: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "input", b"input", "name", b"name", "parameters", b"parameters"
        ],
    ) -> None: ...

type___Hint = Hint

class Unpivot(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

    class Values(google___protobuf___message___Message):
        DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

        @property
        def values(
            self,
        ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
            spark___connect___expressions_pb2___Expression
        ]: ...
        def __init__(
            self,
            *,
            values: typing___Optional[
                typing___Iterable[spark___connect___expressions_pb2___Expression]
            ] = None,
        ) -> None: ...
        def ClearField(
            self, field_name: typing_extensions___Literal["values", b"values"]
        ) -> None: ...
    type___Values = Values

    variable_column_name: typing___Text = ...
    value_column_name: typing___Text = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def ids(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    @property
    def values(self) -> type___Unpivot.Values: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        ids: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
        values: typing___Optional[type___Unpivot.Values] = None,
        variable_column_name: typing___Optional[typing___Text] = None,
        value_column_name: typing___Optional[typing___Text] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_values", b"_values", "input", b"input", "values", b"values"
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_values",
            b"_values",
            "ids",
            b"ids",
            "input",
            b"input",
            "value_column_name",
            b"value_column_name",
            "values",
            b"values",
            "variable_column_name",
            b"variable_column_name",
        ],
    ) -> None: ...
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_values", b"_values"]
    ) -> typing_extensions___Literal["values"]: ...

type___Unpivot = Unpivot

class ToSchema(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def schema(self) -> spark___connect___types_pb2___DataType: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        schema: typing___Optional[spark___connect___types_pb2___DataType] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input", "schema", b"schema"]
    ) -> builtin___bool: ...
    def ClearField(
        self, field_name: typing_extensions___Literal["input", b"input", "schema", b"schema"]
    ) -> None: ...

type___ToSchema = ToSchema

class RepartitionByExpression(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    num_partitions: builtin___int = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def partition_exprs(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        partition_exprs: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
        num_partitions: typing___Optional[builtin___int] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_num_partitions",
            b"_num_partitions",
            "input",
            b"input",
            "num_partitions",
            b"num_partitions",
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_num_partitions",
            b"_num_partitions",
            "input",
            b"input",
            "num_partitions",
            b"num_partitions",
            "partition_exprs",
            b"partition_exprs",
        ],
    ) -> None: ...
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_num_partitions", b"_num_partitions"]
    ) -> typing_extensions___Literal["num_partitions"]: ...

type___RepartitionByExpression = RepartitionByExpression

class MapPartitions(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    is_barrier: builtin___bool = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def func(self) -> spark___connect___expressions_pb2___CommonInlineUserDefinedFunction: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        func: typing___Optional[
            spark___connect___expressions_pb2___CommonInlineUserDefinedFunction
        ] = None,
        is_barrier: typing___Optional[builtin___bool] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_is_barrier",
            b"_is_barrier",
            "func",
            b"func",
            "input",
            b"input",
            "is_barrier",
            b"is_barrier",
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_is_barrier",
            b"_is_barrier",
            "func",
            b"func",
            "input",
            b"input",
            "is_barrier",
            b"is_barrier",
        ],
    ) -> None: ...
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_is_barrier", b"_is_barrier"]
    ) -> typing_extensions___Literal["is_barrier"]: ...

type___MapPartitions = MapPartitions

class GroupMap(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def grouping_expressions(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    @property
    def func(self) -> spark___connect___expressions_pb2___CommonInlineUserDefinedFunction: ...
    @property
    def sorting_expressions(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        grouping_expressions: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
        func: typing___Optional[
            spark___connect___expressions_pb2___CommonInlineUserDefinedFunction
        ] = None,
        sorting_expressions: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["func", b"func", "input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "func",
            b"func",
            "grouping_expressions",
            b"grouping_expressions",
            "input",
            b"input",
            "sorting_expressions",
            b"sorting_expressions",
        ],
    ) -> None: ...

type___GroupMap = GroupMap

class CoGroupMap(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def input_grouping_expressions(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    @property
    def other(self) -> type___Relation: ...
    @property
    def other_grouping_expressions(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    @property
    def func(self) -> spark___connect___expressions_pb2___CommonInlineUserDefinedFunction: ...
    @property
    def input_sorting_expressions(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    @property
    def other_sorting_expressions(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        input_grouping_expressions: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
        other: typing___Optional[type___Relation] = None,
        other_grouping_expressions: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
        func: typing___Optional[
            spark___connect___expressions_pb2___CommonInlineUserDefinedFunction
        ] = None,
        input_sorting_expressions: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
        other_sorting_expressions: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "func", b"func", "input", b"input", "other", b"other"
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "func",
            b"func",
            "input",
            b"input",
            "input_grouping_expressions",
            b"input_grouping_expressions",
            "input_sorting_expressions",
            b"input_sorting_expressions",
            "other",
            b"other",
            "other_grouping_expressions",
            b"other_grouping_expressions",
            "other_sorting_expressions",
            b"other_sorting_expressions",
        ],
    ) -> None: ...

type___CoGroupMap = CoGroupMap

class ApplyInPandasWithState(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    output_schema: typing___Text = ...
    state_schema: typing___Text = ...
    output_mode: typing___Text = ...
    timeout_conf: typing___Text = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def grouping_expressions(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    @property
    def func(self) -> spark___connect___expressions_pb2___CommonInlineUserDefinedFunction: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        grouping_expressions: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
        func: typing___Optional[
            spark___connect___expressions_pb2___CommonInlineUserDefinedFunction
        ] = None,
        output_schema: typing___Optional[typing___Text] = None,
        state_schema: typing___Optional[typing___Text] = None,
        output_mode: typing___Optional[typing___Text] = None,
        timeout_conf: typing___Optional[typing___Text] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["func", b"func", "input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "func",
            b"func",
            "grouping_expressions",
            b"grouping_expressions",
            "input",
            b"input",
            "output_mode",
            b"output_mode",
            "output_schema",
            b"output_schema",
            "state_schema",
            b"state_schema",
            "timeout_conf",
            b"timeout_conf",
        ],
    ) -> None: ...

type___ApplyInPandasWithState = ApplyInPandasWithState

class CollectMetrics(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    name: typing___Text = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def metrics(
        self,
    ) -> google___protobuf___internal___containers___RepeatedCompositeFieldContainer[
        spark___connect___expressions_pb2___Expression
    ]: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        name: typing___Optional[typing___Text] = None,
        metrics: typing___Optional[
            typing___Iterable[spark___connect___expressions_pb2___Expression]
        ] = None,
    ) -> None: ...
    def HasField(
        self, field_name: typing_extensions___Literal["input", b"input"]
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "input", b"input", "metrics", b"metrics", "name", b"name"
        ],
    ) -> None: ...

type___CollectMetrics = CollectMetrics

class Parse(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    ParseFormatValue = typing___NewType("ParseFormatValue", builtin___int)
    type___ParseFormatValue = ParseFormatValue
    ParseFormat: _ParseFormat

    class _ParseFormat(
        google___protobuf___internal___enum_type_wrapper____EnumTypeWrapper[Parse.ParseFormatValue]
    ):
        DESCRIPTOR: google___protobuf___descriptor___EnumDescriptor = ...
        PARSE_FORMAT_UNSPECIFIED = typing___cast(Parse.ParseFormatValue, 0)
        PARSE_FORMAT_CSV = typing___cast(Parse.ParseFormatValue, 1)
        PARSE_FORMAT_JSON = typing___cast(Parse.ParseFormatValue, 2)
    PARSE_FORMAT_UNSPECIFIED = typing___cast(Parse.ParseFormatValue, 0)
    PARSE_FORMAT_CSV = typing___cast(Parse.ParseFormatValue, 1)
    PARSE_FORMAT_JSON = typing___cast(Parse.ParseFormatValue, 2)

    class OptionsEntry(google___protobuf___message___Message):
        DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
        key: typing___Text = ...
        value: typing___Text = ...

        def __init__(
            self,
            *,
            key: typing___Optional[typing___Text] = None,
            value: typing___Optional[typing___Text] = None,
        ) -> None: ...
        def ClearField(
            self, field_name: typing_extensions___Literal["key", b"key", "value", b"value"]
        ) -> None: ...
    type___OptionsEntry = OptionsEntry

    format: type___Parse.ParseFormatValue = ...

    @property
    def input(self) -> type___Relation: ...
    @property
    def schema(self) -> spark___connect___types_pb2___DataType: ...
    @property
    def options(
        self,
    ) -> google___protobuf___internal___containers___ScalarMap[typing___Text, typing___Text]: ...
    def __init__(
        self,
        *,
        input: typing___Optional[type___Relation] = None,
        format: typing___Optional[type___Parse.ParseFormatValue] = None,
        schema: typing___Optional[spark___connect___types_pb2___DataType] = None,
        options: typing___Optional[typing___Mapping[typing___Text, typing___Text]] = None,
    ) -> None: ...
    def HasField(
        self,
        field_name: typing_extensions___Literal[
            "_schema", b"_schema", "input", b"input", "schema", b"schema"
        ],
    ) -> builtin___bool: ...
    def ClearField(
        self,
        field_name: typing_extensions___Literal[
            "_schema",
            b"_schema",
            "format",
            b"format",
            "input",
            b"input",
            "options",
            b"options",
            "schema",
            b"schema",
        ],
    ) -> None: ...
    def WhichOneof(
        self, oneof_group: typing_extensions___Literal["_schema", b"_schema"]
    ) -> typing_extensions___Literal["schema"]: ...

type___Parse = Parse
