From 578be5dcfdece1f48aae8809648ae00f646bb040 Mon Sep 17 00:00:00 2001
From: Todd Lipcon <todd@cloudera.com>
Date: Fri, 4 Dec 2009 15:30:39 -0800
Subject: [PATCH 0395/1179] HDFS-781. Metrics PendingDeletionBlocks is not decremented

Patch: https://issues.apache.org/jira/secure/attachment/12426993/hdfs-781.rel20.1.patch.
Author: Suresh Srinivas
Ref: YDH
---
 .../hadoop/hdfs/server/namenode/FSNamesystem.java  |    1 +
 .../namenode/metrics/TestNameNodeMetrics.java      |   61 ++++++++++++--------
 2 files changed, 38 insertions(+), 24 deletions(-)

diff --git a/src/hdfs/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java b/src/hdfs/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
index a0c3e79..665d34c 100644
--- a/src/hdfs/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
+++ b/src/hdfs/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java
@@ -2835,6 +2835,7 @@ public class FSNamesystem implements FSConstants, FSNamesystemMBean {
       NameNode.stateChangeLog.info("BLOCK* ask "
           + dn.getName() + " to delete " + blockList);
     }
+    pendingDeletionBlocksCount -= blocksToInvalidate.size();
     return blocksToInvalidate.size();
   }
 
diff --git a/src/test/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java b/src/test/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java
index ea07300..88aa800 100644
--- a/src/test/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java
+++ b/src/test/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java
@@ -38,15 +38,18 @@ import org.mortbay.log.Log;
  * Test for metrics published by the Namenode
  */
 public class TestNameNodeMetrics extends TestCase {
+  private static final Configuration CONF = new Configuration();
+  private static final int DFS_REPLICATION_INTERVAL = 1;
+  private static final Path TEST_ROOT_DIR_PATH = 
+    new Path(System.getProperty("test.build.data", "build/test/data"));
+  
   // Number of datanodes in the cluster
   private static final int DATANODE_COUNT = 3; 
-	
-  private static final Configuration CONF = new Configuration();
   static {
     CONF.setLong("dfs.block.size", 100);
     CONF.setInt("io.bytes.per.checksum", 1);
-    CONF.setLong("dfs.heartbeat.interval", 1L);
-    CONF.setInt("dfs.replication.interval", 1);
+    CONF.setLong("dfs.heartbeat.interval", DFS_REPLICATION_INTERVAL);
+    CONF.setInt("dfs.replication.interval", DFS_REPLICATION_INTERVAL);
   }
   
   private MiniDFSCluster cluster;
@@ -57,9 +60,13 @@ public class TestNameNodeMetrics extends TestCase {
   private NameNodeMetrics nnMetrics;
   private NameNode nn;
 
+  private static Path getTestPath(String fileName) {
+    return new Path(TEST_ROOT_DIR_PATH, fileName);
+  }
+  
   @Override
   protected void setUp() throws Exception {
-    cluster = new MiniDFSCluster(CONF, 3, true, null);
+    cluster = new MiniDFSCluster(CONF, DATANODE_COUNT, true, null);
     cluster.waitActive();
     namesystem = cluster.getNameNode().getNamesystem();
     fs = (DistributedFileSystem) cluster.getFileSystem();
@@ -74,9 +81,8 @@ public class TestNameNodeMetrics extends TestCase {
   }
   
   /** create a file with a length of <code>fileLen</code> */
-  private void createFile(String fileName, long fileLen, short replicas) throws IOException {
-    Path filePath = new Path(fileName);
-    DFSTestUtil.createFile(fs, filePath, fileLen, replicas, rand.nextLong());
+  private void createFile(Path file, long fileLen, short replicas) throws IOException {
+    DFSTestUtil.createFile(fs, file, fileLen, replicas, rand.nextLong());
   }
 
   private void updateMetrics() throws Exception {
@@ -92,9 +98,8 @@ public class TestNameNodeMetrics extends TestCase {
     nnMetrics.doUpdates(null);
   }
  
-  private void readFile(FileSystem fileSys,String path) throws IOException {
+  private void readFile(FileSystem fileSys, Path name) throws IOException {
     //Just read file so that getNumBlockLocations are incremented
-    Path name = new Path(path);
     DataInputStream stm = fileSys.open(name);
     byte [] buffer = new byte[4];
     int bytesRead =  stm.read(buffer,0,4);
@@ -105,7 +110,7 @@ public class TestNameNodeMetrics extends TestCase {
   /** Test metrics associated with addition of a file */
   public void testFileAdd() throws Exception {
     // Add files with 100 blocks
-    final String file = "/tmp/t";
+    final Path file = getTestPath("testFileAdd");
     createFile(file, 3200, (short)3);
     final int blockCount = 32;
     int blockCapacity = namesystem.getBlockCapacity();
@@ -119,26 +124,35 @@ public class TestNameNodeMetrics extends TestCase {
       blockCapacity <<= 1;
     }
     updateMetrics();
-    assertEquals(3, metrics.filesTotal.get());
+    int filesTotal = file.depth() + 1; // Add 1 for root
+    assertEquals(filesTotal, metrics.filesTotal.get());
     assertEquals(blockCount, metrics.blocksTotal.get());
     assertEquals(blockCapacity, metrics.blockCapacity.get());
-    fs.delete(new Path(file), true);
+    fs.delete(file, true);
+    filesTotal--; // reduce the filecount for deleted file
+    
+    // Wait for more than DATANODE_COUNT replication intervals to ensure all 
+    // the blocks pending deletion are sent for deletion to the datanodes.
+    Thread.sleep(DFS_REPLICATION_INTERVAL * (DATANODE_COUNT + 1) * 1000);
+    updateMetrics();
+    assertEquals(filesTotal, metrics.filesTotal.get());
+    assertEquals(0, metrics.pendingDeletionBlocks.get());
   }
   
   /** Corrupt a block and ensure metrics reflects it */
   public void testCorruptBlock() throws Exception {
     // Create a file with single block with two replicas
-    String file = "/tmp/t";
+    final Path file = getTestPath("testCorruptBlock");
     createFile(file, 100, (short)2);
     
     // Corrupt first replica of the block
-    LocatedBlock block = namesystem.getBlockLocations(file, 0, 1).get(0);
+    LocatedBlock block = namesystem.getBlockLocations(file.toString(), 0, 1).get(0);
     namesystem.markBlockAsCorrupt(block.getBlock(), block.getLocations()[0]);
     updateMetrics();
     assertEquals(1, metrics.corruptBlocks.get());
     assertEquals(1, metrics.pendingReplicationBlocks.get());
     assertEquals(1, metrics.scheduledReplicationBlocks.get());
-    fs.delete(new Path(file), true);
+    fs.delete(file, true);
     updateMetrics();
     assertEquals(0, metrics.corruptBlocks.get());
     assertEquals(0, metrics.pendingReplicationBlocks.get());
@@ -149,29 +163,28 @@ public class TestNameNodeMetrics extends TestCase {
    * for a file and ensure metrics reflects it
    */
   public void testExcessBlocks() throws Exception {
-    String file = "/tmp/t";
+    Path file = getTestPath("testExcessBlocks");
     createFile(file, 100, (short)2);
     int totalBlocks = 1;
-    namesystem.setReplication(file, (short)1);
+    namesystem.setReplication(file.toString(), (short)1);
     updateMetrics();
     assertEquals(totalBlocks, metrics.excessBlocks.get());
-    assertEquals(totalBlocks, metrics.pendingDeletionBlocks.get());
-    fs.delete(new Path(file), true);
+    fs.delete(file, true);
   }
   
   /** Test to ensure metrics reflects missing blocks */
   public void testMissingBlock() throws Exception {
     // Create a file with single block with two replicas
-    String file = "/tmp/t";
+    Path file = getTestPath("testMissingBlocks");
     createFile(file, 100, (short)1);
     
     // Corrupt the only replica of the block to result in a missing block
-    LocatedBlock block = namesystem.getBlockLocations(file, 0, 1).get(0);
+    LocatedBlock block = namesystem.getBlockLocations(file.toString(), 0, 1).get(0);
     namesystem.markBlockAsCorrupt(block.getBlock(), block.getLocations()[0]);
     updateMetrics();
     assertEquals(1, metrics.underReplicatedBlocks.get());
     assertEquals(1, metrics.missingBlocks.get());
-    fs.delete(new Path(file), true);
+    fs.delete(file, true);
     updateMetrics();
     assertEquals(0, metrics.underReplicatedBlocks.get());
   }
@@ -192,7 +205,7 @@ public class TestNameNodeMetrics extends TestCase {
     final String METHOD_NAME = "TestGetBlockLocationMetric";
     Log.info("Running test "+METHOD_NAME);
   
-    String file1_path = "/tmp/filePath";
+    Path file1_path = new Path("/tmp/filePath");
 
     // When cluster starts first time there are no file  (read,create,open)
     // operations so metric numGetBlockLocations should be 0.
-- 
1.7.0.4

