From ba185a27aa4bb1bd965e6aa32a9b5bf3e8388f91 Mon Sep 17 00:00:00 2001
From: Todd Lipcon <todd@cloudera.com>
Date: Wed, 2 Feb 2011 17:38:39 -0800
Subject: [PATCH 0806/1179] MAPREDUCE-1872, MAPREDUCE-517. Capacity scheduler improvements plus minor framework changes to support

- JobInProgress changes to support locality decisions
- JobQueueJobInProgressListener.JobSchedulingInfo now has equals() method for

Author: Arun Murthy
Ref: CDH-2622
---
 src/contrib/capacity-scheduler/ivy.xml             |    6 +-
 .../hadoop/mapred/CapacitySchedulerConf.java       |  200 +++-
 .../hadoop/mapred/CapacitySchedulerQueue.java      | 1340 ++++++++++++++++++
 .../hadoop/mapred/CapacityTaskScheduler.java       | 1067 +++++----------
 .../hadoop/mapred/JobInitializationPoller.java     |  187 ++--
 .../org/apache/hadoop/mapred/JobQueuesManager.java |  211 +---
 .../org/apache/hadoop/mapred/MemoryMatcher.java    |   37 +-
 .../hadoop/mapred/TestCapacityScheduler.java       | 1447 ++++++++++++--------
 .../TestCapacitySchedulerWithJobTracker.java       |    2 +-
 src/mapred/org/apache/hadoop/mapred/JSPUtil.java   |    1 +
 .../org/apache/hadoop/mapred/JobInProgress.java    |   78 ++
 .../mapred/JobQueueJobInProgressListener.java      |   22 +
 12 files changed, 2989 insertions(+), 1609 deletions(-)
 create mode 100644 src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/CapacitySchedulerQueue.java

diff --git a/src/contrib/capacity-scheduler/ivy.xml b/src/contrib/capacity-scheduler/ivy.xml
index 9a60e9d..5264846 100644
--- a/src/contrib/capacity-scheduler/ivy.xml
+++ b/src/contrib/capacity-scheduler/ivy.xml
@@ -43,11 +43,7 @@
     <dependency org="org.mortbay.jetty"
       name="jetty"
       rev="${jetty.version}"
-      conf="common->master"/>
-    <dependency org="org.mortbay.jetty"
-      name="servlet-api-2.5"
-      rev="${servlet-api-2.5.version}"
-      conf="common->master"/> 
+      conf="common->default"/>
     <dependency org="commons-httpclient"
       name="commons-httpclient"
       rev="${commons-httpclient.version}"
diff --git a/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/CapacitySchedulerConf.java b/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/CapacitySchedulerConf.java
index d45337f..33d0841 100644
--- a/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/CapacitySchedulerConf.java
+++ b/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/CapacitySchedulerConf.java
@@ -36,6 +36,8 @@ class CapacitySchedulerConf {
   
   private int defaultUlimitMinimum;
   
+  private float defaultUserLimitFactor;
+  
   private boolean defaultSupportPriority;
   
   private static final String QUEUE_CONF_PROPERTY_NAME_PREFIX = 
@@ -88,7 +90,7 @@ class CapacitySchedulerConf {
    * The constant which defines the default initialization thread
    * polling interval, denoted in milliseconds.
    */
-  private static final int INITIALIZATION_THREAD_POLLING_INTERVAL = 5000;
+  private static final int INITIALIZATION_THREAD_POLLING_INTERVAL = 3000;
 
   /**
    * The constant which defines the maximum number of worker threads to be
@@ -98,7 +100,16 @@ class CapacitySchedulerConf {
 
   private Configuration rmConf;
 
-  private int defaultMaxJobsPerUsersToInitialize;
+  private int defaultInitToAcceptJobsFactor;
+  private int defaultMaxActiveTasksPerUserToInitialize;
+  private int defaultMaxActiveTasksPerQueueToInitialize;
+  
+  static final String MAX_SYSTEM_JOBS_KEY = 
+    "mapred.capacity-scheduler.maximum-system-jobs";
+  
+  static final int DEFAULT_MAX_SYSTEM_JOBS = 5000;
+  
+  static final int DEFAULT_MAX_TASKS_TO_SCHEDULE_AFTER_OFFSWITCH = 0;
   
   /**
    * Create a new Capacity scheduler conf.
@@ -130,13 +141,25 @@ class CapacitySchedulerConf {
    * which is used by the Capacity Scheduler.
    */
   private void initializeDefaults() {
-    defaultUlimitMinimum = rmConf.getInt(
-        "mapred.capacity-scheduler.default-minimum-user-limit-percent", 100);
+    defaultUlimitMinimum = 
+      rmConf.getInt(
+          "mapred.capacity-scheduler.default-minimum-user-limit-percent", 100);
+    defaultUserLimitFactor = 
+      rmConf.getFloat("mapred.capacity-scheduler.default-user-limit-factor", 
+          1.0f);
     defaultSupportPriority = rmConf.getBoolean(
         "mapred.capacity-scheduler.default-supports-priority", false);
-    defaultMaxJobsPerUsersToInitialize = rmConf.getInt(
-        "mapred.capacity-scheduler.default-maximum-initialized-jobs-per-user",
-        2);
+    defaultMaxActiveTasksPerQueueToInitialize = 
+      rmConf.getInt(
+          "mapred.capacity-scheduler.default-maximum-active-tasks-per-queue", 
+          200000);
+    defaultMaxActiveTasksPerUserToInitialize = 
+      rmConf.getInt(
+          "mapred.capacity-scheduler.default-maximum-active-tasks-per-user", 
+          100000);
+    defaultInitToAcceptJobsFactor =
+      rmConf.getInt("mapred.capacity-scheduler.default-init-accept-jobs-factor", 
+          10);
   }
   
   /**
@@ -294,6 +317,32 @@ class CapacitySchedulerConf {
   }
   
   /**
+   * Get the factor of queue capacity above which a single user in a queue
+   * can consume resources.
+   * 
+   * @param queue queue name
+   * @return factor of queue capacity above which a single user in a queue
+   *         can consume resources
+   */
+  public float getUserLimitFactor(String queue) {
+    return rmConf.getFloat(toFullPropertyName(queue, "user-limit-factor"), 
+        defaultUserLimitFactor);
+  }
+  
+  /**
+   * Set the factor of queue capacity above which a single user in a queue
+   * can consume resources.
+   * 
+   * @param queue queue name
+   * @param userLimitFactor factor of queue capacity above which a single user 
+   *                        in a queue can consume resources
+   */
+  public void setUserLimitFactor(String queue, float userLimitFactor) {
+    rmConf.setFloat(toFullPropertyName(queue, "user-limit-factor"), 
+        userLimitFactor);
+  }
+  
+  /**
    * Reload configuration by clearing the information read from the 
    * underlying configuration file.
    */
@@ -307,38 +356,81 @@ class CapacitySchedulerConf {
       return QUEUE_CONF_PROPERTY_NAME_PREFIX + queue + "." + property;
   }
 
+  public int getMaxSystemJobs() {
+    int maxSystemJobs = 
+      rmConf.getInt(MAX_SYSTEM_JOBS_KEY, DEFAULT_MAX_SYSTEM_JOBS);
+    if (maxSystemJobs <= 0) {
+      throw new IllegalArgumentException("Invalid maximum system jobs: " + 
+          maxSystemJobs);
+    }
+    
+    return maxSystemJobs;
+  }
+
+  public void setMaxSystemJobs(int maxSystemJobs) {
+    rmConf.setInt(MAX_SYSTEM_JOBS_KEY, maxSystemJobs);
+  }
+  
+  public int getInitToAcceptJobsFactor(String queue) {
+    int initToAccepFactor = 
+      rmConf.getInt(toFullPropertyName(queue, "init-accept-jobs-factor"), 
+          defaultInitToAcceptJobsFactor);
+    if(initToAccepFactor <= 0) {
+      throw new IllegalArgumentException(
+          "Invalid maximum jobs per user configuration " + initToAccepFactor);
+    }
+    return initToAccepFactor;
+  }
+  
+  public void setInitToAcceptJobsFactor(String queue, int initToAcceptFactor) {
+    rmConf.setInt(toFullPropertyName(queue, "init-accept-jobs-factor"), 
+        initToAcceptFactor);
+  }
+  
   /**
-   * Gets the maximum number of jobs which are allowed to initialize in the
-   * job queue.
+   * Get the maximum active tasks per queue to be initialized.
    * 
-   * @param queue queue name.
-   * @return maximum number of jobs allowed to be initialized per user.
-   * @throws IllegalArgumentException if maximum number of users is negative
-   * or zero.
+   * @param queue queue name
    */
-  public int getMaxJobsPerUserToInitialize(String queue) {
-    int maxJobsPerUser = rmConf.getInt(toFullPropertyName(queue,
-        "maximum-initialized-jobs-per-user"), 
-        defaultMaxJobsPerUsersToInitialize);
-    if(maxJobsPerUser <= 0) {
-      throw new IllegalArgumentException(
-          "Invalid maximum jobs per user configuration " + maxJobsPerUser);
-    }
-    return maxJobsPerUser;
+  public int getMaxInitializedActiveTasks(String queue) {
+    return rmConf.getInt(toFullPropertyName(queue, 
+                                            "maximum-initialized-active-tasks"), 
+                         defaultMaxActiveTasksPerQueueToInitialize);
   }
   
   /**
-   * Sets the maximum number of jobs which are allowed to be initialized 
-   * for a user in the queue.
+   * Set the maximum active tasks per queue to be initialized.
    * 
-   * @param queue queue name.
-   * @param value maximum number of jobs allowed to be initialized per user.
+   * @param queue queue name
+   * @param value maximum active tasks
    */
-  public void setMaxJobsPerUserToInitialize(String queue, int value) {
-    rmConf.setInt(toFullPropertyName(queue, 
-        "maximum-initialized-jobs-per-user"), value);
+  public void setMaxInitializedActiveTasks(String queue, int value) {
+    rmConf.setInt(toFullPropertyName(queue, "maximum-initialized-active-tasks"), 
+                  value);
   }
-
+  
+  /**
+   * Get the maximum active tasks per-user, per-queue to be initialized.
+   * 
+   * @param queue queue name
+   */
+  public int getMaxInitializedActiveTasksPerUser(String queue) {
+    return rmConf.getInt(toFullPropertyName(queue, 
+                                            "maximum-initialized-active-tasks-per-user"), 
+                         defaultMaxActiveTasksPerUserToInitialize);
+  }
+  
+  /**
+   * Set the maximum active tasks per-user, per-queue to be initialized.
+   * 
+   * @param queue queue name
+   * @param value maximum active tasks
+   */
+  public void setMaxInitializedActiveTasksPerUser(String queue, int value) {
+    rmConf.setInt(toFullPropertyName(queue, "maximum-initialized-active-tasks-per-user"), 
+                  value);
+  }
+  
   /**
    * Amount of time in milliseconds which poller thread and initialization
    * thread would sleep before looking at the queued jobs.
@@ -411,4 +503,52 @@ class CapacitySchedulerConf {
     rmConf.setInt(
         "mapred.capacity-scheduler.init-worker-threads", poolSize);
   }
+  
+  /**
+   * Get the maximum number of tasks which can be scheduled in a heartbeat.
+   * @return the maximum number of tasks which can be scheduled in a heartbeat
+   */
+  public int getMaxTasksPerHeartbeat() {
+    return rmConf.getInt(
+        "mapred.capacity-scheduler.maximum-tasks-per-heartbeat", 
+        Short.MAX_VALUE);
+  }
+
+  /**
+   * Set the maximum number of tasks which can be scheduled in a heartbeat
+   * @param maxTasksPerHeartbeat the maximum number of tasks which can be 
+   *                             scheduled in a heartbeat
+   */
+  public void setMaxTasksPerHeartbeat(int maxTasksPerHeartbeat) {
+    rmConf.setInt("mapred.capacity-scheduler.maximum-tasks-per-heartbeat", 
+        maxTasksPerHeartbeat);
+  }
+  
+  /**
+   * Get the maximum number of tasks to schedule, per heartbeat, after an
+   * off-switch task has been assigned.
+   * 
+   * @return the maximum number of tasks to schedule, per heartbeat, after an
+   *         off-switch task has been assigned
+   */
+  public int getMaxTasksToAssignAfterOffSwitch() {
+    return rmConf.getInt(
+        "mapred.capacity-scheduler.maximum-tasks-after-offswitch", 
+        DEFAULT_MAX_TASKS_TO_SCHEDULE_AFTER_OFFSWITCH);
+  }
+  
+  /**
+   * Set the maximum number of tasks to schedule, per heartbeat, after an
+   * off-switch task has been assigned.
+   * 
+   * @param maxTasksToAssignAfterOffSwitch the maximum number of tasks to 
+   *                                       schedule, per heartbeat, after an
+   *                                       off-switch task has been assigned
+   */
+  public void setMaxTasksToAssignAfterOffSwitch(
+      int maxTasksToAssignAfterOffSwitch) {
+    rmConf.setInt(
+        "mapred.capacity-scheduler.maximum-tasks-after-offswitch", 
+        maxTasksToAssignAfterOffSwitch);
+  }
 }
diff --git a/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/CapacitySchedulerQueue.java b/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/CapacitySchedulerQueue.java
new file mode 100644
index 0000000..c76366e
--- /dev/null
+++ b/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/CapacitySchedulerQueue.java
@@ -0,0 +1,1340 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.mapred;
+
+import java.io.IOException;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.LinkedList;
+import java.util.Map;
+import java.util.Set;
+import java.util.TreeMap;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+
+import org.apache.hadoop.mapreduce.TaskType;
+import org.apache.hadoop.mapred.CapacityTaskScheduler.TaskSchedulingMgr;
+import org.apache.hadoop.mapred.JobQueueJobInProgressListener.JobSchedulingInfo;
+
+
+/***********************************************************************
+ * Keeping track of scheduling information for queues
+ * 
+ * We need to maintain scheduling information relevant to a queue (its 
+ * name, capacity, etc), along with information specific to 
+ * each kind of task, Map or Reduce (num of running tasks, pending 
+ * tasks etc). 
+ * 
+ * This scheduling information is used to decide how to allocate
+ * tasks, redistribute capacity, etc.
+ *  
+ * A QueueSchedulingInfo(QSI) object represents scheduling information for
+ * a  A TaskSchedulingInfo (TSI) object represents scheduling 
+ * information for a particular kind of task (Map or Reduce).
+ *   
+ **********************************************************************/
+class CapacitySchedulerQueue {
+  
+  static final Log LOG = LogFactory.getLog(CapacityTaskScheduler.class);
+  
+  private static class SlotsUsage {
+    /** 
+     * the actual capacity, which depends on how many slots are available
+     * in the cluster at any given time. 
+     */
+    private int capacity = 0;
+    // number of running tasks
+    int numRunningTasks = 0;
+    // number of slots occupied by running tasks
+    int numSlotsOccupied = 0;
+  
+    //the actual maximum capacity which depends on how many slots are available
+    //in cluster at any given time.
+    private int maxCapacity = -1;
+  
+    // Active users
+    Set<String> users = new HashSet<String>();
+    
+    /**
+     * for each user, we need to keep track of number of slots occupied by
+     * running tasks
+     */
+    Map<String, Integer> numSlotsOccupiedByUser = 
+      new HashMap<String, Integer>();
+  
+    /**
+     * reset the variables associated with tasks
+     */
+    void reset() {
+      numRunningTasks = 0;
+      numSlotsOccupied = 0;
+      users.clear();
+      numSlotsOccupiedByUser.clear();
+    }
+  
+  
+    /**
+     * Returns the actual capacity.
+     * capacity.
+     *
+     * @return
+     */
+    int getCapacity() {
+      return capacity;
+    }
+  
+    /**
+     * Mutator method for capacity
+     *
+     * @param capacity
+     */
+    void setCapacity(int capacity) {
+        this.capacity = capacity;
+    }
+  
+    /**
+     * @return the numRunningTasks
+     */
+    int getNumRunningTasks() {
+      return numRunningTasks;
+    }
+  
+    /**
+     * @return the numSlotsOccupied
+     */
+    int getNumSlotsOccupied() {
+      return numSlotsOccupied;
+    }
+  
+    /**
+     * @return number of active users
+     */
+    int getNumActiveUsers() {
+      return users.size();
+    }
+    
+    /**
+     * return information about the tasks
+     */
+    @Override
+    public String toString() {
+      float occupiedSlotsAsPercent =
+          getCapacity() != 0 ?
+            ((float) numSlotsOccupied * 100 / getCapacity()) : 0;
+      StringBuffer sb = new StringBuffer();
+      
+      sb.append("Capacity: " + capacity + " slots\n");
+      
+      if(getMaxCapacity() >= 0) {
+        sb.append("Maximum capacity: " + getMaxCapacity() +" slots\n");
+      }
+      sb.append(String.format("Used capacity: %d (%.1f%% of Capacity)\n",
+          Integer.valueOf(numSlotsOccupied), Float
+              .valueOf(occupiedSlotsAsPercent)));
+      sb.append(String.format("Running tasks: %d\n", Integer
+          .valueOf(numRunningTasks)));
+      // include info on active users
+      if (numSlotsOccupied != 0) {
+        sb.append("Active users:\n");
+        for (Map.Entry<String, Integer> entry : numSlotsOccupiedByUser
+            .entrySet()) {
+          if ((entry.getValue() == null) || (entry.getValue().intValue() <= 0)) {
+            // user has no tasks running
+            continue;
+          }
+          sb.append("User '" + entry.getKey() + "': ");
+          int numSlotsOccupiedByThisUser = entry.getValue().intValue();
+          float p =
+              (float) numSlotsOccupiedByThisUser * 100 / numSlotsOccupied;
+          sb.append(String.format("%d (%.1f%% of used capacity)\n", Long
+              .valueOf(numSlotsOccupiedByThisUser), Float.valueOf(p)));
+        }
+      }
+      return sb.toString();
+    }
+  
+    int getMaxCapacity() {
+      return maxCapacity;
+    }
+  
+    void setMaxCapacity(int maxCapacity) {
+      this.maxCapacity = maxCapacity;
+    }
+    
+    int getNumSlotsOccupiedByUser(String user) {
+      Integer slots = numSlotsOccupiedByUser.get(user);
+      return (slots != null) ? slots : 0;
+    }
+
+
+    void updateCapacities(float capacityPercent, float maxCapacityPercent, 
+                          int clusterCapacity) {
+      //compute new capacity
+      setCapacity((int)(capacityPercent*clusterCapacity/100));
+
+      //compute new max map capacities
+      if(maxCapacityPercent > 0) {
+        setMaxCapacity((int)(maxCapacityPercent*clusterCapacity / 100));
+      }
+    }
+    
+    void updateSlotsUsage(String user, int pendingTasks, int numRunningTasks, int numSlotsOccupied) {
+      this.numRunningTasks += numRunningTasks;
+      this.numSlotsOccupied += numSlotsOccupied;
+      Integer i = this.numSlotsOccupiedByUser.get(user);
+      int slots = numSlotsOccupied + ((i == null) ? 0 : i.intValue());
+      this.numSlotsOccupiedByUser.put(user, slots);
+      if (pendingTasks > 0) {
+        users.add(user);
+      }
+    }
+  }
+
+  // Queue name
+  final String queueName;
+
+  /**
+   * capacity(%) is set in the config
+   */
+  volatile float capacityPercent = 0;
+  
+  
+  /**
+   * maxCapacityPercent(%) is set in config as
+   * mapred.capacity-scheduler.<queue-name>.maximum-capacity
+   * maximum-capacity percent defines a limit beyond which a queue
+   * cannot expand. Remember this limit is dynamic and changes w.r.t
+   * cluster size.
+   */
+  volatile float maxCapacityPercent = -1;
+  
+  /** 
+   * to handle user limits, we need to know how many users have jobs in 
+   * the 
+   */  
+  Map<String, Integer> numJobsByUser = new HashMap<String, Integer>();
+    
+  /**
+   * min value of user limit (same for all users)
+   */
+  volatile int ulMin;
+
+  /**
+   * The factor of queue-capacity above which a single user can consume
+   * queue resources.
+   */
+  volatile float ulMinFactor;
+  
+  /**
+   * We keep a TaskSchedulingInfo object for each kind of task we support
+   */
+  CapacitySchedulerQueue.SlotsUsage mapSlots;
+  CapacitySchedulerQueue.SlotsUsage reduceSlots;
+  
+  /** 
+   * Whether the queue supports priorities.
+   */
+  final boolean supportsPriorities;
+  
+  /**
+   * Information required to track job, user, queue limits 
+   */
+  
+  Map<JobSchedulingInfo, JobInProgress> waitingJobs; // for waiting jobs
+  Map<JobSchedulingInfo, JobInProgress> initializingJobs; // for init'ing jobs
+  Map<JobSchedulingInfo, JobInProgress> runningJobs; // for running jobs
+  
+  /**
+   *  Active tasks in the queue
+   */
+  int activeTasks = 0;
+  
+  /**
+   *  Users in the queue
+   */
+  Map<String, UserInfo> users = new HashMap<String, UserInfo>();
+
+  /**
+   * Comparator for ordering jobs in this queue
+   */
+  public Comparator<JobSchedulingInfo> comparator;
+  
+  int maxJobsToInit;
+  int maxJobsToAccept;
+  int maxJobsPerUserToInit;
+  int maxJobsPerUserToAccept;
+  int maxActiveTasks;
+  int maxActiveTasksPerUser;
+
+  // comparator for jobs in queues that don't support priorities
+  private static final Comparator<JobSchedulingInfo> STARTTIME_JOB_COMPARATOR
+    = new Comparator<JobSchedulingInfo>() {
+    public int compare(JobSchedulingInfo o1, JobSchedulingInfo o2) {
+      // the job that started earlier wins
+      if (o1.getStartTime() < o2.getStartTime()) {
+        return -1;
+      } else {
+        return (o1.getStartTime() == o2.getStartTime() 
+                ? o1.getJobID().compareTo(o2.getJobID()) 
+                : 1);
+      }
+    }
+  };
+
+  public CapacitySchedulerQueue(String queueName, CapacitySchedulerConf conf) {
+    this.queueName = queueName;
+
+    // Do not allow changes to 'supportsPriorities'
+    supportsPriorities = conf.isPrioritySupported(queueName);
+
+    initializeQueue(conf);
+
+    if (supportsPriorities) {
+      // use the default priority-aware comparator
+      comparator = JobQueueJobInProgressListener.FIFO_JOB_QUEUE_COMPARATOR;
+    }
+    else {
+      comparator = STARTTIME_JOB_COMPARATOR;
+    }
+    this.waitingJobs = 
+      new TreeMap<JobSchedulingInfo, JobInProgress>(comparator);
+    this.initializingJobs =
+      new TreeMap<JobSchedulingInfo, JobInProgress>(comparator);
+    this.runningJobs = 
+      new TreeMap<JobSchedulingInfo, JobInProgress>(comparator);
+
+    this.mapSlots = new SlotsUsage();
+    this.reduceSlots = new SlotsUsage();    
+  }
+  
+  synchronized void init(float capacityPercent, float maxCapacityPercent,
+      int ulMin, float ulMinFactor,
+      int maxJobsToInit, int maxJobsPerUserToInit,
+      int maxActiveTasks, int maxActiveTasksPerUser,
+      int maxJobsToAccept, int maxJobsPerUserToAccept) {
+    this.capacityPercent = capacityPercent;
+    this.maxCapacityPercent = maxCapacityPercent;
+    this.ulMin = ulMin;
+    this.ulMinFactor = ulMinFactor;
+    
+    this.maxJobsToInit = maxJobsToInit;
+    this.maxJobsPerUserToInit = maxJobsPerUserToInit; 
+    this.maxActiveTasks = maxActiveTasks;
+    this.maxActiveTasksPerUser = maxActiveTasksPerUser; 
+    this.maxJobsToAccept = maxJobsToAccept;
+    this.maxJobsPerUserToAccept = maxJobsPerUserToAccept;
+    
+    LOG.info("Initializing '" + queueName + "' queue with " +
+        "cap=" + capacityPercent + ", " +
+        "maxCap=" + maxCapacityPercent + ", " +
+        "ulMin=" + ulMin + ", " +
+        "ulMinFactor=" + ulMinFactor + ", " +
+        "supportsPriorities=" + supportsPriorities + ", " +
+        "maxJobsToInit=" + maxJobsToInit + ", " +
+        "maxJobsToAccept=" + maxJobsToAccept + ", " +
+        "maxActiveTasks=" + maxActiveTasks + ", " +
+        "maxJobsPerUserToInit=" + maxJobsPerUserToInit + ", " +
+        "maxJobsPerUserToAccept=" + maxJobsPerUserToAccept + ", " +
+        "maxActiveTasksPerUser=" + maxActiveTasksPerUser
+    );
+    
+    // Sanity checks
+    if (maxActiveTasks < maxActiveTasksPerUser ||
+        maxJobsToInit < maxJobsPerUserToInit || 
+        maxJobsToAccept < maxJobsPerUserToAccept) {
+      throw new IllegalArgumentException("Illegal queue configuration for " +
+      		"queue '" + queueName + "'");
+    }
+  }
+  
+  synchronized void initializeQueue(CapacitySchedulerQueue other) {
+    init(other.capacityPercent, other.maxCapacityPercent, 
+        other.ulMin, other.ulMinFactor, 
+        other.maxJobsToInit, other.maxJobsPerUserToInit, 
+        other.maxActiveTasks, other.maxActiveTasksPerUser, 
+        other.maxJobsToAccept, other.maxJobsPerUserToAccept);
+  }
+  
+  synchronized void initializeQueue(CapacitySchedulerConf conf) {
+    float capacityPercent = conf.getCapacity(queueName);
+    float maxCapacityPercent = conf.getMaxCapacity(queueName);
+    int ulMin = conf.getMinimumUserLimitPercent(queueName);
+    float ulMinFactor = conf.getUserLimitFactor(queueName);
+    
+    int maxSystemJobs = conf.getMaxSystemJobs();
+    int maxJobsToInit = (int)Math.ceil(maxSystemJobs * capacityPercent/100.0);
+    int maxJobsPerUserToInit = 
+      (int)Math.ceil(maxSystemJobs * capacityPercent/100.0 * ulMin/100.0);
+    int maxActiveTasks = conf.getMaxInitializedActiveTasks(queueName);
+    int maxActiveTasksPerUser = 
+      conf.getMaxInitializedActiveTasksPerUser(queueName);
+
+    int jobInitToAcceptFactor = conf.getInitToAcceptJobsFactor(queueName);
+    int maxJobsToAccept = maxJobsToInit * jobInitToAcceptFactor;
+    int maxJobsPerUserToAccept = maxJobsPerUserToInit * jobInitToAcceptFactor;
+    
+    init(capacityPercent, maxCapacityPercent, 
+        ulMin, ulMinFactor, 
+        maxJobsToInit, maxJobsPerUserToInit, 
+        maxActiveTasks, maxActiveTasksPerUser, 
+        maxJobsToAccept, maxJobsPerUserToAccept);
+  }
+
+  /**
+   * @return the queueName
+   */
+  String getQueueName() {
+    return queueName;
+  }
+
+  /**
+   * @return the capacityPercent
+   */
+  float getCapacityPercent() {
+    return capacityPercent;
+  }
+
+  /**
+   * reset the variables associated with tasks
+   */
+  void resetSlotsUsage(TaskType taskType) {
+    if (taskType == TaskType.MAP) {
+      mapSlots.reset();
+    } else if (taskType == TaskType.REDUCE) {
+      reduceSlots.reset();
+    } else {    
+      throw new IllegalArgumentException("Illegal taskType=" + taskType);
+    }
+  }
+
+
+  /**
+   * Returns the actual capacity in terms of slots for the <code>taskType</code>.
+   * @param taskType
+   * @return actual capacity in terms of slots for the <code>taskType</code>
+   */
+  int getCapacity(TaskType taskType) {
+    if (taskType == TaskType.MAP) {
+      return mapSlots.getCapacity();
+    } else if (taskType == TaskType.REDUCE) {
+      return reduceSlots.getCapacity();
+    }
+
+    throw new IllegalArgumentException("Illegal taskType=" + taskType);
+  }
+
+  /**
+   * Get the number of running tasks of the given <code>taskType</code>.
+   * @param taskType
+   * @return
+   */
+  int getNumRunningTasks(TaskType taskType) {
+    if (taskType == TaskType.MAP) {
+      return mapSlots.getNumRunningTasks();
+    } else if (taskType == TaskType.REDUCE) {
+      return reduceSlots.getNumRunningTasks();
+    }
+    
+    throw new IllegalArgumentException("Illegal taskType=" + taskType);
+  }
+
+  /**
+   * Get number of slots occupied of the <code>taskType</code>.
+   * @param taskType
+   * @return number of slots occupied of the <code>taskType</code>
+   */
+  int getNumSlotsOccupied(TaskType taskType) {
+    if (taskType == TaskType.MAP) {
+      return mapSlots.getNumSlotsOccupied();
+    } else if (taskType == TaskType.REDUCE) {
+      return reduceSlots.getNumSlotsOccupied();
+    }
+    
+    throw new IllegalArgumentException("Illegal taskType=" + taskType);
+  }
+
+  /**
+   * Get maximum number of slots for the <code>taskType</code>.
+   * @param taskType
+   * @return maximum number of slots for the <code>taskType</code>
+   */
+  int getMaxCapacity(TaskType taskType) {
+    if (taskType == TaskType.MAP) {
+      return mapSlots.getMaxCapacity();
+    } else if (taskType == TaskType.REDUCE) {
+      return reduceSlots.getMaxCapacity();
+    }
+    
+    throw new IllegalArgumentException("Illegal taskType=" + taskType);
+  }
+
+  /**
+   * Get number of slots occupied by a <code>user</code> of 
+   * <code>taskType</code>.
+   * @param user
+   * @param taskType
+   * @return number of slots occupied by a <code>user</code> of 
+   *         <code>taskType</code>
+   */
+  int getNumSlotsOccupiedByUser(String user, TaskType taskType) {
+    if (taskType == TaskType.MAP) {
+      return mapSlots.getNumSlotsOccupiedByUser(user);
+    } else if (taskType == TaskType.REDUCE) {
+      return reduceSlots.getNumSlotsOccupiedByUser(user);
+    }
+    
+    throw new IllegalArgumentException("Illegal taskType=" + taskType);
+  }
+  
+  int getNumActiveUsersByTaskType(TaskType taskType) {
+    if (taskType == TaskType.MAP) {
+      return mapSlots.getNumActiveUsers();
+    } else if (taskType == TaskType.REDUCE) {
+      return reduceSlots.getNumActiveUsers();
+    }
+    
+    throw new IllegalArgumentException("Illegal taskType=" + taskType);
+  }
+  
+  /**
+   * A new job is added to the 
+   * @param job
+   */
+  void jobAdded(JobInProgress job) {
+    // update user-specific info
+    String user = job.getProfile().getUser();
+    
+    Integer i = numJobsByUser.get(user);
+    if (null == i) {
+      i = 1;
+      // set the count for running tasks to 0
+      mapSlots.numSlotsOccupiedByUser.put(user, 0);
+      reduceSlots.numSlotsOccupiedByUser.put(user, 0);
+    }
+    else {
+      i++;
+    }
+    numJobsByUser.put(user, i);
+  }
+  
+  int getNumJobsByUser(String user) {
+    Integer numJobs = numJobsByUser.get(user);
+    return (numJobs != null) ? numJobs : 0;
+  }
+  
+  /**
+   * A job from the queue has completed.
+   * @param job
+   */
+  void jobCompleted(JobInProgress job) {
+    String user = job.getProfile().getUser();
+    // update numJobsByUser
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("Job to be removed for user " + user);
+    }
+    Integer i = numJobsByUser.get(job.getProfile().getUser());
+    i--;  // i should never be null!
+    if (0 == i.intValue()) {
+      numJobsByUser.remove(user);
+      // remove job footprint from our TSIs
+      mapSlots.numSlotsOccupiedByUser.remove(user);
+      reduceSlots.numSlotsOccupiedByUser.remove(user);
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("No more jobs for user, number of users = " + 
+            numJobsByUser.size());
+      }
+    }
+    else {
+      numJobsByUser.put(user, i);
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("User still has " + i + " jobs, number of users = "
+                + numJobsByUser.size());
+      }
+    }
+  }
+  
+  /**
+   * Update queue usage.
+   * @param type
+   * @param user
+   * @param numRunningTasks
+   * @param numSlotsOccupied
+   */
+  void update(TaskType type, JobInProgress job, String user, 
+      int numRunningTasks, int numSlotsOccupied) {
+    if (type == TaskType.MAP) {
+      mapSlots.updateSlotsUsage(user, job.pendingMaps(), 
+          numRunningTasks, numSlotsOccupied);
+    } else if (type == TaskType.REDUCE) {
+      reduceSlots.updateSlotsUsage(user, job.pendingReduces(), 
+          numRunningTasks, numSlotsOccupied);
+    }
+  }
+  
+  /**
+   * Update queue usage across all running jobs.
+   * @param mapClusterCapacity
+   * @param reduceClusterCapacity
+   * @param mapScheduler
+   * @param reduceScheduler
+   */
+  void updateAll(int mapClusterCapacity, int reduceClusterCapacity, 
+      TaskSchedulingMgr mapScheduler, TaskSchedulingMgr reduceScheduler) {
+   // Compute new capacities for maps and reduces
+    mapSlots.updateCapacities(capacityPercent, maxCapacityPercent, 
+        mapClusterCapacity);
+    reduceSlots.updateCapacities(capacityPercent, maxCapacityPercent, 
+        reduceClusterCapacity);
+
+    // reset running/pending tasks, tasks per user
+    resetSlotsUsage(TaskType.MAP);
+    resetSlotsUsage(TaskType.REDUCE);
+    
+    Collection<JobInProgress> jobs = getRunningJobs(); // Safe to iterate since
+                                                       // we get a copy here
+    for (JobInProgress j : jobs) {
+      if (j.getStatus().getRunState() != JobStatus.RUNNING) {
+        continue;
+      }
+
+      int numMapsRunningForThisJob = mapScheduler.getRunningTasks(j);
+      int numReducesRunningForThisJob = reduceScheduler.getRunningTasks(j);
+      int numRunningMapSlots = 
+        numMapsRunningForThisJob * mapScheduler.getSlotsPerTask(j);
+      int numRunningReduceSlots =
+        numReducesRunningForThisJob * reduceScheduler.getSlotsPerTask(j);
+      int numMapSlotsForThisJob = mapScheduler.getSlotsOccupied(j);
+      int numReduceSlotsForThisJob = reduceScheduler.getSlotsOccupied(j);
+      int numReservedMapSlotsForThisJob = 
+        (mapScheduler.getNumReservedTaskTrackers(j) * 
+         mapScheduler.getSlotsPerTask(j)); 
+      int numReservedReduceSlotsForThisJob = 
+        (reduceScheduler.getNumReservedTaskTrackers(j) * 
+         reduceScheduler.getSlotsPerTask(j)); 
+      
+      j.setSchedulingInfo(
+          CapacityTaskScheduler.getJobQueueSchedInfo(numMapsRunningForThisJob, 
+              numRunningMapSlots,
+              numReservedMapSlotsForThisJob,
+              numReducesRunningForThisJob, 
+              numRunningReduceSlots,
+              numReservedReduceSlotsForThisJob));
+
+      update(TaskType.MAP, j, j.getProfile().getUser(), 
+          numMapsRunningForThisJob, numMapSlotsForThisJob);
+      update(TaskType.REDUCE, j, j.getProfile().getUser(), 
+          numReducesRunningForThisJob, numReduceSlotsForThisJob);
+
+      if (LOG.isDebugEnabled()) {
+        LOG.debug(String.format(queueName + " - updateQSI: job %s: run(m)=%d, "
+            + "occupied(m)=%d, run(r)=%d, occupied(r)=%d, finished(m)=%d,"
+            + " finished(r)=%d, failed(m)=%d, failed(r)=%d, "
+            + "spec(m)=%d, spec(r)=%d, total(m)=%d, total(r)=%d", j
+            .getJobID().toString(), Integer
+            .valueOf(numMapsRunningForThisJob), Integer
+            .valueOf(numMapSlotsForThisJob), Integer
+            .valueOf(numReducesRunningForThisJob), Integer
+            .valueOf(numReduceSlotsForThisJob), Integer.valueOf(j
+            .finishedMaps()), Integer.valueOf(j.finishedReduces()), Integer
+            .valueOf(j.failedMapTasks),
+            Integer.valueOf(j.failedReduceTasks), Integer
+                .valueOf(j.speculativeMapTasks), Integer
+                .valueOf(j.speculativeReduceTasks), Integer
+                .valueOf(j.numMapTasks), Integer.valueOf(j.numReduceTasks)));
+      }
+    }
+  }
+  
+  boolean doesQueueSupportPriorities() {
+    return supportsPriorities;
+  }
+
+  /**
+   * return information about the queue
+   *
+   * @return a String representing the information about the 
+   */
+  @Override
+  public String toString(){
+    // We print out the queue information first, followed by info
+    // on map and reduce tasks and job info
+    StringBuilder sb = new StringBuilder();
+    sb.append("Queue configuration\n");
+    sb.append("Capacity Percentage: ");
+    sb.append(capacityPercent);
+    sb.append("%\n");
+    sb.append("User Limit: " + ulMin + "%\n");
+    sb.append("Priority Supported: " +
+        (doesQueueSupportPriorities() ? "YES":"NO") + "\n");
+    sb.append("-------------\n");
+
+    sb.append("Map tasks\n");
+    sb.append(mapSlots.toString());
+    sb.append("-------------\n");
+    sb.append("Reduce tasks\n");
+    sb.append(reduceSlots.toString());
+    sb.append("-------------\n");
+    
+    sb.append("Job info\n");
+    sb.append("Number of Waiting Jobs: " + getNumWaitingJobs() + "\n");
+    sb.append("Number of Initializing Jobs: " + getNumInitializingJobs() + "\n");
+    sb.append("Number of users who have submitted jobs: " + 
+        numJobsByUser.size() + "\n");
+    return sb.toString();
+  }
+  
+  /**
+   * Functionality to deal with job initialization
+   */
+
+  
+  // per-user information
+  static class UserInfo {
+    
+    Map<JobSchedulingInfo, JobInProgress> waitingJobs; // for waiting jobs
+    Map<JobSchedulingInfo, JobInProgress> initializingJobs; // for init'ing jobs
+    Map<JobSchedulingInfo, JobInProgress> runningJobs; // for running jobs
+    
+    int activeTasks;
+    
+    public UserInfo(Comparator<JobSchedulingInfo> comparator) {
+      waitingJobs = new TreeMap<JobSchedulingInfo, JobInProgress>(comparator);
+      initializingJobs = new TreeMap<JobSchedulingInfo, JobInProgress>(comparator);
+      runningJobs = new TreeMap<JobSchedulingInfo, JobInProgress>(comparator);
+    }
+    
+    int getNumInitializingJobs() {
+      return initializingJobs.size();
+    }
+    
+    int getNumRunningJobs() {
+      return runningJobs.size();
+    }
+    
+    int getNumWaitingJobs() {
+      return waitingJobs.size();
+    }
+    
+    int getNumActiveTasks() {
+      return activeTasks;
+    }
+    
+    public void jobAdded(JobSchedulingInfo jobSchedInfo, JobInProgress job) {
+      waitingJobs.put(jobSchedInfo, job); 
+    }
+    
+    public void removeWaitingJob(JobSchedulingInfo jobSchedInfo) {
+      waitingJobs.remove(jobSchedInfo);
+    }
+    
+    public void jobInitializing(JobSchedulingInfo jobSchedInfo, 
+        JobInProgress job) {
+      if (!initializingJobs.containsKey(jobSchedInfo)) {
+        initializingJobs.put(jobSchedInfo, job);
+        activeTasks += job.desiredTasks();
+      }
+    }
+    
+    public void removeInitializingJob(JobSchedulingInfo jobSchedInfo) {
+      initializingJobs.remove(jobSchedInfo);
+    }
+    
+    public void jobInitialized(JobSchedulingInfo jobSchedInfo, 
+        JobInProgress job) {
+      runningJobs.put(jobSchedInfo, job);
+    }
+    
+    public void jobCompleted(JobSchedulingInfo jobSchedInfo, 
+        JobInProgress job) {
+      // It is *ok* to remove from runningJobs even if the job was never RUNNING
+      runningJobs.remove(jobSchedInfo);
+      activeTasks -= job.desiredTasks();
+    }
+    
+    boolean isInactive() {
+      return activeTasks == 0 && runningJobs.size() == 0  && 
+      waitingJobs.size() == 0 && initializingJobs.size() == 0;
+    }
+  }
+
+  synchronized Collection<JobInProgress> getWaitingJobs() {
+    return Collections.unmodifiableCollection(
+        new LinkedList<JobInProgress>(waitingJobs.values()));
+  }
+  
+  synchronized Collection<JobInProgress> getInitializingJobs() {
+    return Collections.unmodifiableCollection(
+        new LinkedList<JobInProgress>(initializingJobs.values()));
+  }
+  
+  synchronized Collection<JobInProgress> getRunningJobs() {
+    return Collections.unmodifiableCollection(
+        new LinkedList<JobInProgress>(runningJobs.values())); 
+  }
+  
+  synchronized int getNumActiveTasks() {
+    return activeTasks;
+  }
+  
+  synchronized int getNumRunningJobs() {
+    return runningJobs.size();
+  }
+  
+  synchronized int getNumInitializingJobs() {
+    return initializingJobs.size();
+  }
+  
+  synchronized int getNumInitializingJobsByUser(String user) {
+    UserInfo userInfo = users.get(user);
+    return (userInfo == null) ? 0 : userInfo.getNumInitializingJobs();
+  }
+  
+  synchronized int getNumRunningJobsByUser(String user) {
+    UserInfo userInfo = users.get(user);
+    return (userInfo == null) ? 0 : userInfo.getNumRunningJobs();
+  }
+
+  synchronized int getNumActiveTasksByUser(String user) {
+    UserInfo userInfo = users.get(user);
+    return (userInfo == null) ? 0 : userInfo.getNumActiveTasks();
+  }
+
+  synchronized int getNumWaitingJobsByUser(String user) {
+    UserInfo userInfo = users.get(user);
+    return (userInfo == null) ? 0 : userInfo.getNumWaitingJobs();
+  }
+
+  synchronized void addInitializingJob(JobInProgress job) {
+    JobSchedulingInfo jobSchedInfo = new JobSchedulingInfo(job);
+
+    if (!waitingJobs.containsKey(jobSchedInfo)) {
+      // Ideally this should have been an *assert*, but it can't be done
+      // since we make copies in getWaitingJobs which is used in 
+      // JobInitPoller.getJobsToInitialize
+      LOG.warn("Cannot find job " + job.getJobID() + 
+          " in list of waiting jobs!");
+      return;
+    }
+    
+    if (initializingJobs.containsKey(jobSchedInfo)) {
+      LOG.warn("job " + job.getJobID() + " already being init'ed in queue'" +
+          queueName + "'!");
+      return;
+    }
+
+    // Mark the job as running
+    initializingJobs.put(jobSchedInfo, job);
+
+    addJob(jobSchedInfo, job);
+    
+    if (LOG.isDebugEnabled()) {
+      String user = job.getProfile().getUser();
+      LOG.debug("addInitializingJob:" +
+          " job=" + job.getJobID() +
+          " user=" + user + 
+          " queue=" + queueName +
+          " qWaitJobs=" +  getNumWaitingJobs() +
+          " qInitJobs=" +  getNumInitializingJobs()+
+          " qRunJobs=" +  getNumRunningJobs() +
+          " qActiveTasks=" +  getNumActiveTasks() +
+          " uWaitJobs=" +  getNumWaitingJobsByUser(user) +
+          " uInitJobs=" +  getNumInitializingJobsByUser(user) +
+          " uRunJobs=" +  getNumRunningJobsByUser(user) +
+          " uActiveTasks=" +  getNumActiveTasksByUser(user)
+      );
+    }
+
+    // Remove the job from 'waiting' jobs list
+    removeWaitingJob(jobSchedInfo, JobStatus.PREP);
+  }
+  
+  synchronized JobInProgress removeInitializingJob(
+      JobSchedulingInfo jobSchedInfo, int runState) {
+    JobInProgress job = initializingJobs.remove(jobSchedInfo);
+    
+    if (job != null) {
+      String user = job.getProfile().getUser();
+      UserInfo userInfo = users.get(user);
+      userInfo.removeInitializingJob(jobSchedInfo);
+      
+      // Decrement counts if the job is killed _while_ it was selected for
+      // initialization, but aborted
+      // NOTE: addRunningJob calls removeInitializingJob with runState==RUNNING
+      if (runState != JobStatus.RUNNING) {
+        finishJob(jobSchedInfo, job);
+      }
+      
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("removeInitializingJob:" +
+            " job=" + job.getJobID() +
+            " user=" + user + 
+            " queue=" + queueName +
+            " qWaitJobs=" +  getNumWaitingJobs() +
+            " qInitJobs=" +  getNumInitializingJobs()+
+            " qRunJobs=" +  getNumRunningJobs() +
+            " qActiveTasks=" +  getNumActiveTasks() +
+            " uWaitJobs=" +  getNumWaitingJobsByUser(user) +
+            " uInitJobs=" +  getNumInitializingJobsByUser(user) +
+            " uRunJobs=" +  getNumRunningJobsByUser(user) +
+            " uActiveTasks=" +  getNumActiveTasksByUser(user)
+        );
+      }
+    }
+    
+    return job;
+  }
+  
+  synchronized void addRunningJob(JobInProgress job) {
+    JobSchedulingInfo jobSchedInfo = new JobSchedulingInfo(job);
+
+    if (runningJobs.containsKey(jobSchedInfo)) {
+      LOG.info("job " + job.getJobID() + " already running in queue'" +
+          queueName + "'!");
+      return;
+    }
+
+    // Mark the job as running
+    runningJobs.put(jobSchedInfo,job);
+
+    // Update user stats
+    String user = job.getProfile().getUser();
+    UserInfo userInfo = users.get(user);
+    userInfo.jobInitialized(jobSchedInfo, job);
+    
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("addRunningJob:" +
+          " job=" + job.getJobID() +
+          " user=" + user + 
+          " queue=" + queueName +
+          " qWaitJobs=" +  getNumWaitingJobs() +
+          " qInitJobs=" +  getNumInitializingJobs()+
+          " qRunJobs=" +  getNumRunningJobs() +
+          " qActiveTasks=" +  getNumActiveTasks() +
+          " uWaitJobs=" +  getNumWaitingJobsByUser(user) +
+          " uInitJobs=" +  getNumInitializingJobsByUser(user) +
+          " uRunJobs=" +  getNumRunningJobsByUser(user) +
+          " uActiveTasks=" +  getNumActiveTasksByUser(user)
+      );
+    }
+
+    // Remove from 'initializing' list
+    // Note that at this point job.status.state != RUNNING, 
+    // however, logically it is a reasonable state to pass in to ensure
+    // that removeInitializingJob doesn't double-decrement  
+    // the relevant queue/user counters
+    removeInitializingJob(jobSchedInfo, JobStatus.RUNNING);
+  }
+
+  synchronized private void addJob(JobSchedulingInfo jobSchedInfo,
+      JobInProgress job) {
+    // Update queue stats
+    activeTasks += job.desiredTasks();
+    
+    // Update user stats
+    String user = job.getProfile().getUser();
+    UserInfo userInfo = users.get(user);
+    userInfo.jobInitializing(jobSchedInfo, job);
+  }
+  
+  synchronized private void finishJob(JobSchedulingInfo jobSchedInfo,
+      JobInProgress job) {
+    // Update user stats
+    String user = job.getProfile().getUser();
+    UserInfo userInfo = users.get(user);
+    userInfo.jobCompleted(jobSchedInfo, job);
+    
+    if (userInfo.isInactive()) {
+      users.remove(userInfo);
+    }
+
+    // Update queue stats
+    activeTasks -= job.desiredTasks();
+  }
+  
+  synchronized JobInProgress removeRunningJob(JobSchedulingInfo jobSchedInfo, 
+      int runState) {
+    JobInProgress job = runningJobs.remove(jobSchedInfo); 
+
+    // We have to be careful, we might be trying to remove a job  
+    // which might not have been initialized
+    if (job != null) {
+      String user = job.getProfile().getUser();
+      finishJob(jobSchedInfo, job);
+      
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("removeRunningJob:" +
+            " job=" + job.getJobID() +
+            " user=" + user + 
+            " queue=" + queueName +
+            " qWaitJobs=" +  getNumWaitingJobs() +
+            " qInitJobs=" +  getNumInitializingJobs()+
+            " qRunJobs=" +  getNumRunningJobs() +
+            " qActiveTasks=" +  getNumActiveTasks() +
+            " uWaitJobs=" +  getNumWaitingJobsByUser(user) +
+            " uInitJobs=" +  getNumInitializingJobsByUser(user) +
+            " uRunJobs=" +  getNumRunningJobsByUser(user) +
+            " uActiveTasks=" +  getNumActiveTasksByUser(user)
+        );
+      }
+    }
+
+    return job;
+  }
+  
+  synchronized void addWaitingJob(JobInProgress job) throws IOException {
+    JobSchedulingInfo jobSchedInfo = new JobSchedulingInfo(job);
+    if (waitingJobs.containsKey(jobSchedInfo)) {
+      LOG.info("job " + job.getJobID() + " already waiting in queue '" + 
+          queueName + "'!");
+      return;
+    }
+    
+    String user = job.getProfile().getUser();
+
+    // Check acceptance limits
+    checkJobSubmissionLimits(job, user);
+    
+    waitingJobs.put(jobSchedInfo, job);
+    
+    // Update user stats
+    UserInfo userInfo = users.get(user);
+    if (userInfo == null) {
+      userInfo = new UserInfo(comparator);
+      users.put(user, userInfo);
+    }
+    userInfo.jobAdded(jobSchedInfo, job);
+    
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("addWaitingJob:" +
+          " job=" + job.getJobID() +
+          " user=" + user + 
+          " queue=" + queueName +
+          " qWaitJobs=" +  getNumWaitingJobs() +
+          " qInitJobs=" +  getNumInitializingJobs()+
+          " qRunJobs=" +  getNumRunningJobs() +
+          " qActiveTasks=" +  getNumActiveTasks() +
+          " uWaitJobs=" +  getNumWaitingJobsByUser(user) +
+          " uInitJobs=" +  getNumInitializingJobsByUser(user) +
+          " uRunJobs=" +  getNumRunningJobsByUser(user) +
+          " uActiveTasks=" +  getNumActiveTasksByUser(user)
+      );
+    }
+  }
+  
+  synchronized JobInProgress removeWaitingJob(JobSchedulingInfo jobSchedInfo, 
+      int unused) {
+    JobInProgress job = waitingJobs.remove(jobSchedInfo);
+    if (job != null) {
+      String user = job.getProfile().getUser();
+      UserInfo userInfo = users.get(user);
+      userInfo.removeWaitingJob(jobSchedInfo);
+
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("removeWaitingJob:" +
+            " job=" + job.getJobID() +
+            " user=" + user + 
+            " queue=" + queueName +
+            " qWaitJobs=" +  getNumWaitingJobs() +
+            " qInitJobs=" +  getNumInitializingJobs()+
+            " qRunJobs=" +  getNumRunningJobs() +
+            " qActiveTasks=" +  getNumActiveTasks() +
+            " uWaitJobs=" +  getNumWaitingJobsByUser(user) +
+            " uInitJobs=" +  getNumInitializingJobsByUser(user) +
+            " uRunJobs=" +  getNumRunningJobsByUser(user) +
+            " uActiveTasks=" +  getNumActiveTasksByUser(user)
+        );
+      }
+    }
+    
+    return job;
+  }
+
+  synchronized int getNumActiveUsers() {
+    return users.size();
+  }
+  
+  synchronized int getNumWaitingJobs() {
+    return waitingJobs.size(); 
+  } 
+  
+  Comparator<JobSchedulingInfo> getComparator() {
+    return comparator;
+  }
+  
+  /**
+   * Functions to deal with queue-limits.
+   */
+  
+  /**
+   * Check if the queue can be assigned <code>numSlots</code> 
+   * of the given <code>taskType</code> so that the queue doesn't exceed its
+   * configured maximum-capacity.
+   * 
+   * @param taskType
+   * @param numSlots
+   * @return <code>true</code> if slots can be assigned
+   */
+  boolean assignSlotsToQueue(TaskType taskType, int numSlots) {
+    // Check if the queue is running over it's maximum-capacity
+    if (getMaxCapacity(taskType) > 0) {  // Check if max capacity is enabled
+        if ((getNumSlotsOccupied(taskType) + numSlots) > 
+             getMaxCapacity(taskType)) {
+          if (LOG.isDebugEnabled()) {
+            LOG.debug(
+                "Queue " + queueName + " " + "has reached its  max " + 
+                taskType + " capacity");
+            LOG.debug("Current running tasks " + getCapacity(taskType));
+          }
+          return false;
+        }
+      }
+    
+    return true;
+  }
+  /**
+   * Check if the given <code>job</code> and <code>user</code> and 
+   * queue can be assigned the requested number of slots of 
+   * the given <code>taskType</code> for the .
+   * 
+   * This checks to ensure that queue and user are under appropriate limits.
+   * 
+   * @param taskType
+   * @param job
+   * @param user
+   * @return <code>true</code> if the given job/user/queue can be assigned 
+   * the requested number of slots, <code>false</code> otherwise
+   */
+  boolean assignSlotsToJob(TaskType taskType, JobInProgress job, String user) {
+    int numSlotsRequested = job.getNumSlotsPerTask(taskType);
+    
+    // Check to ensure we will not go over the queue's max-capacity
+    if (!assignSlotsToQueue(taskType, numSlotsRequested)) {
+      return false;
+    }
+    
+    // What is our current capacity? 
+    // * It is equal to the max(numSlotsRequested queue-capacity) if
+    //   we're running below capacity. The 'max' ensures that jobs in queues
+    //   with miniscule capacity (< 1 slot) make progress
+    // * If we're running over capacity, then its
+    //   #running plus slotPerTask of the job (which is the number of extra
+    //   slots we're getting).
+    
+    // Allow progress for queues with miniscule capacity
+    int queueCapacity = Math.max(getCapacity(taskType), numSlotsRequested);
+    
+    int queueSlotsOccupied = getNumSlotsOccupied(taskType);
+    int currentCapacity;
+    if (queueSlotsOccupied < queueCapacity) {
+      currentCapacity = queueCapacity;
+    }
+    else {
+      currentCapacity = queueSlotsOccupied + numSlotsRequested;
+    }
+    
+    // Never allow a single user to take more than the 
+    // queue's configured capacity * user-limit-factor.
+    // Also, the queue's configured capacity should be higher than 
+    // queue-hard-limit * ulMin
+    
+    // All users in this queue might not need any slots of type 'taskType'
+    int activeUsers = Math.max(1, getNumActiveUsersByTaskType(taskType));  
+    
+    int limit = 
+      Math.min(
+          Math.max(divideAndCeil(currentCapacity, activeUsers), 
+                   divideAndCeil(ulMin*currentCapacity, 100)),
+          (int)(queueCapacity * ulMinFactor)
+          );
+
+    if ((getNumSlotsOccupiedByUser(user, taskType) + numSlotsRequested) > 
+        limit) {
+      if (LOG.isDebugEnabled()) {
+        LOG.debug("User " + user + " is over limit for queue=" + queueName + 
+            " queueCapacity=" + queueCapacity +
+            " num slots occupied=" + getNumSlotsOccupiedByUser(user, taskType) + 
+            " limit=" + limit +" numSlotsRequested=" + numSlotsRequested + 
+            " currentCapacity=" + currentCapacity + 
+            " numActiveUsers=" + getNumActiveUsersByTaskType(taskType));
+      }
+      return false;
+    }
+
+    return true;
+  }
+  
+  /**
+   * Ceil of result of dividing two integers.
+   * 
+   * This is *not* a utility method. 
+   * Neither <code>a</code> or <code>b</code> should be negative.
+   *  
+   * @param a
+   * @param b
+   * @return ceil of the result of a/b
+   */
+  private static int divideAndCeil(int a, int b) {
+    if (b == 0) {
+      LOG.info("divideAndCeil called with a=" + a + " b=" + b);
+      return 0;
+    }
+    return (a + (b - 1)) / b;
+  }
+
+  /**
+   * Check if the given <code>job</code> can be accepted to the 
+   * queue on behalf of the <code>user</code>.
+   * @param job 
+   * @param user
+   * @return <code>true</code> if the job can be accepted, 
+   *         <code>false</code> otherwise
+   */
+  synchronized void checkJobSubmissionLimits(JobInProgress job, String user) 
+  throws IOException {
+    if (LOG.isDebugEnabled()) {
+      LOG.debug("checkJobSubmissionLimits - " +
+          "qWaitJobs=" + getNumWaitingJobs() + " " +
+          "qInitJobs=" + getNumInitializingJobs() + " " +
+          "qRunJobs=" + getNumRunningJobs() + " " +
+          "maxJobsToAccept=" + maxJobsToAccept +
+          "user=" + user + " " +
+          "uWaitJobs=" +  getNumWaitingJobsByUser(user) + " " +
+          "uRunJobs=" + getNumRunningJobsByUser(user)  + " " +
+          "maxJobsPerUserToAccept=" + maxJobsPerUserToAccept + " " +
+          "");
+    }
+    
+    // Task limits - No point accepting the job if it can never be initialized
+    if (job.desiredTasks() > maxActiveTasksPerUser) {
+      throw new IOException(
+          "Job '" + job.getJobID() + "' from user '" + user  +
+          "' rejected since it has " + job.desiredTasks() + " tasks which" +
+          " exceeds the limit of " + maxActiveTasksPerUser + 
+          " tasks per-user which can be initialized for queue '" + 
+          queueName + "'"
+          );
+    }
+    
+    // Across all jobs in queue
+    int queueWaitingJobs = getNumWaitingJobs();
+    int queueInitializingJobs = getNumInitializingJobs();
+    int queueRunningJobs = getNumRunningJobs();
+    if ((queueWaitingJobs + queueInitializingJobs + queueRunningJobs) >= 
+      maxJobsToAccept) {
+      throw new IOException(
+          "Job '" + job.getJobID() + "' from user '" + user  + 
+          "' rejected since queue '" + queueName + 
+          "' already has " + queueWaitingJobs + " waiting jobs, " + 
+          queueInitializingJobs + " initializing jobs and " + 
+          queueRunningJobs + " running jobs - Exceeds limit of " +
+          maxJobsToAccept + " jobs to accept");
+    }
+    
+    // Across all jobs of the user
+    int userWaitingJobs = getNumWaitingJobsByUser(user);
+    int userInitializingJobs = getNumInitializingJobsByUser(user);
+    int userRunningJobs = getNumRunningJobsByUser(user);
+    if ((userWaitingJobs + userInitializingJobs + userRunningJobs) >= 
+        maxJobsPerUserToAccept) {
+      throw new IOException(
+          "Job '" + job.getJobID() + "' rejected since user '" + user +  
+          "' already has " + userWaitingJobs + " waiting jobs, " +
+          userInitializingJobs + " initializing jobs and " +
+          userRunningJobs + " running jobs - " +
+          " Exceeds limit of " + maxJobsPerUserToAccept + " jobs to accept" +
+          " in queue '" + queueName + "' per user");
+    }
+  }
+  
+  /**
+   * Check if the <code>job</code> can be initialized in the queue.
+   * 
+   * @param job
+   * @return <code>true</code> if the job can be initialized, 
+   *         <code>false</code> otherwise
+   */
+  synchronized boolean initializeJobForQueue(JobInProgress job) {
+    
+    // Check if queue has sufficient number of jobs
+    int runningJobs = getNumRunningJobs();
+    int initializingJobs = getNumInitializingJobs();
+    if ((runningJobs + initializingJobs) >= maxJobsToInit) {
+      LOG.info(getQueueName() + " already has " + runningJobs + 
+          " running jobs and " + initializingJobs + " initializing jobs;" +
+          " cannot initialize " + job.getJobID() + 
+          " since it will exceeed limit of " + maxJobsToInit + 
+          " initialized jobs for this queue");
+      return false;
+    }
+    
+    // Check if queue has too many active tasks
+    if ((activeTasks + job.desiredTasks()) > maxActiveTasks) {
+      LOG.info("Queue '" + getQueueName() + "' has " + activeTasks + 
+          " active tasks, cannot initialize job '" + job.getJobID() + 
+          "' for user '" + job.getProfile().getUser() + "' with " +
+          job.desiredTasks() + " tasks since it will exceed limit of " + 
+          maxActiveTasks + " active tasks for this queue");
+      return false;
+    }
+    
+    return true;
+  }
+  
+  /**
+   * Check if the <code>job</code> can be initialized in the queue
+   * on behalf of the <code>user</code>.
+   * 
+   * @param job
+   * @return <code>true</code> if the job can be initialized, 
+   *         <code>false</code> otherwise
+   */
+  synchronized boolean initializeJobForUser(JobInProgress job) {
+    
+    String user = job.getProfile().getUser();
+    
+    // Check if the user has too many jobs
+    int userRunningJobs = getNumRunningJobsByUser(user);
+    int userInitializingJobs = getNumInitializingJobsByUser(user);
+    if ((userRunningJobs + userInitializingJobs) >= maxJobsPerUserToInit) {
+      LOG.info(getQueueName() + " already has " + userRunningJobs + 
+          " running jobs and " + userInitializingJobs + " initializing jobs" +
+          " for user " + user + "; cannot initialize " + job.getJobID() + 
+          " since it will exceeed limit of " + 
+          maxJobsPerUserToInit + " initialized jobs per user for this queue");
+      return false;
+    }
+    
+    // Check if the user has too many active tasks
+    int userActiveTasks = getNumActiveTasksByUser(user);
+    if ((userActiveTasks + job.desiredTasks()) > maxActiveTasksPerUser) {
+      LOG.info(getQueueName() + " has " + userActiveTasks + 
+          " active tasks for user " + user + 
+          ", cannot initialize " + job.getJobID() + " with " +
+          job.desiredTasks() + " tasks since it will exceed limit of " + 
+          maxActiveTasksPerUser + " active tasks per user for this queue");
+      return false;
+    }
+    
+    return true;
+  }
+
+}
diff --git a/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/CapacityTaskScheduler.java b/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/CapacityTaskScheduler.java
index bee9123..5f23074 100644
--- a/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/CapacityTaskScheduler.java
+++ b/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/CapacityTaskScheduler.java
@@ -57,219 +57,9 @@ import org.apache.hadoop.mapreduce.server.jobtracker.TaskTracker;
 class CapacityTaskScheduler extends TaskScheduler {
 
 
-  /***********************************************************************
-   * Keeping track of scheduling information for queues
-   * 
-   * We need to maintain scheduling information relevant to a queue (its 
-   * name, capacity, etc), along with information specific to 
-   * each kind of task, Map or Reduce (num of running tasks, pending 
-   * tasks etc). 
-   * 
-   * This scheduling information is used to decide how to allocate
-   * tasks, redistribute capacity, etc.
-   *  
-   * A QueueSchedulingInfo(QSI) object represents scheduling information for
-   * a queue. A TaskSchedulingInfo (TSI) object represents scheduling 
-   * information for a particular kind of task (Map or Reduce).
-   *   
-   **********************************************************************/
-
-  private static class TaskSchedulingInfo {
-
-    /** 
-     * the actual capacity, which depends on how many slots are available
-     * in the cluster at any given time. 
-     */
-    private int capacity = 0;
-    // number of running tasks
-    int numRunningTasks = 0;
-    // number of slots occupied by running tasks
-    int numSlotsOccupied = 0;
-
-    //the actual maximum capacity which depends on how many slots are available
-    //in cluster at any given time.
-    private int maxCapacity = -1;
-
-    /**
-     * for each user, we need to keep track of number of slots occupied by
-     * running tasks
-     */
-    Map<String, Integer> numSlotsOccupiedByUser = 
-      new HashMap<String, Integer>();
-
-    /**
-     * reset the variables associated with tasks
-     */
-    void resetTaskVars() {
-      numRunningTasks = 0;
-      numSlotsOccupied = 0;
-      for (String s: numSlotsOccupiedByUser.keySet()) {
-        numSlotsOccupiedByUser.put(s, Integer.valueOf(0));
-      }
-    }
-
-
-    /**
-     * Returns the actual capacity.
-     * capacity.
-     *
-     * @return
-     */
-    int getCapacity() {
-      return capacity;
-    }
-
-    /**
-     * Mutator method for capacity
-     *
-     * @param capacity
-     */
-    void setCapacity(int capacity) {
-        this.capacity = capacity;
-    }
-
-
-    /**
-     * return information about the tasks
-     */
-    @Override
-    public String toString() {
-      float occupiedSlotsAsPercent =
-          getCapacity() != 0 ?
-            ((float) numSlotsOccupied * 100 / getCapacity()) : 0;
-      StringBuffer sb = new StringBuffer();
-      
-      sb.append("Capacity: " + capacity + " slots\n");
-      
-      if(getMaxCapacity() >= 0) {
-        sb.append("Maximum capacity: " + getMaxCapacity() +" slots\n");
-      }
-      sb.append(String.format("Used capacity: %d (%.1f%% of Capacity)\n",
-          Integer.valueOf(numSlotsOccupied), Float
-              .valueOf(occupiedSlotsAsPercent)));
-      sb.append(String.format("Running tasks: %d\n", Integer
-          .valueOf(numRunningTasks)));
-      // include info on active users
-      if (numSlotsOccupied != 0) {
-        sb.append("Active users:\n");
-        for (Map.Entry<String, Integer> entry : numSlotsOccupiedByUser
-            .entrySet()) {
-          if ((entry.getValue() == null) || (entry.getValue().intValue() <= 0)) {
-            // user has no tasks running
-            continue;
-          }
-          sb.append("User '" + entry.getKey() + "': ");
-          int numSlotsOccupiedByThisUser = entry.getValue().intValue();
-          float p =
-              (float) numSlotsOccupiedByThisUser * 100 / numSlotsOccupied;
-          sb.append(String.format("%d (%.1f%% of used capacity)\n", Long
-              .valueOf(numSlotsOccupiedByThisUser), Float.valueOf(p)));
-        }
-      }
-      return sb.toString();
-    }
-
-    int getMaxCapacity() {
-      return maxCapacity;
-    }
-
-    void setMaxCapacity(int maxCapacity) {
-      this.maxCapacity = maxCapacity;
-    }
-  }
-  
-  private static class QueueSchedulingInfo {
-    String queueName;
-
-    /**
-     * capacity(%) is set in the config
-     */
-    float capacityPercent = 0;
-    
-    
-  /**
-   * maxCapacityPercent(%) is set in config as
-   * mapred.capacity-scheduler.queue.<queue-name>.maximum-capacity
-   * maximum-capacity percent defines a limit beyond which a queue
-   * cannot expand. Remember this limit is dynamic and changes w.r.t
-   * cluster size.
-   */
-    float maxCapacityPercent = -1;
-    /** 
-     * to handle user limits, we need to know how many users have jobs in 
-     * the queue.
-     */  
-    Map<String, Integer> numJobsByUser = new HashMap<String, Integer>();
-      
-    /**
-     * min value of user limit (same for all users)
-     */
-    int ulMin;
-    
-    /**
-     * We keep track of the JobQueuesManager only for reporting purposes 
-     * (in toString()). 
-     */
-    private JobQueuesManager jobQueuesManager;
-    
-    /**
-     * We keep a TaskSchedulingInfo object for each kind of task we support
-     */
-    TaskSchedulingInfo mapTSI;
-    TaskSchedulingInfo reduceTSI;
-    
-    public QueueSchedulingInfo(
-      String queueName, float capacityPercent,
-      float maxCapacityPercent, int ulMin, JobQueuesManager jobQueuesManager
-    ) {
-      this.queueName = new String(queueName);
-      this.capacityPercent = capacityPercent;
-      this.maxCapacityPercent = maxCapacityPercent;
-      this.ulMin = ulMin;
-      this.jobQueuesManager = jobQueuesManager;
-      this.mapTSI = new TaskSchedulingInfo();
-      this.reduceTSI = new TaskSchedulingInfo();
-    }
-    
-    /**
-     * return information about the queue
-     *
-     * @return a String representing the information about the queue.
-     */
-    @Override
-    public String toString(){
-      // We print out the queue information first, followed by info
-      // on map and reduce tasks and job info
-      StringBuffer sb = new StringBuffer();
-      sb.append("Queue configuration\n");
-      sb.append("Capacity Percentage: ");
-      sb.append(capacityPercent);
-      sb.append("%\n");
-      sb.append(String.format("User Limit: %d%s\n",ulMin, "%"));
-      sb.append(String.format("Priority Supported: %s\n",
-          (jobQueuesManager.doesQueueSupportPriorities(queueName))?
-              "YES":"NO"));
-      sb.append("-------------\n");
-
-      sb.append("Map tasks\n");
-      sb.append(mapTSI.toString());
-      sb.append("-------------\n");
-      sb.append("Reduce tasks\n");
-      sb.append(reduceTSI.toString());
-      sb.append("-------------\n");
-      
-      sb.append("Job info\n");
-      sb.append(String.format("Number of Waiting Jobs: %d\n", 
-          jobQueuesManager.getWaitingJobCount(queueName)));
-      sb.append(String.format("Number of users who have submitted jobs: %d\n", 
-          numJobsByUser.size()));
-      return sb.toString();
-    }
-  }
-
-  /** quick way to get qsi object given a queue name */
-  private Map<String, QueueSchedulingInfo> queueInfoMap = 
-    new HashMap<String, QueueSchedulingInfo>();
+  /** quick way to get Queue object given a queue name */
+  Map<String, CapacitySchedulerQueue> queueInfoMap = 
+    new HashMap<String, CapacitySchedulerQueue>();
   
   /**
    * This class captures scheduling information we want to display or log.
@@ -285,12 +75,12 @@ class CapacityTaskScheduler extends TaskScheduler {
     
     @Override
     public String toString(){
-      // note that we do not call updateQSIObjects() here for performance
+      // note that we do not call updateAllQueues() here for performance
       // reasons. This means that the data we print out may be slightly
       // stale. This data is updated whenever assignTasks() is called
       // If this doesn't happen, the data gets stale. If we see
       // this often, we may need to detect this situation and call 
-      // updateQSIObjects(), or just call it each time. 
+      // updateAllQueues(), or just call it each time. 
       return scheduler.getDisplayInfo(queueName);
     }
   }
@@ -299,28 +89,32 @@ class CapacityTaskScheduler extends TaskScheduler {
   private static class TaskLookupResult {
 
     static enum LookUpStatus {
-      TASK_FOUND,
+      LOCAL_TASK_FOUND,
       NO_TASK_FOUND,
       TASK_FAILING_MEMORY_REQUIREMENT,
+      OFF_SWITCH_TASK_FOUND
     }
     // constant TaskLookupResult objects. Should not be accessed directly.
     private static final TaskLookupResult NoTaskLookupResult = 
-      new TaskLookupResult(null, TaskLookupResult.LookUpStatus.NO_TASK_FOUND);
+      new TaskLookupResult(null, null, 
+          TaskLookupResult.LookUpStatus.NO_TASK_FOUND);
     private static final TaskLookupResult MemFailedLookupResult = 
-      new TaskLookupResult(null, 
+      new TaskLookupResult(null, null,
           TaskLookupResult.LookUpStatus.TASK_FAILING_MEMORY_REQUIREMENT);
 
     private LookUpStatus lookUpStatus;
     private Task task;
-
+    private JobInProgress job;
+    
     // should not call this constructor directly. use static factory methods.
-    private TaskLookupResult(Task t, LookUpStatus lUStatus) {
+    private TaskLookupResult(Task t, JobInProgress job, LookUpStatus lUStatus) {
       this.task = t;
+      this.job = job;
       this.lookUpStatus = lUStatus;
     }
     
-    static TaskLookupResult getTaskFoundResult(Task t) {
-      return new TaskLookupResult(t, LookUpStatus.TASK_FOUND);
+    static TaskLookupResult getTaskFoundResult(Task t, JobInProgress job) {
+      return new TaskLookupResult(t, job, LookUpStatus.LOCAL_TASK_FOUND);
     }
     static TaskLookupResult getNoTaskFoundResult() {
       return NoTaskLookupResult;
@@ -328,12 +122,19 @@ class CapacityTaskScheduler extends TaskScheduler {
     static TaskLookupResult getMemFailedResult() {
       return MemFailedLookupResult;
     }
-    
+    static TaskLookupResult getOffSwitchTaskFoundResult(Task t, 
+                                                        JobInProgress job) {
+      return new TaskLookupResult(t, job, LookUpStatus.OFF_SWITCH_TASK_FOUND);
+    }
 
     Task getTask() {
       return task;
     }
 
+    JobInProgress getJob() {
+      return job;
+    }
+    
     LookUpStatus getLookUpStatus() {
       return lookUpStatus;
     }
@@ -351,8 +152,8 @@ class CapacityTaskScheduler extends TaskScheduler {
     protected CapacityTaskScheduler scheduler;
     protected TaskType type = null;
 
-    abstract Task obtainNewTask(TaskTrackerStatus taskTracker, 
-        JobInProgress job) throws IOException;
+    abstract TaskLookupResult obtainNewTask(TaskTrackerStatus taskTracker, 
+        JobInProgress job, boolean assignOffSwitch) throws IOException;
 
     int getSlotsOccupied(JobInProgress job) {
       return (getNumReservedTaskTrackers(job) + getRunningTasks(job)) * 
@@ -363,7 +164,6 @@ class CapacityTaskScheduler extends TaskScheduler {
     abstract int getSlotsPerTask(JobInProgress job);
     abstract int getRunningTasks(JobInProgress job);
     abstract int getPendingTasks(JobInProgress job);
-    abstract TaskSchedulingInfo getTSI(QueueSchedulingInfo qsi);
     abstract int getNumReservedTaskTrackers(JobInProgress job);
     
     /**
@@ -389,13 +189,13 @@ class CapacityTaskScheduler extends TaskScheduler {
     }
     
     /**
-     * List of QSIs for assigning tasks.
+     * List of Queues for assigning tasks.
      * Queues are ordered by a ratio of (# of running tasks)/capacity, which
      * indicates how much 'free space' the queue has, or how much it is over
      * capacity. This ordered list is iterated over, when assigning tasks.
      */  
-    private List<QueueSchedulingInfo> qsiForAssigningTasks = 
-      new ArrayList<QueueSchedulingInfo>();
+    private List<CapacitySchedulerQueue> queuesForAssigningTasks = 
+      new ArrayList<CapacitySchedulerQueue>();
 
     /**
      * Comparator to sort queues.
@@ -403,33 +203,37 @@ class CapacityTaskScheduler extends TaskScheduler {
      * reducers, we use reduceTSI. So we'll need separate comparators.  
      */ 
     private static abstract class QueueComparator 
-      implements Comparator<QueueSchedulingInfo> {
-      abstract TaskSchedulingInfo getTSI(QueueSchedulingInfo qsi);
-      public int compare(QueueSchedulingInfo q1, QueueSchedulingInfo q2) {
-        TaskSchedulingInfo t1 = getTSI(q1);
-        TaskSchedulingInfo t2 = getTSI(q2);
+      implements Comparator<CapacitySchedulerQueue> {
+      abstract TaskType getTaskType();
+      
+      public int compare(CapacitySchedulerQueue q1, CapacitySchedulerQueue q2) {
         // look at how much capacity they've filled. Treat a queue with
         // capacity=0 equivalent to a queue running at capacity
-        double r1 = (0 == t1.getCapacity())? 1.0f:
-          (double)t1.numSlotsOccupied/(double) t1.getCapacity();
-        double r2 = (0 == t2.getCapacity())? 1.0f:
-          (double)t2.numSlotsOccupied/(double) t2.getCapacity();
+        TaskType taskType = getTaskType();
+        double r1 = (0 == q1.getCapacity(taskType))? 1.0f:
+          (double)q1.getNumSlotsOccupied(taskType)/(double) q1.getCapacity(taskType);
+        double r2 = (0 == q2.getCapacity(taskType))? 1.0f:
+          (double)q2.getNumSlotsOccupied(taskType)/(double) q2.getCapacity(taskType);
         if (r1<r2) return -1;
         else if (r1>r2) return 1;
         else return 0;
       }
     }
+    
     // subclass for map and reduce comparators
     private static final class MapQueueComparator extends QueueComparator {
-      TaskSchedulingInfo getTSI(QueueSchedulingInfo qsi) {
-        return qsi.mapTSI;
+      @Override
+      TaskType getTaskType() {
+        return TaskType.MAP;
       }
     }
     private static final class ReduceQueueComparator extends QueueComparator {
-      TaskSchedulingInfo getTSI(QueueSchedulingInfo qsi) {
-        return qsi.reduceTSI;
+      @Override
+      TaskType getTaskType() {
+        return TaskType.REDUCE;
       }
     }
+    
     // these are our comparator instances
     protected final static MapQueueComparator mapComparator = new MapQueueComparator();
     protected final static ReduceQueueComparator reduceComparator = new ReduceQueueComparator();
@@ -439,9 +243,9 @@ class CapacityTaskScheduler extends TaskScheduler {
     // Returns queues sorted according to the QueueComparator.
     // Mainly for testing purposes.
     String[] getOrderedQueues() {
-      List<String> queues = new ArrayList<String>(qsiForAssigningTasks.size());
-      for (QueueSchedulingInfo qsi : qsiForAssigningTasks) {
-        queues.add(qsi.queueName);
+      List<String> queues = new ArrayList<String>(queuesForAssigningTasks.size());
+      for (CapacitySchedulerQueue queue : queuesForAssigningTasks) {
+        queues.add(queue.queueName);
       }
       return queues.toArray(new String[queues.size()]);
     }
@@ -451,14 +255,15 @@ class CapacityTaskScheduler extends TaskScheduler {
     }
     
     // let the scheduling mgr know which queues are in the system
-    void initialize(Map<String, QueueSchedulingInfo> qsiMap) { 
-      // add all the qsi objects to our list and sort
-      qsiForAssigningTasks.addAll(qsiMap.values());
-      Collections.sort(qsiForAssigningTasks, queueComparator);
+    void initialize(Map<String, CapacitySchedulerQueue> queues) { 
+      // add all the queue objects to our list and sort
+      queuesForAssigningTasks.clear();
+      queuesForAssigningTasks.addAll(queues.values());
+      Collections.sort(queuesForAssigningTasks, queueComparator);
     }
     
-    private synchronized void updateCollectionOfQSIs() {
-      Collections.sort(qsiForAssigningTasks, queueComparator);
+    private synchronized void sortQueues() {
+      Collections.sort(queuesForAssigningTasks, queueComparator);
     }
 
     /**
@@ -479,74 +284,49 @@ class CapacityTaskScheduler extends TaskScheduler {
       return (a + (b - 1)) / b;
     }
     
-    private boolean isUserOverLimit(JobInProgress j, QueueSchedulingInfo qsi) {
-      // what is our current capacity? It is equal to the queue-capacity if
-      // we're running below capacity. If we're running over capacity, then its
-      // #running plus slotPerTask of the job (which is the number of extra
-      // slots we're getting).
-      int currentCapacity;
-      TaskSchedulingInfo tsi = getTSI(qsi);
-      if (tsi.numSlotsOccupied < tsi.getCapacity()) {
-        currentCapacity = tsi.getCapacity();
-      }
-      else {
-        currentCapacity = tsi.numSlotsOccupied + getSlotsPerTask(j);
-      }
-      int limit = 
-        Math.max(divideAndCeil(currentCapacity, qsi.numJobsByUser.size()), 
-                 divideAndCeil(qsi.ulMin*currentCapacity, 100));
-      String user = j.getProfile().getUser();
-      if (tsi.numSlotsOccupiedByUser.get(user) >= limit) {
-        if (LOG.isDebugEnabled()) {
-          LOG.debug("User " + user + " is over limit, num slots occupied=" + 
-                    tsi.numSlotsOccupiedByUser.get(user) + ", limit=" + limit);
-        }
-        return true;
-      }
-      else {
-        return false;
-      }
-    }
-
     /*
      * This is the central scheduling method. 
      * It tries to get a task from jobs in a single queue. 
      * Always return a TaskLookupResult object. Don't return null. 
      */
     private TaskLookupResult getTaskFromQueue(TaskTracker taskTracker,
-                                              QueueSchedulingInfo qsi)
+                                              int availableSlots,
+                                              CapacitySchedulerQueue queue,
+                                              boolean assignOffSwitch)
     throws IOException {
       TaskTrackerStatus taskTrackerStatus = taskTracker.getStatus();
       // we only look at jobs in the running queues, as these are the ones
       // who have been potentially initialized
 
-      for (JobInProgress j : 
-        scheduler.jobQueuesManager.getRunningJobQueue(qsi.queueName)) {
+      for (JobInProgress j : queue.getRunningJobs()) {
         // only look at jobs that can be run. We ignore jobs that haven't 
         // initialized, or have completed but haven't been removed from the 
         // running queue. 
         if (j.getStatus().getRunState() != JobStatus.RUNNING) {
           continue;
         }
-        //Check if queue is over maximum-capacity
-        if(this.areTasksInQueueOverMaxCapacity(qsi,j.getNumSlotsPerTask(type))) {
+        
+        // Check to ensure that the job/user/queue are under limits
+        if (!queue.assignSlotsToJob(type, j, j.getProfile().getUser())) {
           continue;
         }
-        // check if the job's user is over limit
-        if (isUserOverLimit(j, qsi)) {
-          continue;
-        } 
+
         //If this job meets memory requirements. Ask the JobInProgress for
         //a task to be scheduled on the task tracker.
         //if we find a job then we pass it on.
         if (scheduler.memoryMatcher.matchesMemoryRequirements(j, type,
-                                                              taskTrackerStatus)) {
+                                                              taskTrackerStatus,
+                                                              availableSlots)) {
           // We found a suitable job. Get task from it.
-          Task t = obtainNewTask(taskTrackerStatus, j);
+          TaskLookupResult tlr = 
+            obtainNewTask(taskTrackerStatus, j, assignOffSwitch);
           //if there is a task return it immediately.
-          if (t != null) {
+          if (tlr.getLookUpStatus() == 
+                  TaskLookupResult.LookUpStatus.LOCAL_TASK_FOUND || 
+              tlr.getLookUpStatus() == 
+                  TaskLookupResult.LookUpStatus.OFF_SWITCH_TASK_FOUND) {
             // we're successful in getting a task
-            return TaskLookupResult.getTaskFoundResult(t);
+            return tlr;
           } else {
             //skip to the next job in the queue.
             if (LOG.isDebugEnabled()) {
@@ -576,79 +356,28 @@ class CapacityTaskScheduler extends TaskScheduler {
         // if we're here, this job has no task to run. Look at the next job.
       }//end of for loop
 
-      // if we're here, we haven't found any task to run among all jobs in 
-      // the queue. This could be because there is nothing to run, or that 
-      // the user limit for some user is too strict, i.e., there's at least 
-      // one user who doesn't have enough tasks to satisfy his limit. If 
-      // it's the latter case, re-look at jobs without considering user 
-      // limits, and get a task from the first eligible job; however
-      // we do not 'reserve' slots on tasktrackers anymore since the user is 
-      // already over the limit
-      // Note: some of the code from above is repeated here. This is on 
-      // purpose as it improves overall readability.  
-      // Note: we walk through jobs again. Some of these jobs, which weren't
-      // considered in the first pass, shouldn't be considered here again, 
-      // but we still check for their viability to keep the code simple. In
-      // some cases, for high mem jobs that have nothing to run, we call 
-      // obtainNewTask() unnecessarily. Should this be a problem, we can 
-      // create a list of jobs to look at (those whose users were over 
-      // limit) in the first pass and walk through that list only. 
-      for (JobInProgress j : 
-        scheduler.jobQueuesManager.getRunningJobQueue(qsi.queueName)) {
-        if (j.getStatus().getRunState() != JobStatus.RUNNING) {
-          continue;
-        }
-        //Check if queue is over maximum-capacity
-        if (this.areTasksInQueueOverMaxCapacity(
-          qsi, j.getNumSlotsPerTask(type))) {
-          continue;
-        }
-        
-        if (scheduler.memoryMatcher.matchesMemoryRequirements(j, type,
-            taskTrackerStatus)) {
-          // We found a suitable job. Get task from it.
-          Task t = obtainNewTask(taskTrackerStatus, j);
-          //if there is a task return it immediately.
-          if (t != null) {
-            // we're successful in getting a task
-            return TaskLookupResult.getTaskFoundResult(t);
-          } else {
-            //skip to the next job in the queue.
-            continue;
-          }
-        } else {
-          //if memory requirements don't match then we check if the 
-          //job has either pending or speculative task. If the job
-          //has pending or speculative task we block till this job
-          //tasks get scheduled, so that high memory jobs are not 
-          //starved
-          if (getPendingTasks(j) != 0 || hasSpeculativeTask(j, taskTrackerStatus)) {
-            return TaskLookupResult.getMemFailedResult();
-          } 
-        }//end of memory check block
-      }//end of for loop
-
       // found nothing for this queue, look at the next one.
       if (LOG.isDebugEnabled()) {
-        String msg = "Found no task from the queue " + qsi.queueName;
+        String msg = "Found no task from the queue " + queue.queueName;
         LOG.debug(msg);
       }
       return TaskLookupResult.getNoTaskFoundResult();
     }
 
     // Always return a TaskLookupResult object. Don't return null. 
-    // The caller is responsible for ensuring that the QSI objects and the 
+    // The caller is responsible for ensuring that the Queue objects and the 
     // collections are up-to-date.
-    private TaskLookupResult assignTasks(TaskTracker taskTracker) 
+    private TaskLookupResult assignTasks(TaskTracker taskTracker, 
+                                         int availableSlots, 
+                                         boolean assignOffSwitch) 
     throws IOException {
       TaskTrackerStatus taskTrackerStatus = taskTracker.getStatus();
 
-      printQSIs();
+      printQueues();
 
       // Check if this tasktracker has been reserved for a job...
       JobInProgress job = taskTracker.getJobForFallowSlot(type);
       if (job != null) {
-        int availableSlots = taskTracker.getAvailableSlots(type);
         if (LOG.isDebugEnabled()) {
           LOG.debug(job.getJobID() + ": Checking 'reserved' tasktracker " + 
                     taskTracker.getTrackerName() + " with " + availableSlots + 
@@ -660,17 +389,11 @@ class CapacityTaskScheduler extends TaskScheduler {
           taskTracker.unreserveSlots(type, job);
           
           // We found a suitable job. Get task from it.
-          Task t = obtainNewTask(taskTrackerStatus, job);
-          //if there is a task return it immediately.
-          if (t != null) {
-            if (LOG.isDebugEnabled()) {
-              LOG.info(job.getJobID() + ": Got " + t.getTaskID() + 
-                       " for reserved tasktracker " + 
-                       taskTracker.getTrackerName());
-            }
-            // we're successful in getting a task
-            return TaskLookupResult.getTaskFoundResult(t);
-          } 
+          if (type == TaskType.MAP) {
+            // Don't care about locality!
+            job.overrideSchedulingOpportunities();
+          }
+          return obtainNewTask(taskTrackerStatus, job, true);
         } else {
           // Re-reserve the current tasktracker
           taskTracker.reserveSlots(type, job, availableSlots);
@@ -685,19 +408,15 @@ class CapacityTaskScheduler extends TaskScheduler {
       }
       
       
-      for (QueueSchedulingInfo qsi : qsiForAssigningTasks) {
-        // we may have queues with capacity=0. We shouldn't look at jobs from 
-        // these queues
-        if (0 == getTSI(qsi).getCapacity()) {
-          continue;
-        }
-
+      for (CapacitySchedulerQueue queue : queuesForAssigningTasks) {
         //This call is for optimization if we are already over the
         //maximum-capacity we avoid traversing the queues.
-        if(this.areTasksInQueueOverMaxCapacity(qsi,1)) {
+        if (!queue.assignSlotsToQueue(type, 1)) {
           continue;
         }
-        TaskLookupResult tlr = getTaskFromQueue(taskTracker, qsi);
+        
+        TaskLookupResult tlr = 
+          getTaskFromQueue(taskTracker, availableSlots, queue, assignOffSwitch);
         TaskLookupResult.LookUpStatus lookUpStatus = tlr.getLookUpStatus();
 
         if (lookUpStatus == TaskLookupResult.LookUpStatus.NO_TASK_FOUND) {
@@ -705,7 +424,8 @@ class CapacityTaskScheduler extends TaskScheduler {
         }
 
         // if we find a task, return
-        if (lookUpStatus == TaskLookupResult.LookUpStatus.TASK_FOUND) {
+        if (lookUpStatus == TaskLookupResult.LookUpStatus.LOCAL_TASK_FOUND ||
+            lookUpStatus == TaskLookupResult.LookUpStatus.OFF_SWITCH_TASK_FOUND) {
           return tlr;
         }
         // if there was a memory mismatch, return
@@ -719,58 +439,23 @@ class CapacityTaskScheduler extends TaskScheduler {
       return TaskLookupResult.getNoTaskFoundResult();
     }
 
-
-    /**
-     * Check if maximum-capacity is set for this queue.
-     * If set and greater than 0 ,
-     * check if numofslotsoccupied+numSlotsPerTask is greater than
-     * maximum-capacity , if yes , implies this queue is over limit.
-     *
-     * Incase noOfSlotsOccupied is less than maximum-capacity ,but ,
-     * numOfSlotsOccupied + noSlotsPerTask is more than maximum-capacity we
-     * still dont assign the task . This may lead to under utilization of very
-     * small set of slots. But this is ok , as we strictly respect the
-     * maximum-capacity limit.
-     * 
-     * @param qsi
-     * @return true if queue is over limit.
-     */
-
-    private boolean areTasksInQueueOverMaxCapacity(
-      QueueSchedulingInfo qsi, int numSlotsPerTask) {
-      TaskSchedulingInfo tsi = getTSI(qsi);
-      if (tsi.getMaxCapacity() >= 0) {
-        if ((tsi.numSlotsOccupied + numSlotsPerTask) > tsi.getMaxCapacity()) {
-          if (LOG.isDebugEnabled()) {
-            LOG.debug(
-              "Queue " + qsi.queueName + " " + "has reached its  max " + type +
-                "Capacity");
-            LOG.debug("Current running tasks " + tsi.getCapacity());
-
-          }
-          return true;
-        }
-      }
-      return false;
-    }
-
     // for debugging.
-    private void printQSIs() {
+    private void printQueues() {
       if (LOG.isDebugEnabled()) {
         StringBuffer s = new StringBuffer();
-        for (QueueSchedulingInfo qsi : qsiForAssigningTasks) {
-          TaskSchedulingInfo tsi = getTSI(qsi);
-          Collection<JobInProgress> runJobs =
-            scheduler.jobQueuesManager.getRunningJobQueue(qsi.queueName);
+        for (CapacitySchedulerQueue queue : queuesForAssigningTasks) {
+          Collection<JobInProgress> runJobs = queue.getRunningJobs();
           s.append(
             String.format(
               " Queue '%s'(%s): runningTasks=%d, "
                 + "occupiedSlots=%d, capacity=%d, runJobs=%d  maxCapacity=%d ",
-              qsi.queueName,
-              this.type, Integer.valueOf(tsi.numRunningTasks), Integer
-                .valueOf(tsi.numSlotsOccupied), Integer
-                .valueOf(tsi.getCapacity()), Integer.valueOf(runJobs.size()),
-              Integer.valueOf(tsi.getMaxCapacity())));
+              queue.queueName,
+              this.type, 
+              Integer.valueOf(queue.getNumRunningTasks(type)), 
+              Integer.valueOf(queue.getNumSlotsOccupied(type)), 
+              Integer.valueOf(queue.getCapacity(type)), 
+              Integer.valueOf(runJobs.size()),
+              Integer.valueOf(queue.getMaxCapacity(type))));
         }
         LOG.debug(s);
       }
@@ -811,13 +496,37 @@ class CapacityTaskScheduler extends TaskScheduler {
     }
 
     @Override
-    Task obtainNewTask(TaskTrackerStatus taskTracker, JobInProgress job) 
+    TaskLookupResult obtainNewTask(TaskTrackerStatus taskTracker, 
+                                   JobInProgress job, boolean assignOffSwitch) 
     throws IOException {
       ClusterStatus clusterStatus = 
         scheduler.taskTrackerManager.getClusterStatus();
       int numTaskTrackers = clusterStatus.getTaskTrackers();
-      return job.obtainNewMapTask(taskTracker, numTaskTrackers, 
-          scheduler.taskTrackerManager.getNumberOfUniqueHosts());
+      int numUniqueHosts = scheduler.taskTrackerManager.getNumberOfUniqueHosts();
+      
+      // Inform the job it is about to get a scheduling opportunity
+      job.schedulingOpportunity();
+      
+      // First, try to get a 'local' task
+      Task t = 
+        job.obtainNewLocalMapTask(taskTracker, numTaskTrackers, numUniqueHosts);
+      
+      if (t != null) {
+        return TaskLookupResult.getTaskFoundResult(t, job); 
+      }
+      
+      // Next, try to get an 'off-switch' task if appropriate
+      // Do not bother as much about locality for High-RAM jobs
+      if (job.getNumSlotsPerMap() > 1 || 
+          (assignOffSwitch && 
+              job.scheduleOffSwitch(numTaskTrackers))) {
+        t = 
+          job.obtainNewNonLocalMapTask(taskTracker, numTaskTrackers, numUniqueHosts);
+      }
+      
+      return (t != null) ? 
+          TaskLookupResult.getOffSwitchTaskFoundResult(t, job) :
+          TaskLookupResult.getNoTaskFoundResult();
     }
 
     @Override
@@ -840,11 +549,6 @@ class CapacityTaskScheduler extends TaskScheduler {
       return job.getNumSlotsPerTask(TaskType.MAP);
     }
 
-    @Override
-    TaskSchedulingInfo getTSI(QueueSchedulingInfo qsi) {
-      return qsi.mapTSI;
-    }
-
     int getNumReservedTaskTrackers(JobInProgress job) {
       return job.getNumReservedTaskTrackersForMaps();
     }
@@ -857,7 +561,6 @@ class CapacityTaskScheduler extends TaskScheduler {
           hasSpeculativeTask(job.getTasks(TaskType.MAP), 
               job.getStatus().mapProgress(), tts));
     }
-
   }
 
   /**
@@ -872,13 +575,17 @@ class CapacityTaskScheduler extends TaskScheduler {
     }
 
     @Override
-    Task obtainNewTask(TaskTrackerStatus taskTracker, JobInProgress job) 
+    TaskLookupResult obtainNewTask(TaskTrackerStatus taskTracker, 
+                                   JobInProgress job, boolean unused) 
     throws IOException {
       ClusterStatus clusterStatus = 
         scheduler.taskTrackerManager.getClusterStatus();
       int numTaskTrackers = clusterStatus.getTaskTrackers();
-      return job.obtainNewReduceTask(taskTracker, numTaskTrackers, 
+      Task t = job.obtainNewReduceTask(taskTracker, numTaskTrackers, 
           scheduler.taskTrackerManager.getNumberOfUniqueHosts());
+      
+      return (t != null) ? TaskLookupResult.getTaskFoundResult(t, job) :
+        TaskLookupResult.getNoTaskFoundResult();
     }
 
     @Override
@@ -902,11 +609,6 @@ class CapacityTaskScheduler extends TaskScheduler {
       return job.getNumSlotsPerTask(TaskType.REDUCE);    
     }
 
-    @Override
-    TaskSchedulingInfo getTSI(QueueSchedulingInfo qsi) {
-      return qsi.reduceTSI;
-    }
-
     int getNumReservedTaskTrackers(JobInProgress job) {
       return job.getNumReservedTaskTrackersForReduces();
     }
@@ -919,7 +621,6 @@ class CapacityTaskScheduler extends TaskScheduler {
           hasSpeculativeTask(job.getTasks(TaskType.REDUCE), 
               job.getStatus().reduceProgress(), tts));
     }
-
   }
   
   /** the scheduling mgrs for Map and Reduce tasks */ 
@@ -928,11 +629,6 @@ class CapacityTaskScheduler extends TaskScheduler {
 
   MemoryMatcher memoryMatcher = new MemoryMatcher(this);
 
-  /** we keep track of the number of map/reduce slots we saw last */
-  private int prevMapClusterCapacity = 0;
-  private int prevReduceClusterCapacity = 0;
-  
-    
   static final Log LOG = LogFactory.getLog(CapacityTaskScheduler.class);
   protected JobQueuesManager jobQueuesManager;
   protected CapacitySchedulerConf schedConf;
@@ -955,7 +651,9 @@ class CapacityTaskScheduler extends TaskScheduler {
   private long memSizeForReduceSlotOnJT;
   private long limitMaxMemForMapTasks;
   private long limitMaxMemForReduceTasks;
-  private boolean assignMultipleTasks = true;
+  
+  private volatile int maxTasksPerHeartbeat;
+  private volatile int maxTasksToAssignAfterOffSwitch;
 
   public CapacityTaskScheduler() {
     this(new Clock());
@@ -971,8 +669,45 @@ class CapacityTaskScheduler extends TaskScheduler {
   public void setResourceManagerConf(CapacitySchedulerConf conf) {
     this.schedConf = conf;
   }
+  
+  @Override
+  public synchronized void refresh() throws IOException {
+    Configuration conf = new Configuration();
+    CapacitySchedulerConf schedConf = new CapacitySchedulerConf();
+    
+    // Refresh
+    QueueManager queueManager = taskTrackerManager.getQueueManager();
+    Set<String> queueNames = queueManager.getQueues();
+    Map<String, CapacitySchedulerQueue> newQueues =
+      parseQueues(queueManager.getQueues(), schedConf);
+    
+    // Check to ensure no queue has been deleted
+    checkForQueueDeletion(queueInfoMap, newQueues);
+    
+    // Re-intialize the scheduler
+    initialize(queueManager, newQueues, conf, schedConf);
+    
+    // Inform the job-init-poller
+    initializationPoller.reinit(queueNames);
+    
+    // Finally, reset the configuration
+    setConf(conf);
+    this.schedConf = schedConf;
+  }
 
-  private void initializeMemoryRelatedConf() {
+  private void 
+  checkForQueueDeletion(Map<String, CapacitySchedulerQueue> currentQueues, 
+      Map<String, CapacitySchedulerQueue> newQueues) 
+  throws IOException {
+    for (String queueName : currentQueues.keySet()) {
+      if (!newQueues.containsKey(queueName)) {
+        throw new IOException("Couldn't find queue '" + queueName + 
+            "' during refresh!");
+      }
+    }
+  }
+  
+  private void initializeMemoryRelatedConf(Configuration conf) {
     //handling @deprecated
     if (conf.get(
       CapacitySchedulerConf.DEFAULT_PERCENTAGE_OF_PMEM_IN_VMEM_PROPERTY) !=
@@ -1080,83 +815,103 @@ class CapacityTaskScheduler extends TaskScheduler {
       schedConf = new CapacitySchedulerConf();
     }
 
-    initializeMemoryRelatedConf();
-    
-    // read queue info from config file
+    // Initialize queues
     QueueManager queueManager = taskTrackerManager.getQueueManager();
-    Set<String> queues = queueManager.getQueues();
-    // Sanity check: there should be at least one queue. 
-    if (0 == queues.size()) {
-      throw new IllegalStateException("System has no queue configured");
+    Set<String> queueNames = queueManager.getQueues();
+    initialize(queueManager, parseQueues(queueNames, schedConf), 
+        getConf(), schedConf);
+    
+    // listen to job changes
+    taskTrackerManager.addJobInProgressListener(jobQueuesManager);
+
+    //Start thread for initialization
+    if (initializationPoller == null) {
+      this.initializationPoller = new JobInitializationPoller(
+          jobQueuesManager, schedConf, queueNames, taskTrackerManager);
     }
+    initializationPoller.init(queueNames.size(), schedConf);
+    initializationPoller.setDaemon(true);
+    initializationPoller.start();
 
-    Set<String> queuesWithoutConfiguredCapacity = new HashSet<String>();
-    float totalCapacityPercent = 0.0f;
-    for (String queueName: queues) {
-      float capacityPercent = schedConf.getCapacity(queueName);
-      if (capacityPercent == -1.0) {
-        queuesWithoutConfiguredCapacity.add(queueName);
-      }else {
-        totalCapacityPercent += capacityPercent;
+    started = true;
+    LOG.info("Capacity scheduler initialized " + queueNames.size() + " queues");  
+  }
+  
+  
+  void initialize(QueueManager queueManager,
+      Map<String, CapacitySchedulerQueue> newQueues,
+      Configuration conf, CapacitySchedulerConf schedConf) {
+    // Memory related configs
+    initializeMemoryRelatedConf(conf);
+
+    // Setup queues
+    for (Map.Entry<String, CapacitySchedulerQueue> e : newQueues.entrySet()) {
+      String newQueueName = e.getKey();
+      CapacitySchedulerQueue newQueue = e.getValue();
+      CapacitySchedulerQueue currentQueue = queueInfoMap.get(newQueueName);
+      if (currentQueue != null) {
+        currentQueue.initializeQueue(newQueue);
+        LOG.info("Updated queue configs for " + newQueueName);
+      } else {
+        queueInfoMap.put(newQueueName, newQueue);
+        LOG.info("Added new queue: " + newQueueName);
       }
+    }
 
-      float maxCapacityPercent = schedConf.getMaxCapacity(queueName);
-      int ulMin = schedConf.getMinimumUserLimitPercent(queueName);
-      // create our QSI and add to our hashmap
-      QueueSchedulingInfo qsi = new QueueSchedulingInfo(
-        queueName, capacityPercent, maxCapacityPercent ,ulMin, jobQueuesManager);
-      queueInfoMap.put(queueName, qsi);
-
-      // create the queues of job objects
-      boolean supportsPrio = schedConf.isPrioritySupported(queueName);
-      jobQueuesManager.createQueue(queueName, supportsPrio);
-      
+    // Set SchedulingDisplayInfo
+    for (String queueName : queueInfoMap.keySet()) {
       SchedulingDisplayInfo schedulingInfo = 
         new SchedulingDisplayInfo(queueName, this);
       queueManager.setSchedulerInfo(queueName, schedulingInfo);
-      
     }
-    float remainingQuantityToAllocate = 100 - totalCapacityPercent;
-    float quantityToAllocate = 
-      remainingQuantityToAllocate/queuesWithoutConfiguredCapacity.size();
-    for(String queue: queuesWithoutConfiguredCapacity) {
-      QueueSchedulingInfo qsi = queueInfoMap.get(queue); 
-      qsi.capacityPercent = quantityToAllocate;
-      if(qsi.maxCapacityPercent >= 0) {
-        if(qsi.capacityPercent > qsi.maxCapacityPercent) {
-          throw new IllegalStateException(
-            " Allocated capacity of " + qsi.capacityPercent +
-              " to unconfigured queue " + qsi.queueName +
-              " is greater than maximum Capacity " + qsi.maxCapacityPercent);
-        }
-      }
-      schedConf.setCapacity(queue, quantityToAllocate);
-    }    
-    
-    if (totalCapacityPercent > 100.0) {
-      throw new IllegalArgumentException(
-        "Sum of queue capacities over 100% at "
-          + totalCapacityPercent);
-    }    
+
+    // Inform the queue manager 
+    jobQueuesManager.setQueues(queueInfoMap);
     
     // let our mgr objects know about the queues
     mapScheduler.initialize(queueInfoMap);
     reduceScheduler.initialize(queueInfoMap);
     
-    // listen to job changes
-    taskTrackerManager.addJobInProgressListener(jobQueuesManager);
+    // scheduling tunables
+    maxTasksPerHeartbeat = schedConf.getMaxTasksPerHeartbeat();
+    maxTasksToAssignAfterOffSwitch = 
+      schedConf.getMaxTasksToAssignAfterOffSwitch();
+  }
+  
+  Map<String, CapacitySchedulerQueue> 
+  parseQueues(Collection<String> queueNames, CapacitySchedulerConf schedConf) 
+  throws IOException {
+    Map<String, CapacitySchedulerQueue> queueInfoMap = 
+      new HashMap<String, CapacitySchedulerQueue>();
+    
+    // Sanity check: there should be at least one queue. 
+    if (0 == queueNames.size()) {
+      throw new IllegalStateException("System has no queue configured");
+    }
 
-    //Start thread for initialization
-    if (initializationPoller == null) {
-      this.initializationPoller = new JobInitializationPoller(
-          jobQueuesManager,schedConf,queues, taskTrackerManager);
+    float totalCapacityPercent = 0.0f;
+    for (String queueName: queueNames) {
+      float capacityPercent = schedConf.getCapacity(queueName);
+      if (capacityPercent == -1.0) {
+        throw new IOException("Queue '" + queueName + 
+            "' doesn't have configured capacity!");
+      } 
+      
+      totalCapacityPercent += capacityPercent;
+
+      // create our Queue and add to our hashmap
+      CapacitySchedulerQueue queue = 
+        new CapacitySchedulerQueue(queueName, schedConf);
+      queueInfoMap.put(queueName, queue);
     }
-    initializationPoller.init(queueManager.getQueues(), schedConf);
-    initializationPoller.setDaemon(true);
-    initializationPoller.start();
+    
+    if (Math.floor(totalCapacityPercent) != 100) {
+      throw new IllegalArgumentException(
+        "Sum of queue capacities not 100% at "
+          + totalCapacityPercent);
+    }    
 
-    started = true;
-    LOG.info("Capacity scheduler initialized " + queues.size() + " queues");  
+    return queueInfoMap;
   }
   
   /** mostly for testing purposes */
@@ -1183,126 +938,35 @@ class CapacityTaskScheduler extends TaskScheduler {
 
   /**
    * provided for the test classes
-   * lets you update the QSI objects and sorted collections
+   * lets you update the Queue objects and sorted collections
    */ 
-  void updateQSIInfoForTests() {
+  void updateQueueUsageForTests() {
     ClusterStatus c = taskTrackerManager.getClusterStatus();
     int mapClusterCapacity = c.getMaxMapTasks();
     int reduceClusterCapacity = c.getMaxReduceTasks();
-    // update the QSI objects
-    updateQSIObjects(mapClusterCapacity, reduceClusterCapacity);
-    mapScheduler.updateCollectionOfQSIs();
-    reduceScheduler.updateCollectionOfQSIs();
+    // update the Queue objects
+    updateAllQueues(mapClusterCapacity, reduceClusterCapacity);
+    mapScheduler.sortQueues();
+    reduceScheduler.sortQueues();
+    mapScheduler.printQueues();
+    reduceScheduler.printQueues();
   }
 
   /**
-   * Update individual QSI objects.
+   * Update all queues to reflect current usage.
    * We don't need exact information for all variables, just enough for us
    * to make scheduling decisions. For example, we don't need an exact count
    * of numRunningTasks. Once we count upto the grid capacity, any
    * number beyond that will make no difference.
    */
-  private synchronized void updateQSIObjects(
-    int mapClusterCapacity,
-      int reduceClusterCapacity) {
+  private synchronized void updateAllQueues(
+    int mapClusterCapacity, int reduceClusterCapacity) {
     // if # of slots have changed since last time, update.
     // First, compute whether the total number of TT slots have changed
-    for (QueueSchedulingInfo qsi: queueInfoMap.values()) {
-      // compute new capacities, if TT slots have changed
-      if (mapClusterCapacity != prevMapClusterCapacity) {
-        qsi.mapTSI.setCapacity(
-          (int)
-          (qsi.capacityPercent*mapClusterCapacity/100));
-
-        //compute new max map capacities
-        if(qsi.maxCapacityPercent > 0) {
-          qsi.mapTSI.setMaxCapacity(
-            (int) (qsi.maxCapacityPercent * mapClusterCapacity / 100));
-        }
-      }
-      if (reduceClusterCapacity != prevReduceClusterCapacity) {
-        qsi.reduceTSI.setCapacity(
-          (int)
-            (qsi.capacityPercent * reduceClusterCapacity / 100));
-
-        //compute new max reduce capacities
-        if (qsi.maxCapacityPercent > 0) {
-          qsi.reduceTSI.setMaxCapacity(
-            (int) (qsi.maxCapacityPercent * reduceClusterCapacity / 100));
-        }
-      }
-
-      // reset running/pending tasks, tasks per user
-      qsi.mapTSI.resetTaskVars();
-      qsi.reduceTSI.resetTaskVars();
-      // update stats on running jobs
-      for (JobInProgress j:
-        jobQueuesManager.getRunningJobQueue(qsi.queueName)) {
-        if (j.getStatus().getRunState() != JobStatus.RUNNING) {
-          continue;
-        }
-
-        int numMapsRunningForThisJob = mapScheduler.getRunningTasks(j);
-        int numReducesRunningForThisJob = reduceScheduler.getRunningTasks(j);
-        int numRunningMapSlots = 
-          numMapsRunningForThisJob * mapScheduler.getSlotsPerTask(j);
-        int numRunningReduceSlots =
-          numReducesRunningForThisJob * reduceScheduler.getSlotsPerTask(j);
-        int numMapSlotsForThisJob = mapScheduler.getSlotsOccupied(j);
-        int numReduceSlotsForThisJob = reduceScheduler.getSlotsOccupied(j);
-        int numReservedMapSlotsForThisJob = 
-          (mapScheduler.getNumReservedTaskTrackers(j) * 
-           mapScheduler.getSlotsPerTask(j)); 
-        int numReservedReduceSlotsForThisJob = 
-          (reduceScheduler.getNumReservedTaskTrackers(j) * 
-           reduceScheduler.getSlotsPerTask(j)); 
-        j.setSchedulingInfo(getJobQueueSchedInfo(numMapsRunningForThisJob, 
-                              numRunningMapSlots,
-                              numReservedMapSlotsForThisJob,
-                              numReducesRunningForThisJob, 
-                              numRunningReduceSlots,
-                              numReservedReduceSlotsForThisJob));
-        qsi.mapTSI.numRunningTasks += numMapsRunningForThisJob;
-        qsi.reduceTSI.numRunningTasks += numReducesRunningForThisJob;
-        qsi.mapTSI.numSlotsOccupied += numMapSlotsForThisJob;
-        qsi.reduceTSI.numSlotsOccupied += numReduceSlotsForThisJob;
-        Integer i =
-            qsi.mapTSI.numSlotsOccupiedByUser.get(j.getProfile().getUser());
-        qsi.mapTSI.numSlotsOccupiedByUser.put(j.getProfile().getUser(),
-            Integer.valueOf(i.intValue() + numMapSlotsForThisJob));
-        i = qsi.reduceTSI.numSlotsOccupiedByUser.get(j.getProfile().getUser());
-        qsi.reduceTSI.numSlotsOccupiedByUser.put(j.getProfile().getUser(),
-            Integer.valueOf(i.intValue() + numReduceSlotsForThisJob));
-        if (LOG.isDebugEnabled()) {
-          LOG.debug(String.format("updateQSI: job %s: run(m)=%d, "
-              + "occupied(m)=%d, run(r)=%d, occupied(r)=%d, finished(m)=%d,"
-              + " finished(r)=%d, failed(m)=%d, failed(r)=%d, "
-              + "spec(m)=%d, spec(r)=%d, total(m)=%d, total(r)=%d", j
-              .getJobID().toString(), Integer
-              .valueOf(numMapsRunningForThisJob), Integer
-              .valueOf(numMapSlotsForThisJob), Integer
-              .valueOf(numReducesRunningForThisJob), Integer
-              .valueOf(numReduceSlotsForThisJob), Integer.valueOf(j
-              .finishedMaps()), Integer.valueOf(j.finishedReduces()), Integer
-              .valueOf(j.failedMapTasks),
-              Integer.valueOf(j.failedReduceTasks), Integer
-                  .valueOf(j.speculativeMapTasks), Integer
-                  .valueOf(j.speculativeReduceTasks), Integer
-                  .valueOf(j.numMapTasks), Integer.valueOf(j.numReduceTasks)));
-        }
-
-        /*
-         * it's fine walking down the entire list of running jobs - there
-         * probably will not be many, plus, we may need to go through the
-         * list to compute numSlotsOccupiedByUser. If this is expensive, we
-         * can keep a list of running jobs per user. Then we only need to
-         * consider the first few jobs per user.
-         */
-      }
+    for (CapacitySchedulerQueue queue: queueInfoMap.values()) {
+      queue.updateAll(mapClusterCapacity, reduceClusterCapacity, 
+                 mapScheduler, reduceScheduler);
     }
-
-    prevMapClusterCapacity = mapClusterCapacity;
-    prevReduceClusterCapacity = reduceClusterCapacity;
   }
 
   private static final int JOBQUEUE_SCHEDULINGINFO_INITIAL_LENGTH = 175;
@@ -1321,18 +985,6 @@ class CapacityTaskScheduler extends TaskScheduler {
     return sb.toString();
   }
 
-  /**
-   * Sets whether the scheduler can assign multiple tasks in a heartbeat
-   * or not.
-   * 
-   * This method is used only for testing purposes.
-   * 
-   * @param assignMultipleTasks true, to assign multiple tasks per heartbeat
-   */
-  void setAssignMultipleTasks(boolean assignMultipleTasks) {
-    this.assignMultipleTasks = assignMultipleTasks;
-  }
-
   /*
    * The grand plan for assigning a task.
    * 
@@ -1370,39 +1022,17 @@ class CapacityTaskScheduler extends TaskScheduler {
     }
 
     /* 
-     * update all our QSI objects.
-     * This involves updating each qsi structure. This operation depends
+     * update all our queues
+     * This involves updating each queue structure. This operation depends
      * on the number of running jobs in a queue, and some waiting jobs. If it
      * becomes expensive, do it once every few heartbeats only.
      */ 
-    updateQSIObjects(mapClusterCapacity, reduceClusterCapacity);
+    updateAllQueues(mapClusterCapacity, reduceClusterCapacity);
+    
+    // schedule tasks
     List<Task> result = new ArrayList<Task>();
-    if (assignMultipleTasks) {
-      addReduceTask(taskTracker, result, maxReduceSlots, currentReduceSlots);
-      addMapTask(taskTracker, result, maxMapSlots, currentMapSlots);
-    } else {
-      /* 
-       * If TT has Map and Reduce slot free, we need to figure out whether to
-       * give it a Map or Reduce task.
-       * Number of ways to do this. For now, base decision on how much is needed
-       * versus how much is used (default to Map, if equal).
-       */
-      if ((maxReduceSlots - currentReduceSlots) 
-          > (maxMapSlots - currentMapSlots)) {
-        addReduceTask(taskTracker, result, maxReduceSlots, currentReduceSlots);
-        if (result.size() == 0) {
-          addMapTask(taskTracker, result, maxMapSlots, currentMapSlots);
-        }
-      } else {
-        addMapTask(taskTracker, result, maxMapSlots, currentMapSlots);
-        if (result.size() == 0) {
-          addReduceTask(taskTracker, result, maxReduceSlots, currentReduceSlots);
-        }
-      }
-      if (result.size() == 0) {
-        return null;
-      }
-    }
+    addMapTasks(taskTracker, result, maxMapSlots, currentMapSlots);
+    addReduceTask(taskTracker, result, maxReduceSlots, currentReduceSlots);
     return result;
   }
 
@@ -1411,10 +1041,12 @@ class CapacityTaskScheduler extends TaskScheduler {
   private void addReduceTask(TaskTracker taskTracker, List<Task> tasks,
                                   int maxReduceSlots, int currentReduceSlots) 
                     throws IOException {
-    if (maxReduceSlots > currentReduceSlots) {
-      reduceScheduler.updateCollectionOfQSIs();
-      TaskLookupResult tlr = reduceScheduler.assignTasks(taskTracker);
-      if (TaskLookupResult.LookUpStatus.TASK_FOUND == tlr.getLookUpStatus()) {
+    int availableSlots = maxReduceSlots - currentReduceSlots;
+    if (availableSlots > 0) {
+      reduceScheduler.sortQueues();
+      TaskLookupResult tlr = 
+        reduceScheduler.assignTasks(taskTracker, availableSlots, true);
+      if (TaskLookupResult.LookUpStatus.LOCAL_TASK_FOUND == tlr.getLookUpStatus()) {
         tasks.add(tlr.getTask());
       }
     }
@@ -1422,44 +1054,78 @@ class CapacityTaskScheduler extends TaskScheduler {
   
   // Pick a map task and add to the list of tasks, if there's space
   // on the TT to run one.
-  private void addMapTask(TaskTracker taskTracker, List<Task> tasks, 
+  private void addMapTasks(TaskTracker taskTracker, List<Task> tasks, 
                               int maxMapSlots, int currentMapSlots)
                     throws IOException {
-    if (maxMapSlots > currentMapSlots) {
-      mapScheduler.updateCollectionOfQSIs();
-      TaskLookupResult tlr = mapScheduler.assignTasks(taskTracker);
-      if (TaskLookupResult.LookUpStatus.TASK_FOUND == tlr.getLookUpStatus()) {
-        tasks.add(tlr.getTask());
+    int availableSlots = maxMapSlots - currentMapSlots;
+    boolean assignOffSwitch = true;
+    int tasksToAssignAfterOffSwitch = this.maxTasksToAssignAfterOffSwitch;
+    while (availableSlots > 0) {
+      mapScheduler.sortQueues();
+      TaskLookupResult tlr = mapScheduler.assignTasks(taskTracker, 
+                                                      availableSlots,
+                                                      assignOffSwitch);
+      if (TaskLookupResult.LookUpStatus.NO_TASK_FOUND == 
+            tlr.getLookUpStatus() || 
+          TaskLookupResult.LookUpStatus.TASK_FAILING_MEMORY_REQUIREMENT == 
+            tlr.getLookUpStatus()) {
+        break;
+      }
+
+      Task t = tlr.getTask();
+      JobInProgress job = tlr.getJob();
+
+      tasks.add(t);
+
+      if (tasks.size() >= maxTasksPerHeartbeat) {
+        return;
+      }
+      
+      if (TaskLookupResult.LookUpStatus.OFF_SWITCH_TASK_FOUND == 
+        tlr.getLookUpStatus()) {
+        // Atmost 1 off-switch task per-heartbeat
+        assignOffSwitch = false;
+      }
+      
+      // Respect limits on #tasks to assign after an off-switch task is assigned
+      if (!assignOffSwitch) {
+        if (tasksToAssignAfterOffSwitch == 0) {
+          if (LOG.isDebugEnabled()) {
+            LOG.debug("Hit limit of max tasks after off-switch: " + 
+                this.maxTasksToAssignAfterOffSwitch + " after " + 
+                tasks.size() + " maps.");
+          }
+          return;
+        }
+        --tasksToAssignAfterOffSwitch;
       }
+      
+      // Assigned some slots
+      availableSlots -= t.getNumSlotsRequired();
+      
+      // Update the queue
+      CapacitySchedulerQueue queue = 
+        queueInfoMap.get(job.getProfile().getQueueName());
+      queue.update(TaskType.MAP, job,
+          job.getProfile().getUser(), 1, t.getNumSlotsRequired());
     }
   }
   
   // called when a job is added
   synchronized void jobAdded(JobInProgress job) throws IOException {
-    QueueSchedulingInfo qsi = 
+    CapacitySchedulerQueue queue = 
       queueInfoMap.get(job.getProfile().getQueueName());
-    // qsi shouldn't be null
-    // update user-specific info
-    Integer i = qsi.numJobsByUser.get(job.getProfile().getUser());
-    if (null == i) {
-      i = 1;
-      // set the count for running tasks to 0
-      qsi.mapTSI.numSlotsOccupiedByUser.put(job.getProfile().getUser(),
-          Integer.valueOf(0));
-      qsi.reduceTSI.numSlotsOccupiedByUser.put(job.getProfile().getUser(),
-          Integer.valueOf(0));
-    }
-    else {
-      i++;
-    }
-    qsi.numJobsByUser.put(job.getProfile().getUser(), i);
+    
+    // Inform the queue
+    queue.jobAdded(job);
     
     // setup scheduler specific job information
     preInitializeJob(job);
     
     if (LOG.isDebugEnabled()) {
-      LOG.debug("Job " + job.getJobID().toString() + " is added under user " 
-              + job.getProfile().getUser() + ", user now has " + i + " jobs");
+      String user = job.getProfile().getUser();
+      LOG.debug("Job " + job.getJobID() + " is added under user " + user + 
+                ", user now has " + queue.getNumJobsByUser(user) + " jobs");
     }
   }
 
@@ -1484,43 +1150,23 @@ class CapacityTaskScheduler extends TaskScheduler {
   
   // called when a job completes
   synchronized void jobCompleted(JobInProgress job) {
-    QueueSchedulingInfo qsi = 
+    CapacitySchedulerQueue queue = 
       queueInfoMap.get(job.getProfile().getQueueName());
-    // qsi shouldn't be null
-    // update numJobsByUser
-    if (LOG.isDebugEnabled()) {
-      LOG.debug("Job to be removed for user " + job.getProfile().getUser());
-    }
-    Integer i = qsi.numJobsByUser.get(job.getProfile().getUser());
-    i--;
-    if (0 == i.intValue()) {
-      qsi.numJobsByUser.remove(job.getProfile().getUser());
-      // remove job footprint from our TSIs
-      qsi.mapTSI.numSlotsOccupiedByUser.remove(job.getProfile().getUser());
-      qsi.reduceTSI.numSlotsOccupiedByUser.remove(job.getProfile().getUser());
-      if (LOG.isDebugEnabled()) {
-        LOG.debug("No more jobs for user, number of users = " + qsi.numJobsByUser.size());
-      }
-    }
-    else {
-      qsi.numJobsByUser.put(job.getProfile().getUser(), i);
-      if (LOG.isDebugEnabled()) {
-        LOG.debug("User still has " + i + " jobs, number of users = "
-                + qsi.numJobsByUser.size());
-      }
-    }
+    
+    // Inform the queue
+    queue.jobCompleted(job);
   }
   
   @Override
   public synchronized Collection<JobInProgress> getJobs(String queueName) {
     Collection<JobInProgress> jobCollection = new ArrayList<JobInProgress>();
-    Collection<JobInProgress> runningJobs = 
-        jobQueuesManager.getRunningJobQueue(queueName);
+    CapacitySchedulerQueue queue = queueInfoMap.get(queueName);
+    Collection<JobInProgress> runningJobs = queue.getRunningJobs();
+    jobCollection.addAll(queue.getInitializingJobs());
     if (runningJobs != null) {
       jobCollection.addAll(runningJobs);
     }
-    Collection<JobInProgress> waitingJobs = 
-      jobQueuesManager.getWaitingJobs(queueName);
+    Collection<JobInProgress> waitingJobs = queue.getWaitingJobs();
     Collection<JobInProgress> tempCollection = new ArrayList<JobInProgress>();
     if(waitingJobs != null) {
       tempCollection.addAll(waitingJobs);
@@ -1536,12 +1182,23 @@ class CapacityTaskScheduler extends TaskScheduler {
     return initializationPoller;
   }
 
+  /**
+   * @return the jobQueuesManager
+   */
+  JobQueuesManager getJobQueuesManager() {
+    return jobQueuesManager;
+  }
+
+  Map<String, CapacitySchedulerQueue> getQueueInfoMap() {
+    return queueInfoMap;
+  }
+
   synchronized String getDisplayInfo(String queueName) {
-    QueueSchedulingInfo qsi = queueInfoMap.get(queueName);
-    if (null == qsi) { 
+    CapacitySchedulerQueue queue = queueInfoMap.get(queueName);
+    if (null == queue) { 
       return null;
     }
-    return qsi.toString();
+    return queue.toString();
   }
 
 }
diff --git a/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/JobInitializationPoller.java b/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/JobInitializationPoller.java
index 2981944..25b856f 100644
--- a/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/JobInitializationPoller.java
+++ b/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/JobInitializationPoller.java
@@ -19,11 +19,15 @@ package org.apache.hadoop.mapred;
 
 import java.util.ArrayList;
 import java.util.Collection;
+import java.util.Collections;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.Iterator;
+import java.util.Map;
 import java.util.Set;
 import java.util.TreeMap;
 import java.util.Map.Entry;
+import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.atomic.AtomicInteger;
 
 import org.apache.commons.logging.Log;
@@ -68,16 +72,6 @@ public class JobInitializationPoller extends Thread {
   private static final Log LOG = LogFactory
       .getLog(JobInitializationPoller.class.getName());
 
-  /*
-   * The poller picks up jobs across users to initialize based on user limits.
-   * Suppose the user limit for a queue is 25%, it means atmost 4 users' jobs
-   * can run together. However, in order to account for jobs from a user that
-   * might complete faster than others, it initializes jobs from an additional
-   * number of users as a backlog. This variable defines the additional
-   * number of users whose jobs can be considered for initializing. 
-   */
-  private static final int MAX_ADDITIONAL_USERS_TO_INIT = 2;
-
   private JobQueuesManager jobQueueManager;
   private long sleepInterval;
   private int poolSize;
@@ -100,11 +94,12 @@ public class JobInitializationPoller extends Thread {
      * The hash map which maintains relationship between queue to jobs to
      * initialize per queue.
      */
-    private HashMap<String, TreeMap<JobSchedulingInfo, JobInProgress>> jobsPerQueue;
+    private Map<String, Map<JobSchedulingInfo, JobInProgress>> jobsPerQueue;
 
     public JobInitializationThread() {
       startIniting = true;
-      jobsPerQueue = new HashMap<String, TreeMap<JobSchedulingInfo, JobInProgress>>();
+      jobsPerQueue = 
+        new ConcurrentHashMap<String, Map<JobSchedulingInfo, JobInProgress>>();
     }
 
     @Override
@@ -156,8 +151,7 @@ public class JobInitializationPoller extends Thread {
      * @return First job in the queue and removes it.
      */
     private JobInProgress getFirstJobInQueue(String queue) {
-      TreeMap<JobSchedulingInfo, JobInProgress> jobsList = jobsPerQueue
-          .get(queue);
+      Map<JobSchedulingInfo, JobInProgress> jobsList = jobsPerQueue.get(queue);
       synchronized (jobsList) {
         if (jobsList.isEmpty()) {
           return null;
@@ -186,8 +180,7 @@ public class JobInitializationPoller extends Thread {
     }
 
     void addJobsToQueue(String queue, JobInProgress job) {
-      TreeMap<JobSchedulingInfo, JobInProgress> jobs = jobsPerQueue
-          .get(queue);
+      Map<JobSchedulingInfo, JobInProgress> jobs = jobsPerQueue.get(queue);
       if (jobs == null) {
         LOG.error("Invalid queue passed to the thread : " + queue
             + " For job :: " + job.getJobID());
@@ -199,43 +192,20 @@ public class JobInitializationPoller extends Thread {
       }
     }
 
-    void addQueue(String queue) {
-      TreeMap<JobSchedulingInfo, JobInProgress> jobs = new TreeMap<JobSchedulingInfo, JobInProgress>(
-          jobQueueManager.getComparator(queue));
-      jobsPerQueue.put(queue, jobs);
-    }
-  }
+    void addQueue(String queueName) {
+      CapacitySchedulerQueue queue = jobQueueManager.getQueue(queueName);
 
-  /**
-   * The queue information class maintains following information per queue:
-   * Maximum users allowed to initialize job in the particular queue. Maximum
-   * jobs allowed to be initialize per user in the queue.
-   * 
-   */
-  private class QueueInfo {
-    String queue;
-    int maxUsersAllowedToInitialize;
-    int maxJobsPerUserToInitialize;
-
-    public QueueInfo(String queue, int maxUsersAllowedToInitialize,
-        int maxJobsPerUserToInitialize) {
-      this.queue = queue;
-      this.maxJobsPerUserToInitialize = maxJobsPerUserToInitialize;
-      this.maxUsersAllowedToInitialize = maxUsersAllowedToInitialize;
+      TreeMap<JobSchedulingInfo, JobInProgress> jobs = 
+        new TreeMap<JobSchedulingInfo, JobInProgress>(queue.getComparator());
+      jobsPerQueue.put(queueName, jobs);
     }
   }
 
   /**
-   * Map which contains the configuration used for initializing jobs
-   * in that associated to a particular job queue.
-   */
-  private HashMap<String, QueueInfo> jobQueues;
-
-  /**
    * Set of jobs which have been passed to Initialization threads.
    * This is maintained so that we dont call initTasks() for same job twice.
    */
-  private HashMap<JobID,JobInProgress> initializedJobs;
+  private HashMap<JobID, JobInProgress> initializedJobs;
 
   private volatile boolean running;
 
@@ -244,41 +214,34 @@ public class JobInitializationPoller extends Thread {
    * The map which provides information which thread should be used to
    * initialize jobs for a given job queue.
    */
-  private HashMap<String, JobInitializationThread> threadsToQueueMap;
+  private Map<String, JobInitializationThread> threadsToQueueMap;
 
   public JobInitializationPoller(JobQueuesManager mgr,
       CapacitySchedulerConf rmConf, Set<String> queue, 
       TaskTrackerManager ttm) {
     initializedJobs = new HashMap<JobID,JobInProgress>();
-    jobQueues = new HashMap<String, QueueInfo>();
     this.jobQueueManager = mgr;
-    threadsToQueueMap = new HashMap<String, JobInitializationThread>();
+    threadsToQueueMap = 
+      Collections.synchronizedMap(new HashMap<String, 
+          JobInitializationThread>());
     super.setName("JobInitializationPollerThread");
     running = true;
     this.ttm = ttm;
   }
 
+  void setTaskTrackerManager(TaskTrackerManager ttm) {
+    this.ttm = ttm;
+  }
+  
   /*
    * method to read all configuration values required by the initialisation
    * poller
    */
 
-  void init(Set<String> queues, 
+  void init(int numQueues, 
             CapacitySchedulerConf capacityConf) {
-    for (String queue : queues) {
-      int userlimit = capacityConf.getMinimumUserLimitPercent(queue);
-      int maxUsersToInitialize = ((100 / userlimit) + MAX_ADDITIONAL_USERS_TO_INIT);
-      int maxJobsPerUserToInitialize = capacityConf
-          .getMaxJobsPerUserToInitialize(queue);
-      QueueInfo qi = new QueueInfo(queue, maxUsersToInitialize,
-          maxJobsPerUserToInitialize);
-      jobQueues.put(queue, qi);
-    }
     sleepInterval = capacityConf.getSleepInterval();
-    poolSize = capacityConf.getMaxWorkerThreads();
-    if (poolSize > queues.size()) {
-      poolSize = queues.size();
-    }
+    poolSize = Math.min(capacityConf.getMaxWorkerThreads(), numQueues);
     assignThreadsToQueues();
     Collection<JobInitializationThread> threads = threadsToQueueMap.values();
     for (JobInitializationThread t : threads) {
@@ -289,6 +252,20 @@ public class JobInitializationPoller extends Thread {
     }
   }
 
+  void reinit(Set<String> queues) {
+    Set<String> oldQueues = threadsToQueueMap.keySet();
+    int i=0;
+    JobInitializationThread[] threads = 
+      threadsToQueueMap.values().toArray(new JobInitializationThread[0]);
+    for (String newQueue : queues) {
+      if (!oldQueues.contains(newQueue)) {
+        JobInitializationThread t = threads[i++ % threads.length];
+        t.addQueue(newQueue);
+        threadsToQueueMap.put(newQueue, t);
+      }
+    }
+  }
+  
   /**
    * This is main thread of initialization poller, We essentially do 
    * following in the main threads:
@@ -323,7 +300,7 @@ public class JobInitializationPoller extends Thread {
    * 
    */
   void selectJobsToInitialize() {
-    for (String queue : jobQueues.keySet()) {
+    for (String queue : jobQueueManager.getAllQueues()) {
       ArrayList<JobInProgress> jobsToInitialize = getJobsToInitialize(queue);
       printJobs(jobsToInitialize);
       JobInitializationThread t = threadsToQueueMap.get(queue);
@@ -368,8 +345,9 @@ public class JobInitializationPoller extends Thread {
    * 
    */
   private void assignThreadsToQueues() {
-    int countOfQueues = jobQueues.size();
-    String[] queues = (String[]) jobQueues.keySet().toArray(
+    Collection<String> queueNames = jobQueueManager.getAllQueues();
+    int countOfQueues = queueNames.size();
+    String[] queues = (String[]) queueNames.toArray(
         new String[countOfQueues]);
     int numberOfQueuesPerThread = countOfQueues / poolSize;
     int numberOfQueuesAssigned = 0;
@@ -425,22 +403,17 @@ public class JobInitializationPoller extends Thread {
    * already been initialized. The latter user's initialized jobs are redundant,
    * but we'll leave them initialized.
    * 
-   * @param queue name of the queue to pick the jobs to initialize.
+   * @param queueName name of the queue to pick the jobs to initialize.
    * @return list of jobs to be initalized in a queue. An empty queue is
    *         returned if no jobs are found.
    */
-  ArrayList<JobInProgress> getJobsToInitialize(String queue) {
-    QueueInfo qi = jobQueues.get(queue);
+  ArrayList<JobInProgress> getJobsToInitialize(String queueName) {
+    CapacitySchedulerQueue queue = jobQueueManager.getQueue(queueName);
     ArrayList<JobInProgress> jobsToInitialize = new ArrayList<JobInProgress>();
-    // use the configuration parameter which is configured for the particular
-    // queue.
-    int maximumUsersAllowedToInitialize = qi.maxUsersAllowedToInitialize;
-    int maxJobsPerUserAllowedToInitialize = qi.maxJobsPerUserToInitialize;
-    int maxJobsPerQueueToInitialize = maximumUsersAllowedToInitialize
-        * maxJobsPerUserAllowedToInitialize;
-    int countOfJobsInitialized = 0;
-    HashMap<String, Integer> userJobsInitialized = new HashMap<String, Integer>();
-    Collection<JobInProgress> jobs = jobQueueManager.getWaitingJobs(queue);
+
+    Set<String> usersOverLimit = new HashSet<String>();
+    Collection<JobInProgress> jobs = queue.getWaitingJobs();
+    
     /*
      * Walk through the collection of waiting jobs.
      *  We maintain a map of jobs that have already been initialized. If a 
@@ -456,40 +429,45 @@ public class JobInitializationPoller extends Thread {
      */
     for (JobInProgress job : jobs) {
       String user = job.getProfile().getUser();
-      int numberOfJobs = userJobsInitialized.get(user) == null ? 0
-          : userJobsInitialized.get(user);
-      // If the job is already initialized then add the count against user
-      // then continue.
+      // If the job is already initialized then continue.
       if (initializedJobs.containsKey(job.getJobID())) {
-        userJobsInitialized.put(user, Integer.valueOf(numberOfJobs + 1));
-        countOfJobsInitialized++;
         continue;
       }
-      boolean isUserPresent = userJobsInitialized.containsKey(user);
-      if (!isUserPresent
-          && userJobsInitialized.size() < maximumUsersAllowedToInitialize) {
-        // this is a new user being considered and the number of users
-        // is within limits.
-        userJobsInitialized.put(user, Integer.valueOf(numberOfJobs + 1));
-        jobsToInitialize.add(job);
-        initializedJobs.put(job.getJobID(),job);
-        countOfJobsInitialized++;
-      } else if (isUserPresent
-          && numberOfJobs < maxJobsPerUserAllowedToInitialize) {
-        userJobsInitialized.put(user, Integer.valueOf(numberOfJobs + 1));
-        jobsToInitialize.add(job);
-        initializedJobs.put(job.getJobID(),job);
-        countOfJobsInitialized++;
-      }
-      /*
-       * if the maximum number of jobs to initalize for a queue is reached
-       * then we stop looking at further jobs. The jobs beyond this number
-       * can be initialized.
+
+      /** 
+       * Ensure we will not exceed queue limits
        */
-      if(countOfJobsInitialized > maxJobsPerQueueToInitialize) {
+      if (!queue.initializeJobForQueue(job)) {
         break;
       }
+      
+      
+      /**
+       *  Ensure we will not exceed user limits
+       */
+      
+      // Ensure we don't process a user's jobs out of order 
+      if (usersOverLimit.contains(user)) {
+        continue;
+      }
+      
+      // Check if the user is within limits 
+      if (!queue.initializeJobForUser(job)) {
+        usersOverLimit.add(user);   // Note down the user
+        continue;
+      }
+      
+      // Ready to initialize! 
+      // Double check to ensure that the job has not been killed!
+      if (job.getStatus().getRunState() == JobStatus.PREP) {
+        initializedJobs.put(job.getJobID(), job);
+        jobsToInitialize.add(job);
+
+        // Inform the queue
+        queue.addInitializingJob(job);
+      }
     }
+    
     return jobsToInitialize;
   }
 
@@ -536,7 +514,6 @@ public class JobInitializationPoller extends Thread {
           LOG.info("Removing scheduled jobs from waiting queue"
               + job.getJobID());
           jobsIterator.remove();
-          jobQueueManager.removeJobFromWaitingQueue(job);
           continue;
         }
       }
diff --git a/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/JobQueuesManager.java b/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/JobQueuesManager.java
index 1657034..38278bc 100644
--- a/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/JobQueuesManager.java
+++ b/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/JobQueuesManager.java
@@ -18,6 +18,7 @@
 package org.apache.hadoop.mapred;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Comparator;
@@ -25,6 +26,7 @@ import java.util.HashMap;
 import java.util.LinkedList;
 import java.util.Map;
 import java.util.TreeMap;
+import java.util.concurrent.ConcurrentHashMap;
 
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
@@ -36,140 +38,32 @@ import org.apache.hadoop.mapred.JobStatusChangeEvent.EventType;
  * one or more queues. 
  */
 class JobQueuesManager extends JobInProgressListener {
-
-  /* 
-   * If a queue supports priorities, jobs must be 
-   * sorted on priorities, and then on their start times (technically, 
-   * their insertion time.  
-   * If a queue doesn't support priorities, jobs are
-   * sorted based on their start time.  
-   */
   
-  // comparator for jobs in queues that don't support priorities
-  private static final Comparator<JobSchedulingInfo> STARTTIME_JOB_COMPARATOR
-    = new Comparator<JobSchedulingInfo>() {
-    public int compare(JobSchedulingInfo o1, JobSchedulingInfo o2) {
-      // the job that started earlier wins
-      if (o1.getStartTime() < o2.getStartTime()) {
-        return -1;
-      } else {
-        return (o1.getStartTime() == o2.getStartTime() 
-                ? o1.getJobID().compareTo(o2.getJobID()) 
-                : 1);
-      }
-    }
-  };
-  
-  // class to store queue info
-  private static class QueueInfo {
-
-    // whether the queue supports priorities
-    boolean supportsPriorities;
-    Map<JobSchedulingInfo, JobInProgress> waitingJobs; // for waiting jobs
-    Map<JobSchedulingInfo, JobInProgress> runningJobs; // for running jobs
-    
-    public Comparator<JobSchedulingInfo> comparator;
-    
-    QueueInfo(boolean prio) {
-      this.supportsPriorities = prio;
-      if (supportsPriorities) {
-        // use the default priority-aware comparator
-        comparator = JobQueueJobInProgressListener.FIFO_JOB_QUEUE_COMPARATOR;
-      }
-      else {
-        comparator = STARTTIME_JOB_COMPARATOR;
-      }
-      waitingJobs = new TreeMap<JobSchedulingInfo, JobInProgress>(comparator);
-      runningJobs = new TreeMap<JobSchedulingInfo, JobInProgress>(comparator);
-    }
-    
-    Collection<JobInProgress> getWaitingJobs() {
-      synchronized (waitingJobs) {
-        return Collections.unmodifiableCollection(
-            new LinkedList<JobInProgress>(waitingJobs.values()));
-      }
-    }
-    
-    Collection<JobInProgress> getRunningJobs() {
-      synchronized (runningJobs) {
-       return Collections.unmodifiableCollection(
-           new LinkedList<JobInProgress>(runningJobs.values())); 
-      }
-    }
-    
-    void addRunningJob(JobInProgress job) {
-      synchronized (runningJobs) {
-       runningJobs.put(new JobSchedulingInfo(job),job); 
-      }
-    }
-    
-    JobInProgress removeRunningJob(JobSchedulingInfo jobInfo) {
-      synchronized (runningJobs) {
-        return runningJobs.remove(jobInfo); 
-      }
-    }
-    
-    JobInProgress removeWaitingJob(JobSchedulingInfo schedInfo) {
-      synchronized (waitingJobs) {
-        return waitingJobs.remove(schedInfo);
-      }
-    }
-    
-    void addWaitingJob(JobInProgress job) {
-      synchronized (waitingJobs) {
-        waitingJobs.put(new JobSchedulingInfo(job), job);
-      }
-    }
-    
-    int getWaitingJobCount() {
-      synchronized (waitingJobs) {
-       return waitingJobs.size(); 
-      }
-    }
-    
-  }
-  
-  // we maintain a hashmap of queue-names to queue info
-  private Map<String, QueueInfo> jobQueues = 
-    new HashMap<String, QueueInfo>();
   private static final Log LOG = LogFactory.getLog(JobQueuesManager.class);
   private CapacityTaskScheduler scheduler;
+  // Queues in the system
+  private Collection<String> jobQueueNames;
+  private Map<String, CapacitySchedulerQueue> jobQueues = 
+    new HashMap<String, CapacitySchedulerQueue>();
 
   
   JobQueuesManager(CapacityTaskScheduler s) {
     this.scheduler = s;
   }
   
-  /**
-   * create an empty queue with the default comparator
-   * @param queueName The name of the queue
-   * @param supportsPriotities whether the queue supports priorities
-   */
-  public void createQueue(String queueName, boolean supportsPriotities) {
-    jobQueues.put(queueName, new QueueInfo(supportsPriotities));
-  }
-  
-  /**
-   * Returns the queue of running jobs associated with the name
-   */
-  public Collection<JobInProgress> getRunningJobQueue(String queueName) {
-    return jobQueues.get(queueName).getRunningJobs();
-  }
-  
-  /**
-   * Returns the queue of waiting jobs associated with queue name.
-   * 
-   */
-  Collection<JobInProgress> getWaitingJobs(String queueName) {
-    return jobQueues.get(queueName).getWaitingJobs();
+  void setQueues(Map<String, CapacitySchedulerQueue> queues) {
+    this.jobQueues = queues;
+    this.jobQueueNames = new ArrayList<String>(queues.keySet());
   }
   
   @Override
   public void jobAdded(JobInProgress job) throws IOException {
-    LOG.info("Job submitted to queue " + job.getProfile().getQueueName());
+    LOG.info("Job " + job.getJobID() + " submitted to queue " + 
+        job.getProfile().getQueueName());
+    
     // add job to the right queue
-    QueueInfo qi = jobQueues.get(job.getProfile().getQueueName());
-    if (null == qi) {
+    CapacitySchedulerQueue queue = getQueue(job.getProfile().getQueueName());
+    if (null == queue) {
       // job was submitted to a queue we're not aware of
       LOG.warn("Invalid queue " + job.getProfile().getQueueName() + 
           " specified for job" + job.getProfile().getJobID() + 
@@ -178,7 +72,7 @@ class JobQueuesManager extends JobInProgressListener {
     }
     // add job to waiting queue. It will end up in the right place, 
     // based on priority. 
-    qi.addWaitingJob(job);
+    queue.addWaitingJob(job);
     // let scheduler know. 
     scheduler.jobAdded(job);
   }
@@ -188,15 +82,21 @@ class JobQueuesManager extends JobInProgressListener {
    * job queue manager.
    */
   private void jobCompleted(JobInProgress job, JobSchedulingInfo oldInfo, 
-                            QueueInfo qi) {
+      CapacitySchedulerQueue queue, int runState) {
     LOG.info("Job " + job.getJobID().toString() + " submitted to queue " 
         + job.getProfile().getQueueName() + " has completed");
     //remove jobs from both queue's a job can be in
     //running and waiting queue at the same time.
-    qi.removeRunningJob(oldInfo);
-    qi.removeWaitingJob(oldInfo);
-    // let scheduler know
-    scheduler.jobCompleted(job);
+    JobInProgress waitingJob = queue.removeWaitingJob(oldInfo, runState);
+    JobInProgress initializingJob = 
+      queue.removeInitializingJob(oldInfo, runState);
+    JobInProgress runningJob = queue.removeRunningJob(oldInfo, runState);
+    
+    // let scheduler know if necessary
+    // sometimes this isn't necessary if the job was rejected during submission
+    if (runningJob != null || initializingJob != null || waitingJob != null) {
+      scheduler.jobCompleted(job);
+    }
   }
   
   // Note that job is removed when the job completes i.e in jobUpated()
@@ -206,27 +106,36 @@ class JobQueuesManager extends JobInProgressListener {
   // This is used to reposition a job in the queue. A job can get repositioned 
   // because of the change in the job priority or job start-time.
   private void reorderJobs(JobInProgress job, JobSchedulingInfo oldInfo, 
-                           QueueInfo qi) {
-    
-    if(qi.removeWaitingJob(oldInfo) != null) {
-      qi.addWaitingJob(job);
+      CapacitySchedulerQueue queue, int runState) {
+    if(queue.removeWaitingJob(oldInfo, runState) != null) {
+      try {
+        queue.addWaitingJob(job);
+      } catch (IOException ioe) {
+        // Ignore, cannot happen
+        LOG.warn("Couldn't change priority!");
+        return;
+      }
     }
-    if(qi.removeRunningJob(oldInfo) != null) {
-      qi.addRunningJob(job);
+    if (queue.removeInitializingJob(oldInfo, runState) != null) {
+      queue.addInitializingJob(job);
+    }
+    if(queue.removeRunningJob(oldInfo, runState) != null) {
+      queue.addRunningJob(job);
     }
   }
   
   // This is used to move a job from the waiting queue to the running queue.
   private void makeJobRunning(JobInProgress job, JobSchedulingInfo oldInfo, 
-                              QueueInfo qi) {
+                              CapacitySchedulerQueue queue) {
     // Removing of the job from job list is responsibility of the
     //initialization poller.
     // Add the job to the running queue
-    qi.addRunningJob(job);
+    queue.addRunningJob(job);
   }
   
   // Update the scheduler as job's state has changed
-  private void jobStateChanged(JobStatusChangeEvent event, QueueInfo qi) {
+  private void jobStateChanged(JobStatusChangeEvent event, 
+                               CapacitySchedulerQueue queue) {
     JobInProgress job = event.getJobInProgress();
     JobSchedulingInfo oldJobStateInfo = 
       new JobSchedulingInfo(event.getOldStatus());
@@ -235,16 +144,17 @@ class JobQueuesManager extends JobInProgressListener {
     if (event.getEventType() == EventType.PRIORITY_CHANGED 
         || event.getEventType() == EventType.START_TIME_CHANGED) {
       // Make a priority change
-      reorderJobs(job, oldJobStateInfo, qi);
+      int runState = job.getStatus().getRunState();
+      reorderJobs(job, oldJobStateInfo, queue, runState);
     } else if (event.getEventType() == EventType.RUN_STATE_CHANGED) {
       // Check if the job is complete
       int runState = job.getStatus().getRunState();
       if (runState == JobStatus.SUCCEEDED
           || runState == JobStatus.FAILED
           || runState == JobStatus.KILLED) {
-        jobCompleted(job, oldJobStateInfo, qi);
+        jobCompleted(job, oldJobStateInfo, queue, runState);
       } else if (runState == JobStatus.RUNNING) {
-        makeJobRunning(job, oldJobStateInfo, qi);
+        makeJobRunning(job, oldJobStateInfo, queue);
       }
     }
   }
@@ -252,8 +162,8 @@ class JobQueuesManager extends JobInProgressListener {
   @Override
   public void jobUpdated(JobChangeEvent event) {
     JobInProgress job = event.getJobInProgress();
-    QueueInfo qi = jobQueues.get(job.getProfile().getQueueName());
-    if (null == qi) {
+    CapacitySchedulerQueue queue = getQueue(job.getProfile().getQueueName());
+    if (null == queue) {
       // can't find queue for job. Shouldn't happen. 
       LOG.warn("Could not find queue " + job.getProfile().getQueueName() + 
           " when updating job " + job.getProfile().getJobID());
@@ -262,26 +172,15 @@ class JobQueuesManager extends JobInProgressListener {
     
     // Check if this is the status change
     if (event instanceof JobStatusChangeEvent) {
-      jobStateChanged((JobStatusChangeEvent)event, qi);
+      jobStateChanged((JobStatusChangeEvent)event, queue);
     }
   }
   
-  void removeJobFromWaitingQueue(JobInProgress job) {
-    String queue = job.getProfile().getQueueName();
-    QueueInfo qi = jobQueues.get(queue);
-    qi.removeWaitingJob(new JobSchedulingInfo(job));
-  }
-  
-  Comparator<JobSchedulingInfo> getComparator(String queue) {
-    return jobQueues.get(queue).comparator;
+  CapacitySchedulerQueue getQueue(String queue) {
+    return jobQueues.get(queue);
   }
   
-  int getWaitingJobCount(String queue) {
-    QueueInfo qi = jobQueues.get(queue);
-    return qi.getWaitingJobCount();
-  }
-
-  boolean doesQueueSupportPriorities(String queueName) {
-    return jobQueues.get(queueName).supportsPriorities;
+  Collection<String> getAllQueues() {
+    return Collections.unmodifiableCollection(jobQueueNames);
   }
 }
diff --git a/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/MemoryMatcher.java b/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/MemoryMatcher.java
index 072ed78..9b45b42 100644
--- a/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/MemoryMatcher.java
+++ b/src/contrib/capacity-scheduler/src/java/org/apache/hadoop/mapred/MemoryMatcher.java
@@ -45,17 +45,21 @@ class MemoryMatcher {
     return true;
   }
 
+  
   /**
    * Find the memory that is already used by all the running tasks
    * residing on the given TaskTracker.
    * 
    * @param taskTracker
    * @param taskType 
+   * @param availableSlots
    * @return amount of memory that is used by the residing tasks,
    *          null if memory cannot be computed for some reason.
    */
-  synchronized Long getMemReservedForTasks(
-      TaskTrackerStatus taskTracker, TaskType taskType) {
+  synchronized long getMemReservedForTasks(
+      TaskTrackerStatus taskTracker, TaskType taskType, int availableSlots) {
+    int currentlyScheduled = 
+      currentlyScheduled(taskTracker, taskType, availableSlots);
     long vmem = 0;
 
     for (TaskStatus task : taskTracker.getTaskReports()) {
@@ -80,18 +84,38 @@ class MemoryMatcher {
       }
     }
 
-    return Long.valueOf(vmem);
+    long currentlyScheduledVMem = 
+      currentlyScheduled * ((taskType == TaskType.MAP) ? 
+          scheduler.getMemSizeForMapSlot() : 
+            scheduler.getMemSizeForReduceSlot());
+    return vmem + currentlyScheduledVMem; 
   }
 
+  private int currentlyScheduled(TaskTrackerStatus taskTracker, 
+                                 TaskType taskType, int availableSlots) {
+    int scheduled = 0;
+    if (taskType == TaskType.MAP) {
+      scheduled = 
+        (taskTracker.getMaxMapSlots() - taskTracker.countOccupiedMapSlots()) - 
+            availableSlots;
+    } else {
+      scheduled = 
+        (taskTracker.getMaxReduceSlots() - 
+            taskTracker.countOccupiedReduceSlots()) - availableSlots;
+    }
+    return scheduled;
+  }
   /**
    * Check if a TT has enough memory to run of task specified from this job.
    * @param job
    * @param taskType 
    * @param taskTracker
+   * @param availableSlots
    * @return true if this TT has enough memory for this job. False otherwise.
    */
   boolean matchesMemoryRequirements(JobInProgress job,TaskType taskType, 
-                                    TaskTrackerStatus taskTracker) {
+                                    TaskTrackerStatus taskTracker, 
+                                    int availableSlots) {
 
     if (LOG.isDebugEnabled()) {
       LOG.debug("Matching memory requirements of " + job.getJobID().toString()
@@ -106,7 +130,8 @@ class MemoryMatcher {
       return true;
     }
 
-    Long memUsedOnTT = getMemReservedForTasks(taskTracker, taskType);
+    long memUsedOnTT = 
+      getMemReservedForTasks(taskTracker, taskType, availableSlots);
     long totalMemUsableOnTT = 0;
     long memForThisTask = 0;
     if (taskType == TaskType.MAP) {
@@ -120,7 +145,7 @@ class MemoryMatcher {
               * taskTracker.getMaxReduceSlots();
     }
 
-    long freeMemOnTT = totalMemUsableOnTT - memUsedOnTT.longValue();
+    long freeMemOnTT = totalMemUsableOnTT - memUsedOnTT;
     if (memForThisTask > freeMemOnTT) {
       if (LOG.isDebugEnabled()) {
         LOG.debug("memForThisTask (" + memForThisTask + ") > freeMemOnTT ("
diff --git a/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java b/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java
index e1e5d07..a2494c8 100644
--- a/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java
+++ b/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java
@@ -34,13 +34,13 @@ import junit.framework.TestCase;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 
+import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.io.BytesWritable;
 import org.apache.hadoop.mapred.JobStatusChangeEvent.EventType;
-import org.apache.hadoop.conf.Configuration;
-
 import org.apache.hadoop.mapreduce.TaskType;
 import org.apache.hadoop.mapreduce.server.jobtracker.TaskTracker;
 import org.apache.hadoop.mapreduce.split.JobSplit;
+import org.apache.hadoop.security.authorize.AccessControlList;
 
 public class TestCapacityScheduler extends TestCase {
 
@@ -168,8 +168,11 @@ public class TestCapacityScheduler extends TestCase {
     private int speculativeReduceTaskCounter = 0;
     public FakeJobInProgress(JobID jId, JobConf jobConf,
         FakeTaskTrackerManager taskTrackerManager, String user, 
-        JobTracker jt) {
+        JobTracker jt) throws IOException {
       super(jId, jobConf, jt);
+      if (user == null) {
+        user = "drwho";
+      }
       this.taskTrackerManager = taskTrackerManager;
       this.startTime = System.currentTimeMillis();
       this.status.setJobPriority(JobPriority.NORMAL);
@@ -192,6 +195,18 @@ public class TestCapacityScheduler extends TestCase {
     }
 
     @Override
+    public Task obtainNewLocalMapTask(final TaskTrackerStatus tts, int clusterSize,
+        int ignored) throws IOException {
+      return obtainNewMapTask(tts, clusterSize, ignored);
+    }
+    
+    @Override
+    public Task obtainNewNonLocalMapTask(final TaskTrackerStatus tts, 
+        int clusterSize, int ignored) throws IOException {
+      return obtainNewMapTask(tts, clusterSize, ignored);
+    }
+    
+    @Override
     public Task obtainNewMapTask(final TaskTrackerStatus tts, int clusterSize,
         int ignored) throws IOException {
       boolean areAllMapsRunning = (mapTaskCtr == numMapTasks);
@@ -312,7 +327,7 @@ public class TestCapacityScheduler extends TestCase {
 
     public FakeFailingJobInProgress(JobID id, JobConf jobConf,
         FakeTaskTrackerManager taskTrackerManager, String user, 
-        JobTracker jt) {
+        JobTracker jt) throws IOException {
       super(id, jobConf, taskTrackerManager, user, jt);
     }
     
@@ -402,15 +417,26 @@ public class TestCapacityScheduler extends TestCase {
   }
   
   static class FakeQueueManager extends QueueManager {
-    private Set<String> queues = null;
+    private static final Map<String,AccessControlList> acls =
+      new HashMap<String,AccessControlList>() {
+        final AccessControlList allEnabledAcl = new AccessControlList("*");
+        @Override
+        public AccessControlList get(Object key) {
+          return allEnabledAcl;
+        }
+      };
     FakeQueueManager() {
       super(new Configuration());
     }
-    void setQueues(Set<String> queues) {
-      this.queues = queues;
-    }
-    public synchronized Set<String> getQueues() {
-      return queues;
+    void setQueues(Set<String> newQueues) {
+      queues.clear();
+      for (String qName : newQueues) {
+        try {
+          queues.put(qName, new Queue(qName, acls, Queue.QueueState.RUNNING));
+        } catch (Throwable t) {
+          throw new RuntimeException("Unable to initialize queue " + qName, t);
+        }
+      }
     }
   }
   
@@ -419,7 +445,7 @@ public class TestCapacityScheduler extends TestCase {
     int reduces = 0;
     int maxMapTasksPerTracker = 2;
     int maxReduceTasksPerTracker = 1;
-    List<JobInProgressListener> listeners =
+    List<JobInProgressListener> mylisteners =
       new ArrayList<JobInProgressListener>();
     FakeQueueManager qm = new FakeQueueManager();
     
@@ -494,7 +520,7 @@ public class TestCapacityScheduler extends TestCase {
         JobStatus newStatus = (JobStatus)jip.getStatus().clone();
         JobStatusChangeEvent event = new JobStatusChangeEvent(jip, 
             EventType.RUN_STATE_CHANGED, oldStatus, newStatus);
-        for (JobInProgressListener listener : listeners) {
+        for (JobInProgressListener listener : mylisteners) {
           listener.jobUpdated(event);
         }
       } catch (Exception ioe) {
@@ -525,16 +551,16 @@ public class TestCapacityScheduler extends TestCase {
 
 
     public void addJobInProgressListener(JobInProgressListener listener) {
-      listeners.add(listener);
+      mylisteners.add(listener);
     }
 
     public void removeJobInProgressListener(JobInProgressListener listener) {
-      listeners.remove(listener);
+      mylisteners.remove(listener);
     }
     
     public void submitJob(JobInProgress job) throws IOException {
       jobs.put(job.getJobID(), job);
-      for (JobInProgressListener listener : listeners) {
+      for (JobInProgressListener listener : mylisteners) {
         listener.jobAdded(job);
       }
     }
@@ -595,7 +621,7 @@ public class TestCapacityScheduler extends TestCase {
       JobStatusChangeEvent event = 
         new JobStatusChangeEvent (fjob, EventType.RUN_STATE_CHANGED, oldStatus, 
                                   newStatus);
-      for (JobInProgressListener listener : listeners) {
+      for (JobInProgressListener listener : mylisteners) {
         listener.jobUpdated(event);
       }
     }
@@ -608,7 +634,7 @@ public class TestCapacityScheduler extends TestCase {
       JobStatusChangeEvent event = 
         new JobStatusChangeEvent (fjob, EventType.PRIORITY_CHANGED, oldStatus, 
                                   newStatus);
-      for (JobInProgressListener listener : listeners) {
+      for (JobInProgressListener listener : mylisteners) {
         listener.jobUpdated(event);
       }
     }
@@ -625,7 +651,7 @@ public class TestCapacityScheduler extends TestCase {
       JobStatusChangeEvent event = 
         new JobStatusChangeEvent (fjob, EventType.START_TIME_CHANGED, oldStatus,
                                   newStatus);
-      for (JobInProgressListener listener : listeners) {
+      for (JobInProgressListener listener : mylisteners) {
         listener.jobUpdated(event);
       }
     }
@@ -745,7 +771,6 @@ public class TestCapacityScheduler extends TestCase {
             numReduceTasksPerTracker);
     clock = new FakeClock();
     scheduler = new CapacityTaskScheduler(clock);
-    scheduler.setAssignMultipleTasks(false);
     scheduler.setTaskTrackerManager(taskTrackerManager);
 
     conf = new JobConf();
@@ -838,9 +863,9 @@ public class TestCapacityScheduler extends TestCase {
     taskTrackerManager.initJob(fjob1);
     
     // check if the jobs are missing from the waiting queue
-    // The jobs are not removed from waiting queue until they are scheduled 
+    // The jobs are not removed from waiting queue until they are scheduled
     assertEquals("Waiting queue is garbled on job init", 2, 
-                 scheduler.jobQueuesManager.getWaitingJobs("default")
+                 scheduler.jobQueuesManager.getQueue("default").getWaitingJobs()
                           .size());
     
     // test if changing the job priority/start-time works as expected in the 
@@ -857,8 +882,9 @@ public class TestCapacityScheduler extends TestCase {
     // mark the job as complete
     taskTrackerManager.finalizeJob(fjob1);
     
-    Collection<JobInProgress> rqueue = 
-      scheduler.jobQueuesManager.getRunningJobQueue("default");
+    CapacitySchedulerQueue queue = 
+      scheduler.jobQueuesManager.getQueue("default"); 
+    Collection<JobInProgress> rqueue = queue.getRunningJobs();
     
     // check if the job is removed from the scheduler
     assertFalse("Scheduler contains completed job", 
@@ -875,15 +901,18 @@ public class TestCapacityScheduler extends TestCase {
    * @throws IOException
    */
   public void testMaxCapacities() throws IOException {
+    System.err.println("testMaxCapacities");
     this.setUp(4,1,1);
-    taskTrackerManager.addQueues(new String[] {"default"});
+    taskTrackerManager.addQueues(new String[] {"default", "q2"});
     ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
     queues.add(new FakeQueueInfo("default", 25.0f, false, 1));
-
+    queues.add(new FakeQueueInfo("q2", 75.0f, false, 1));
+    
     resConf.setFakeQueues(queues);
     resConf.setMaxCapacity("default", 50.0f);
+    resConf.setUserLimitFactor("default", 2);
+    
     scheduler.setResourceManagerConf(resConf);
-    scheduler.setAssignMultipleTasks(true);
     scheduler.start();
 
     //submit the Job
@@ -894,22 +923,22 @@ public class TestCapacityScheduler extends TestCase {
 
     //first call of assign task should give task from default queue.
     //default uses 1 map and 1 reduce slots are used
-    checkMultipleAssignment(
-      "tt1", "attempt_test_0001_m_000001_0 on tt1",
-      "attempt_test_0001_r_000001_0 on tt1");
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0001_m_000001_0 on tt1",
+        "attempt_test_0001_r_000001_0 on tt1"});
 
     //second call of assign task
     //default uses 2 map and 2 reduce slots
-    checkMultipleAssignment(
-      "tt2", "attempt_test_0001_m_000002_0 on tt2",
-      "attempt_test_0001_r_000002_0 on tt2");
+    checkAssignments("tt2", 
+        new String[] {
+        "attempt_test_0001_m_000002_0 on tt2",
+        "attempt_test_0001_r_000002_0 on tt2"});
 
 
     //Now we have reached the max capacity limit for default ,
     //no further tasks would be assigned to this queue.
-    checkMultipleAssignment(
-      "tt3", null,
-      null);
+    checkAssignments("tt3", new String[] {});
   }
   
   // test if the queue reflects the changes
@@ -966,18 +995,19 @@ public class TestCapacityScheduler extends TestCase {
   private JobInProgress[] getJobsInQueue(boolean waiting) {
     Collection<JobInProgress> queue = 
       waiting 
-      ? scheduler.jobQueuesManager.getWaitingJobs("default")
-      : scheduler.jobQueuesManager.getRunningJobQueue("default");
+      ? scheduler.jobQueuesManager.getQueue("default").getWaitingJobs()
+      : scheduler.jobQueuesManager.getQueue("default").getRunningJobs();
     return queue.toArray(new JobInProgress[0]);
   }
   
   // tests if tasks can be assinged when there are multiple jobs from a same
   // user
   public void testJobFinished() throws Exception {
-    taskTrackerManager.addQueues(new String[] {"default"});
+    taskTrackerManager.addQueues(new String[] {"default", "q2"});
     
     ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
     queues.add(new FakeQueueInfo("default", 50.0f, true, 25));
+    queues.add(new FakeQueueInfo("q2", 50.0f, true, 25));
     resConf.setFakeQueues(queues);
     scheduler.setResourceManagerConf(resConf);
     scheduler.start();
@@ -988,31 +1018,32 @@ public class TestCapacityScheduler extends TestCase {
     
     // I. Check multiple assignments with running tasks within job
     // ask for a task from first job
-    Task t = checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
-    //  ask for another task from the first job
-    t = checkAssignment("tt1", "attempt_test_0001_m_000002_0 on tt1");
-    
+    checkAssignments("tt1", 
+                     new String[] {"attempt_test_0001_m_000001_0 on tt1", 
+                                   "attempt_test_0001_m_000002_0 on tt1"}
+      );
+
     // complete tasks
     taskTrackerManager.finishTask("tt1", "attempt_test_0001_m_000001_0", j1);
     taskTrackerManager.finishTask("tt1", "attempt_test_0001_m_000002_0", j1);
     
     // II. Check multiple assignments with running tasks across jobs
     // ask for a task from first job
-    t = checkAssignment("tt1", "attempt_test_0001_m_000003_0 on tt1");
-    
-    //  ask for a task from the second job
-    t = checkAssignment("tt1", "attempt_test_0002_m_000001_0 on tt1");
-    
-    // complete tasks
-    taskTrackerManager.finishTask("tt1", "attempt_test_0002_m_000001_0", j2);
+    checkAssignments("tt1", 
+                     new String[] {"attempt_test_0001_m_000003_0 on tt1", 
+                                   "attempt_test_0002_m_000001_0 on tt1"}
+    );
+
+    // complete task from job1
     taskTrackerManager.finishTask("tt1", "attempt_test_0001_m_000003_0", j1);
     
     // III. Check multiple assignments with completed tasks across jobs
     // ask for a task from the second job
-    t = checkAssignment("tt1", "attempt_test_0002_m_000002_0 on tt1");
+    checkAssignment("tt1", "attempt_test_0002_m_000002_0 on tt1");
     
-    // complete task
+    // complete tasks
     taskTrackerManager.finishTask("tt1", "attempt_test_0002_m_000002_0", j2);
+    taskTrackerManager.finishTask("tt1", "attempt_test_0002_m_000001_0", j2);
     
     // IV. Check assignment with completed job
     // finish first job
@@ -1020,7 +1051,7 @@ public class TestCapacityScheduler extends TestCase {
     
     // ask for another task from the second job
     // if tasks can be assigned then the structures are properly updated 
-    t = checkAssignment("tt1", "attempt_test_0002_m_000003_0 on tt1");
+    checkAssignment("tt1", "attempt_test_0002_m_000003_0 on tt1");
     
     // complete task
     taskTrackerManager.finishTask("tt1", "attempt_test_0002_m_000003_0", j2);
@@ -1032,7 +1063,6 @@ public class TestCapacityScheduler extends TestCase {
    * @throws Exception
    */
   public void testMultiTaskAssignmentInSingleQueue() throws Exception {
-    try {
       setUp(1, 6, 2);
       // set up some queues
       String[] qs = {"default"};
@@ -1042,25 +1072,13 @@ public class TestCapacityScheduler extends TestCase {
       resConf.setFakeQueues(queues);
       scheduler.setResourceManagerConf(resConf);
       scheduler.start();
-      scheduler.setAssignMultipleTasks(true);
 
       //Submit the job with 6 maps and 2 reduces
       FakeJobInProgress j1 = submitJobAndInit(
         JobStatus.PREP, 6, 2, "default", "u1");
 
       List<Task> tasks = scheduler.assignTasks(tracker("tt1"));
-      assertEquals(tasks.size(), 2);
-      for (Task task : tasks) {
-        if (task.toString().contains("_m_")) {
-          LOG.info(" map task assigned " + task.toString());
-          assertEquals(task.toString(), "attempt_test_0001_m_000001_0 on tt1");
-        } else if (task.toString().contains("_r_")) {
-          LOG.info(" reduce task assigned " + task.toString());
-          assertEquals(task.toString(), "attempt_test_0001_r_000001_0 on tt1");
-        } else {
-          fail(" should not have come here " + task.toString());
-        }
-      }
+      assertEquals(tasks.size(), 7);
 
       for (Task task : tasks) {
         if (task.toString().equals("attempt_test_0001_m_000001_0 on tt1")) {
@@ -1071,123 +1089,53 @@ public class TestCapacityScheduler extends TestCase {
         }
       }
 
-      tasks = scheduler.assignTasks(tracker("tt1"));
-      assertEquals(tasks.size(), 2);
-      for (Task task : tasks) {
-        if (task.toString().contains("_m_")) {
-          LOG.info(" map task assigned " + task.toString());
-          assertEquals(task.toString(), "attempt_test_0001_m_000002_0 on tt1");
-        } else if (task.toString().contains("_r_")) {
-          LOG.info(" reduce task assigned " + task.toString());
-          assertEquals(task.toString(), "attempt_test_0001_r_000002_0 on tt1");
-        } else {
-          fail(" should not have come here " + task.toString());
-        }
-      }
-
-      //now both the reduce slots are being used , hence we should not 
-      // get only 1 map task in this assignTasks call.
+      // Only 1 reduce left
       tasks = scheduler.assignTasks(tracker("tt1"));
       assertEquals(tasks.size(), 1);
-      for (Task task : tasks) {
-        if (task.toString().contains("_m_")) {
-          LOG.info(" map task assigned " + task.toString());
-          assertEquals(task.toString(), "attempt_test_0001_m_000003_0 on tt1");
-        } else if (task.toString().contains("_r_")) {
-          LOG.info(" reduce task assigned " + task.toString());
-          fail("should not give reduce task " + task.toString());
-        } else {
-          fail(" should not have come here " + task.toString());
-        }
-      }
-    } finally {
-      scheduler.setAssignMultipleTasks(false);
-    }
   }
 
   public void testMultiTaskAssignmentInMultipleQueues() throws Exception {
-    try {
-      setUp(1, 6, 2);
+      setUp(1, 4, 2);
       // set up some queues
-      String[] qs = {"default","q1"};
+      String[] qs = {"q1","q2"};
       taskTrackerManager.addQueues(qs);
       ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
-      queues.add(new FakeQueueInfo("default", 50.0f, true, 25));
       queues.add(new FakeQueueInfo("q1", 50.0f, true, 25));
+      queues.add(new FakeQueueInfo("q2", 50.0f, true, 25));
       resConf.setFakeQueues(queues);
+      resConf.setUserLimitFactor("q1", 4);
+      resConf.setUserLimitFactor("q2", 4);
       scheduler.setResourceManagerConf(resConf);
       scheduler.start();
-      scheduler.setAssignMultipleTasks(true);
 
+      System.err.println("testMultiTaskAssignmentInMultipleQueues");
       //Submit the job with 6 maps and 2 reduces
-      submitJobAndInit(
-        JobStatus.PREP, 6, 1, "default", "u1");
-
-      FakeJobInProgress j2 = submitJobAndInit(JobStatus.PREP,2,1,"q1","u2");
-
-      List<Task> tasks = scheduler.assignTasks(tracker("tt1"));
-      assertEquals(tasks.size(), 2);
+      FakeJobInProgress j1 = 
+        submitJobAndInit(JobStatus.PREP, 6, 1, "q1", "u1");
+      FakeJobInProgress j2 = 
+        submitJobAndInit(JobStatus.PREP,2,1,"q2","u2");
+
+      List<Task> tasks = checkAssignments("tt1", 
+          new String[] {"attempt_test_0002_m_000001_0 on tt1",
+                        "attempt_test_0001_m_000001_0 on tt1",
+                        "attempt_test_0001_m_000002_0 on tt1",
+                        "attempt_test_0002_m_000002_0 on tt1",
+                        "attempt_test_0002_r_000001_0 on tt1",
+                        });
+      //Now finish the tasks
       for (Task task : tasks) {
-        if (task.toString().contains("_m_")) {
-          LOG.info(" map task assigned " + task.toString());
-          assertEquals(task.toString(), "attempt_test_0001_m_000001_0 on tt1");
-        } else if (task.toString().contains("_r_")) {
-          LOG.info(" reduce task assigned " + task.toString());
-          assertEquals(task.toString(), "attempt_test_0001_r_000001_0 on tt1");
-        } else {
-          fail(" should not have come here " + task.toString());
-        }
-      }
-      
-      // next assignment will be for job in second queue.
-      tasks = scheduler.assignTasks(tracker("tt1"));
-      assertEquals(tasks.size(), 2);
-      for (Task task : tasks) {
-        if (task.toString().contains("_m_")) {
-          LOG.info(" map task assigned " + task.toString());
-          assertEquals(task.toString(), "attempt_test_0002_m_000001_0 on tt1");
-        } else if (task.toString().contains("_r_")) {
-          LOG.info(" reduce task assigned " + task.toString());
-          assertEquals(task.toString(), "attempt_test_0002_r_000001_0 on tt1");
-        } else {
-          fail(" should not have come here " + task.toString());
-        }
+        FakeJobInProgress j = 
+          (task.getTaskID().getJobID().getId() == 1) ? j1 : j2;
+        taskTrackerManager.finishTask("tt1", task.getTaskID().toString(), j);
       }
 
-      //now both the reduce slots are being used , hence we sholdnot get only 1
-      //map task in this assignTasks call.
-      tasks = scheduler.assignTasks(tracker("tt1"));
-      assertEquals(tasks.size(), 1);
-      for (Task task : tasks) {
-        if (task.toString().contains("_m_")) {
-          LOG.info(" map task assigned " + task.toString());
-          // we get from job 2 because the queues are equal in capacity usage
-          // and sorting leaves order unchanged.
-          assertEquals(task.toString(), "attempt_test_0002_m_000002_0 on tt1");
-        } else if (task.toString().contains("_r_")) {
-          LOG.info(" reduce task assigned " + task.toString());
-          fail("should not give reduce task " + task.toString());
-        } else {
-          fail(" should not have come here " + task.toString());
-        }
-      }
-
-      tasks = scheduler.assignTasks(tracker("tt1"));
-      assertEquals(tasks.size(), 1);
-      for (Task task : tasks) {
-        if (task.toString().contains("_m_")) {
-          LOG.info(" map task assigned " + task.toString());
-          assertEquals(task.toString(), "attempt_test_0001_m_000002_0 on tt1");
-        } else if (task.toString().contains("_r_")) {
-          LOG.info(" reduce task assigned " + task.toString());
-          fail("should not give reduce task " + task.toString());
-        } else {
-          fail(" should not have come here " + task.toString());
-        }
-      }
-    } finally {
-      scheduler.setAssignMultipleTasks(false);
-    }
+      checkAssignments("tt1", 
+          new String[] {"attempt_test_0001_m_000003_0 on tt1",
+                        "attempt_test_0001_m_000004_0 on tt1",
+                        "attempt_test_0001_m_000005_0 on tt1",
+                        "attempt_test_0001_m_000006_0 on tt1",
+                        "attempt_test_0001_r_000001_0 on tt1",
+                        });
   }
 
   // basic tests, should be able to submit to queues
@@ -1207,12 +1155,17 @@ public class TestCapacityScheduler extends TestCase {
     JobInProgress j = submitJobAndInit(JobStatus.PREP, 10, 10, null, "u1");
     
     // when we ask for a task, we should get one, from the job submitted
-    Task t;
-    t = checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
+    checkAssignments("tt1", 
+        new String[] {"attempt_test_0001_m_000001_0 on tt1", 
+                      "attempt_test_0001_m_000002_0 on tt1", 
+                      "attempt_test_0001_r_000001_0 on tt1"});
     // submit another job, to a different queue
     j = submitJobAndInit(JobStatus.PREP, 10, 10, "q2", "u1");
     // now when we get a task, it should be from the second job
-    t = checkAssignment("tt2", "attempt_test_0002_m_000001_0 on tt2");
+    checkAssignments("tt2", 
+        new String[] {"attempt_test_0002_m_000001_0 on tt2", 
+        "attempt_test_0002_m_000002_0 on tt2", 
+        "attempt_test_0002_r_000001_0 on tt2"});
   }
   
   public void testGetJobs() throws Exception {
@@ -1228,8 +1181,8 @@ public class TestCapacityScheduler extends TestCase {
       submitJobs(1, 4, "default");
    
     JobQueuesManager mgr = scheduler.jobQueuesManager;
-    
-    while(mgr.getWaitingJobs("default").size() < 4){
+    CapacitySchedulerQueue queue = mgr.getQueue("default");
+    while(queue.getWaitingJobs().size() < 4){
       Thread.sleep(1);
     }
     //Raise status change events for jobs submitted.
@@ -1243,46 +1196,24 @@ public class TestCapacityScheduler extends TestCase {
         subJobsList.get("u1").containsAll(jobs));
   }
   
-  //Basic test to test capacity allocation across the queues which have no
-  //capacity configured.
-  
-  public void testCapacityAllocationToQueues() throws Exception {
-    String[] qs = {"default","q1","q2","q3","q4"};
-    taskTrackerManager.addQueues(qs);
-    ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
-    queues.add(new FakeQueueInfo("default",25.0f,true,25));
-    queues.add(new FakeQueueInfo("q1",-1.0f,true,25));
-    queues.add(new FakeQueueInfo("q2",-1.0f,true,25));
-    queues.add(new FakeQueueInfo("q3",-1.0f,true,25));
-    queues.add(new FakeQueueInfo("q4",-1.0f,true,25));
-    resConf.setFakeQueues(queues);
-    scheduler.setResourceManagerConf(resConf);
-    scheduler.start(); 
-    assertEquals(18.75f, resConf.getCapacity("q1"));
-    assertEquals(18.75f, resConf.getCapacity("q2"));
-    assertEquals(18.75f, resConf.getCapacity("q3"));
-    assertEquals(18.75f, resConf.getCapacity("q4"));
-  }
-
   public void testCapacityAllocFailureWithLowerMaxCapacity()
     throws Exception {
     String[] qs = {"default", "q1"};
     taskTrackerManager.addQueues(qs);
     ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
     queues.add(new FakeQueueInfo("default", 50.0f, true, 50));
-    queues.add(new FakeQueueInfo("q1", -1.0f, true, 50));
+    queues.add(new FakeQueueInfo("q1", 50.0f, true, 50));
     resConf.setFakeQueues(queues);
     resConf.setMaxCapacity("q1", 40.0f);
     scheduler.setResourceManagerConf(resConf);
+    boolean failed = false;
     try {
       scheduler.start();
       fail("Scheduler start should fail ");
-    } catch (IllegalStateException ise) {
-      assertEquals(
-        ise.getMessage(),
-        " Allocated capacity of " + 50.0f + " to unconfigured queue " +
-          "q1" + " is greater than maximum Capacity " + 40.0f);
+    } catch (IllegalArgumentException iae) {
+      failed = true;  
     }
+    assertTrue("Scheduler start didn't fail!", failed);
   }
 
   // Tests how capacity is computed and assignment of tasks done
@@ -1307,19 +1238,25 @@ public class TestCapacityScheduler extends TestCase {
     submitJobAndInit(JobStatus.PREP, 10, 0, "q2", "u1");
     
     // job from q2 runs first because it has some non-zero capacity.
-    checkAssignment("tt1", "attempt_test_0002_m_000001_0 on tt1");
+    checkAssignments("tt1", 
+        new String[] {"attempt_test_0002_m_000001_0 on tt1", 
+        "attempt_test_0002_m_000002_0 on tt1"});
     verifyCapacity("0", "default");
     verifyCapacity("3", "q2");
     
     // add another tt to increase tt slots
     taskTrackerManager.addTaskTracker("tt3");
-    checkAssignment("tt2", "attempt_test_0002_m_000002_0 on tt2");
+    checkAssignments("tt2", 
+        new String[] {"attempt_test_0002_m_000003_0 on tt2", 
+        "attempt_test_0002_m_000004_0 on tt2"});
     verifyCapacity("0", "default");
     verifyCapacity("5", "q2");
     
     // add another tt to increase tt slots
     taskTrackerManager.addTaskTracker("tt4");
-    checkAssignment("tt3", "attempt_test_0002_m_000003_0 on tt3");
+    checkAssignments("tt3", 
+        new String[] {"attempt_test_0002_m_000005_0 on tt3", 
+        "attempt_test_0002_m_000006_0 on tt3"});
     verifyCapacity("0", "default");
     verifyCapacity("7", "q2");
     
@@ -1327,7 +1264,9 @@ public class TestCapacityScheduler extends TestCase {
     taskTrackerManager.addTaskTracker("tt5");
     // now job from default should run, as it is furthest away
     // in terms of runningMaps / capacity.
-    checkAssignment("tt4", "attempt_test_0001_m_000001_0 on tt4");
+    checkAssignments("tt4", 
+        new String[] {"attempt_test_0001_m_000001_0 on tt4", 
+        "attempt_test_0002_m_000007_0 on tt4"});
     verifyCapacity("1", "default");
     verifyCapacity("9", "q2");
   }
@@ -1336,7 +1275,7 @@ public class TestCapacityScheduler extends TestCase {
                                           String queue) throws IOException {
     String schedInfo = taskTrackerManager.getQueueManager().
                           getSchedulerInfo(queue).toString();    
-    assertTrue(schedInfo.contains("Map tasks\nCapacity: " 
+    assertTrue(schedInfo, schedInfo.contains("Map tasks\nCapacity: " 
         + expectedCapacity + " slots"));
   }
   
@@ -1348,6 +1287,8 @@ public class TestCapacityScheduler extends TestCase {
     ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
     queues.add(new FakeQueueInfo("default", 50.0f, true, 25));
     queues.add(new FakeQueueInfo("q2", 50.0f, true, 25));
+    resConf.setUserLimitFactor("default", 4);
+    resConf.setUserLimitFactor("q2", 4);
     resConf.setFakeQueues(queues);
     scheduler.setResourceManagerConf(resConf);
     scheduler.start();
@@ -1355,15 +1296,18 @@ public class TestCapacityScheduler extends TestCase {
     // submit a job  
     submitJobAndInit(JobStatus.PREP, 10, 10, "q2", "u1");
     // for queue 'q2', the capacity for maps is 2. Since we're the only user,
-    // we should get a task 
-    checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
-    // I should get another map task. 
-    checkAssignment("tt1", "attempt_test_0001_m_000002_0 on tt1");
+    // we should get 2 task 
+    checkAssignments("tt1", 
+        new String[] {"attempt_test_0001_m_000001_0 on tt1", 
+        "attempt_test_0001_m_000002_0 on tt1", 
+        "attempt_test_0001_r_000001_0 on tt1"});
+
     // Now we're at full capacity for maps. If I ask for another map task,
     // I should get a map task from the default queue's capacity. 
-    checkAssignment("tt2", "attempt_test_0001_m_000003_0 on tt2");
-    // and another
-    checkAssignment("tt2", "attempt_test_0001_m_000004_0 on tt2");
+    checkAssignments("tt2", 
+        new String[] {"attempt_test_0001_m_000003_0 on tt2", 
+        "attempt_test_0001_m_000004_0 on tt2", 
+        "attempt_test_0001_r_000002_0 on tt2"});
   }
 
   /**
@@ -1376,12 +1320,17 @@ public class TestCapacityScheduler extends TestCase {
   public void testHighMemoryBlockingWithMaxCapacity()
       throws IOException {
 
-    taskTrackerManager = new FakeTaskTrackerManager(2, 2, 2);
+    final int NUM_MAP_SLOTS = 2;
+    final int NUM_REDUCE_SLOTS = 2;
+    taskTrackerManager = 
+      new FakeTaskTrackerManager(2, NUM_MAP_SLOTS, NUM_REDUCE_SLOTS);
 
-    taskTrackerManager.addQueues(new String[] { "defaultXYZ" });
+    taskTrackerManager.addQueues(new String[] { "defaultXYZ", "q2" });
     ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
     queues.add(new FakeQueueInfo("defaultXYZ", 25.0f, true, 50));
+    queues.add(new FakeQueueInfo("q2", 75.0f, true, 50));
     resConf.setFakeQueues(queues);
+    resConf.setUserLimitFactor("defaultXYZ", 2);
 
     //defaultXYZ can go up to 2 map and 2 reduce slots
     resConf.setMaxCapacity("defaultXYZ", 50.0f);
@@ -1399,7 +1348,6 @@ public class TestCapacityScheduler extends TestCase {
         JobTracker.MAPRED_CLUSTER_REDUCE_MEMORY_MB_PROPERTY, 1 * 1024);
     scheduler.setResourceManagerConf(resConf);
     scheduler.start();
-    scheduler.setAssignMultipleTasks(true);
 
     JobConf jConf = new JobConf(conf);
     jConf.setMemoryForMapTask(2 * 1024);
@@ -1421,13 +1369,15 @@ public class TestCapacityScheduler extends TestCase {
 
 
     //high ram map from job 1 and normal reduce task from job 1
-    List<Task> tasks = checkMultipleAssignment(
-      "tt1", "attempt_test_0001_m_000001_0 on tt1",
-      "attempt_test_0001_r_000001_0 on tt1");
+    List<Task> tasks = checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0001_m_000001_0 on tt1",
+        "attempt_test_0001_r_000001_0 on tt1"});
 
     checkOccupiedSlots("defaultXYZ", TaskType.MAP, 1, 2, 200.0f,1,0);
     checkOccupiedSlots("defaultXYZ", TaskType.REDUCE, 1, 1, 100.0f,0,2);
-    checkMemReservedForTasksOnTT("tt1", 2 * 1024L, 1 * 1024L);
+    checkMemReservedForTasksOnTT("tt1", 2 * 1024L, 1 * 1024L, 
+                                 NUM_MAP_SLOTS-2, NUM_REDUCE_SLOTS-1);
 
     //we have reached the maximum limit for map, so no more map tasks.
     //we have used 1 reduce already and 1 more reduce slot is left for the
@@ -1451,7 +1401,8 @@ public class TestCapacityScheduler extends TestCase {
 
     checkOccupiedSlots("defaultXYZ", TaskType.MAP, 1, 2, 200.0f,1,0);
     checkOccupiedSlots("defaultXYZ", TaskType.REDUCE, 1, 2, 200.0f,0,2);
-    checkMemReservedForTasksOnTT("tt2", 2 * 1024L, 2 * 1024L);
+    checkMemReservedForTasksOnTT("tt2", 2 * 1024L, 2 * 1024L, 
+                                 NUM_MAP_SLOTS-2, NUM_REDUCE_SLOTS-2);
 
     //complete the high ram job on tt1.
     for (Task task : t2) {
@@ -1472,14 +1423,14 @@ public class TestCapacityScheduler extends TestCase {
   public void testUserLimitsWithMaxCapacities() throws Exception {
     setUp(2, 2, 2);
     // set up some queues
-    String[] qs = {"default"};
+    String[] qs = {"default", "q2"};
     taskTrackerManager.addQueues(qs);
     ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
     queues.add(new FakeQueueInfo("default", 50.0f, true, 50));
+    queues.add(new FakeQueueInfo("q2", 50.0f, true, 50));
     resConf.setFakeQueues(queues);
     resConf.setMaxCapacity("default", 75.0f);
     scheduler.setResourceManagerConf(resConf);
-    scheduler.setAssignMultipleTasks(true);
     scheduler.start();
 
     // submit a job
@@ -1493,22 +1444,22 @@ public class TestCapacityScheduler extends TestCase {
     //  1 map and 1 reduce.
     // after max capacity it is 1.5 each.
 
-    //first job would be given 1 job each.
-    List<Task> t1 = this.checkMultipleAssignment(
-      "tt1", "attempt_test_0001_m_000001_0 on tt1",
-      "attempt_test_0001_r_000001_0 on tt1");
+    //each job would be given 1 map task each.
+    checkAssignments("tt1", 
+      new String[] {"attempt_test_0001_m_000001_0 on tt1",
+        "attempt_test_0002_m_000001_0 on tt1", 
+        "attempt_test_0001_r_000001_0 on tt1"});
 
-    //for user u1 we have reached the limit. that is 1 job.
-    //1 more map and reduce tasks.
-    List<Task> t2 = this.checkMultipleAssignment(
-      "tt1", "attempt_test_0002_m_000001_0 on tt1",
-      "attempt_test_0002_r_000001_0 on tt1");
+    //abt to hit max map capacity for default
+    //hit user limit for reduces
+    checkAssignments("tt2", 
+        new String[] {"attempt_test_0001_m_000002_0 on tt2",
+          "attempt_test_0002_r_000001_0 on tt2"});
 
-    t1 = this.checkMultipleAssignment(
-      "tt2", "attempt_test_0001_m_000002_0 on tt2",
-      "attempt_test_0001_r_000002_0 on tt2");
-
-    t1 = this.checkMultipleAssignment("tt2", null,null);
+    // only 1 reduce slot is remaining on tt2
+    // no more maps since no map slots are available 
+    checkAssignments("tt2", 
+        new String[] { "attempt_test_0001_r_000002_0 on tt2"});
   }
 
 
@@ -1527,17 +1478,19 @@ public class TestCapacityScheduler extends TestCase {
     // submit a job  
     submitJobAndInit(JobStatus.PREP, 10, 10, "q2", "u1");
     // for queue 'q2', the capacity for maps is 2. Since we're the only user,
-    // we should get a task 
-    checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
+    // we should get 2 maps and 1 reduce 
+    checkAssignments("tt1", 
+        new String[]{"attempt_test_0001_m_000001_0 on tt1", 
+        "attempt_test_0001_m_000002_0 on tt1", 
+        "attempt_test_0001_r_000001_0 on tt1"});
+    
     // Submit another job, from a different user
     submitJobAndInit(JobStatus.PREP, 10, 10, "q2", "u2");
-    // Now if I ask for a map task, it should come from the second job 
-    checkAssignment("tt1", "attempt_test_0002_m_000001_0 on tt1");
-    // Now we're at full capacity for maps. If I ask for another map task,
-    // I should get a map task from the default queue's capacity. 
-    checkAssignment("tt2", "attempt_test_0001_m_000002_0 on tt2");
-    // and another
-    checkAssignment("tt2", "attempt_test_0002_m_000002_0 on tt2");
+    // Now if I ask for a map task, it should come from the second job from default queue's capacity 
+    checkAssignments("tt2", 
+        new String[]{"attempt_test_0002_m_000001_0 on tt2", 
+        "attempt_test_0002_m_000002_0 on tt2", 
+        "attempt_test_0002_r_000001_0 on tt2"});
   }
 
   // test user limits when a 2nd job is submitted much after first job 
@@ -1555,21 +1508,26 @@ public class TestCapacityScheduler extends TestCase {
     // submit a job  
     submitJobAndInit(JobStatus.PREP, 10, 10, "q2", "u1");
     // for queue 'q2', the capacity for maps is 2. Since we're the only user,
-    // we should get a task 
-    checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
-    // since we're the only job, we get another map
-    checkAssignment("tt1", "attempt_test_0001_m_000002_0 on tt1");
+    // we should get 2 map tasks & 1 reduce 
+    checkAssignments("tt1", 
+        new String[] {"attempt_test_0001_m_000001_0 on tt1", 
+        "attempt_test_0001_m_000002_0 on tt1", 
+        "attempt_test_0001_r_000001_0 on tt1"});
+    
     // Submit another job, from a different user
     submitJobAndInit(JobStatus.PREP, 10, 10, "q2", "u2");
     // Now if I ask for a map task, it should come from the second job 
-    checkAssignment("tt2", "attempt_test_0002_m_000001_0 on tt2");
-    // and another
-    checkAssignment("tt2", "attempt_test_0002_m_000002_0 on tt2");
+    checkAssignments("tt2", 
+        new String[] {"attempt_test_0002_m_000001_0 on tt2", 
+        "attempt_test_0002_m_000002_0 on tt2", 
+        "attempt_test_0002_r_000001_0 on tt2"});
   }
 
   // test user limits when a 2nd job is submitted much after first job 
   // and we need to wait for first job's task to complete
   public void testUserLimits3() throws Exception {
+    System.err.println("testUserLimits3");
+    
     // set up some queues
     String[] qs = {"default", "q2"};
     taskTrackerManager.addQueues(qs);
@@ -1584,27 +1542,38 @@ public class TestCapacityScheduler extends TestCase {
     FakeJobInProgress j1 = submitJobAndInit(JobStatus.PREP, 10, 10, "q2", "u1");
     // for queue 'q2', the capacity for maps is 2. Since we're the only user,
     // we should get a task 
-    checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
-    // since we're the only job, we get another map
-    checkAssignment("tt1", "attempt_test_0001_m_000002_0 on tt1");
-    // we get two more maps from 'default queue'
-    checkAssignment("tt2", "attempt_test_0001_m_000003_0 on tt2");
-    checkAssignment("tt2", "attempt_test_0001_m_000004_0 on tt2");
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0001_m_000001_0 on tt1", 
+        "attempt_test_0001_m_000002_0 on tt1", 
+        "attempt_test_0001_r_000001_0 on tt1"});
+
+    // No tasks assigned since u1 has hit user limits of 50% i.e. q2 capacity
+    checkAssignments("tt2", new String[] {});
+
     // Submit another job, from a different user
     FakeJobInProgress j2 = submitJobAndInit(JobStatus.PREP, 10, 10, "q2", "u2");
-    // one of the task finishes
-    taskTrackerManager.finishTask("tt1", "attempt_test_0001_m_000001_0", j1);
+    
     // Now if I ask for a map task, it should come from the second job 
-    checkAssignment("tt1", "attempt_test_0002_m_000001_0 on tt1");
-    // another task from job1 finishes, another new task to job2
-    taskTrackerManager.finishTask("tt1", "attempt_test_0001_m_000002_0", j1);
-    checkAssignment("tt1", "attempt_test_0002_m_000002_0 on tt1");
+    // and reduce from job2
+    checkAssignments("tt2", 
+        new String[] {
+        "attempt_test_0002_m_000001_0 on tt2",
+        "attempt_test_0002_m_000002_0 on tt2",
+        "attempt_test_0002_r_000001_0 on tt2",
+        });
+    
+    // A task from job1 finishes
+    // job1 shud get the map slot since u1 has only 1 task running 
+    taskTrackerManager.finishTask("tt1", "attempt_test_0001_m_000001_0", j1);
+    checkAssignments("tt1", new String[] {"attempt_test_0001_m_000003_0 on tt1"});
+    
     // now we have equal number of tasks from each job. Whichever job's
     // task finishes, that job gets a new task
-    taskTrackerManager.finishTask("tt2", "attempt_test_0001_m_000003_0", j1);
-    checkAssignment("tt2", "attempt_test_0001_m_000005_0 on tt2");
-    taskTrackerManager.finishTask("tt1", "attempt_test_0002_m_000001_0", j2);
-    checkAssignment("tt1", "attempt_test_0002_m_000003_0 on tt1");
+    taskTrackerManager.finishTask("tt2", "attempt_test_0002_m_000001_0", j2);
+    checkAssignments("tt2", new String[] {"attempt_test_0002_m_000003_0 on tt2"});
+    taskTrackerManager.finishTask("tt1", "attempt_test_0001_m_000002_0", j1);
+    checkAssignment("tt1", "attempt_test_0001_m_000004_0 on tt1");
   }
 
   // test user limits with many users, more slots
@@ -1624,23 +1593,44 @@ public class TestCapacityScheduler extends TestCase {
 
     // u1 submits job
     FakeJobInProgress j1 = submitJobAndInit(JobStatus.PREP, 10, 10, null, "u1");
-    // it gets the first 5 slots
-    checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0001_m_000002_0 on tt1");
-    checkAssignment("tt2", "attempt_test_0001_m_000003_0 on tt2");
-    checkAssignment("tt2", "attempt_test_0001_m_000004_0 on tt2");
-    checkAssignment("tt3", "attempt_test_0001_m_000005_0 on tt3");
+    // it gets the first 6 slots
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0001_m_000001_0 on tt1",
+        "attempt_test_0001_m_000002_0 on tt1",
+        "attempt_test_0001_r_000001_0 on tt1"
+    });
+    checkAssignments("tt2", 
+        new String[] {
+        "attempt_test_0001_m_000003_0 on tt2",
+        "attempt_test_0001_m_000004_0 on tt2",
+        "attempt_test_0001_r_000002_0 on tt2"
+    });
+    checkAssignments("tt3", 
+        new String[] {
+        "attempt_test_0001_m_000005_0 on tt3",
+        "attempt_test_0001_m_000006_0 on tt3",
+        "attempt_test_0001_r_000003_0 on tt3"
+    });
+    
     // u2 submits job with 4 slots
     FakeJobInProgress j2 = submitJobAndInit(JobStatus.PREP, 4, 4, null, "u2");
     // u2 should get next 4 slots
-    checkAssignment("tt3", "attempt_test_0002_m_000001_0 on tt3");
-    checkAssignment("tt4", "attempt_test_0002_m_000002_0 on tt4");
-    checkAssignment("tt4", "attempt_test_0002_m_000003_0 on tt4");
-    checkAssignment("tt5", "attempt_test_0002_m_000004_0 on tt5");
-    // last slot should go to u1, since u2 has no more tasks
-    checkAssignment("tt5", "attempt_test_0001_m_000006_0 on tt5");
+    checkAssignments("tt4", 
+        new String[] {
+        "attempt_test_0002_m_000001_0 on tt4",
+        "attempt_test_0002_m_000002_0 on tt4",
+        "attempt_test_0002_r_000001_0 on tt4"
+    });
+    checkAssignments("tt5", 
+        new String[] {
+        "attempt_test_0002_m_000003_0 on tt5",
+        "attempt_test_0002_m_000004_0 on tt5",
+        "attempt_test_0002_r_000002_0 on tt5"
+    });
+
     // u1 finishes a task
-    taskTrackerManager.finishTask("tt5", "attempt_test_0001_m_000006_0", j1);
+    taskTrackerManager.finishTask("tt3", "attempt_test_0001_m_000006_0", j1);
     // u1 submits a few more jobs 
     // All the jobs are inited when submitted
     // because of addition of Eager Job Initializer all jobs in this
@@ -1654,10 +1644,10 @@ public class TestCapacityScheduler extends TestCase {
     submitJobAndInit(JobStatus.PREP, 2, 2, null, "u3");
     // next slot should go to u3, even though u2 has an earlier job, since
     // user limits have changed and u1/u2 are over limits
-    checkAssignment("tt5", "attempt_test_0007_m_000001_0 on tt5");
+    checkAssignment("tt3", "attempt_test_0007_m_000001_0 on tt3");
     // some other task finishes and u3 gets it
-    taskTrackerManager.finishTask("tt5", "attempt_test_0002_m_000004_0", j1);
-    checkAssignment("tt5", "attempt_test_0007_m_000002_0 on tt5");
+    taskTrackerManager.finishTask("tt3", "attempt_test_0001_m_000005_0", j1);
+    checkAssignment("tt3", "attempt_test_0007_m_000002_0 on tt3");
     // now, u2 finishes a task
     taskTrackerManager.finishTask("tt4", "attempt_test_0002_m_000002_0", j1);
     // next slot will go to u1, since u3 has nothing to run and u1's job is 
@@ -1673,6 +1663,7 @@ public class TestCapacityScheduler extends TestCase {
    */
   public void testUserLimitsForHighMemoryJobs()
       throws IOException {
+    System.err.println("testUserLimitsForHighMemoryJobs");
     taskTrackerManager = new FakeTaskTrackerManager(1, 10, 10);
     scheduler.setTaskTrackerManager(taskTrackerManager);
     String[] qs = { "default" };
@@ -1714,30 +1705,25 @@ public class TestCapacityScheduler extends TestCase {
     jConf.setUser("u2");
     FakeJobInProgress job2 = submitJobAndInit(JobStatus.PREP, jConf);
 
-    // Verify that normal job takes 3 task assignments to hit user limits
-    checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0001_r_000001_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0001_m_000002_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0001_r_000002_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0001_m_000003_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0001_r_000003_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0001_m_000004_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0001_r_000004_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0001_m_000005_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0001_r_000005_0 on tt1");
-    // u1 has 5 map slots and 5 reduce slots. u2 has none. So u1's user limits
-    // are hit. So u2 should get slots
-
-    checkAssignment("tt1", "attempt_test_0002_m_000001_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0002_r_000001_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0002_m_000002_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0002_r_000002_0 on tt1");
+    // Verify that normal job takes 3 task assignments to hit user limits,
+    // and then j2 gets 4 slots
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0001_m_000001_0 on tt1",
+        "attempt_test_0001_m_000002_0 on tt1",
+        "attempt_test_0001_m_000003_0 on tt1",
+        "attempt_test_0001_m_000004_0 on tt1",
+        "attempt_test_0001_m_000005_0 on tt1",
+        "attempt_test_0002_m_000001_0 on tt1",
+        "attempt_test_0002_m_000002_0 on tt1",
+        "attempt_test_0001_r_000001_0 on tt1",
+    });
 
     // u1 has 5 map slots and 5 reduce slots. u2 has 4 map slots and 4 reduce
     // slots. Because of high memory tasks, giving u2 another task would
     // overflow limits. So, no more tasks should be given to anyone.
-    assertNull(scheduler.assignTasks(tracker("tt1")));
-    assertNull(scheduler.assignTasks(tracker("tt1")));
+//    assertEquals(0, scheduler.assignTasks(tracker("tt1")).size());
+//    assertEquals(0, scheduler.assignTasks(tracker("tt1")).size());
   }
 
   /*
@@ -1775,6 +1761,7 @@ public class TestCapacityScheduler extends TestCase {
    */
 
   public void testSchedulingInformation() throws Exception {
+    System.err.println("testSchedulingInformation()");
     String[] qs = {"default", "q2"};
     taskTrackerManager = new FakeTaskTrackerManager(2, 1, 1);
     scheduler.setTaskTrackerManager(taskTrackerManager);
@@ -1783,6 +1770,8 @@ public class TestCapacityScheduler extends TestCase {
     queues.add(new FakeQueueInfo("default", 50.0f, true, 25));
     queues.add(new FakeQueueInfo("q2", 50.0f, true, 25));
     resConf.setFakeQueues(queues);
+    resConf.setMaxInitializedActiveTasksPerUser("default", 4);  // 4 tasks max
+    resConf.setMaxInitializedActiveTasksPerUser("q2", 4);  // 4 tasks max
     scheduler.setResourceManagerConf(resConf);
     scheduler.start();
 
@@ -1797,7 +1786,7 @@ public class TestCapacityScheduler extends TestCase {
     String schedulingInfo2 =
         queueManager.getJobQueueInfo("q2").getSchedulingInfo();
     String[] infoStrings = schedulingInfo.split("\n");
-    assertEquals(infoStrings.length, 18);
+    assertEquals(infoStrings.length, 19);
     assertEquals(infoStrings[0], "Queue configuration");
     assertEquals(infoStrings[1], "Capacity Percentage: 50.0%");
     assertEquals(infoStrings[2], "User Limit: 25%");
@@ -1817,7 +1806,8 @@ public class TestCapacityScheduler extends TestCase {
     assertEquals(infoStrings[14], "-------------");
     assertEquals(infoStrings[15], "Job info");
     assertEquals(infoStrings[16], "Number of Waiting Jobs: 0");
-    assertEquals(infoStrings[17], "Number of users who have submitted jobs: 0");
+    assertEquals(infoStrings[17], "Number of Initializing Jobs: 0");
+    assertEquals(infoStrings[18], "Number of users who have submitted jobs: 0");
     assertEquals(schedulingInfo, schedulingInfo2);
 
     //Testing with actual job submission.
@@ -1828,13 +1818,14 @@ public class TestCapacityScheduler extends TestCase {
     infoStrings = schedulingInfo.split("\n");
 
     //waiting job should be equal to number of jobs submitted.
-    assertEquals(infoStrings.length, 18);
+    assertEquals(infoStrings.length, 19);
     assertEquals(infoStrings[7], "Used capacity: 0 (0.0% of Capacity)");
     assertEquals(infoStrings[8], "Running tasks: 0");
     assertEquals(infoStrings[12], "Used capacity: 0 (0.0% of Capacity)");
     assertEquals(infoStrings[13], "Running tasks: 0");
     assertEquals(infoStrings[16], "Number of Waiting Jobs: 5");
-    assertEquals(infoStrings[17], "Number of users who have submitted jobs: 1");
+    assertEquals(infoStrings[17], "Number of Initializing Jobs: 0");
+    assertEquals(infoStrings[18], "Number of users who have submitted jobs: 1");
 
     //Initalize the jobs but don't raise events
     controlledInitializationPoller.selectJobsToInitialize();
@@ -1842,74 +1833,61 @@ public class TestCapacityScheduler extends TestCase {
     schedulingInfo =
       queueManager.getJobQueueInfo("default").getSchedulingInfo();
     infoStrings = schedulingInfo.split("\n");
-    assertEquals(infoStrings.length, 18);
-    //should be previous value as nothing is scheduled because no events
-    //has been raised after initialization.
+    assertEquals(infoStrings.length, 19);
+    //2 jobs are now 'ready to init'
+    //3 are waiting due to init task limits
     assertEquals(infoStrings[7], "Used capacity: 0 (0.0% of Capacity)");
     assertEquals(infoStrings[8], "Running tasks: 0");
     assertEquals(infoStrings[12], "Used capacity: 0 (0.0% of Capacity)");
     assertEquals(infoStrings[13], "Running tasks: 0");
-    assertEquals(infoStrings[16], "Number of Waiting Jobs: 5");
+    assertEquals(infoStrings[16], "Number of Waiting Jobs: 3");
 
     //Raise status change event so that jobs can move to running queue.
     raiseStatusChangeEvents(scheduler.jobQueuesManager);
     raiseStatusChangeEvents(scheduler.jobQueuesManager, "q2");
     //assign one job
-    Task t1 = checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0001_m_000001_0 on tt1", 
+        "attempt_test_0001_r_000001_0 on tt1"});
+    
     //Initalize extra job.
     controlledInitializationPoller.selectJobsToInitialize();
 
     //Get scheduling information, now the number of waiting job should have
-    //changed to 4 as one is scheduled and has become running.
+    //be 3 and initializing is 0 as 2 have been scheduled.
     // make sure we update our stats
-    scheduler.updateQSIInfoForTests();
+    scheduler.updateQueueUsageForTests();
     schedulingInfo =
       queueManager.getJobQueueInfo("default").getSchedulingInfo();
     infoStrings = schedulingInfo.split("\n");
-    assertEquals(infoStrings.length, 20);
-    assertEquals(infoStrings[7], "Used capacity: 1 (100.0% of Capacity)");
-    assertEquals(infoStrings[8], "Running tasks: 1");
-    assertEquals(infoStrings[9], "Active users:");
-    assertEquals(infoStrings[10], "User 'u1': 1 (100.0% of used capacity)");
-    assertEquals(infoStrings[14], "Used capacity: 0 (0.0% of Capacity)");
-    assertEquals(infoStrings[15], "Running tasks: 0");
-    assertEquals(infoStrings[18], "Number of Waiting Jobs: 4");
-
-    //assign a reduce task
-    Task t2 = checkAssignment("tt1", "attempt_test_0001_r_000001_0 on tt1");
-    // make sure we update our stats
-    scheduler.updateQSIInfoForTests();
-    schedulingInfo =
-      queueManager.getJobQueueInfo("default").getSchedulingInfo();
-    infoStrings = schedulingInfo.split("\n");
-    assertEquals(infoStrings.length, 22);
-    assertEquals(infoStrings[7], "Used capacity: 1 (100.0% of Capacity)");
-    assertEquals(infoStrings[8], "Running tasks: 1");
-    assertEquals(infoStrings[9], "Active users:");
-    assertEquals(infoStrings[10], "User 'u1': 1 (100.0% of used capacity)");
-    assertEquals(infoStrings[14], "Used capacity: 1 (100.0% of Capacity)");
-    assertEquals(infoStrings[15], "Running tasks: 1");
-    assertEquals(infoStrings[16], "Active users:");
-    assertEquals(infoStrings[17], "User 'u1': 1 (100.0% of used capacity)");
-    assertEquals(infoStrings[20], "Number of Waiting Jobs: 4");
-
+    assertEquals(schedulingInfo, 23, infoStrings.length);
+    assertEquals(infoStrings[7], infoStrings[7], "Used capacity: 1 (100.0% of Capacity)");
+    assertEquals(infoStrings[8], infoStrings[8], "Running tasks: 1");
+    assertEquals(infoStrings[9], infoStrings[9], "Active users:");
+    assertEquals(infoStrings[10], infoStrings[10], "User 'u1': 1 (100.0% of used capacity)");
+    assertEquals(infoStrings[14], infoStrings[14], "Used capacity: 1 (100.0% of Capacity)");
+    assertEquals(infoStrings[15], infoStrings[15], "Running tasks: 1");
+    assertEquals(infoStrings[18], infoStrings[20], "Number of Waiting Jobs: 3");
+    assertEquals(infoStrings[18], infoStrings[21], "Number of Initializing Jobs: 0");
+    
     //Complete the job and check the running tasks count
     FakeJobInProgress u1j1 = userJobs.get(0);
-    taskTrackerManager.finishTask("tt1", t1.getTaskID().toString(), u1j1);
-    taskTrackerManager.finishTask("tt1", t2.getTaskID().toString(), u1j1);
+    taskTrackerManager.finishTask("tt1", "attempt_test_0001_m_000001_0", u1j1);
+    taskTrackerManager.finishTask("tt1", "attempt_test_0001_r_000001_0", u1j1);
     taskTrackerManager.finalizeJob(u1j1);
 
     // make sure we update our stats
-    scheduler.updateQSIInfoForTests();
+    scheduler.updateQueueUsageForTests();
     schedulingInfo =
       queueManager.getJobQueueInfo("default").getSchedulingInfo();
     infoStrings = schedulingInfo.split("\n");
-    assertEquals(infoStrings.length, 18);
-    assertEquals(infoStrings[7], "Used capacity: 0 (0.0% of Capacity)");
-    assertEquals(infoStrings[8], "Running tasks: 0");
-    assertEquals(infoStrings[12], "Used capacity: 0 (0.0% of Capacity)");
-    assertEquals(infoStrings[13], "Running tasks: 0");
-    assertEquals(infoStrings[16], "Number of Waiting Jobs: 4");
+    assertEquals(infoStrings.length, 19);
+    assertEquals(infoStrings[7], infoStrings[7], "Used capacity: 0 (0.0% of Capacity)");
+    assertEquals(infoStrings[8], infoStrings[8], "Running tasks: 0");
+    assertEquals(infoStrings[12], infoStrings[12], "Used capacity: 0 (0.0% of Capacity)");
+    assertEquals(infoStrings[13], infoStrings[13], "Running tasks: 0");
+    assertEquals(infoStrings[16], infoStrings[16], "Number of Waiting Jobs: 3");
 
     //Fail a job which is initialized but not scheduled and check the count.
     FakeJobInProgress u1j2 = userJobs.get(1);
@@ -1919,18 +1897,18 @@ public class TestCapacityScheduler extends TestCase {
     //Run initializer to clean up failed jobs
     controlledInitializationPoller.selectJobsToInitialize();
     // make sure we update our stats
-    scheduler.updateQSIInfoForTests();
+    scheduler.updateQueueUsageForTests();
     schedulingInfo =
       queueManager.getJobQueueInfo("default").getSchedulingInfo();
     infoStrings = schedulingInfo.split("\n");
-    assertEquals(infoStrings.length, 18);
-    //should be previous value as nothing is scheduled because no events
-    //has been raised after initialization.
+    assertEquals(infoStrings.length, 19);
+    //2 more jobs are now in 'initializing state', none 'initialized'
     assertEquals(infoStrings[7], "Used capacity: 0 (0.0% of Capacity)");
     assertEquals(infoStrings[8], "Running tasks: 0");
     assertEquals(infoStrings[12], "Used capacity: 0 (0.0% of Capacity)");
     assertEquals(infoStrings[13], "Running tasks: 0");
-    assertEquals(infoStrings[16], "Number of Waiting Jobs: 3");
+    assertEquals(infoStrings[16], "Number of Waiting Jobs: 1");
+    assertEquals(infoStrings[17], "Number of Initializing Jobs: 2");
 
     //Fail a job which is not initialized but is in the waiting queue.
     FakeJobInProgress u1j5 = userJobs.get(4);
@@ -1941,18 +1919,19 @@ public class TestCapacityScheduler extends TestCase {
     //run initializer to clean up failed job
     controlledInitializationPoller.selectJobsToInitialize();
     // make sure we update our stats
-    scheduler.updateQSIInfoForTests();
+    scheduler.updateQueueUsageForTests();
     schedulingInfo =
       queueManager.getJobQueueInfo("default").getSchedulingInfo();
     infoStrings = schedulingInfo.split("\n");
-    assertEquals(infoStrings.length, 18);
-    //should be previous value as nothing is scheduled because no events
-    //has been raised after initialization.
+    assertEquals(infoStrings.length, 19);
+    //no more waiting jobs
+    //all jobs are initing
     assertEquals(infoStrings[7], "Used capacity: 0 (0.0% of Capacity)");
     assertEquals(infoStrings[8], "Running tasks: 0");
     assertEquals(infoStrings[12], "Used capacity: 0 (0.0% of Capacity)");
     assertEquals(infoStrings[13], "Running tasks: 0");
-    assertEquals(infoStrings[16], "Number of Waiting Jobs: 2");
+    assertEquals(infoStrings[16], "Number of Waiting Jobs: 0");
+    assertEquals(infoStrings[17], "Number of Initializing Jobs: 2");
 
     //Raise status change events as none of the intialized jobs would be
     //in running queue as we just failed the second job which was initialized
@@ -1962,38 +1941,45 @@ public class TestCapacityScheduler extends TestCase {
 
     //Now schedule a map should be job3 of the user as job1 succeeded job2
     //failed and now job3 is running
-    t1 = checkAssignment("tt1", "attempt_test_0003_m_000001_0 on tt1");
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0003_m_000001_0 on tt1",
+        "attempt_test_0003_r_000001_0 on tt1"});
     FakeJobInProgress u1j3 = userJobs.get(2);
     assertTrue("User Job 3 not running ",
         u1j3.getStatus().getRunState() == JobStatus.RUNNING);
 
-    //now the running count of map should be one and waiting jobs should be
+    //now the running count of map should be one and initing jobs should be
     //one. run the poller as it is responsible for waiting count
     controlledInitializationPoller.selectJobsToInitialize();
     // make sure we update our stats
-    scheduler.updateQSIInfoForTests();
+    scheduler.updateQueueUsageForTests();
     schedulingInfo =
       queueManager.getJobQueueInfo("default").getSchedulingInfo();
     infoStrings = schedulingInfo.split("\n");
-    assertEquals(infoStrings.length, 20);
-    assertEquals(infoStrings[7], "Used capacity: 1 (100.0% of Capacity)");
-    assertEquals(infoStrings[8], "Running tasks: 1");
-    assertEquals(infoStrings[9], "Active users:");
-    assertEquals(infoStrings[10], "User 'u1': 1 (100.0% of used capacity)");
-    assertEquals(infoStrings[18], "Number of Waiting Jobs: 1");
+    assertEquals(infoStrings.length, 23);
+    assertEquals(infoStrings[7], infoStrings[7], "Used capacity: 1 (100.0% of Capacity)");
+    assertEquals(infoStrings[8], infoStrings[8], "Running tasks: 1");
+    assertEquals(infoStrings[9], infoStrings[9], "Active users:");
+    assertEquals(infoStrings[10], infoStrings[10], "User 'u1': 1 (100.0% of used capacity)");
+    assertEquals(infoStrings[14], infoStrings[14], "Used capacity: 1 (100.0% of Capacity)");
+    assertEquals(infoStrings[15], infoStrings[15], "Running tasks: 1");
+    assertEquals(infoStrings[18], infoStrings[20], "Number of Waiting Jobs: 0");
+    assertEquals(infoStrings[18], infoStrings[21], "Number of Initializing Jobs: 0");
 
     //Fail the executing job
     taskTrackerManager.finalizeJob(u1j3, JobStatus.FAILED);
     // make sure we update our stats
-    scheduler.updateQSIInfoForTests();
+    scheduler.updateQueueUsageForTests();
     //Now running counts should become zero
     schedulingInfo =
       queueManager.getJobQueueInfo("default").getSchedulingInfo();
     infoStrings = schedulingInfo.split("\n");
-    assertEquals(infoStrings.length, 18);
+    assertEquals(infoStrings.length, 19);
     assertEquals(infoStrings[7], "Used capacity: 0 (0.0% of Capacity)");
     assertEquals(infoStrings[8], "Running tasks: 0");
-    assertEquals(infoStrings[16], "Number of Waiting Jobs: 1");
+    assertEquals(infoStrings[16], "Number of Waiting Jobs: 0");
+    assertEquals(infoStrings[17], "Number of Initializing Jobs: 0");
   }
 
   /**
@@ -2030,8 +2016,9 @@ public class TestCapacityScheduler extends TestCase {
     // assert that all tasks are launched even though they transgress the
     // scheduling limits.
 
-    checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0001_r_000001_0 on tt1");
+    checkAssignments("tt1", 
+        new String[] {"attempt_test_0001_m_000001_0 on tt1", 
+        "attempt_test_0001_r_000001_0 on tt1"});
   }
 
   /**
@@ -2044,7 +2031,10 @@ public class TestCapacityScheduler extends TestCase {
       throws IOException {
 
     // 2 map and 1 reduce slots
-    taskTrackerManager = new FakeTaskTrackerManager(1, 2, 1);
+    final int NUM_MAP_SLOTS = 2;
+    final int NUM_REDUCE_SLOTS = 1;
+    taskTrackerManager = 
+      new FakeTaskTrackerManager(1, NUM_MAP_SLOTS, NUM_REDUCE_SLOTS);
 
     taskTrackerManager.addQueues(new String[] { "default" });
     ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
@@ -2095,18 +2085,15 @@ public class TestCapacityScheduler extends TestCase {
     FakeJobInProgress job2 = submitJobAndInit(JobStatus.PREP, jConf);
     
     // first, a map from j1 will run
-    checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
-    // Total 2 map slots should be accounted for.
+    checkAssignments("tt1", 
+        new String[] {"attempt_test_0001_m_000001_0 on tt1",
+        "attempt_test_0002_r_000001_0 on tt1"});
+    // Total 2 maps & 1 reduce slot should be accounted for.
     checkOccupiedSlots("default", TaskType.MAP, 1, 2, 100.0f);
-    checkMemReservedForTasksOnTT("tt1", 2 * 1024L, 0L);
-
-    // at this point, the scheduler tries to schedule another map from j1. 
-    // there isn't enough space. The second job's reduce should be scheduled.
-    checkAssignment("tt1", "attempt_test_0002_r_000001_0 on tt1");
-    // Total 1 reduce slot should be accounted for.
     checkOccupiedSlots("default", TaskType.REDUCE, 1, 1,
         100.0f);
-    checkMemReservedForTasksOnTT("tt1", 2 * 1024L, 1 * 1024L);
+    checkMemReservedForTasksOnTT("tt1", 2 * 1024L, 1 * 1024L,
+                                 NUM_MAP_SLOTS-2, NUM_REDUCE_SLOTS-1);
   }
 
   /**
@@ -2127,7 +2114,10 @@ public class TestCapacityScheduler extends TestCase {
       throws IOException {
 
     LOG.debug("Starting the scheduler.");
-    taskTrackerManager = new FakeTaskTrackerManager(3, 2, 2);
+    final int NUM_MAP_SLOTS = 2;
+    final int NUM_REDUCE_SLOTS = 2;
+    taskTrackerManager = 
+      new FakeTaskTrackerManager(3, NUM_MAP_SLOTS, NUM_REDUCE_SLOTS);
 
     ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
     queues.add(new FakeQueueInfo("default", 100.0f, true, 25));
@@ -2161,25 +2151,22 @@ public class TestCapacityScheduler extends TestCase {
     FakeJobInProgress job1 = submitJobAndInit(JobStatus.PREP, jConf);
 
     // Fill a tt with this job's tasks.
-    checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
-    // Total 1 map slot should be accounted for.
-    checkOccupiedSlots("default", TaskType.MAP, 1, 1, 16.7f);
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0001_m_000001_0 on tt1", 
+        "attempt_test_0001_m_000002_0 on tt1", 
+        "attempt_test_0001_r_000001_0 on tt1"});
+    // Total 2 map slot and 1 reduce should be accounted for.
+    checkOccupiedSlots("default", TaskType.MAP, 1, 2, 33.33f);
     assertEquals(
-        CapacityTaskScheduler.getJobQueueSchedInfo(1, 1, 0, 0, 0, 0),
+        CapacityTaskScheduler.getJobQueueSchedInfo(2, 2, 0, 1, 1, 0),
         (String) job1.getSchedulingInfo());
-    checkMemReservedForTasksOnTT("tt1", 1 * 1024L, 0L);
-
-    // same for reduces.
-    checkAssignment("tt1", "attempt_test_0001_r_000001_0 on tt1");
-    checkOccupiedSlots("default", TaskType.REDUCE, 1, 1, 16.7f);
-    assertEquals(
-        CapacityTaskScheduler.getJobQueueSchedInfo(1, 1, 0, 1, 1, 0),
-        (String) job1.getSchedulingInfo());
-    checkMemReservedForTasksOnTT("tt1", 1 * 1024L, 1 * 1024L);
+    checkMemReservedForTasksOnTT("tt1", 2 * 1024L, 1 * 1024L, 
+                                 NUM_MAP_SLOTS-2, NUM_REDUCE_SLOTS-1);
 
     // fill another TT with the rest of the tasks of the job
-    checkAssignment("tt2", "attempt_test_0001_m_000002_0 on tt2");
-    checkAssignment("tt2", "attempt_test_0001_r_000002_0 on tt2");
+    checkAssignments("tt2", 
+        new String[] {"attempt_test_0001_r_000002_0 on tt2"});
 
     LOG.debug("Submit one high memory(2GB maps/reduces) job of "
         + "2 map, 2 reduce tasks.");
@@ -2194,19 +2181,19 @@ public class TestCapacityScheduler extends TestCase {
 
     // Have another TT run one task of each type of the high RAM
     // job. This will fill up the TT. 
-    checkAssignment("tt3", "attempt_test_0002_m_000001_0 on tt3");
+    checkAssignments("tt3", 
+        new String[] {
+        "attempt_test_0002_m_000001_0 on tt3",
+        "attempt_test_0002_r_000001_0 on tt3"
+    });
+    
     checkOccupiedSlots("default", TaskType.MAP, 1, 4, 66.7f);
     assertEquals(
-        CapacityTaskScheduler.getJobQueueSchedInfo(1, 2, 0, 0, 0, 0),
-        (String) job2.getSchedulingInfo());
-    checkMemReservedForTasksOnTT("tt3", 2 * 1024L, 0L);
-
-    checkAssignment("tt3", "attempt_test_0002_r_000001_0 on tt3");
-    checkOccupiedSlots("default", TaskType.REDUCE, 1, 4, 66.7f);
-    assertEquals(
         CapacityTaskScheduler.getJobQueueSchedInfo(1, 2, 0, 1, 2, 0),
         (String) job2.getSchedulingInfo());
-    checkMemReservedForTasksOnTT("tt3", 2 * 1024L, 2 * 1024L);
+    checkMemReservedForTasksOnTT("tt3", 2 * 1024L, 2 * 1024L, 
+                                 NUM_MAP_SLOTS-2, NUM_REDUCE_SLOTS-2);
+
 
     LOG.debug("Submit one normal memory(1GB maps/reduces) job of "
         + "1 map, 1 reduce tasks.");
@@ -2221,23 +2208,33 @@ public class TestCapacityScheduler extends TestCase {
 
     // Send a TT with insufficient space for task assignment,
     // This will cause a reservation for the high RAM job.
-    assertNull(scheduler.assignTasks(tracker("tt1")));
+    checkAssignments("tt2", 
+        new String[] {
+        "attempt_test_0002_m_000002_0 on tt2"
+    });
 
     // reserved tasktrackers contribute to occupied slots for maps and reduces
     checkOccupiedSlots("default", TaskType.MAP, 1, 6, 100.0f);
     checkOccupiedSlots("default", TaskType.REDUCE, 1, 6, 100.0f);
-    checkMemReservedForTasksOnTT("tt1", 1 * 1024L, 1 * 1024L);
+    checkMemReservedForTasksOnTT("tt2", 2 * 1024L, 1 * 1024L, 
+                                 0, NUM_REDUCE_SLOTS-1);
     LOG.info(job2.getSchedulingInfo());
     assertEquals(
-        CapacityTaskScheduler.getJobQueueSchedInfo(1, 2, 2, 1, 2, 2),
+        CapacityTaskScheduler.getJobQueueSchedInfo(2, 4, 0, 1, 2, 2),
         (String) job2.getSchedulingInfo());
     assertEquals(
         CapacityTaskScheduler.getJobQueueSchedInfo(0, 0, 0, 0, 0, 0),
         (String) job3.getSchedulingInfo());
     
-    // Reservations are already done for job2. So job3 should go ahead.
-    checkAssignment("tt2", "attempt_test_0003_m_000001_0 on tt2");
-    checkAssignment("tt2", "attempt_test_0003_r_000001_0 on tt2");
+    // Reservations are already done for job2. 
+    // So job3 should go ahead. 
+    // However, it has hit the user limit of 6 for reduces (incl. the reserved
+    // slot), so we should only get a map.
+    taskTrackerManager.finishTask("tt1", "attempt_test_0001_m_000001_0", job1);
+    scheduler.updateQueueUsageForTests();
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0003_m_000001_0 on tt1"});
   }
 
   /**
@@ -2250,7 +2247,10 @@ public class TestCapacityScheduler extends TestCase {
   public void testMemoryMatchingWithRetiredJobs() throws IOException {
     // create a cluster with a single node.
     LOG.debug("Starting cluster with 1 tasktracker, 2 map and 2 reduce slots");
-    taskTrackerManager = new FakeTaskTrackerManager(1, 2, 2);
+    final int NUM_MAP_SLOTS = 2;
+    final int NUM_REDUCE_SLOTS = 2;
+    taskTrackerManager = 
+      new FakeTaskTrackerManager(1, NUM_MAP_SLOTS, NUM_REDUCE_SLOTS);
 
     // create scheduler
     ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
@@ -2274,35 +2274,33 @@ public class TestCapacityScheduler extends TestCase {
     scheduler.start();
     
     // submit a normal job
-    LOG.debug("Submitting a normal job with 2 maps and 2 reduces");
+    LOG.debug("Submitting a normal job with 1 maps and 1 reduces");
     JobConf jConf = new JobConf();
-    jConf.setNumMapTasks(2);
-    jConf.setNumReduceTasks(2);
+    jConf.setNumMapTasks(1);
+    jConf.setNumReduceTasks(1);
     jConf.setMemoryForMapTask(512);
     jConf.setMemoryForReduceTask(512);
     jConf.setQueueName("default");
     jConf.setUser("u1");
+    jConf.setSpeculativeExecution(false);
     FakeJobInProgress job1 = submitJobAndInit(JobStatus.PREP, jConf);
 
-    // 1st cycle - 1 map gets assigned.
-    Task t = checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
-    // Total 1 map slot should be accounted for.
+    // 1st cycle - 1 map & 1 reduce gets assigned.
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0001_m_000001_0 on tt1",
+        "attempt_test_0001_r_000001_0 on tt1"});
+    // Total 1 map & 1 reduce slot should be accounted for.
     checkOccupiedSlots("default", TaskType.MAP, 1, 1, 50.0f);
-    checkMemReservedForTasksOnTT("tt1",  512L, 0L);
-
-    // 1st cycle of reduces - 1 reduce gets assigned.
-    Task t1 = checkAssignment("tt1", "attempt_test_0001_r_000001_0 on tt1");
-    // Total 1 reduce slot should be accounted for.
-    checkOccupiedSlots("default", TaskType.REDUCE, 1, 1,
-        50.0f);
-    checkMemReservedForTasksOnTT("tt1",  512L, 512L);
+    checkOccupiedSlots("default", TaskType.REDUCE, 1, 1, 50.0f);
+    checkMemReservedForTasksOnTT("tt1",  512L, 512L, 
+                                 NUM_MAP_SLOTS-1, NUM_REDUCE_SLOTS-1);
     
     // kill this job !
     taskTrackerManager.killJob(job1.getJobID());
     // No more map/reduce slots should be accounted for.
     checkOccupiedSlots("default", TaskType.MAP, 0, 0, 0.0f);
-    checkOccupiedSlots("default", TaskType.REDUCE, 0, 0,
-        0.0f);
+    checkOccupiedSlots("default", TaskType.REDUCE, 0, 0, 0.0f);
     
     // retire the job
     taskTrackerManager.removeJob(job1.getJobID());
@@ -2320,53 +2318,55 @@ public class TestCapacityScheduler extends TestCase {
     
     // since with HADOOP-5964, we don't rely on a job conf to get
     // the memory occupied, scheduling should be able to work correctly.
-    t1 = checkAssignment("tt1", "attempt_test_0002_m_000001_0 on tt1");
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0002_m_000001_0 on tt1",
+        "attempt_test_0002_r_000001_0 on tt1"
+    });
     checkOccupiedSlots("default", TaskType.MAP, 1, 1, 50);
-    checkMemReservedForTasksOnTT("tt1", 1024L, 512L);
-
-    // assign a reduce now.
-    t1 = checkAssignment("tt1", "attempt_test_0002_r_000001_0 on tt1");
     checkOccupiedSlots("default", TaskType.REDUCE, 1, 1, 50);
-    checkMemReservedForTasksOnTT("tt1", 1024L, 1024L);
+    checkMemReservedForTasksOnTT("tt1", 1024L, 1024L, 
+                                 NUM_MAP_SLOTS-2, NUM_REDUCE_SLOTS-2);
     
     // now, no more can be assigned because all the slots are blocked.
-    assertNull(scheduler.assignTasks(tracker("tt1")));
+    assertEquals(0, scheduler.assignTasks(tracker("tt1")).size());
 
     // finish the tasks on the tracker.
-    taskTrackerManager.finishTask("tt1", t.getTaskID().toString(), job1);
-    taskTrackerManager.finishTask("tt1", t1.getTaskID().toString(), job1);
-    
-    // now a new task can be assigned.
-    t = checkAssignment("tt1", "attempt_test_0002_m_000002_0 on tt1");
+    taskTrackerManager.finishTask("tt1", "attempt_test_0001_m_000001_0", job1);
+    taskTrackerManager.finishTask("tt1", "attempt_test_0001_r_000001_0", job1);
+    
+    // now new tasks can be assigned.
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0002_m_000002_0 on tt1",
+        "attempt_test_0002_r_000002_0 on tt1"});
     checkOccupiedSlots("default", TaskType.MAP, 1, 2, 100.0f);
-    // memory used will change because of the finished task above.
-    checkMemReservedForTasksOnTT("tt1", 1024L, 512L);
-    
-    // reduce can be assigned.
-    t = checkAssignment("tt1", "attempt_test_0002_r_000002_0 on tt1");
     checkOccupiedSlots("default", TaskType.REDUCE, 1, 2, 100.0f);
-    checkMemReservedForTasksOnTT("tt1", 1024L, 1024L);
+    checkMemReservedForTasksOnTT("tt1", 1024L, 1024L, 
+                                 NUM_MAP_SLOTS-2, NUM_REDUCE_SLOTS-2);
   }
 
   /*
    * Test cases for Job Initialization poller.
-   */
-  
-  /*
+   * 
    * This test verifies that the correct number of jobs for
    * correct number of users is initialized.
    * It also verifies that as jobs of users complete, new jobs
    * from the correct users are initialized.
    */
   public void testJobInitialization() throws Exception {
+    System.err.println("testJobInitialization");
     // set up the scheduler
     String[] qs = { "default" };
     taskTrackerManager = new FakeTaskTrackerManager(2, 1, 1);
     scheduler.setTaskTrackerManager(taskTrackerManager);
+    controlledInitializationPoller.setTaskTrackerManager(taskTrackerManager);
     taskTrackerManager.addQueues(qs);
     ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
     queues.add(new FakeQueueInfo("default", 100.0f, true, 100));
     resConf.setFakeQueues(queues);
+    resConf.setMaxSystemJobs(6);  // 6 jobs max
+    resConf.setMaxInitializedActiveTasksPerUser("default", 4);  // 4 tasks max
     scheduler.setResourceManagerConf(resConf);
     scheduler.start();
   
@@ -2376,7 +2376,7 @@ public class TestCapacityScheduler extends TestCase {
     // submit 4 jobs each for 3 users.
     HashMap<String, ArrayList<FakeJobInProgress>> userJobs = submitJobs(3,
         4, "default");
-
+        
     // get the jobs submitted.
     ArrayList<FakeJobInProgress> u1Jobs = userJobs.get("u1");
     ArrayList<FakeJobInProgress> u2Jobs = userJobs.get("u2");
@@ -2387,13 +2387,15 @@ public class TestCapacityScheduler extends TestCase {
     Set<JobID> initializedJobs = initPoller.getInitializedJobList();
     
     // we should have 12 (3 x 4) jobs in the job queue
-    assertEquals(mgr.getWaitingJobs("default").size(), 12);
-
+    assertEquals(mgr.getQueue("default").getWaitingJobs().size(), 12);
+        
     // run one poller iteration.
     controlledInitializationPoller.selectJobsToInitialize();
     
+    System.err.println("3 TTM #listeners=" + taskTrackerManager.mylisteners.size());
+    
     // the poller should initialize 6 jobs
-    // 3 users and 2 jobs from each
+    // 3 users and 2 jobs (with 2 tasks) from each
     assertEquals(initializedJobs.size(), 6);
 
     assertTrue("Initialized jobs didnt contain the user1 job 1",
@@ -2419,7 +2421,7 @@ public class TestCapacityScheduler extends TestCase {
     // since no jobs have started running, there should be no
     // change to the initialized jobs.
     assertEquals(initializedJobs.size(), 6);
-    assertFalse("Initialized jobs contains user 4 jobs",
+    assertFalse("Initialized jobs doesn't contain user 4 jobs",
         initializedJobs.contains(u4j1.getJobID()));
     
     // This event simulates raising the event on completion of setup task
@@ -2427,22 +2429,41 @@ public class TestCapacityScheduler extends TestCase {
     raiseStatusChangeEvents(mgr);
     
     // get some tasks assigned.
-    Task t1 = checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
-    Task t2 = checkAssignment("tt1", "attempt_test_0001_r_000001_0 on tt1");
-    Task t3 = checkAssignment("tt2", "attempt_test_0002_m_000001_0 on tt2");
-    Task t4 = checkAssignment("tt2", "attempt_test_0002_r_000001_0 on tt2");
-    taskTrackerManager.finishTask("tt1", t1.getTaskID().toString(), u1Jobs.get(0));
-    taskTrackerManager.finishTask("tt1", t2.getTaskID().toString(), u1Jobs.get(0));
-    taskTrackerManager.finishTask("tt2", t3.getTaskID().toString(), u1Jobs.get(1));
-    taskTrackerManager.finishTask("tt2", t4.getTaskID().toString(), u1Jobs.get(1));
-
-    // as some jobs have running tasks, the poller will now
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0001_m_000001_0 on tt1",
+        "attempt_test_0001_r_000001_0 on tt1"
+    });
+    checkAssignments("tt2", 
+        new String[] {
+        "attempt_test_0002_m_000001_0 on tt2",
+        "attempt_test_0002_r_000001_0 on tt2"
+    });
+    taskTrackerManager.finishTask("tt1", "attempt_test_0001_m_000001_0", u1Jobs.get(0));
+    taskTrackerManager.finishTask("tt1", "attempt_test_0002_m_000001_0", u1Jobs.get(0));
+    taskTrackerManager.finishTask("tt2", "attempt_test_0001_r_000001_0", u1Jobs.get(1));
+    taskTrackerManager.finishTask("tt2", "attempt_test_0002_r_000001_0", u1Jobs.get(1));
+    
+    // as max running jobs is 6, still no more jobs can be inited
+    controlledInitializationPoller.selectJobsToInitialize();
+
+    // count should be 4 since 2 jobs are running
+    assertEquals(initializedJobs.size(), 4);
+    
+    // Job has completed
+    taskTrackerManager.finalizeJob(u1Jobs.get(0));
+    taskTrackerManager.finalizeJob(u1Jobs.get(1));
+    
+    // count should now be 4 since we haven't called the poller yet
+    assertEquals(initializedJobs.size(), 4);
+
+    // as some jobs have completed, the poller will now
     // pick up new jobs to initialize.
     controlledInitializationPoller.selectJobsToInitialize();
 
     // count should still be the same
     assertEquals(initializedJobs.size(), 6);
-    
+
     // new jobs that have got into the list
     assertTrue(initializedJobs.contains(u1Jobs.get(2).getJobID()));
     assertTrue(initializedJobs.contains(u1Jobs.get(3).getJobID()));
@@ -2455,33 +2476,130 @@ public class TestCapacityScheduler extends TestCase {
         initializedJobs.contains(u1Jobs.get(1).getJobID()));
     
     // finish one more job
-    t1 = checkAssignment("tt1", "attempt_test_0003_m_000001_0 on tt1");
-    t2 = checkAssignment("tt1", "attempt_test_0003_r_000001_0 on tt1");
-    taskTrackerManager.finishTask("tt1", t1.getTaskID().toString(), u1Jobs.get(2));
-    taskTrackerManager.finishTask("tt1", t2.getTaskID().toString(), u1Jobs.get(2));
-
-    // no new jobs should be picked up, because max user limit
-    // is still 3.
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0003_m_000001_0 on tt1",
+        "attempt_test_0003_r_000001_0 on tt1"
+    });
+    taskTrackerManager.finishTask("tt1", "attempt_test_0003_m_000001_0", u1Jobs.get(2));
+    taskTrackerManager.finishTask("tt1", "attempt_test_0003_r_000001_0", u1Jobs.get(2));
+
+    // no new jobs should be picked up, because max running jobs is 6, job3 
+    // hasn't been marked as 'complete' yet
     controlledInitializationPoller.selectJobsToInitialize();
     
     assertEquals(initializedJobs.size(), 5);
     
     // run 1 more jobs.. 
-    t1 = checkAssignment("tt1", "attempt_test_0004_m_000001_0 on tt1");
-    t1 = checkAssignment("tt1", "attempt_test_0004_r_000001_0 on tt1");
-    taskTrackerManager.finishTask("tt1", t1.getTaskID().toString(), u1Jobs.get(3));
-    taskTrackerManager.finishTask("tt1", t2.getTaskID().toString(), u1Jobs.get(3));
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0004_m_000001_0 on tt1",
+        "attempt_test_0004_r_000001_0 on tt1"
+    });
+    
+    // Finish job_0003
+    taskTrackerManager.finalizeJob(u1Jobs.get(2));
     
     // Now initialised jobs should contain user 4's job, as
-    // user 1's jobs are all done and the number of users is
-    // below the limit
+    // user 1's jobs are all done u2 and u3 already have 6 active tasks
     controlledInitializationPoller.selectJobsToInitialize();
     assertEquals(initializedJobs.size(), 5);
     assertTrue(initializedJobs.contains(u4j1.getJobID()));
     
     controlledInitializationPoller.stopRunning();
   }
+  
+  /**
+   * This testcase test limits on job-submission per-user and per-queue.
+   */
+  public void testJobSubmissionLimits() throws Exception {
+    System.err.println("testJobSubmissionLimits");
+    
+    // set up the scheduler
+    String[] qs = {"default", "q2"};
+    taskTrackerManager = new FakeTaskTrackerManager(2, 1, 1);
+    scheduler.setTaskTrackerManager(taskTrackerManager);
+    taskTrackerManager.addQueues(qs);
+    ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
+    queues.add(new FakeQueueInfo("default", 50.0f, true, 50));
+    queues.add(new FakeQueueInfo("q2", 50.0f, true, 25));
+    resConf.setFakeQueues(queues);
+    resConf.setMaxInitializedActiveTasksPerUser("default", 4);  // 4 tasks max
+    resConf.setMaxInitializedActiveTasksPerUser("q2", 4);  // 4 tasks max
+    resConf.setInitToAcceptJobsFactor("default", 1);
+    resConf.setMaxSystemJobs(12); // max 12 running jobs in the system, hence
+
+    // In queue 'default'
+    // max (pending+running) jobs -> 12 * 1 * .5 = 6 
+    // max jobs per user to init -> 12 * .5 * .5 = 2
+    scheduler.setResourceManagerConf(resConf);
+    scheduler.start();
+  
+    JobQueuesManager mgr = scheduler.jobQueuesManager;
+    JobInitializationPoller initPoller = scheduler.getInitializationPoller();
+
+    // submit 2 jobs each for 3 users, the maximum possible to default
+    HashMap<String, ArrayList<FakeJobInProgress>> userJobs = 
+      submitJobs(3, 2, "default");
+        
+    // get the jobs submitted.
+    ArrayList<FakeJobInProgress> u1Jobs = userJobs.get("u1");
+    ArrayList<FakeJobInProgress> u2Jobs = userJobs.get("u2");
+    ArrayList<FakeJobInProgress> u3Jobs = userJobs.get("u3");
+    
+    // reference to the initializedJobs data structure
+    // changes are reflected in the set as they are made by the poller
+    Set<JobID> initializedJobs = initPoller.getInitializedJobList();
+    
+    // we should have 6 jobs in the job queue
+    assertEquals(6, mgr.getQueue("default").getWaitingJobs().size());
+        
+    // run one poller iteration.
+    controlledInitializationPoller.selectJobsToInitialize();
+        
+    // the poller should initialize 6 jobs
+    // 3 users and 2 jobs (with 2 tasks) from each
+    assertEquals(initializedJobs.size(), 6);
+    
+    // now submit one more job from another user, should fail since default's
+    // job submission capacity is full
+    boolean jobSubmissionFailed = false;
+    try {
+      FakeJobInProgress u4j1 = 
+        submitJob(JobStatus.PREP, 1, 1, "default", "u4");
+    } catch (IOException ioe) {
+      jobSubmissionFailed = true;
+    }
+    assertTrue("Job submission of 7th job to 'default' queue didn't fail!", 
+        jobSubmissionFailed);
 
+    // fail some jobs to clear up quota
+    taskTrackerManager.finalizeJob(u2Jobs.get(0), JobStatus.FAILED);
+    taskTrackerManager.finalizeJob(u3Jobs.get(0), JobStatus.FAILED);
+    
+    FakeJobInProgress u1j3 = 
+      submitJob(JobStatus.PREP, 1, 1, "default", "u1");
+
+    // run the poller again.
+    controlledInitializationPoller.selectJobsToInitialize();
+
+    // the poller should initialize 4 jobs
+    // 2 from u1 and one each from u2 and u3
+    assertEquals(initializedJobs.size(), 4);
+
+    // Should fail since u1 is already at limit of 3 jobs
+    jobSubmissionFailed = false;
+    try {
+      FakeJobInProgress u1j4 = 
+        submitJob(JobStatus.PREP, 1, 1, "default", "u1");
+    } catch (IOException ioe) {
+      jobSubmissionFailed = true;
+    }
+    
+    assertTrue("Job submission of 4th job of user 'u1' to queue 'default' " +
+    		"didn't fail!", jobSubmissionFailed);
+  }
+  
   /*
    * testHighPriorityJobInitialization() shows behaviour when high priority job
    * is submitted into a queue and how initialisation happens for the same.
@@ -2492,24 +2610,28 @@ public class TestCapacityScheduler extends TestCase {
     ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
     queues.add(new FakeQueueInfo("default", 100.0f, true, 100));
     resConf.setFakeQueues(queues);
+    resConf.setMaxSystemJobs(6); // 6 jobs max
+    resConf.setMaxInitializedActiveTasksPerUser("default", 4);  // 4 tasks max
     scheduler.setResourceManagerConf(resConf);
     scheduler.start();
 
     JobInitializationPoller initPoller = scheduler.getInitializationPoller();
     Set<JobID> initializedJobsList = initPoller.getInitializedJobList();
 
-    // submit 3 jobs for 3 users
-    submitJobs(3,3,"default");
+    // submit 3 jobs for 3 users, only 2 each should be inited since max active
+    // tasks per user is 4 and max jobs is 6
+    HashMap<String, ArrayList<FakeJobInProgress>> userJobs = 
+      submitJobs(3,3,"default");
     controlledInitializationPoller.selectJobsToInitialize();
     assertEquals(initializedJobsList.size(), 6);
     
     // submit 2 job for a different user. one of them will be made high priority
     FakeJobInProgress u4j1 = submitJob(JobStatus.PREP, 1, 1, "default", "u4");
-    FakeJobInProgress u4j2 = submitJob(JobStatus.PREP, 1, 1, "default", "u4");
+    FakeJobInProgress u4j2 = submitJob(JobStatus.PREP, 2, 2, "default", "u4");
     
     controlledInitializationPoller.selectJobsToInitialize();
     
-    // shouldn't change
+    // shouldn't change since max jobs is 6
     assertEquals(initializedJobsList.size(), 6);
     
     assertFalse("Contains U4J1 high priority job " , 
@@ -2518,18 +2640,31 @@ public class TestCapacityScheduler extends TestCase {
         initializedJobsList.contains(u4j2.getJobID()));
 
     // change priority of one job
-    taskTrackerManager.setPriority(u4j1, JobPriority.VERY_HIGH);
+    System.err.println("changing prio");
+    taskTrackerManager.setPriority(u4j2, JobPriority.VERY_HIGH);
+    
+    // Finish one of the inited jobs
+    // run 1 more jobs.. 
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0001_m_000001_0 on tt1",
+        "attempt_test_0002_m_000001_0 on tt1",
+        "attempt_test_0001_r_000001_0 on tt1"
+    });
     
+    // Finish job_0003
+    taskTrackerManager.finalizeJob(userJobs.get("u1").get(0));
+
     controlledInitializationPoller.selectJobsToInitialize();
     
     // the high priority job should get initialized, but not the
     // low priority job from u4, as we have already exceeded the
     // limit.
-    assertEquals(initializedJobsList.size(), 7);
-    assertTrue("Does not contain U4J1 high priority job " , 
-        initializedJobsList.contains(u4j1.getJobID()));
-    assertFalse("Contains U4J2 Normal priority job " , 
+    assertEquals(initializedJobsList.size(), 5);
+    assertTrue("Does not contain U4J2 high priority job " , 
         initializedJobsList.contains(u4j2.getJobID()));
+    assertFalse("Contains U4J1 Normal priority job " , 
+        initializedJobsList.contains(u4j1.getJobID()));
     controlledInitializationPoller.stopRunning();
   }
   
@@ -2541,9 +2676,7 @@ public class TestCapacityScheduler extends TestCase {
     resConf.setFakeQueues(queues);
     scheduler.setResourceManagerConf(resConf);
     scheduler.start();
-    
-    JobQueuesManager mgr = scheduler.jobQueuesManager;
-    
+        
     // check proper running job movement and completion
     checkRunningJobMovementAndCompletion();
 
@@ -2572,8 +2705,9 @@ public class TestCapacityScheduler extends TestCase {
       submitJob(JobStatus.PREP, 1, 1, "q1", "u1");
     controlledInitializationPoller.selectJobsToInitialize();
     raiseStatusChangeEvents(scheduler.jobQueuesManager, "q1");
-    Task t = checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
-    t = checkAssignment("tt1", "attempt_test_0001_r_000001_0 on tt1");
+    checkAssignments("tt1", 
+        new String[] {"attempt_test_0001_m_000001_0 on tt1", 
+        "attempt_test_0001_r_000001_0 on tt1"});
   }
   
   public void testFailedJobInitalizations() throws Exception {
@@ -2595,19 +2729,20 @@ public class TestCapacityScheduler extends TestCase {
     job.getStatus().setRunState(JobStatus.PREP);
     taskTrackerManager.submitJob(job);
     //check if job is present in waiting list.
+    CapacitySchedulerQueue queue = mgr.getQueue("default");
     assertEquals("Waiting job list does not contain submitted job",
-        1, mgr.getWaitingJobCount("default"));
+        1, queue.getNumWaitingJobs());
     assertTrue("Waiting job does not contain submitted job", 
-        mgr.getWaitingJobs("default").contains(job));
+        queue.getWaitingJobs().contains(job));
     //initialization should fail now.
     controlledInitializationPoller.selectJobsToInitialize();
     //Check if the job has been properly cleaned up.
     assertEquals("Waiting job list contains submitted job",
-        0, mgr.getWaitingJobCount("default"));
+        0, queue.getNumWaitingJobs());
     assertFalse("Waiting job contains submitted job", 
-        mgr.getWaitingJobs("default").contains(job));
+        queue.getWaitingJobs().contains(job));
     assertFalse("Waiting job contains submitted job", 
-        mgr.getRunningJobQueue("default").contains(job));
+        queue.getRunningJobs().contains(job));
   }
   
   private void checkRunningJobMovementAndCompletion() throws IOException {
@@ -2625,14 +2760,19 @@ public class TestCapacityScheduler extends TestCase {
     raiseStatusChangeEvents(mgr);
     
     // it should be there in both the queues.
-    assertTrue("Job not present in Job Queue",
-        mgr.getWaitingJobs("default").contains(job));
+    CapacitySchedulerQueue queue = mgr.getQueue("default");
+    assertTrue("Job present in waiting Job Queue",
+        !queue.getWaitingJobs().contains(job));
+    assertTrue("Job present in initializing Job Queue",
+        !queue.getInitializingJobs().contains(job));
     assertTrue("Job not present in Running Queue",
-        mgr.getRunningJobQueue("default").contains(job));
+        queue.getRunningJobs().contains(job));
     
     // assign a task
-    Task t = checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
-    t = checkAssignment("tt1", "attempt_test_0001_r_000001_0 on tt1");
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0001_m_000001_0 on tt1", 
+        "attempt_test_0001_r_000001_0 on tt1"});
     
     controlledInitializationPoller.selectJobsToInitialize();
     
@@ -2642,7 +2782,7 @@ public class TestCapacityScheduler extends TestCase {
     // the job should also be removed from the job queue as tasks
     // are scheduled
     assertFalse("Job present in Job Queue",
-        mgr.getWaitingJobs("default").contains(job));
+        queue.getWaitingJobs().contains(job));
     
     // complete tasks and job
     taskTrackerManager.finishTask("tt1", "attempt_test_0001_m_000001_0", job);
@@ -2651,7 +2791,7 @@ public class TestCapacityScheduler extends TestCase {
     
     // make sure it is removed from the run queue
     assertFalse("Job present in running queue",
-        mgr.getRunningJobQueue("default").contains(job));
+        queue.getRunningJobs().contains(job));
   }
   
   private void checkFailedRunningJobMovement() throws IOException {
@@ -2663,14 +2803,15 @@ public class TestCapacityScheduler extends TestCase {
       submitJobAndInit(JobStatus.RUNNING, 1, 1, "default", "u1");
     
     //check if the job is present in running queue.
+    CapacitySchedulerQueue queue = mgr.getQueue("default");
     assertTrue("Running jobs list does not contain submitted job",
-        mgr.getRunningJobQueue("default").contains(job));
+        queue.getRunningJobs().contains(job));
     
     taskTrackerManager.finalizeJob(job, JobStatus.KILLED);
     
     //check if the job is properly removed from running queue.
     assertFalse("Running jobs list does not contain submitted job",
-        mgr.getRunningJobQueue("default").contains(job));
+        queue.getRunningJobs().contains(job));
     
   }
   
@@ -2718,14 +2859,18 @@ public class TestCapacityScheduler extends TestCase {
     controlledInitializationPoller.selectJobsToInitialize();
     raiseStatusChangeEvents(mgr);
 
-    checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0001_m_000001_0 on tt1" , 
+        "attempt_test_0001_r_000001_0 on tt1"});
     assertTrue("Pending maps of job1 greater than zero", 
         (fjob1.pendingMaps() == 0));
-    checkAssignment("tt2", "attempt_test_0001_m_000001_1 on tt2");
-    checkAssignment("tt1", "attempt_test_0001_r_000001_0 on tt1");
-    assertTrue("Pending reduces of job2 greater than zero", 
+    assertTrue("Pending reduces of job1 greater than zero", 
         (fjob1.pendingReduces() == 0));
-    checkAssignment("tt2", "attempt_test_0001_r_000001_1 on tt2");
+    checkAssignments("tt2", 
+        new String[] {
+        "attempt_test_0001_m_000001_1 on tt2", 
+        "attempt_test_0001_r_000001_1 on tt2"});
 
     taskTrackerManager.finishTask("tt1", "attempt_test_0001_m_000001_0", fjob1);
     taskTrackerManager.finishTask("tt2", "attempt_test_0001_m_000001_1", fjob1);
@@ -2733,8 +2878,10 @@ public class TestCapacityScheduler extends TestCase {
     taskTrackerManager.finishTask("tt2", "attempt_test_0001_r_000001_1", fjob1);
     taskTrackerManager.finalizeJob(fjob1);
     
-    checkAssignment("tt1", "attempt_test_0002_m_000001_0 on tt1");
-    checkAssignment("tt1", "attempt_test_0002_r_000001_0 on tt1");
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0002_m_000001_0 on tt1", 
+        "attempt_test_0002_r_000001_0 on tt1"});
     taskTrackerManager.finishTask("tt1", "attempt_test_0002_m_000001_0", fjob2);
     taskTrackerManager.finishTask("tt2", "attempt_test_0002_r_000001_0", fjob2);
     taskTrackerManager.finalizeJob(fjob2);    
@@ -2752,7 +2899,7 @@ public class TestCapacityScheduler extends TestCase {
 
     taskTrackerManager.addQueues(new String[] { "default" });
     ArrayList<FakeQueueInfo> queues = new ArrayList<FakeQueueInfo>();
-    queues.add(new FakeQueueInfo("default", 100.0f, true, 25));
+    queues.add(new FakeQueueInfo("default", 100.0f, true, 100));
     resConf.setFakeQueues(queues);
     scheduler.setTaskTrackerManager(taskTrackerManager);
     // enabled memory-based scheduling
@@ -2769,28 +2916,55 @@ public class TestCapacityScheduler extends TestCase {
     scheduler.start();
 
     LOG.debug("Submit a regular memory(1GB vmem maps/reduces) job of "
-        + "3 map/red tasks");
+        + "1 map & 0 red tasks");
     JobConf jConf = new JobConf(conf);
     jConf = new JobConf(conf);
     jConf.setMemoryForMapTask(1 * 1024);
     jConf.setMemoryForReduceTask(1 * 1024);
-    jConf.setNumMapTasks(3);
-    jConf.setNumReduceTasks(3);
+    jConf.setNumMapTasks(1);
+    jConf.setNumReduceTasks(0);
     jConf.setQueueName("default");
     jConf.setUser("u1");
     FakeJobInProgress job1 = submitJobAndInit(JobStatus.PREP, jConf);
-
-    // assign one map task of job1 on all the TTs
     checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
-    checkAssignment("tt2", "attempt_test_0001_m_000002_0 on tt2");
-    checkAssignment("tt3", "attempt_test_0001_m_000003_0 on tt3");
-    scheduler.updateQSIInfoForTests();
-
+    scheduler.updateQueueUsageForTests();
     LOG.info(job1.getSchedulingInfo());
     assertEquals(
-        CapacityTaskScheduler.getJobQueueSchedInfo(3, 3, 0, 0, 0, 0), 
+        CapacityTaskScheduler.getJobQueueSchedInfo(1, 1, 0, 0, 0, 0), 
         (String) job1.getSchedulingInfo());
 
+    jConf = new JobConf(conf);
+    jConf = new JobConf(conf);
+    jConf.setMemoryForMapTask(1 * 1024);
+    jConf.setMemoryForReduceTask(1 * 1024);
+    jConf.setNumMapTasks(1);
+    jConf.setNumReduceTasks(0);
+    jConf.setQueueName("default");
+    jConf.setUser("u1");
+    FakeJobInProgress job2 = submitJobAndInit(JobStatus.PREP, jConf);
+    checkAssignment("tt2", "attempt_test_0002_m_000001_0 on tt2");
+    scheduler.updateQueueUsageForTests();
+    LOG.info(job2.getSchedulingInfo());
+    assertEquals(
+        CapacityTaskScheduler.getJobQueueSchedInfo(1, 1, 0, 0, 0, 0), 
+        (String) job2.getSchedulingInfo());
+
+    jConf = new JobConf(conf);
+    jConf = new JobConf(conf);
+    jConf.setMemoryForMapTask(1 * 1024);
+    jConf.setMemoryForReduceTask(1 * 1024);
+    jConf.setNumMapTasks(1);
+    jConf.setNumReduceTasks(0);
+    jConf.setQueueName("default");
+    jConf.setUser("u1");
+    FakeJobInProgress job3 = submitJobAndInit(JobStatus.PREP, jConf);
+    checkAssignment("tt3", "attempt_test_0003_m_000001_0 on tt3");
+    scheduler.updateQueueUsageForTests();
+    LOG.info(job3.getSchedulingInfo());
+    assertEquals(
+        CapacityTaskScheduler.getJobQueueSchedInfo(1, 1, 0, 0, 0, 0), 
+        (String) job3.getSchedulingInfo());
+
     LOG.debug("Submit one high memory(2GB maps, 0MB reduces) job of "
         + "2 map tasks");
     jConf.setMemoryForMapTask(2 * 1024);
@@ -2798,8 +2972,8 @@ public class TestCapacityScheduler extends TestCase {
     jConf.setNumMapTasks(2);
     jConf.setNumReduceTasks(0);
     jConf.setQueueName("default");
-    jConf.setUser("u1");
-    FakeJobInProgress job2 = submitJobAndInit(JobStatus.PREP, jConf);
+    jConf.setUser("u2");
+    FakeJobInProgress job4 = submitJobAndInit(JobStatus.PREP, jConf);
 
     LOG.debug("Submit another regular memory(1GB vmem maps/reduces) job of "
         + "2 map/red tasks");
@@ -2809,51 +2983,57 @@ public class TestCapacityScheduler extends TestCase {
     jConf.setNumMapTasks(2);
     jConf.setNumReduceTasks(2);
     jConf.setQueueName("default");
-    jConf.setUser("u1");
-    FakeJobInProgress job3 = submitJobAndInit(JobStatus.PREP, jConf);
+    jConf.setUser("u3");
+    FakeJobInProgress job5 = submitJobAndInit(JobStatus.PREP, jConf);
 
-    // Job2, a high memory job cannot be accommodated on a any TT. But with each
+    // Job4, a high memory job cannot be accommodated on a any TT. But with each
     // trip to the scheduler, each of the TT should be reserved by job2.
-    assertNull(scheduler.assignTasks(tracker("tt1")));
-    scheduler.updateQSIInfoForTests();
-    LOG.info(job2.getSchedulingInfo());
+    assertEquals(0, scheduler.assignTasks(tracker("tt1")).size());
+    scheduler.updateQueueUsageForTests();
+    LOG.info(job4.getSchedulingInfo());
     assertEquals(
         CapacityTaskScheduler.getJobQueueSchedInfo(0, 0, 2, 0, 0, 0), 
-        (String) job2.getSchedulingInfo());
+        (String) job4.getSchedulingInfo());
 
-    assertNull(scheduler.assignTasks(tracker("tt2")));
-    scheduler.updateQSIInfoForTests();
-    LOG.info(job2.getSchedulingInfo());
+    assertEquals(0, scheduler.assignTasks(tracker("tt2")).size());
+    scheduler.updateQueueUsageForTests();
+    LOG.info(job4.getSchedulingInfo());
     assertEquals(
         CapacityTaskScheduler.getJobQueueSchedInfo(0, 0, 4, 0, 0, 0), 
-        (String) job2.getSchedulingInfo());
+        (String) job4.getSchedulingInfo());
 
-    // Job2 has only 2 pending tasks. So no more reservations. Job3 should get
+    // Job4 has only 2 pending tasks. So no more reservations. Job5 should get
     // slots on tt3. tt1 and tt2 should not be assigned any slots with the
     // reservation stats intact.
-    assertNull(scheduler.assignTasks(tracker("tt1")));
-    scheduler.updateQSIInfoForTests();
-    LOG.info(job2.getSchedulingInfo());
+    assertEquals(0, scheduler.assignTasks(tracker("tt1")).size());
+    scheduler.updateQueueUsageForTests();
+    LOG.info(job4.getSchedulingInfo());
     assertEquals(
         CapacityTaskScheduler.getJobQueueSchedInfo(0, 0, 4, 0, 0, 0), 
-        (String) job2.getSchedulingInfo());
+        (String) job4.getSchedulingInfo());
 
-    assertNull(scheduler.assignTasks(tracker("tt2")));
-    scheduler.updateQSIInfoForTests();
-    LOG.info(job2.getSchedulingInfo());
+    assertEquals(0, scheduler.assignTasks(tracker("tt2")).size());
+    scheduler.updateQueueUsageForTests();
+    LOG.info(job4.getSchedulingInfo());
     assertEquals(
         CapacityTaskScheduler.getJobQueueSchedInfo(0, 0, 4, 0, 0, 0), 
-        (String) job2.getSchedulingInfo());
+        (String) job4.getSchedulingInfo());
+
+    checkAssignments("tt3", 
+        new String[] {
+        "attempt_test_0005_m_000001_0 on tt3"});
+    scheduler.updateQueueUsageForTests();
+    LOG.info(job5.getSchedulingInfo());
+    assertEquals(
+        CapacityTaskScheduler.getJobQueueSchedInfo(1, 1, 0, 0, 0, 0), 
+        (String) job5.getSchedulingInfo());
 
-    checkAssignment("tt3", "attempt_test_0003_m_000001_0 on tt3");
-    scheduler.updateQSIInfoForTests();
-    LOG.info(job2.getSchedulingInfo());
     assertEquals(
         CapacityTaskScheduler.getJobQueueSchedInfo(0, 0, 4, 0, 0, 0), 
-        (String) job2.getSchedulingInfo());
+        (String) job4.getSchedulingInfo());
 
     // No more tasks there in job3 also
-    assertNull(scheduler.assignTasks(tracker("tt3")));
+    assertEquals(0, scheduler.assignTasks(tracker("tt3")).size());
 }
 
   /**
@@ -2904,72 +3084,107 @@ public class TestCapacityScheduler extends TestCase {
     jConf.setMemoryForReduceTask(1 * 1024);
     jConf.setNumMapTasks(6);
     jConf.setNumReduceTasks(6);
-    jConf.setUser("u1");
+    jConf.setUser("u2");
     jConf.setQueueName("q1");
     FakeJobInProgress job2 = submitJobAndInit(JobStatus.PREP, jConf);
 
     // Map 1 of high memory job
-    checkAssignment("tt1", "attempt_test_0001_m_000001_0 on tt1");
+    // Map 1 of normal job
+    // Map 1 of normal job
+    // Map 1 of normal job, since comparator won't change on equals
+    // Reduce 1 of high memory job
+    checkAssignments("tt1", 
+        new String[] {
+        "attempt_test_0001_m_000001_0 on tt1",
+        "attempt_test_0002_m_000001_0 on tt1",
+        "attempt_test_0002_m_000002_0 on tt1",
+        "attempt_test_0002_m_000003_0 on tt1",
+        "attempt_test_0001_r_000001_0 on tt1"
+        });
     checkQueuesOrder(qs, scheduler
         .getOrderedQueues(TaskType.MAP));
-
-    // Reduce 1 of high memory job
-    checkAssignment("tt1", "attempt_test_0001_r_000001_0 on tt1");
     checkQueuesOrder(qs, scheduler
         .getOrderedQueues(TaskType.REDUCE));
+    scheduler.updateQueueUsageForTests();
+    assertEquals(
+        CapacityTaskScheduler.getJobQueueSchedInfo(1, 2, 2, 1, 2, 0), 
+        (String) job1.getSchedulingInfo());
+    assertEquals(
+        CapacityTaskScheduler.getJobQueueSchedInfo(3, 3, 0, 0, 0, 0), 
+        (String) job2.getSchedulingInfo());
 
-    // Map 1 of normal job
-    checkAssignment("tt1", "attempt_test_0002_m_000001_0 on tt1");
-    checkQueuesOrder(reversedQs, scheduler
-        .getOrderedQueues(TaskType.MAP));
 
     // Reduce 1 of normal job
     checkAssignment("tt1", "attempt_test_0002_r_000001_0 on tt1");
     checkQueuesOrder(reversedQs, scheduler
         .getOrderedQueues(TaskType.REDUCE));
-
-    // Map 2 of normal job
-    checkAssignment("tt1", "attempt_test_0002_m_000002_0 on tt1");
-    checkQueuesOrder(reversedQs, scheduler
-        .getOrderedQueues(TaskType.MAP));
+    scheduler.updateQueueUsageForTests();
+    assertEquals(
+        CapacityTaskScheduler.getJobQueueSchedInfo(1, 2, 2, 1, 2, 0), 
+        (String) job1.getSchedulingInfo());
+    assertEquals(
+        CapacityTaskScheduler.getJobQueueSchedInfo(3, 3, 0, 1, 1, 0), 
+        (String) job2.getSchedulingInfo());
 
     // Reduce 2 of normal job
     checkAssignment("tt1", "attempt_test_0002_r_000002_0 on tt1");
     checkQueuesOrder(reversedQs, scheduler
         .getOrderedQueues(TaskType.REDUCE));
-
-    // Now both the queues are equally served. But the comparator doesn't change
-    // the order if queues are equally served.
-
-    // Map 3 of normal job
-    checkAssignment("tt2", "attempt_test_0002_m_000003_0 on tt2");
-    checkQueuesOrder(reversedQs, scheduler
-        .getOrderedQueues(TaskType.MAP));
+    scheduler.updateQueueUsageForTests();
+    assertEquals(
+        CapacityTaskScheduler.getJobQueueSchedInfo(1, 2, 2, 1, 2, 0), 
+        (String) job1.getSchedulingInfo());
+    assertEquals(
+        CapacityTaskScheduler.getJobQueueSchedInfo(3, 3, 0, 2, 2, 0), 
+        (String) job2.getSchedulingInfo());
 
     // Reduce 3 of normal job
-    checkAssignment("tt2", "attempt_test_0002_r_000003_0 on tt2");
+    checkAssignment("tt1", "attempt_test_0002_r_000003_0 on tt1");
     checkQueuesOrder(reversedQs, scheduler
         .getOrderedQueues(TaskType.REDUCE));
+    scheduler.updateQueueUsageForTests();
+    assertEquals(
+        CapacityTaskScheduler.getJobQueueSchedInfo(1, 2, 2, 1, 2, 0), 
+        (String) job1.getSchedulingInfo());
+    assertEquals(
+        CapacityTaskScheduler.getJobQueueSchedInfo(3, 3, 0, 3, 3, 0), 
+        (String) job2.getSchedulingInfo());
 
     // Map 2 of high memory job
-    checkAssignment("tt2", "attempt_test_0001_m_000002_0 on tt2");
-    checkQueuesOrder(qs, scheduler
-        .getOrderedQueues(TaskType.MAP));
-
-    // Reduce 2 of high memory job
-    checkAssignment("tt2", "attempt_test_0001_r_000002_0 on tt2");
-    checkQueuesOrder(qs, scheduler
-        .getOrderedQueues(TaskType.REDUCE));
-
     // Map 4 of normal job
-    checkAssignment("tt2", "attempt_test_0002_m_000004_0 on tt2");
+    // Map 4 of normal job
+    // Reduce 2 of high memory job
+    checkAssignments("tt2", 
+        new String[] {
+        "attempt_test_0002_m_000004_0 on tt2",
+        "attempt_test_0002_m_000005_0 on tt2",
+        "attempt_test_0001_m_000002_0 on tt2",
+        "attempt_test_0002_m_000006_0 on tt2",
+        "attempt_test_0001_r_000002_0 on tt2"
+    });
     checkQueuesOrder(reversedQs, scheduler
         .getOrderedQueues(TaskType.MAP));
+    checkQueuesOrder(qs, scheduler
+        .getOrderedQueues(TaskType.REDUCE));
+    scheduler.updateQueueUsageForTests();
+    assertEquals( // user limit is 6
+        CapacityTaskScheduler.getJobQueueSchedInfo(2, 4, 2, 2, 4, 0), 
+        (String) job1.getSchedulingInfo());
+    assertEquals(
+        CapacityTaskScheduler.getJobQueueSchedInfo(6, 6, 0, 3, 3, 0), 
+        (String) job2.getSchedulingInfo());
 
     // Reduce 4 of normal job
     checkAssignment("tt2", "attempt_test_0002_r_000004_0 on tt2");
     checkQueuesOrder(reversedQs, scheduler
         .getOrderedQueues(TaskType.REDUCE));
+    scheduler.updateQueueUsageForTests();
+    assertEquals(// user limit is 6
+        CapacityTaskScheduler.getJobQueueSchedInfo(2, 4, 2, 2, 4, 0), 
+        (String) job1.getSchedulingInfo());
+    assertEquals(
+        CapacityTaskScheduler.getJobQueueSchedInfo(6, 6, 0, 4, 4, 0), 
+        (String) job2.getSchedulingInfo());
   }
 
   private void checkFailedInitializedJobMovement() throws IOException {
@@ -2983,9 +3198,13 @@ public class TestCapacityScheduler extends TestCase {
     p.selectJobsToInitialize();
     //Don't raise the status change event.
     
+    CapacitySchedulerQueue queue = mgr.getQueue("default");
+    
     //check in waiting and initialized jobs list.
-    assertTrue("Waiting jobs list does not contain the job",
-        mgr.getWaitingJobs("default").contains(job));
+    assertTrue("Waiting jobs list does contain the job",
+        !queue.getWaitingJobs().contains(job));
+    assertTrue("Initialzing jobs does not contain the job",
+        !queue.getInitializingJobs().contains(job));
     
     assertTrue("Initialized job does not contain the job",
         p.getInitializedJobList().contains(job.getJobID()));
@@ -2995,7 +3214,7 @@ public class TestCapacityScheduler extends TestCase {
     
     //Check if the job is present in waiting queue
     assertFalse("Waiting jobs list contains failed job",
-        mgr.getWaitingJobs("default").contains(job));
+        queue.getWaitingJobs().contains(job));
     
     //run the poller to do the cleanup
     p.selectJobsToInitialize();
@@ -3012,14 +3231,15 @@ public class TestCapacityScheduler extends TestCase {
         "u1");
     
     // check in waiting and initialized jobs list.
-    assertTrue("Waiting jobs list does not contain the job", mgr
-        .getWaitingJobs("default").contains(job));
+    CapacitySchedulerQueue queue = mgr.getQueue("default");
+    assertTrue("Waiting jobs list does not contain the job", 
+        queue.getWaitingJobs().contains(job));
     // fail the waiting job
     taskTrackerManager.finalizeJob(job, JobStatus.KILLED);
 
     // Check if the job is present in waiting queue
-    assertFalse("Waiting jobs list contains failed job", mgr
-        .getWaitingJobs("default").contains(job));
+    assertFalse("Waiting jobs list contains failed job", 
+        queue.getWaitingJobs().contains(job));
   }
   
   private void raiseStatusChangeEvents(JobQueuesManager mgr) {
@@ -3027,7 +3247,7 @@ public class TestCapacityScheduler extends TestCase {
   }
   
   private void raiseStatusChangeEvents(JobQueuesManager mgr, String queueName) {
-    Collection<JobInProgress> jips = mgr.getWaitingJobs(queueName);
+    Collection<JobInProgress> jips = mgr.getQueue(queueName).getInitializingJobs();
     for(JobInProgress jip : jips) {
       if(jip.getStatus().getRunState() == JobStatus.RUNNING) {
         JobStatusChangeEvent evt = new JobStatusChangeEvent(jip,
@@ -3067,6 +3287,30 @@ public class TestCapacityScheduler extends TestCase {
     return tasks.get(0);
   }
 
+  protected String getAssignedTasks(List<Task> tasks) {
+    if (tasks.size() == 0) {
+      return "<empty>";
+    }
+    StringBuffer s = new StringBuffer(tasks.get(0).toString());
+    for (int i=1; i < tasks.size(); ++i) {
+      s.append(", ");
+      s.append(tasks.get(i).toString());
+    }
+    return s.toString();
+  }
+  
+  protected List<Task> checkAssignments(String taskTrackerName,
+      String[] expectedTasks) throws IOException {
+    List<Task> tasks = scheduler.assignTasks(tracker(taskTrackerName));
+    assertNotNull(getAssignedTasks(tasks), tasks);
+    assertEquals(getAssignedTasks(tasks), expectedTasks.length, tasks.size());
+    for (int i=0; i < tasks.size(); ++i) {
+      assertEquals(getAssignedTasks(tasks) + " -> " + expectedTasks[i], 
+                   expectedTasks[i], tasks.get(i).toString());
+    }
+    return tasks;
+  }
+
   /**
    * Get the amount of memory that is reserved for tasks on the taskTracker and
    * verify that it matches what is expected.
@@ -3076,15 +3320,16 @@ public class TestCapacityScheduler extends TestCase {
    * @param expectedMemForReducesOnTT
    */
   private void checkMemReservedForTasksOnTT(String taskTracker,
-      Long expectedMemForMapsOnTT, Long expectedMemForReducesOnTT) {
+      Long expectedMemForMapsOnTT, Long expectedMemForReducesOnTT,
+      int numAvailableMapSlots, int numAvailableReduceSlots) {
     Long observedMemForMapsOnTT =
       scheduler.memoryMatcher.getMemReservedForTasks(
         tracker(taskTracker).getStatus(),
-            TaskType.MAP);
+            TaskType.MAP, numAvailableMapSlots);
     Long observedMemForReducesOnTT =
       scheduler.memoryMatcher.getMemReservedForTasks(
         tracker(taskTracker).getStatus(),
-            TaskType.REDUCE);
+            TaskType.REDUCE, numAvailableReduceSlots);
     if (expectedMemForMapsOnTT == null) {
       assertEquals(observedMemForMapsOnTT, null);
     } else {
@@ -3118,7 +3363,7 @@ public class TestCapacityScheduler extends TestCase {
     int expectedOccupiedSlots, float expectedOccupiedSlotsPercent,int incrMapIndex
     ,int incrReduceIndex
   ) {
-    scheduler.updateQSIInfoForTests();
+    scheduler.updateQueueUsageForTests();
     QueueManager queueManager = scheduler.taskTrackerManager.getQueueManager();
     String schedulingInfo =
         queueManager.getJobQueueInfo(queue).getSchedulingInfo();
diff --git a/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacitySchedulerWithJobTracker.java b/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacitySchedulerWithJobTracker.java
index b8763f5..9e00180 100644
--- a/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacitySchedulerWithJobTracker.java
+++ b/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacitySchedulerWithJobTracker.java
@@ -60,7 +60,7 @@ public class TestCapacitySchedulerWithJobTracker extends
           .getTaskScheduler();
       JobQueuesManager mgr = scheduler.jobQueuesManager;
       assertEquals("Failed job present in Waiting queue", 0, mgr
-          .getWaitingJobCount("default"));
+          .getQueue("default").getNumWaitingJobs());
     }
   }
 
diff --git a/src/mapred/org/apache/hadoop/mapred/JSPUtil.java b/src/mapred/org/apache/hadoop/mapred/JSPUtil.java
index c105458..6f2436a 100644
--- a/src/mapred/org/apache/hadoop/mapred/JSPUtil.java
+++ b/src/mapred/org/apache/hadoop/mapred/JSPUtil.java
@@ -371,6 +371,7 @@ class JSPUtil {
     throws IOException {
 
     StringBuffer sb = new StringBuffer();
+    
     sb.append("<table border=\"1\" cellpadding=\"5\" cellspacing=\"0\">\n");
 
     Iterator<RetireJobInfo> iterator = 
diff --git a/src/mapred/org/apache/hadoop/mapred/JobInProgress.java b/src/mapred/org/apache/hadoop/mapred/JobInProgress.java
index b53215a..db56159 100644
--- a/src/mapred/org/apache/hadoop/mapred/JobInProgress.java
+++ b/src/mapred/org/apache/hadoop/mapred/JobInProgress.java
@@ -168,6 +168,19 @@ public class JobInProgress {
   private final int anyCacheLevel;
   
   /**
+   * Number of scheduling opportunities (heartbeats) given to this Job
+   */
+  private volatile long numSchedulingOpportunities;
+  
+  static String LOCALITY_WAIT_FACTOR = "mapreduce.job.locality.wait.factor";
+  static final float DEFAULT_LOCALITY_WAIT_FACTOR = 1.0f;
+  
+  /**
+   * Percentage of the cluster the job is willing to wait to get better locality
+   */
+  private float localityWaitFactor = 1.0f;
+  
+  /**
    * A special value indicating that 
    * {@link #findNewMapTask(TaskTrackerStatus, int, int, int, double)} should
    * schedule any only off-switch and speculative map tasks for this job.
@@ -473,6 +486,7 @@ public class JobInProgress {
     Map<Node, List<TaskInProgress>> cache = 
       new IdentityHashMap<Node, List<TaskInProgress>>(maxLevel);
     
+    Set<String> uniqueHosts = new TreeSet<String>();
     for (int i = 0; i < splits.length; i++) {
       String[] splitLocations = splits[i].getLocations();
       if (splitLocations == null || splitLocations.length == 0) {
@@ -482,6 +496,7 @@ public class JobInProgress {
 
       for(String host: splitLocations) {
         Node node = jobtracker.resolveAndAddToTopology(host);
+        uniqueHosts.add(host);
         LOG.info("tip:" + maps[i].getTIPId() + " has split on node:" + node);
         for (int j = 0; j < maxLevel; j++) {
           List<TaskInProgress> hostMaps = cache.get(node);
@@ -502,6 +517,19 @@ public class JobInProgress {
         }
       }
     }
+    
+    // Calibrate the localityWaitFactor - Do not override user intent!
+    if (localityWaitFactor == DEFAULT_LOCALITY_WAIT_FACTOR) {
+      int jobNodes = uniqueHosts.size();
+      int clusterNodes = jobtracker.getNumberOfUniqueHosts();
+      
+      if (clusterNodes > 0) {
+        localityWaitFactor = 
+          Math.min((float)jobNodes/clusterNodes, localityWaitFactor);
+      }
+      LOG.info(jobId + " LOCALITY_WAIT_FACTOR=" + localityWaitFactor);
+    }
+    
     return cache;
   }
   
@@ -645,6 +673,10 @@ public class JobInProgress {
     }
     LOG.info("Input size for job " + jobId + " = " + inputLength
         + ". Number of splits = " + splits.length);
+
+    // Set localityWaitFactor before creating cache
+    localityWaitFactor = 
+      conf.getFloat(LOCALITY_WAIT_FACTOR, DEFAULT_LOCALITY_WAIT_FACTOR);
     if (numMapTasks > 0) { 
       nonRunningMapCache = createCache(splits, maxLevel);
     }
@@ -767,6 +799,15 @@ public class JobInProgress {
     return numReduceTasks - runningReduceTasks - failedReduceTIPs - 
     finishedReduceTasks + speculativeReduceTasks;
   }
+  
+  /**
+   * Return total number of map and reduce tasks desired by the job.
+   * @return total number of map and reduce tasks desired by the job
+   */
+  public int desiredTasks() {
+    return desiredMaps() + desiredReduces();
+  }
+  
   public int getNumSlotsPerTask(TaskType taskType) {
     if (taskType == TaskType.MAP) {
       return numSlotsPerMap;
@@ -1209,6 +1250,10 @@ public class JobInProgress {
     Task result = maps[target].getTaskToRun(tts.getTrackerName());
     if (result != null) {
       addRunningTaskToTIP(maps[target], result.getTaskID(), tts, true);
+      if (maxCacheLevel < NON_LOCAL_CACHE_LEVEL) {
+        resetSchedulingOpportunities();
+        // TODO(todd) double check this logic
+      }
     }
 
     return result;
@@ -1286,6 +1331,39 @@ public class JobInProgress {
     return obtainNewMapTask(tts, clusterSize, numUniqueHosts,
         NON_LOCAL_CACHE_LEVEL);
   }
+
+  public void schedulingOpportunity() {
+    ++numSchedulingOpportunities;
+  }
+  
+  public void resetSchedulingOpportunities() {
+    numSchedulingOpportunities = 0;
+  }
+  
+  public long getNumSchedulingOpportunities() {
+    return numSchedulingOpportunities;
+  }
+
+  private static final long OVERRIDE = 1000000;
+  public void overrideSchedulingOpportunities() {
+    numSchedulingOpportunities = OVERRIDE;
+  }
+  
+  /**
+   * Check if we can schedule an off-switch task for this job.
+   * 
+   * @return <code>true</code> if we can schedule off-switch, 
+   *         <code>false</code> otherwise
+   * We check the number of missed opportunities for the job. 
+   * If it has 'waited' long enough we go ahead and schedule.
+   */
+  public boolean scheduleOffSwitch(int numTaskTrackers) {
+    long missedTaskTrackers = getNumSchedulingOpportunities();
+    long requiredSlots = 
+      Math.min((desiredMaps() - finishedMaps()), numTaskTrackers);
+    
+    return (requiredSlots  * localityWaitFactor) < missedTaskTrackers;
+  }
   
   /**
    * Return a CleanupTask, if appropriate, to run on the given tasktracker
diff --git a/src/mapred/org/apache/hadoop/mapred/JobQueueJobInProgressListener.java b/src/mapred/org/apache/hadoop/mapred/JobQueueJobInProgressListener.java
index 621c50e..1196f12 100644
--- a/src/mapred/org/apache/hadoop/mapred/JobQueueJobInProgressListener.java
+++ b/src/mapred/org/apache/hadoop/mapred/JobQueueJobInProgressListener.java
@@ -54,6 +54,28 @@ class JobQueueJobInProgressListener extends JobInProgressListener {
     JobPriority getPriority() {return priority;}
     long getStartTime() {return startTime;}
     JobID getJobID() {return id;}
+    
+    @Override
+    public boolean equals(Object obj) {
+      if (obj == null || obj.getClass() != JobSchedulingInfo.class) {
+        return false;
+      } else if (obj == this) {
+        return true;
+      }
+      else if (obj instanceof JobSchedulingInfo) {
+        JobSchedulingInfo that = (JobSchedulingInfo)obj;
+        return (this.id.equals(that.id) && 
+                this.startTime == that.startTime && 
+                this.priority == that.priority);
+      }
+      return false;
+    }
+
+    @Override
+    public int hashCode() {
+      return (int)(id.hashCode() * priority.hashCode() + startTime);
+    }
+
   }
   
   static final Comparator<JobSchedulingInfo> FIFO_JOB_QUEUE_COMPARATOR
-- 
1.7.0.4

