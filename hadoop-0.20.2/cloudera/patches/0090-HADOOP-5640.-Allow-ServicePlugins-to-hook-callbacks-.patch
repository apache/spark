From c58318cfa6e26b7dbacd4093d646fc8b66f9eda6 Mon Sep 17 00:00:00 2001
From: Aaron Kimball <aaron@cloudera.com>
Date: Fri, 12 Mar 2010 14:58:23 -0800
Subject: [PATCH 0090/1179] HADOOP-5640. Allow ServicePlugins to hook callbacks into key service events

Description: <a href="http://issues.apache.org/jira/browse/HADOOP-5257" title="Export namenode/datanode functionality through a pluggable RPC layer"><del>HADOOP-5257</del></a> added the ability for NameNode and DataNode to start and stop ServicePlugin implementations at NN/DN start/stop. However, this is insufficient integration for some common use cases.

<p>We should add some functionality for Plugins to subscribe to events generated by the service they're plugging into. Some potential hook points are:</p>

<p>NameNode:</p>
<ul class="alternate" type="square">
	<li>new datanode registered</li>
	<li>datanode has died</li>
	<li>exception caught</li>
	<li>etc?</li>
</ul>

<p>DataNode:</p>
<ul class="alternate" type="square">
	<li>startup</li>
	<li>initial registration with NN complete (this is important for HADOOP-4707 to sync up datanode.dnRegistration.name with the NN-side registration)</li>
	<li>namenode reconnect</li>
	<li>some block transfer hooks?</li>
	<li>exception caught</li>
</ul>

<p>I see two potential routes for implementation:</p>

<p>1) We make an enum for the types of hookpoints and have a general function in the ServicePlugin interface. Something like:</p>

<div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent">
<pre class="code-java"><span class="code-keyword">enum</span> HookPoint {
  DN_STARTUP,
  DN_RECEIVED_NEW_BLOCK,
  DN_CAUGHT_EXCEPTION,
 ...
}

void runHook(HookPoint hp, <span class="code-object">Object</span> value);</pre>
</div></div>

<p>2) We make classes specific to each "pluggable" as was originally suggested in HADDOP-5257. Something like:</p>

<div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent">
<pre class="code-java">class DataNodePlugin {
  void datanodeStarted() {}
  void receivedNewBlock(block info, etc) {}
  void caughtException(Exception e) {}
  ...
}</pre>
</div></div>

<p>I personally prefer option (2) since we can ensure plugin API compatibility at compile-time, and we avoid an ugly switch statement in a runHook() function.</p>

<p>Interested to hear what people's thoughts are here.</p>
Reason: API Improvement
Author: Todd Lipcon
Ref: UNKNOWN
---
 .../org/apache/hadoop/util/PluginDispatcher.java   |  130 ++++++++++++++++++++
 src/core/org/apache/hadoop/util/ServicePlugin.java |    3 +
 .../apache/hadoop/util/SingleArgumentRunnable.java |   25 ++++
 .../hadoop/hdfs/server/datanode/DataNode.java      |   40 +++---
 .../hdfs/server/datanode/DatanodePlugin.java       |   49 ++++++++
 .../hadoop/hdfs/server/namenode/NameNode.java      |   26 ++---
 .../hdfs/server/namenode/NamenodePlugin.java       |   30 +++++
 .../apache/hadoop/util/TestPluginDispatcher.java   |  124 +++++++++++++++++++
 8 files changed, 388 insertions(+), 39 deletions(-)
 create mode 100644 src/core/org/apache/hadoop/util/PluginDispatcher.java
 create mode 100644 src/core/org/apache/hadoop/util/SingleArgumentRunnable.java
 create mode 100644 src/hdfs/org/apache/hadoop/hdfs/server/datanode/DatanodePlugin.java
 create mode 100644 src/hdfs/org/apache/hadoop/hdfs/server/namenode/NamenodePlugin.java
 create mode 100644 src/test/core/org/apache/hadoop/util/TestPluginDispatcher.java

diff --git a/src/core/org/apache/hadoop/util/PluginDispatcher.java b/src/core/org/apache/hadoop/util/PluginDispatcher.java
new file mode 100644
index 0000000..8dbe171
--- /dev/null
+++ b/src/core/org/apache/hadoop/util/PluginDispatcher.java
@@ -0,0 +1,130 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.util;
+
+import org.apache.commons.logging.*;
+
+import org.apache.hadoop.conf.Configuration;
+
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.List;
+import java.util.concurrent.Executor;
+import java.util.concurrent.Executors;
+
+/**
+ * Provides convenience functions for dispatching calls through
+ * to plugins registered with a class. Classes that wish to provide
+ * plugin interfaces should use this class to load the plugin list
+ * from the Configuration and to dispatch calls to the loaded instances.
+ *
+ * Calls dispatched through this class are performed on a second thread
+ * so as to not block execution of the plugged service.
+ */
+public class PluginDispatcher<T extends ServicePlugin> {
+  public static final Log LOG = LogFactory.getLog(PluginDispatcher.class.getName());
+
+  private final List<T> plugins;
+  private Executor executor;
+
+  /**
+   * Load a PluginDispatcher from the given Configuration. The start()
+   * callback will not be automatically called.
+   *
+   * @param conf the Configuration from which to load
+   * @param key the configuration key that lists class names to instantiate
+   * @param clazz the class or interface from which plugins must extend
+   */
+  public static <X extends ServicePlugin> PluginDispatcher<X> createFromConfiguration(
+    Configuration conf, String key, Class<X> clazz) {
+    List<X> plugins = conf.getInstances(key, clazz);
+    return new PluginDispatcher<X>(plugins);
+  }
+
+  PluginDispatcher(Collection<T> plugins) {
+    this.plugins = Collections.synchronizedList(new ArrayList<T>(plugins));
+    executor = Executors.newSingleThreadExecutor();
+  }
+
+  PluginDispatcher(Collection<T> plugins, Executor executor) {
+    this.plugins = Collections.synchronizedList(new ArrayList<T>(plugins));
+    this.executor = executor;
+  }
+
+  /**
+   * Dispatch a call to all active plugins.
+   *
+   * Exceptions will be caught and logged at WARN level.
+   *
+   * @param callback a function which will run once for each plugin, with
+   * that plugin as the argument
+   */
+  public void dispatchCall(final SingleArgumentRunnable<T> callback) {
+    executor.execute(new Runnable() {
+      public void run() {
+        for (T plugin : plugins) {
+          try {
+            callback.run(plugin);
+          } catch (Throwable t) {
+            LOG.warn("Uncaught exception dispatching to plugin " + plugin, t);
+          }
+        }
+      }});
+  }
+
+  /**
+   * Dispatches the start(...) hook common to all ServicePlugins. This
+   * also automatically removes any plugin that throws an exception while
+   * attempting to start.
+   *
+   * @param plugPoint passed to ServicePlugin.start()
+   */
+  public void dispatchStart(final Object plugPoint) {
+    dispatchCall(
+      new SingleArgumentRunnable<T>() {
+        public void run(T p) {
+          try {
+            p.start(plugPoint);
+          } catch (Throwable t) {
+            LOG.error("ServicePlugin " + p + " could not be started. " +
+                      "Removing from future callbacks.", t);
+            plugins.remove(p);
+          }
+        }
+      });
+  }
+
+  /**
+   * Convenience function for dispatching the stop() hook common to all
+   * ServicePlugins.
+   */
+  public void dispatchStop() {
+    dispatchCall(
+      new SingleArgumentRunnable<T>() {
+        public void run(T p) {
+          try {
+            p.stop();
+          } catch (Throwable t) {
+            LOG.warn("ServicePlugin " + p + " could not be stopped", t);
+          }
+        }
+      });
+  }
+}
diff --git a/src/core/org/apache/hadoop/util/ServicePlugin.java b/src/core/org/apache/hadoop/util/ServicePlugin.java
index a83294e..c2543be 100644
--- a/src/core/org/apache/hadoop/util/ServicePlugin.java
+++ b/src/core/org/apache/hadoop/util/ServicePlugin.java
@@ -35,6 +35,9 @@ public interface ServicePlugin extends Closeable {
   /**
    * This method is invoked when the service instance has been started.
    *
+   * If the plugin fails to initialize and throws an exception, the
+   * PluginDispatcher instance will log an error and remove the plugin.
+   *
    * @param service The service instance invoking this method
    */
   void start(Object service);
diff --git a/src/core/org/apache/hadoop/util/SingleArgumentRunnable.java b/src/core/org/apache/hadoop/util/SingleArgumentRunnable.java
new file mode 100644
index 0000000..0c5e445
--- /dev/null
+++ b/src/core/org/apache/hadoop/util/SingleArgumentRunnable.java
@@ -0,0 +1,25 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.util;
+
+/**
+ * Simple interface for a Runnable that takes a single argument.
+ */
+public interface SingleArgumentRunnable<T> {
+  public void run(T arg);
+}
\ No newline at end of file
diff --git a/src/hdfs/org/apache/hadoop/hdfs/server/datanode/DataNode.java b/src/hdfs/org/apache/hadoop/hdfs/server/datanode/DataNode.java
index 509427b..b571438 100644
--- a/src/hdfs/org/apache/hadoop/hdfs/server/datanode/DataNode.java
+++ b/src/hdfs/org/apache/hadoop/hdfs/server/datanode/DataNode.java
@@ -88,8 +88,10 @@ import org.apache.hadoop.security.authorize.PolicyProvider;
 import org.apache.hadoop.security.authorize.ServiceAuthorizationManager;
 import org.apache.hadoop.util.Daemon;
 import org.apache.hadoop.util.DiskChecker;
-import org.apache.hadoop.util.ServicePlugin;
+import org.apache.hadoop.util.PluginDispatcher;
 import org.apache.hadoop.util.ReflectionUtils;
+import org.apache.hadoop.util.ServicePlugin;
+import org.apache.hadoop.util.SingleArgumentRunnable;
 import org.apache.hadoop.util.StringUtils;
 import org.apache.hadoop.util.DiskChecker.DiskErrorException;
 import org.apache.hadoop.util.DiskChecker.DiskOutOfSpaceException;
@@ -192,7 +194,7 @@ public class DataNode extends Configured
   public Daemon blockScannerThread = null;
   
   /** Activated plug-ins. */
-  private List<ServicePlugin> plugins;
+  private PluginDispatcher<DatanodePlugin> pluginDispatcher;
   
   private static final Random R = new Random();
   
@@ -402,15 +404,9 @@ public class DataNode extends Configured
 
     LOG.info("dnRegistration = " + dnRegistration);
     
-    plugins = conf.getInstances("dfs.datanode.plugins", ServicePlugin.class);
-    for (ServicePlugin p: plugins) {
-      try {
-        p.start(this);
-        LOG.info("Started plug-in " + p);
-      } catch (Throwable t) {
-        LOG.warn("ServicePlugin " + p + " could not be started", t);
-      }
-    }
+    pluginDispatcher = PluginDispatcher.createFromConfiguration(
+      conf, "dfs.datanode.plugins", DatanodePlugin.class);
+    pluginDispatcher.dispatchStart(this);
   }
 
   /**
@@ -551,6 +547,7 @@ public class DataNode extends Configured
         } catch (InterruptedException ie) {}
       }
     }
+
     assert ("".equals(storage.getStorageID()) 
             && !"".equals(dnRegistration.getStorageID()))
             || storage.getStorageID().equals(dnRegistration.getStorageID()) :
@@ -578,17 +575,10 @@ public class DataNode extends Configured
    * Otherwise, deadlock might occur.
    */
   public void shutdown() {
-    if (plugins != null) {
-      for (ServicePlugin p : plugins) {
-        try {
-          p.stop();
-          LOG.info("Stopped plug-in " + p);
-        } catch (Throwable t) {
-          LOG.warn("ServicePlugin " + p + " could not be stopped", t);
-        }
-      }
+    if (pluginDispatcher != null) {
+      pluginDispatcher.dispatchStop();
     }
-    
+
     if (infoServer != null) {
       try {
         infoServer.stop();
@@ -906,6 +896,10 @@ public class DataNode extends Configured
       LOG.info("DatanodeCommand action: DNA_REGISTER");
       if (shouldRun) {
         register();
+        pluginDispatcher.dispatchCall(
+          new SingleArgumentRunnable<DatanodePlugin>() {
+            public void run(DatanodePlugin p) { p.reregistrationComplete(); }
+          });
       }
       break;
     case DatanodeProtocol.DNA_FINALIZE:
@@ -1231,6 +1225,10 @@ public class DataNode extends Configured
     if (dn != null) {
       //register datanode
       dn.register();
+      dn.pluginDispatcher.dispatchCall(
+        new SingleArgumentRunnable<DatanodePlugin>() {
+          public void run(DatanodePlugin p) { p.initialRegistrationComplete(); }
+        });
       dn.dataNodeThread = new Thread(dn, dnThreadName);
       dn.dataNodeThread.setDaemon(true); // needed for JUnit testing
       dn.dataNodeThread.start();
diff --git a/src/hdfs/org/apache/hadoop/hdfs/server/datanode/DatanodePlugin.java b/src/hdfs/org/apache/hadoop/hdfs/server/datanode/DatanodePlugin.java
new file mode 100644
index 0000000..feebd70
--- /dev/null
+++ b/src/hdfs/org/apache/hadoop/hdfs/server/datanode/DatanodePlugin.java
@@ -0,0 +1,49 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.hadoop.hdfs.server.datanode;
+
+import org.apache.hadoop.util.ServicePlugin;
+
+public abstract class DatanodePlugin implements ServicePlugin {
+
+  // ServicePlugin hooks
+
+  /** {@inheritDoc} */
+  public abstract void start(Object obj);
+
+  /** {@inheritDoc} */
+  public abstract void stop();
+
+  // Datanode specific hooks
+
+  /**
+   * The DataNode has registered itself with the NameNode during the initial
+   * startup sequence. This is called before the DataNode Thread has started
+   * running.
+   */
+  public void initialRegistrationComplete() {}
+
+  /**
+   * The DataNode has re-registered itself with the NameNode in response to a
+   * DNA_REGISTER event. This occurs when the NN has lost and regained contact
+   * with the DataNode.
+   */
+  public void reregistrationComplete() {}
+}
\ No newline at end of file
diff --git a/src/hdfs/org/apache/hadoop/hdfs/server/namenode/NameNode.java b/src/hdfs/org/apache/hadoop/hdfs/server/namenode/NameNode.java
index 925c1ca..bbd7a58 100644
--- a/src/hdfs/org/apache/hadoop/hdfs/server/namenode/NameNode.java
+++ b/src/hdfs/org/apache/hadoop/hdfs/server/namenode/NameNode.java
@@ -43,8 +43,9 @@ import org.apache.hadoop.hdfs.server.protocol.UpgradeCommand;
 import org.apache.hadoop.http.HttpServer;
 import org.apache.hadoop.ipc.*;
 import org.apache.hadoop.conf.*;
-import org.apache.hadoop.util.ServicePlugin;
+import org.apache.hadoop.util.PluginDispatcher;
 import org.apache.hadoop.util.ReflectionUtils;
+import org.apache.hadoop.util.ServicePlugin;
 import org.apache.hadoop.util.StringUtils;
 import org.apache.hadoop.net.NetUtils;
 import org.apache.hadoop.net.NetworkTopology;
@@ -138,7 +139,7 @@ public class NameNode implements ClientProtocol, DatanodeProtocol,
   /** Is service level authorization enabled? */
   private boolean serviceAuthEnabled = false;
   /** Activated plug-ins. */
-  private List<ServicePlugin> plugins;
+  private PluginDispatcher<NamenodePlugin> pluginDispatcher;
   
   /** Format a new filesystem.  Destroys any filesystem that may already
    * exist at this location.  **/
@@ -207,14 +208,9 @@ public class NameNode implements ClientProtocol, DatanodeProtocol,
     this.server.start();  //start RPC server   
     startTrashEmptier(conf);
     
-    plugins = conf.getInstances("dfs.namenode.plugins", ServicePlugin.class);
-    for (ServicePlugin p: plugins) {
-      try {
-        p.start(this);
-      } catch (Throwable t) {
-        LOG.warn("ServicePlugin " + p + " could not be started", t);
-      }
-    }
+    pluginDispatcher = PluginDispatcher.createFromConfiguration(
+      conf, "dfs.namenode.plugins", NamenodePlugin.class);
+    pluginDispatcher.dispatchStart(this);
   }
 
   private void startTrashEmptier(Configuration conf) throws IOException {
@@ -314,14 +310,8 @@ public class NameNode implements ClientProtocol, DatanodeProtocol,
     if (stopRequested)
       return;
     stopRequested = true;
-    if (plugins != null) {
-      for (ServicePlugin p : plugins) {
-        try {
-          p.stop();
-        } catch (Throwable t) {
-          LOG.warn("ServicePlugin " + p + " could not be stopped", t);
-        }
-      }
+    if (pluginDispatcher != null) {
+      pluginDispatcher.dispatchStop();
     }
     try {
       if (httpServer != null) httpServer.stop();
diff --git a/src/hdfs/org/apache/hadoop/hdfs/server/namenode/NamenodePlugin.java b/src/hdfs/org/apache/hadoop/hdfs/server/namenode/NamenodePlugin.java
new file mode 100644
index 0000000..f6c6d87
--- /dev/null
+++ b/src/hdfs/org/apache/hadoop/hdfs/server/namenode/NamenodePlugin.java
@@ -0,0 +1,30 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hdfs.server.namenode;
+
+import org.apache.hadoop.util.ServicePlugin;
+
+public abstract class NamenodePlugin implements ServicePlugin {
+  // ServicePlugin hooks
+
+  /** {@inheritDoc} */
+  public abstract void start(Object obj);
+
+  /** {@inheritDoc} */
+  public abstract void stop();
+}
\ No newline at end of file
diff --git a/src/test/core/org/apache/hadoop/util/TestPluginDispatcher.java b/src/test/core/org/apache/hadoop/util/TestPluginDispatcher.java
new file mode 100644
index 0000000..474c9af
--- /dev/null
+++ b/src/test/core/org/apache/hadoop/util/TestPluginDispatcher.java
@@ -0,0 +1,124 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.util;
+
+
+import java.util.Arrays;
+import java.util.List;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.Executor;
+
+import junit.framework.TestCase;
+
+public class TestPluginDispatcher extends TestCase {
+
+  /**
+   * Ensure that dispatch works in general
+   */
+  public void testDispatch() {
+    AtomicInteger runCount = new AtomicInteger(0);
+
+    List<TestPlugin> plugins = Arrays.asList(
+      new TestPlugin[] {
+        new TestPlugin(runCount)
+      });
+
+    PluginDispatcher<TestPlugin> dispatcher =
+      new PluginDispatcher<TestPlugin>(plugins, new SameThreadExecutor());
+
+    dispatcher.dispatchCall(new RunMethodRunner());
+    assertEquals(runCount.get(), 1);
+  }
+
+  /**
+   * Ensure that, if a plugin is faulty during startup, it is removed
+   * from the plugin dispatcher.
+   */
+  public void testRemovalOnStartError() {
+    AtomicInteger runCount = new AtomicInteger(0);
+
+    List<TestPlugin> plugins = Arrays.asList(
+      new TestPlugin[] {
+        new TestPlugin(runCount),
+        new FaultyPlugin(runCount),
+        new TestPlugin(runCount)
+      });
+
+    PluginDispatcher<TestPlugin> dispatcher =
+      new PluginDispatcher<TestPlugin>(plugins, new SameThreadExecutor());
+
+    // Before we start the plugins, we can dispatch a call
+    // and it goes to all 3 plugins
+    dispatcher.dispatchCall(new RunMethodRunner());
+    assertEquals(runCount.get(), 3);
+
+    // When we dispatch the start, it should kill the faulty plugin
+    runCount.set(0);
+    dispatcher.dispatchStart(this);
+    dispatcher.dispatchCall(new RunMethodRunner());
+    assertEquals(runCount.get(), 2);
+  }
+
+  /**
+   * SingleArgumentRunnable that just calls plugin.run()
+   */
+  static class RunMethodRunner implements SingleArgumentRunnable<TestPlugin> {
+    public void run(TestPlugin p) {
+      p.run();
+    }
+  }
+
+  /**
+   * Plugin which increments a counter when its run method is called.
+   */
+  public static class TestPlugin implements ServicePlugin {
+    final AtomicInteger ai;
+
+    public TestPlugin(AtomicInteger ai) {
+      this.ai = ai;
+    }
+    public void start(Object service) {}
+    public void stop() {}
+    public void close() {}
+    public void run() {
+      ai.getAndIncrement();
+    }
+  }
+
+  /**
+   * Plugin which throws a RuntimeException on start.
+   */
+  public static class FaultyPlugin extends TestPlugin {
+    public FaultyPlugin(AtomicInteger ai) {
+      super(ai);
+    }
+    public void start(Object service) {
+      throw new RuntimeException("Kaboom!");
+    }
+  }
+
+  /**
+   * Executor which runs Runnables in the same thread that submits them.
+   */
+  public static class SameThreadExecutor implements Executor {
+    public void execute(Runnable r) {
+      r.run();
+    }
+  }
+}
\ No newline at end of file
-- 
1.7.0.4

